reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124985162-172.17.0.15-1598485748913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0cb10620-be32-4d57-b84f-e530aee4df00,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-9f8771e8-6afa-433e-9d4a-acfd0625123c,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-261f0982-08b2-4706-9aab-3cab1f650158,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-6b4f116c-1fc8-4f0c-b4a3-7972ef3e902f,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-8599ec7b-d3f8-4f20-b330-712fd6b082d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ac1f9676-1be8-4e25-a493-1b0bde6d276e,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-e8c71cda-1692-4a32-a360-1728c95999f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-aa245c13-9536-4b43-bc25-f296f9d08f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124985162-172.17.0.15-1598485748913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0cb10620-be32-4d57-b84f-e530aee4df00,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-9f8771e8-6afa-433e-9d4a-acfd0625123c,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-261f0982-08b2-4706-9aab-3cab1f650158,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-6b4f116c-1fc8-4f0c-b4a3-7972ef3e902f,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-8599ec7b-d3f8-4f20-b330-712fd6b082d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ac1f9676-1be8-4e25-a493-1b0bde6d276e,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-e8c71cda-1692-4a32-a360-1728c95999f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-aa245c13-9536-4b43-bc25-f296f9d08f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287269697-172.17.0.15-1598485859858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-6040f321-68c1-46c4-9e33-16d70d1686ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-3624fbc2-81ee-4227-914f-2d3706c74195,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f031df8d-f3d0-4e34-982d-7f75d6b3133d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-8b32948b-5846-4fec-ab0e-75261f4c61d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-c2a5b00d-0fc6-44a4-8416-a054ccba92e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-459bd4f8-1140-4722-9797-f584ab5e464d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ff16d5a4-0bda-44a3-b97d-90a6f9293aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-cb7fd389-e45c-41b5-91c4-608a135b67f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287269697-172.17.0.15-1598485859858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-6040f321-68c1-46c4-9e33-16d70d1686ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-3624fbc2-81ee-4227-914f-2d3706c74195,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-f031df8d-f3d0-4e34-982d-7f75d6b3133d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-8b32948b-5846-4fec-ab0e-75261f4c61d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-c2a5b00d-0fc6-44a4-8416-a054ccba92e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-459bd4f8-1140-4722-9797-f584ab5e464d,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ff16d5a4-0bda-44a3-b97d-90a6f9293aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-cb7fd389-e45c-41b5-91c4-608a135b67f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079704697-172.17.0.15-1598485960575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-150be383-6e26-40fe-a0fe-d11158d63409,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-285867f7-1af4-473f-ad9c-973664bbdd56,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ad3917a5-d1f2-4cab-8df4-d6ed495b124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-6a86ce5c-2524-4c3c-8ade-268e1dc7ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-df2a86ae-1e85-47e7-8e56-c823f54fa513,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e714924-1ac2-4dd3-9451-af4e7f919fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f816675a-b694-4063-b4ba-fc133c2ee8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-c1461a6e-b6c1-450f-8f61-b62b18339476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079704697-172.17.0.15-1598485960575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-150be383-6e26-40fe-a0fe-d11158d63409,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-285867f7-1af4-473f-ad9c-973664bbdd56,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-ad3917a5-d1f2-4cab-8df4-d6ed495b124f,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-6a86ce5c-2524-4c3c-8ade-268e1dc7ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-df2a86ae-1e85-47e7-8e56-c823f54fa513,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e714924-1ac2-4dd3-9451-af4e7f919fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-f816675a-b694-4063-b4ba-fc133c2ee8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-c1461a6e-b6c1-450f-8f61-b62b18339476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565550200-172.17.0.15-1598486091690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-79e917a5-f4a6-4ceb-be89-3df0964e0879,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4d9fb580-0da9-4539-86d2-39330784cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3d5106e2-0d7a-454a-8fe8-243680fc886f,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-e909755c-6930-4f85-a1f5-81938db2b725,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-a5ffeb57-3218-4093-8ae1-5584cdfd979b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-7b99c7b7-2631-4daf-8d48-beeef18e47f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-6f63e69c-6f44-4399-acab-6bf09581a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-02f7fb9f-d4a8-42c2-9467-43fec3790773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565550200-172.17.0.15-1598486091690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-79e917a5-f4a6-4ceb-be89-3df0964e0879,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-4d9fb580-0da9-4539-86d2-39330784cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3d5106e2-0d7a-454a-8fe8-243680fc886f,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-e909755c-6930-4f85-a1f5-81938db2b725,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-a5ffeb57-3218-4093-8ae1-5584cdfd979b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-7b99c7b7-2631-4daf-8d48-beeef18e47f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-6f63e69c-6f44-4399-acab-6bf09581a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-02f7fb9f-d4a8-42c2-9467-43fec3790773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775329258-172.17.0.15-1598486430484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-4c479f9a-c013-4f22-bdba-11d2e2a11b48,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-27e34edd-ec9b-4b85-9510-fb6ef7fe258b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-5b7bfc80-2745-4d15-9d6e-50878a18a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-ade9f41c-b318-4417-b16a-6ea182e5e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-10f10758-eb5c-449f-a596-8192d11493c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-218abc58-85f3-4bfd-acf6-41539c231694,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-36376d72-b2cc-4a36-952e-cde5a8d4472b,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-b52b54be-ebd2-4db8-b762-64bd864c2773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775329258-172.17.0.15-1598486430484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37305,DS-4c479f9a-c013-4f22-bdba-11d2e2a11b48,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-27e34edd-ec9b-4b85-9510-fb6ef7fe258b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-5b7bfc80-2745-4d15-9d6e-50878a18a78e,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-ade9f41c-b318-4417-b16a-6ea182e5e39c,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-10f10758-eb5c-449f-a596-8192d11493c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-218abc58-85f3-4bfd-acf6-41539c231694,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-36376d72-b2cc-4a36-952e-cde5a8d4472b,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-b52b54be-ebd2-4db8-b762-64bd864c2773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745811393-172.17.0.15-1598486504896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-53c4d82c-2112-4ed6-9dfe-e066e85929bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-f69282ea-f30b-4f67-b703-d9bb62da3c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-f0e09172-1e1a-4219-8aca-eaaa31d27908,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-e583848b-9935-4637-97bb-8edf3bc808ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b4ca3739-fd9f-4694-ac1f-05313c702073,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-24f63b69-e37a-4eb0-a6f2-5971467b455a,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-f517ffed-59d8-4d3b-ac3a-55e8de9ba18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-bcf2d4c0-e712-4440-9d2a-ef60fde199ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745811393-172.17.0.15-1598486504896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-53c4d82c-2112-4ed6-9dfe-e066e85929bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-f69282ea-f30b-4f67-b703-d9bb62da3c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-f0e09172-1e1a-4219-8aca-eaaa31d27908,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-e583848b-9935-4637-97bb-8edf3bc808ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b4ca3739-fd9f-4694-ac1f-05313c702073,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-24f63b69-e37a-4eb0-a6f2-5971467b455a,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-f517ffed-59d8-4d3b-ac3a-55e8de9ba18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-bcf2d4c0-e712-4440-9d2a-ef60fde199ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175208204-172.17.0.15-1598486689972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-a8e21d71-d817-43c9-8e46-6cd683111612,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-acd4b841-6040-4103-af61-e0e34a1e525e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-44eff9c5-de69-4081-a9e7-b7622d21326f,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-756b34a0-e0bb-400c-ae8d-f91e00bbb538,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-03dfd47d-3545-44e3-ac2b-3f59b784b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-f25446aa-9cdf-4b87-9548-1c5a18a66115,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-93005718-df83-4944-8388-ec5da7482af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-32cc4004-7831-4851-a84c-f2a9c886f0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175208204-172.17.0.15-1598486689972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-a8e21d71-d817-43c9-8e46-6cd683111612,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-acd4b841-6040-4103-af61-e0e34a1e525e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-44eff9c5-de69-4081-a9e7-b7622d21326f,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-756b34a0-e0bb-400c-ae8d-f91e00bbb538,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-03dfd47d-3545-44e3-ac2b-3f59b784b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-f25446aa-9cdf-4b87-9548-1c5a18a66115,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-93005718-df83-4944-8388-ec5da7482af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-32cc4004-7831-4851-a84c-f2a9c886f0db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931878681-172.17.0.15-1598486791772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-d0399c12-16cb-4ea4-98d6-83b56aecac02,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-557b101e-0a85-46f3-917a-d94194b5cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-64579655-20d0-437a-81e8-286793c5219f,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-2b76e22c-92d9-458e-81bd-4bf2cb5e01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6a33917e-26ad-455a-8987-31de310becb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-18f3cbf8-3e97-45da-9550-b5f79a8888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-8885ca29-09b5-4930-92e8-dfb3ddc4be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-64e72592-8a9f-4f05-9ce5-22784083bde5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931878681-172.17.0.15-1598486791772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-d0399c12-16cb-4ea4-98d6-83b56aecac02,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-557b101e-0a85-46f3-917a-d94194b5cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-64579655-20d0-437a-81e8-286793c5219f,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-2b76e22c-92d9-458e-81bd-4bf2cb5e01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6a33917e-26ad-455a-8987-31de310becb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-18f3cbf8-3e97-45da-9550-b5f79a8888e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-8885ca29-09b5-4930-92e8-dfb3ddc4be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-64e72592-8a9f-4f05-9ce5-22784083bde5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953403794-172.17.0.15-1598486818935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-703fece2-de75-46a5-9ad0-df49937c59b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-31ebc6e7-fd59-4633-8b74-a07362eff954,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-11bc1ea5-ab8e-440d-bfbd-a8b337b02ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-62243140-bbb9-4008-8b7b-73dcbe1cc5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-9973f889-3e11-4548-a74d-51972f73c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-44e54ff1-2589-4d60-bbf9-af656d37524f,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-180c7213-1fe3-4261-bac2-4f374e71d795,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-1d1eec7b-de02-46c4-92da-e4d2a4944b81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953403794-172.17.0.15-1598486818935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-703fece2-de75-46a5-9ad0-df49937c59b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-31ebc6e7-fd59-4633-8b74-a07362eff954,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-11bc1ea5-ab8e-440d-bfbd-a8b337b02ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-62243140-bbb9-4008-8b7b-73dcbe1cc5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-9973f889-3e11-4548-a74d-51972f73c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-44e54ff1-2589-4d60-bbf9-af656d37524f,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-180c7213-1fe3-4261-bac2-4f374e71d795,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-1d1eec7b-de02-46c4-92da-e4d2a4944b81,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400697409-172.17.0.15-1598486886153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-aa2004a1-4db8-4199-a4bc-805fa03d67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-57f835d6-478c-44e5-bd36-6ae4f01ab7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-c4ad67b3-c2bd-4fd0-80cd-fa3d61a72677,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-64dac66c-32a4-4985-8c5e-7b9a4f445669,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-172e8b0a-cb4d-4e70-be66-c1f4c09efc52,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3ce8a397-1d4f-400c-a32f-108b16328490,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-8c1ea477-fe4e-42ca-8031-24b1d325a391,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f5a7ea7e-7853-41b6-81ca-187a899c37ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400697409-172.17.0.15-1598486886153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-aa2004a1-4db8-4199-a4bc-805fa03d67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-57f835d6-478c-44e5-bd36-6ae4f01ab7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-c4ad67b3-c2bd-4fd0-80cd-fa3d61a72677,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-64dac66c-32a4-4985-8c5e-7b9a4f445669,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-172e8b0a-cb4d-4e70-be66-c1f4c09efc52,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3ce8a397-1d4f-400c-a32f-108b16328490,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-8c1ea477-fe4e-42ca-8031-24b1d325a391,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f5a7ea7e-7853-41b6-81ca-187a899c37ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546994087-172.17.0.15-1598487089837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-50fea129-f312-4eb5-ad82-2421228200ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-4e16f651-38da-46f0-af89-dad469f72f57,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-ac35c550-fedb-4371-8cd9-3d1ee315ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c33c3d49-8004-4b01-bf4b-2a84ba9547ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-582de4e3-0494-459f-befe-34bd8b297e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-c38fe8a5-26b4-4e72-8585-57e55aa3586f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5666f5bd-ac8f-4be7-a1cd-aa2d04f6c163,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a843b08f-a89d-49ef-b763-a6721f8f6fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546994087-172.17.0.15-1598487089837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-50fea129-f312-4eb5-ad82-2421228200ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-4e16f651-38da-46f0-af89-dad469f72f57,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-ac35c550-fedb-4371-8cd9-3d1ee315ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c33c3d49-8004-4b01-bf4b-2a84ba9547ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-582de4e3-0494-459f-befe-34bd8b297e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-c38fe8a5-26b4-4e72-8585-57e55aa3586f,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-5666f5bd-ac8f-4be7-a1cd-aa2d04f6c163,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a843b08f-a89d-49ef-b763-a6721f8f6fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724208005-172.17.0.15-1598487125046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-e022bb41-31d1-4fb2-aaf8-31d1ead26a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-32e64f04-77b7-4a09-b612-7e006a2ca53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-f53da73e-06e2-4234-a27e-edfff194140e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-27bc3b36-c37f-4219-8008-bbb6f7a4af36,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-f40886c5-2f55-4f52-923b-e993cdd92161,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2ea05304-8c80-4768-ba04-a7c486ba8157,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-2bb48846-3fc5-4cf1-9f81-0022d7b8c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-ca2c8430-4c4b-4a96-93dd-91d090993a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724208005-172.17.0.15-1598487125046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-e022bb41-31d1-4fb2-aaf8-31d1ead26a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-32e64f04-77b7-4a09-b612-7e006a2ca53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-f53da73e-06e2-4234-a27e-edfff194140e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-27bc3b36-c37f-4219-8008-bbb6f7a4af36,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-f40886c5-2f55-4f52-923b-e993cdd92161,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2ea05304-8c80-4768-ba04-a7c486ba8157,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-2bb48846-3fc5-4cf1-9f81-0022d7b8c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-ca2c8430-4c4b-4a96-93dd-91d090993a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342463961-172.17.0.15-1598487535374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-b5bed8a2-eaa8-488b-84e1-ba50c7ffbac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-eb65c5c6-1bde-4254-929b-e689390df971,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-4c159ef2-bacc-4359-903b-048a35fcb362,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1d8948c1-9a1c-4f8b-a672-6b819a9e872c,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-208c2b73-df3a-4a18-956b-3d47f3a7b402,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-565d36ae-c67d-4160-9ee0-376cfdd9a2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f1b62bfa-93b4-4245-a78b-737a9696a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ccf0b1c1-ab98-4869-9703-d4db4d7e33b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342463961-172.17.0.15-1598487535374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-b5bed8a2-eaa8-488b-84e1-ba50c7ffbac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-eb65c5c6-1bde-4254-929b-e689390df971,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-4c159ef2-bacc-4359-903b-048a35fcb362,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-1d8948c1-9a1c-4f8b-a672-6b819a9e872c,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-208c2b73-df3a-4a18-956b-3d47f3a7b402,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-565d36ae-c67d-4160-9ee0-376cfdd9a2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-f1b62bfa-93b4-4245-a78b-737a9696a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ccf0b1c1-ab98-4869-9703-d4db4d7e33b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617673695-172.17.0.15-1598487570966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-fa4820de-f544-4a9a-b560-a2e273452dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-86b8e497-3cb7-4468-9fd3-6c43d9d9bc67,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-3a6efd99-d6ce-402c-9bbf-9c35e4ddb4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-049c59a9-b622-471d-a84e-f39dd1da1063,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-ee93a9ce-959e-4229-a9d4-3b246a48483b,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-5e97b66e-da7e-473f-8673-bc167be0f291,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-7f7a4805-544e-4a26-99b3-ade4bfe1a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-55e55a53-4aee-4f4b-bd4e-99a22ac24865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617673695-172.17.0.15-1598487570966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-fa4820de-f544-4a9a-b560-a2e273452dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-86b8e497-3cb7-4468-9fd3-6c43d9d9bc67,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-3a6efd99-d6ce-402c-9bbf-9c35e4ddb4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-049c59a9-b622-471d-a84e-f39dd1da1063,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-ee93a9ce-959e-4229-a9d4-3b246a48483b,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-5e97b66e-da7e-473f-8673-bc167be0f291,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-7f7a4805-544e-4a26-99b3-ade4bfe1a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-55e55a53-4aee-4f4b-bd4e-99a22ac24865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614776470-172.17.0.15-1598487609984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-edb2cdc9-9ce4-4ce2-858d-fc73201e753c,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-108a81f4-0a51-40dd-9af6-f74c3fd0c48e,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-fbce7b36-a34f-4835-bda9-49e402a43537,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-531b6c9f-7e8b-4fcf-8b67-8af4c46585aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-87fcbc7e-5310-4dd2-be12-5c1584da8956,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4cd562d1-de69-4691-9006-02319d88965f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-7e166982-e920-4104-a966-4416510d09b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-0b370067-2645-42fb-8a86-a7f334537349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614776470-172.17.0.15-1598487609984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-edb2cdc9-9ce4-4ce2-858d-fc73201e753c,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-108a81f4-0a51-40dd-9af6-f74c3fd0c48e,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-fbce7b36-a34f-4835-bda9-49e402a43537,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-531b6c9f-7e8b-4fcf-8b67-8af4c46585aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-87fcbc7e-5310-4dd2-be12-5c1584da8956,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4cd562d1-de69-4691-9006-02319d88965f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-7e166982-e920-4104-a966-4416510d09b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-0b370067-2645-42fb-8a86-a7f334537349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073025224-172.17.0.15-1598487678933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-95933d23-4ead-4996-a746-13b073fe8009,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-a28bffcc-0761-49fc-802c-7cd54380e37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-8edd9e4a-c156-4fa1-b415-8c6c827b47a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-f0efc8cd-047b-466d-bcc1-a0ba2ce14003,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-133499b9-2ae3-461b-9d61-d1c0164df160,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-45de84ae-3e36-4666-aedf-2f337b4c2442,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-bb44f1d7-f7c5-4267-9413-092a29fee999,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-dd79b592-0f58-4a06-ad1c-67d42fcc838b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073025224-172.17.0.15-1598487678933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-95933d23-4ead-4996-a746-13b073fe8009,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-a28bffcc-0761-49fc-802c-7cd54380e37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-8edd9e4a-c156-4fa1-b415-8c6c827b47a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-f0efc8cd-047b-466d-bcc1-a0ba2ce14003,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-133499b9-2ae3-461b-9d61-d1c0164df160,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-45de84ae-3e36-4666-aedf-2f337b4c2442,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-bb44f1d7-f7c5-4267-9413-092a29fee999,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-dd79b592-0f58-4a06-ad1c-67d42fcc838b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777327807-172.17.0.15-1598487813017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-be2b1a0e-9bf3-4758-9ff7-a5838c7aaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-40c293ee-6034-40f4-b0a5-6cc5fddadbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ba2306d8-f634-4ae8-bd0d-d54fd9f96f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-9e21f5ed-dc54-4f2a-b783-c1154768dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-81bb5cf5-3472-4736-866e-5057da73e5af,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-67617589-c1d9-41e8-8349-47cdc406fade,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-dad913b3-37a7-4d4a-bcef-a63177e66c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-54ad0f8d-6351-4cfe-a0fd-d860e2b1036d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777327807-172.17.0.15-1598487813017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38869,DS-be2b1a0e-9bf3-4758-9ff7-a5838c7aaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-40c293ee-6034-40f4-b0a5-6cc5fddadbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ba2306d8-f634-4ae8-bd0d-d54fd9f96f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-9e21f5ed-dc54-4f2a-b783-c1154768dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-81bb5cf5-3472-4736-866e-5057da73e5af,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-67617589-c1d9-41e8-8349-47cdc406fade,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-dad913b3-37a7-4d4a-bcef-a63177e66c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-54ad0f8d-6351-4cfe-a0fd-d860e2b1036d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275055283-172.17.0.15-1598488079114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-0d578e8c-31eb-4623-8cda-9cfedf67c273,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-2c2a2d6c-6e7f-4673-9d7e-f881f30c42be,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b4bf3936-11f9-458c-8af9-ecf1a5c9ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-9b103ad5-01fb-43c1-86ad-1bab71a5a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-781b9fba-85a1-485e-ac9c-68b4ee0dde1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-3128801f-2129-4312-9093-f4bb2e43b195,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-142ad488-daf8-436f-bf97-198f7873fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-3570e7d6-769c-4587-9450-807ceb635128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275055283-172.17.0.15-1598488079114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-0d578e8c-31eb-4623-8cda-9cfedf67c273,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-2c2a2d6c-6e7f-4673-9d7e-f881f30c42be,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b4bf3936-11f9-458c-8af9-ecf1a5c9ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-9b103ad5-01fb-43c1-86ad-1bab71a5a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-781b9fba-85a1-485e-ac9c-68b4ee0dde1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-3128801f-2129-4312-9093-f4bb2e43b195,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-142ad488-daf8-436f-bf97-198f7873fe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-3570e7d6-769c-4587-9450-807ceb635128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542514482-172.17.0.15-1598488150872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-8742c1f0-582c-47c2-accd-9bfcb8a86375,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-98434870-9415-4beb-8d6c-34db0b3d96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8acb6e29-1115-43f6-96a0-ef04a5f21f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7de04c42-3afe-483f-bae0-7347de348279,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-feb2af9f-4384-47b8-bf33-2b163f304b99,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-219deb1a-f6a2-4040-b5a3-48884d64570e,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-32586e3d-de50-47e5-a80d-d715a25eba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-3bf59810-8be5-47cb-b89e-ae158c41d011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542514482-172.17.0.15-1598488150872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45095,DS-8742c1f0-582c-47c2-accd-9bfcb8a86375,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-98434870-9415-4beb-8d6c-34db0b3d96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8acb6e29-1115-43f6-96a0-ef04a5f21f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-7de04c42-3afe-483f-bae0-7347de348279,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-feb2af9f-4384-47b8-bf33-2b163f304b99,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-219deb1a-f6a2-4040-b5a3-48884d64570e,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-32586e3d-de50-47e5-a80d-d715a25eba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-3bf59810-8be5-47cb-b89e-ae158c41d011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944987724-172.17.0.15-1598488257831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-9cbbab13-7487-449a-b544-f379d114176d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-f70e06c3-1d39-4875-b6b4-c0e86dc8f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-257a929c-ef50-4007-891b-026b61603911,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-ef32b5f2-81ca-4f29-ace8-33128de75a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-97b59de3-2f3e-472a-9f50-8862bc640705,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-22f89781-422c-47ef-9e1c-5004b844e005,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-d9c55a79-f05b-4981-8c45-5c995709187b,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-167474dd-2de9-4d8b-bc77-928c9fdc0efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944987724-172.17.0.15-1598488257831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-9cbbab13-7487-449a-b544-f379d114176d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-f70e06c3-1d39-4875-b6b4-c0e86dc8f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-257a929c-ef50-4007-891b-026b61603911,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-ef32b5f2-81ca-4f29-ace8-33128de75a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-97b59de3-2f3e-472a-9f50-8862bc640705,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-22f89781-422c-47ef-9e1c-5004b844e005,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-d9c55a79-f05b-4981-8c45-5c995709187b,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-167474dd-2de9-4d8b-bc77-928c9fdc0efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131768470-172.17.0.15-1598488488118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-e3e39e0a-e307-490d-bb79-74c4ed79ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8fd0cd95-baa5-49e9-bffe-780ed6ad4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-e370e16c-a901-404a-9dac-4134da9df6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b16e40c6-ae9f-4aef-aa3e-d050fb9c1936,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-21d4064b-95e3-4d87-b2d8-08da249b3ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-a5e2e062-5108-4f74-ba37-1214f50a64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-e5e18cbd-8c43-42e7-9ab8-6303a2ec1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a841fb34-39af-4faa-bb6a-fe16011a7c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131768470-172.17.0.15-1598488488118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-e3e39e0a-e307-490d-bb79-74c4ed79ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-8fd0cd95-baa5-49e9-bffe-780ed6ad4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-e370e16c-a901-404a-9dac-4134da9df6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-b16e40c6-ae9f-4aef-aa3e-d050fb9c1936,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-21d4064b-95e3-4d87-b2d8-08da249b3ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-a5e2e062-5108-4f74-ba37-1214f50a64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-e5e18cbd-8c43-42e7-9ab8-6303a2ec1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a841fb34-39af-4faa-bb6a-fe16011a7c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570124431-172.17.0.15-1598488525254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-f73109dc-c7b5-43fc-9479-d4ccf6d33a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-488177fa-153e-4d21-81d5-1b2a332373ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-e5091c99-e615-4540-9181-6b11c64846c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0b78fda4-b6cf-43b1-a6d8-817de42b5763,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-264d42ef-bec9-4753-8f6d-ad68da88bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-74b96eac-58ac-4f44-8d66-5edc3c24f324,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-78f25001-eeae-4da8-aaae-5c872e4c04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-0b68d902-9bbe-4e7e-b80a-abad0b0914c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570124431-172.17.0.15-1598488525254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-f73109dc-c7b5-43fc-9479-d4ccf6d33a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-488177fa-153e-4d21-81d5-1b2a332373ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-e5091c99-e615-4540-9181-6b11c64846c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0b78fda4-b6cf-43b1-a6d8-817de42b5763,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-264d42ef-bec9-4753-8f6d-ad68da88bc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-74b96eac-58ac-4f44-8d66-5edc3c24f324,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-78f25001-eeae-4da8-aaae-5c872e4c04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-0b68d902-9bbe-4e7e-b80a-abad0b0914c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13421049-172.17.0.15-1598488663239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-0e438d19-7f89-4cac-aca9-f523641067cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-27a0adff-6381-4bcd-ac61-fee21f643037,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-f425b4a7-cc1b-4d2f-84cf-0689fe13483f,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4288afab-91d0-4753-b083-0c53fc725793,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-a2d9f0c2-e11c-4c0a-90b4-b4d9ed3a2615,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-bc342929-91c3-45f8-bc97-8d75636ce077,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-5f933790-5036-4248-a3de-0d03c85c1b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-61d417d8-9969-4907-85e4-86f051a3fffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13421049-172.17.0.15-1598488663239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-0e438d19-7f89-4cac-aca9-f523641067cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-27a0adff-6381-4bcd-ac61-fee21f643037,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-f425b4a7-cc1b-4d2f-84cf-0689fe13483f,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4288afab-91d0-4753-b083-0c53fc725793,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-a2d9f0c2-e11c-4c0a-90b4-b4d9ed3a2615,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-bc342929-91c3-45f8-bc97-8d75636ce077,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-5f933790-5036-4248-a3de-0d03c85c1b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-61d417d8-9969-4907-85e4-86f051a3fffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133436100-172.17.0.15-1598488699692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-004e1a5c-432d-4469-9276-baef7f51831f,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-3c7dde14-ff56-4a92-8787-41cf321b7ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-5e70236b-ebaa-47b1-93ca-f2ad558124b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-f40fb19a-a08c-454d-84f2-41bdd9eb6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-4fad2596-c68f-4c20-8726-36ebabb6a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-81c1b1e1-28f8-4b72-8a01-ab616c4e020d,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-4c402f77-afc8-496c-bbfe-09bd5568e377,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b893fe82-3e56-406a-8d14-5e769e4d5e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133436100-172.17.0.15-1598488699692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-004e1a5c-432d-4469-9276-baef7f51831f,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-3c7dde14-ff56-4a92-8787-41cf321b7ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-5e70236b-ebaa-47b1-93ca-f2ad558124b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-f40fb19a-a08c-454d-84f2-41bdd9eb6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-4fad2596-c68f-4c20-8726-36ebabb6a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-81c1b1e1-28f8-4b72-8a01-ab616c4e020d,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-4c402f77-afc8-496c-bbfe-09bd5568e377,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-b893fe82-3e56-406a-8d14-5e769e4d5e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671368675-172.17.0.15-1598488775373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38851,DS-d48c6129-b057-4571-9903-02c797758171,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1939e84b-3008-467f-98a6-47feb7f3010e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-f8c9f632-8517-4614-806a-2b530274006b,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-1d018481-4b9a-40f7-a760-9d9bb7bbc434,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-ad666f6b-fabc-47a1-b07c-b23f92023e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-bb50bf47-79f4-4c18-9d19-62672f108531,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-874fcf3a-1921-458d-ad06-6ea85268b94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e0c4ac51-9853-4614-8a80-f766c3a374c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671368675-172.17.0.15-1598488775373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38851,DS-d48c6129-b057-4571-9903-02c797758171,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1939e84b-3008-467f-98a6-47feb7f3010e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-f8c9f632-8517-4614-806a-2b530274006b,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-1d018481-4b9a-40f7-a760-9d9bb7bbc434,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-ad666f6b-fabc-47a1-b07c-b23f92023e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-bb50bf47-79f4-4c18-9d19-62672f108531,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-874fcf3a-1921-458d-ad06-6ea85268b94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-e0c4ac51-9853-4614-8a80-f766c3a374c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948784311-172.17.0.15-1598488812192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-bbbd249c-0b03-48fb-b2c9-16e2a1752c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-aee75301-4533-4ec9-a1b8-46e42c22146b,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-5d164d62-56bf-462c-a427-27a897c8eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-d93e88b2-7da8-4072-95f2-f82510e09a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-042f8bb1-ddbb-473f-865e-7e52b5168e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-561cf788-e414-45b3-85d0-66d2ee98ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-0d500996-7559-4b55-96c9-d5057709fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-a5a9cc49-49ff-4099-93af-3cabb207baf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948784311-172.17.0.15-1598488812192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-bbbd249c-0b03-48fb-b2c9-16e2a1752c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-aee75301-4533-4ec9-a1b8-46e42c22146b,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-5d164d62-56bf-462c-a427-27a897c8eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-d93e88b2-7da8-4072-95f2-f82510e09a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-042f8bb1-ddbb-473f-865e-7e52b5168e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-561cf788-e414-45b3-85d0-66d2ee98ba0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-0d500996-7559-4b55-96c9-d5057709fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-a5a9cc49-49ff-4099-93af-3cabb207baf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996727410-172.17.0.15-1598488845922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33370,DS-ac0091e5-b356-4c12-b91c-427cb3e8d469,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1f7d25d9-5955-48f9-bf95-d9fc3642b754,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-e30b02f8-2e9f-433f-bf75-ca9c94b602a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-14aa5bc7-2d38-407d-a9ca-a8afa529ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8c06922e-cd94-455b-8c49-79e07b14e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-854be763-cbd0-4ba6-868c-5894a2690d35,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-99fc408f-d7c4-43fa-99c1-cd7232ba865b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-fcc645d2-e47e-4d53-b692-9b318408e800,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996727410-172.17.0.15-1598488845922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33370,DS-ac0091e5-b356-4c12-b91c-427cb3e8d469,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1f7d25d9-5955-48f9-bf95-d9fc3642b754,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-e30b02f8-2e9f-433f-bf75-ca9c94b602a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-14aa5bc7-2d38-407d-a9ca-a8afa529ed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8c06922e-cd94-455b-8c49-79e07b14e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-854be763-cbd0-4ba6-868c-5894a2690d35,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-99fc408f-d7c4-43fa-99c1-cd7232ba865b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-fcc645d2-e47e-4d53-b692-9b318408e800,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388121076-172.17.0.15-1598489239834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-a18a45ce-0e9f-4744-a9c8-99bc1acd4014,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-1c4d3a11-eddc-458e-8203-0f133e2e4e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-8019d564-1361-4020-ae92-dd1ecc76c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-fbce1480-9d5c-49e8-b04f-bcac6a18a865,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-a996fd16-a947-4110-9ba4-5249f1ab1e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-fd0ccd28-378d-49b0-96e0-7c08271fd690,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-50852de8-eafc-4b7b-8569-5ffe772a3533,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d0f88c0f-c617-41c7-9293-d7c44f4bc615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388121076-172.17.0.15-1598489239834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-a18a45ce-0e9f-4744-a9c8-99bc1acd4014,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-1c4d3a11-eddc-458e-8203-0f133e2e4e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-8019d564-1361-4020-ae92-dd1ecc76c75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-fbce1480-9d5c-49e8-b04f-bcac6a18a865,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-a996fd16-a947-4110-9ba4-5249f1ab1e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-fd0ccd28-378d-49b0-96e0-7c08271fd690,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-50852de8-eafc-4b7b-8569-5ffe772a3533,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d0f88c0f-c617-41c7-9293-d7c44f4bc615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088589549-172.17.0.15-1598489306911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-bee6a86a-49dc-4b30-80df-ca44b3d862da,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-649fc5d2-eaaf-453e-b6df-64a487178a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-6aec5714-2d4c-412d-872a-5dfb27930fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-9b23415c-14af-4730-8ea7-f5f89c52bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-d12e8c73-7816-4e3e-8527-cdd7d328e664,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-76f32427-4560-4601-bf26-5095ca3f8f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-4f35624d-dc12-4419-9166-010c57857fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-cf5d7c95-1077-437a-8345-0665de00312f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088589549-172.17.0.15-1598489306911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-bee6a86a-49dc-4b30-80df-ca44b3d862da,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-649fc5d2-eaaf-453e-b6df-64a487178a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-6aec5714-2d4c-412d-872a-5dfb27930fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-9b23415c-14af-4730-8ea7-f5f89c52bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-d12e8c73-7816-4e3e-8527-cdd7d328e664,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-76f32427-4560-4601-bf26-5095ca3f8f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-4f35624d-dc12-4419-9166-010c57857fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-cf5d7c95-1077-437a-8345-0665de00312f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601823519-172.17.0.15-1598489448265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-deaad32e-c5d7-4235-a8b4-4a7186cd1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-0b3d97d8-e619-414d-98a1-7d3a796c4bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7d858895-4f07-4f83-88c4-424d026a9a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-bc940681-e604-40b8-8b3d-859590fba45c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-56df282b-9524-42ff-8f2f-37aadd975c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-cf3c9c5e-0eec-4eb2-9167-7223b61003ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-5606d16c-45b8-4115-bcf0-e21b899aabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-01be6e09-1d0d-46b5-a73f-adf92cc3a7e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601823519-172.17.0.15-1598489448265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-deaad32e-c5d7-4235-a8b4-4a7186cd1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-0b3d97d8-e619-414d-98a1-7d3a796c4bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7d858895-4f07-4f83-88c4-424d026a9a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-bc940681-e604-40b8-8b3d-859590fba45c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-56df282b-9524-42ff-8f2f-37aadd975c95,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-cf3c9c5e-0eec-4eb2-9167-7223b61003ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-5606d16c-45b8-4115-bcf0-e21b899aabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-01be6e09-1d0d-46b5-a73f-adf92cc3a7e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572814133-172.17.0.15-1598489657762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-eeb0e94d-4aad-4419-8127-d5f69eba8716,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ee40fa9f-459c-479e-b940-306257cb19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-f3ae91bf-50a8-4ca3-9f75-e0f7b310bfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-df443ae5-0a06-4cd6-9185-cd468344a290,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-c6a3d094-e95b-4f61-b286-eb66044ce120,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-bb039425-d244-4410-af90-91beb18c8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-69499dc2-3310-44a8-9d8e-50b533fc9a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-87c80a06-ca62-496e-94e5-de1c4478828a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572814133-172.17.0.15-1598489657762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-eeb0e94d-4aad-4419-8127-d5f69eba8716,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-ee40fa9f-459c-479e-b940-306257cb19e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-f3ae91bf-50a8-4ca3-9f75-e0f7b310bfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-df443ae5-0a06-4cd6-9185-cd468344a290,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-c6a3d094-e95b-4f61-b286-eb66044ce120,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-bb039425-d244-4410-af90-91beb18c8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-69499dc2-3310-44a8-9d8e-50b533fc9a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-87c80a06-ca62-496e-94e5-de1c4478828a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223134832-172.17.0.15-1598489768089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-d338d2dc-bfca-4038-9afa-88ff4e49e099,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-ccde194a-542c-4306-8dec-3a3107b702f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-1b1eb665-6407-42b4-83fe-e3ce5c1d0cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-5fe3f4dd-64bf-4284-a52e-0e5fa44047a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-97010820-0f49-4a16-b40e-cff1c03caceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ca2a6380-b193-4c33-a626-070276a879a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-1c73d189-b6a2-4919-b821-3123c586defe,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-18c92acc-c3f3-4773-81f0-f17117c67145,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223134832-172.17.0.15-1598489768089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-d338d2dc-bfca-4038-9afa-88ff4e49e099,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-ccde194a-542c-4306-8dec-3a3107b702f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-1b1eb665-6407-42b4-83fe-e3ce5c1d0cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-5fe3f4dd-64bf-4284-a52e-0e5fa44047a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-97010820-0f49-4a16-b40e-cff1c03caceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ca2a6380-b193-4c33-a626-070276a879a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-1c73d189-b6a2-4919-b821-3123c586defe,DISK], DatanodeInfoWithStorage[127.0.0.1:36447,DS-18c92acc-c3f3-4773-81f0-f17117c67145,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781310112-172.17.0.15-1598489913126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-c56e557e-fbd1-46cf-bc9f-a84ba09ff714,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-855ed9c4-3766-49b6-b96a-fc85efd21354,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-161db732-e153-45dd-9330-4497228838e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-71924107-274e-4f0d-8d1d-878d79b02d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-1e47a81f-ba35-4cb9-929e-6f9e1f756493,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-f4481bbb-8e76-448d-90fb-01becdb6176e,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-73795c46-2f4b-4c2d-9677-4f4f61907f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-d7c049ab-f83e-4ca3-a140-3aaffe3ff430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781310112-172.17.0.15-1598489913126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-c56e557e-fbd1-46cf-bc9f-a84ba09ff714,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-855ed9c4-3766-49b6-b96a-fc85efd21354,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-161db732-e153-45dd-9330-4497228838e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-71924107-274e-4f0d-8d1d-878d79b02d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-1e47a81f-ba35-4cb9-929e-6f9e1f756493,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-f4481bbb-8e76-448d-90fb-01becdb6176e,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-73795c46-2f4b-4c2d-9677-4f4f61907f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-d7c049ab-f83e-4ca3-a140-3aaffe3ff430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115644884-172.17.0.15-1598490252398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-432681f0-1225-479e-840e-64f6e670ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-b6ada65d-f7d5-4b79-a833-9e8c932dac68,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0a53a750-0aa5-49a8-8dc7-91e6efe713a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-911b5721-332b-4c24-91ef-01fbd821e275,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-aa84886f-b1b9-4932-bd9f-c8679ccb37dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f544ffd9-4e1b-4a65-b6b5-7c60a47f8259,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bacbdeb2-c8d6-4ac8-b38e-b7b6466f9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-6f550012-c2cf-452a-bed3-9d4c300ea8f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115644884-172.17.0.15-1598490252398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-432681f0-1225-479e-840e-64f6e670ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-b6ada65d-f7d5-4b79-a833-9e8c932dac68,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-0a53a750-0aa5-49a8-8dc7-91e6efe713a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-911b5721-332b-4c24-91ef-01fbd821e275,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-aa84886f-b1b9-4932-bd9f-c8679ccb37dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f544ffd9-4e1b-4a65-b6b5-7c60a47f8259,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bacbdeb2-c8d6-4ac8-b38e-b7b6466f9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-6f550012-c2cf-452a-bed3-9d4c300ea8f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23244928-172.17.0.15-1598490402537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40563,DS-be3ff0f8-2f0e-4960-a3fc-8ab545253da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-fc90aa55-6785-4692-9aae-781be6204a99,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-57f8fd2c-9485-4d4a-b92a-7511a5e33d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-2580cedd-c8ab-4518-864b-94e0fb3825a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-a7c3f61e-daa9-45e5-a0c0-5b56b30ef999,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-33e281c2-5d56-4b9e-bc49-97c2dc8999b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-affab3f6-28ca-4328-b9cd-874a12f0059c,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-f9178a41-37db-442e-a32c-990eb819be0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23244928-172.17.0.15-1598490402537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40563,DS-be3ff0f8-2f0e-4960-a3fc-8ab545253da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-fc90aa55-6785-4692-9aae-781be6204a99,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-57f8fd2c-9485-4d4a-b92a-7511a5e33d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-2580cedd-c8ab-4518-864b-94e0fb3825a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-a7c3f61e-daa9-45e5-a0c0-5b56b30ef999,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-33e281c2-5d56-4b9e-bc49-97c2dc8999b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-affab3f6-28ca-4328-b9cd-874a12f0059c,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-f9178a41-37db-442e-a32c-990eb819be0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819958530-172.17.0.15-1598490441259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-8aaa6d02-d5c3-4d0d-8ff2-1a346249fe78,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-3b4f394b-ed31-4fdf-bcb8-40c1ae8cb49c,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-795a1b90-1eb6-4e32-9277-043f8c41c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-a8641af0-1b46-43b3-a63c-c5f3d9c3eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-89f3a317-7896-43e6-a0bf-e224157462d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-40f0472d-881c-455c-8435-c89f19076ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-83814655-afd8-47fc-a5a3-4e7bb554a879,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-418c131c-d0a4-4900-9855-eeaa9884a0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819958530-172.17.0.15-1598490441259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-8aaa6d02-d5c3-4d0d-8ff2-1a346249fe78,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-3b4f394b-ed31-4fdf-bcb8-40c1ae8cb49c,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-795a1b90-1eb6-4e32-9277-043f8c41c56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-a8641af0-1b46-43b3-a63c-c5f3d9c3eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-89f3a317-7896-43e6-a0bf-e224157462d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-40f0472d-881c-455c-8435-c89f19076ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-83814655-afd8-47fc-a5a3-4e7bb554a879,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-418c131c-d0a4-4900-9855-eeaa9884a0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460091193-172.17.0.15-1598490466189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-fa71e441-424c-42eb-8b84-937be70fb954,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-937703ac-cf27-4252-9deb-17abbfad3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-fcd2c2bb-7de9-443e-83c4-0a9948414b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-4ffdf782-2650-4dbb-8203-1428fdcc6179,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-ac98e76e-7594-430c-b748-9cd61c1f307d,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4c12fb40-df63-469c-9fe2-10b7bb20e942,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-1a060b7b-5d06-48f1-97c7-de100fd08763,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-ba13353d-d150-4016-948c-f701444776b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460091193-172.17.0.15-1598490466189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-fa71e441-424c-42eb-8b84-937be70fb954,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-937703ac-cf27-4252-9deb-17abbfad3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-fcd2c2bb-7de9-443e-83c4-0a9948414b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-4ffdf782-2650-4dbb-8203-1428fdcc6179,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-ac98e76e-7594-430c-b748-9cd61c1f307d,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-4c12fb40-df63-469c-9fe2-10b7bb20e942,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-1a060b7b-5d06-48f1-97c7-de100fd08763,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-ba13353d-d150-4016-948c-f701444776b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142235705-172.17.0.15-1598490503414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-69085235-401b-42d9-b5d6-a1bd083d7e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-0ed3d474-7cc2-45aa-ba50-8d1da96e8362,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-93ff5a88-5a40-4e50-a8ce-e5f859a170ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-86c1f060-ed7d-449b-9dac-b18d8a71f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-9a923300-fc29-49cc-a891-95e8ff02f5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-72f347d9-c22b-4489-b675-01605e63ce1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-760f4730-4761-4c89-b585-e210359f127b,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-2393e545-b0fc-4503-91ed-1dde919eacbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142235705-172.17.0.15-1598490503414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-69085235-401b-42d9-b5d6-a1bd083d7e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-0ed3d474-7cc2-45aa-ba50-8d1da96e8362,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-93ff5a88-5a40-4e50-a8ce-e5f859a170ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-86c1f060-ed7d-449b-9dac-b18d8a71f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-9a923300-fc29-49cc-a891-95e8ff02f5db,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-72f347d9-c22b-4489-b675-01605e63ce1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-760f4730-4761-4c89-b585-e210359f127b,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-2393e545-b0fc-4503-91ed-1dde919eacbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272089321-172.17.0.15-1598490545625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42462,DS-d11f8a4c-1fb9-4a38-9a25-ad17f6815ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-68819150-e818-463c-8db9-8d55dc8e229c,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9947d5ec-3abd-433d-b815-e4847cc2c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-85c5d485-9a3c-47b9-b4f3-96e56a03dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-0cf5fb14-2cd6-463c-9381-413e76d9264b,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-7e9cab60-7538-4ee8-a5d1-1e2a61359d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-220f2448-4735-44c5-9c31-973e4f4b6477,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-d4bcd2f4-c4da-43ec-8e9f-d9814a0a3737,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272089321-172.17.0.15-1598490545625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42462,DS-d11f8a4c-1fb9-4a38-9a25-ad17f6815ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-68819150-e818-463c-8db9-8d55dc8e229c,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9947d5ec-3abd-433d-b815-e4847cc2c8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-85c5d485-9a3c-47b9-b4f3-96e56a03dc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-0cf5fb14-2cd6-463c-9381-413e76d9264b,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-7e9cab60-7538-4ee8-a5d1-1e2a61359d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-220f2448-4735-44c5-9c31-973e4f4b6477,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-d4bcd2f4-c4da-43ec-8e9f-d9814a0a3737,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 20 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: might be true error
Total execution time in seconds : 5313
