reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560379656-172.17.0.20-1598684877403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-5444ca51-1771-48ba-999f-614bab8f1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-1c1828c2-cd7d-464c-8cfb-a42abe220742,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-2432a634-4bc1-4a7f-9cb5-9b72ee6439f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-f6a0376b-cc5a-4885-83e3-e9c7ef87c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-d2c06412-d301-4fed-814b-16f540aa94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-4bc41a77-0d26-43aa-8e2b-261dbde1d082,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-673e4c28-ed31-464b-8d69-c66786eed2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-456c102a-0393-417f-8dda-b3883c426cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560379656-172.17.0.20-1598684877403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-5444ca51-1771-48ba-999f-614bab8f1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-1c1828c2-cd7d-464c-8cfb-a42abe220742,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-2432a634-4bc1-4a7f-9cb5-9b72ee6439f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-f6a0376b-cc5a-4885-83e3-e9c7ef87c16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-d2c06412-d301-4fed-814b-16f540aa94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-4bc41a77-0d26-43aa-8e2b-261dbde1d082,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-673e4c28-ed31-464b-8d69-c66786eed2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-456c102a-0393-417f-8dda-b3883c426cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040716066-172.17.0.20-1598685095035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-d6e41bf8-3ecd-4ae7-9cef-38169ee80908,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-a2ddfe34-95fc-4db0-89d9-35cd4fafbd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-3d3931c1-2a7c-45ea-b09f-832d09da6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-43187e45-4fbb-4278-a45e-543898480db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-66a83133-e510-4edc-ae10-c5ec7b956e89,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-de12e099-9b3c-404c-ac6d-705e62782be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-3bf421d1-bf5b-4bfa-93c9-1712f8c0ab61,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-50a5330c-8873-4ee7-a0b0-095e3cea61f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040716066-172.17.0.20-1598685095035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-d6e41bf8-3ecd-4ae7-9cef-38169ee80908,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-a2ddfe34-95fc-4db0-89d9-35cd4fafbd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-3d3931c1-2a7c-45ea-b09f-832d09da6af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-43187e45-4fbb-4278-a45e-543898480db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-66a83133-e510-4edc-ae10-c5ec7b956e89,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-de12e099-9b3c-404c-ac6d-705e62782be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-3bf421d1-bf5b-4bfa-93c9-1712f8c0ab61,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-50a5330c-8873-4ee7-a0b0-095e3cea61f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061793224-172.17.0.20-1598685589377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-3b26683d-3404-42cc-a7d5-a1c45335cf69,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-ef169f52-be4c-494b-9b9f-83c0c1ba8662,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e898fcc8-51f9-4327-baf6-ea4869e1812a,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-3bbe11b3-a761-44ab-b225-75908eb435e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-c17cc3c8-2635-42a7-b0c5-5b40e20d20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-1e3d358b-5c2a-4ba4-97c7-153b1b494ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-4511f045-6089-4b01-8d12-fb775934726c,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-94ec149c-a88f-4c2d-86b7-64567ad2257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061793224-172.17.0.20-1598685589377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45014,DS-3b26683d-3404-42cc-a7d5-a1c45335cf69,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-ef169f52-be4c-494b-9b9f-83c0c1ba8662,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-e898fcc8-51f9-4327-baf6-ea4869e1812a,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-3bbe11b3-a761-44ab-b225-75908eb435e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-c17cc3c8-2635-42a7-b0c5-5b40e20d20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-1e3d358b-5c2a-4ba4-97c7-153b1b494ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-4511f045-6089-4b01-8d12-fb775934726c,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-94ec149c-a88f-4c2d-86b7-64567ad2257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846472218-172.17.0.20-1598685692418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-9e369e0d-be87-4318-9061-b1f1f446e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-dad556eb-9295-499a-aba2-68238f849ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0264bba2-c89d-44b7-8577-87889976e881,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-3bc960da-f285-4fd9-92c1-e1af6a3023a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-3eb35310-0faa-413a-93b1-33a3097794dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-f47e5724-cb32-46ba-94b7-830b73a4cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-6b832a73-cf49-468f-bc35-9455480cecff,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-b8e52311-393f-48f9-831c-7899bc511133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846472218-172.17.0.20-1598685692418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-9e369e0d-be87-4318-9061-b1f1f446e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-dad556eb-9295-499a-aba2-68238f849ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0264bba2-c89d-44b7-8577-87889976e881,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-3bc960da-f285-4fd9-92c1-e1af6a3023a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-3eb35310-0faa-413a-93b1-33a3097794dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-f47e5724-cb32-46ba-94b7-830b73a4cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-6b832a73-cf49-468f-bc35-9455480cecff,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-b8e52311-393f-48f9-831c-7899bc511133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890191729-172.17.0.20-1598685864609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-0d06f631-58b7-409a-94a5-cbbfa5c22516,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-18c61b1b-3fb7-4e4e-8d3b-f0299bf6501c,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-8fce3936-b867-436f-8d06-163e3a36dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-b7cd5111-61e5-4d7d-87a0-d4f192931611,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-dde95750-5c6b-4523-b80d-207e74b3180a,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-2a60d5ba-dfc4-44fe-a504-e67a7bc40053,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-43b4fe6c-8a90-4e6c-ab1c-821a72457a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-ad5a9faf-46ce-4b26-b3b2-6bba6df332bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890191729-172.17.0.20-1598685864609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-0d06f631-58b7-409a-94a5-cbbfa5c22516,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-18c61b1b-3fb7-4e4e-8d3b-f0299bf6501c,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-8fce3936-b867-436f-8d06-163e3a36dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-b7cd5111-61e5-4d7d-87a0-d4f192931611,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-dde95750-5c6b-4523-b80d-207e74b3180a,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-2a60d5ba-dfc4-44fe-a504-e67a7bc40053,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-43b4fe6c-8a90-4e6c-ab1c-821a72457a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-ad5a9faf-46ce-4b26-b3b2-6bba6df332bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239849265-172.17.0.20-1598686294842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-a1df31f9-8a02-4985-8ca7-00805de49794,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-95089a94-c3d5-46fc-8b0f-0ca3737ba714,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-9f5e0a3a-f480-49ea-be1e-56919e408a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-831e3523-1db4-478f-8917-a70d1cf4bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-04ca5cfc-69da-4076-b3b0-776cb5c6197f,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d3b082f9-a544-480d-820b-3abccddcaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-db7bb4f2-0b4e-4ce9-a86e-ff15125a1d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-ec1bde65-0cb3-4df1-b96c-150f090e1e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239849265-172.17.0.20-1598686294842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-a1df31f9-8a02-4985-8ca7-00805de49794,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-95089a94-c3d5-46fc-8b0f-0ca3737ba714,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-9f5e0a3a-f480-49ea-be1e-56919e408a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-831e3523-1db4-478f-8917-a70d1cf4bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-04ca5cfc-69da-4076-b3b0-776cb5c6197f,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d3b082f9-a544-480d-820b-3abccddcaeda,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-db7bb4f2-0b4e-4ce9-a86e-ff15125a1d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-ec1bde65-0cb3-4df1-b96c-150f090e1e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847405146-172.17.0.20-1598686830593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-5a16c84a-b3e8-4379-b85e-bb10fff41f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-3b741db5-5d97-4770-aa2e-b6f48a5f33d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-518f7d43-f4eb-4ac6-954a-06551361cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3a216d30-0fe8-4e05-99b1-1a3a0538747a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-78fa2202-0a52-4156-bacd-8ab78cb537ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-36adf713-c19f-487f-bfdf-64a27d4314b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f17b38a2-8a94-48dd-9df9-ffacd88811ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-81add1bd-1bef-4a80-b7f5-8d38cc53867d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847405146-172.17.0.20-1598686830593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-5a16c84a-b3e8-4379-b85e-bb10fff41f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-3b741db5-5d97-4770-aa2e-b6f48a5f33d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-518f7d43-f4eb-4ac6-954a-06551361cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3a216d30-0fe8-4e05-99b1-1a3a0538747a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-78fa2202-0a52-4156-bacd-8ab78cb537ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-36adf713-c19f-487f-bfdf-64a27d4314b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f17b38a2-8a94-48dd-9df9-ffacd88811ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-81add1bd-1bef-4a80-b7f5-8d38cc53867d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163746949-172.17.0.20-1598687716463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-c47cd339-eb7f-4240-aa3e-d4ed8a6e01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-2867b350-c1bf-4e4e-b48f-2e7da50778b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-68d1fd3e-2c66-4bb5-a105-c095aab2b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-e88d2da6-960b-425d-95bb-e1fdab805457,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-d7452ba0-ca42-4dc9-9f35-9d0e75d8df91,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-acdc2907-8d0a-47c8-9c48-d58ec70f5cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-be152655-b5da-4746-ac44-c0654fc447d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-f624eb77-678f-4531-922b-92e43974ce0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163746949-172.17.0.20-1598687716463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-c47cd339-eb7f-4240-aa3e-d4ed8a6e01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-2867b350-c1bf-4e4e-b48f-2e7da50778b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-68d1fd3e-2c66-4bb5-a105-c095aab2b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-e88d2da6-960b-425d-95bb-e1fdab805457,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-d7452ba0-ca42-4dc9-9f35-9d0e75d8df91,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-acdc2907-8d0a-47c8-9c48-d58ec70f5cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-be152655-b5da-4746-ac44-c0654fc447d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-f624eb77-678f-4531-922b-92e43974ce0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461772308-172.17.0.20-1598687964504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-14d14100-55cf-430a-9f2a-7682a78d0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-0bcbc723-fcd8-4ae8-ba50-e88b55a1743c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-1b400627-99b9-440e-85d2-9ad639e61447,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-b39cdec0-f05f-4d95-911d-6dd636d12c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-25a144bd-c202-4567-a590-d9d4da305232,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-5390c467-7b5d-4c4d-96a9-f864ae609b93,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-384d9a0b-f81d-45cf-a7ad-ea7d272922fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-17ca1a3b-fd85-4e92-b6c7-d2275d45a9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461772308-172.17.0.20-1598687964504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-14d14100-55cf-430a-9f2a-7682a78d0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-0bcbc723-fcd8-4ae8-ba50-e88b55a1743c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-1b400627-99b9-440e-85d2-9ad639e61447,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-b39cdec0-f05f-4d95-911d-6dd636d12c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-25a144bd-c202-4567-a590-d9d4da305232,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-5390c467-7b5d-4c4d-96a9-f864ae609b93,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-384d9a0b-f81d-45cf-a7ad-ea7d272922fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-17ca1a3b-fd85-4e92-b6c7-d2275d45a9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923036820-172.17.0.20-1598688143593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-20ad8551-69c2-4b97-b502-e0f1d0462da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b7e51606-d1ec-4af0-9bea-84cc742710ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-24bea576-7072-448d-b481-b8a78c4d12c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-ff1ec73e-61b2-475d-b3d7-69dc0329e53a,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5697253f-b314-4668-a8ef-611890f2ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-98dfd1bf-df0d-4d8a-bf79-ad59f91ed3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f4f30102-c55d-40c1-888c-3765390b5279,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-887a6c14-3e0f-4763-bb3b-1364be4d3f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923036820-172.17.0.20-1598688143593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-20ad8551-69c2-4b97-b502-e0f1d0462da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b7e51606-d1ec-4af0-9bea-84cc742710ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-24bea576-7072-448d-b481-b8a78c4d12c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-ff1ec73e-61b2-475d-b3d7-69dc0329e53a,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5697253f-b314-4668-a8ef-611890f2ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-98dfd1bf-df0d-4d8a-bf79-ad59f91ed3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-f4f30102-c55d-40c1-888c-3765390b5279,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-887a6c14-3e0f-4763-bb3b-1364be4d3f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546446820-172.17.0.20-1598688555808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-39304382-0faf-4342-b017-a32e3cd9203b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-ac68fd3a-0cf0-4fed-af02-a9432582a152,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-4bc26199-a2f4-492a-bfde-3e350a765129,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-b6ba7da3-0260-4ad2-96e5-d3c90e4e31c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ac9715ce-6589-4d3a-b8db-8217035b6055,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-34be39e0-ab7d-432f-8d17-20408a291f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-650b9f32-18cd-417c-a6c6-c492e1c8a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-c7ecf412-1917-4308-9c7c-5968af43c725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546446820-172.17.0.20-1598688555808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-39304382-0faf-4342-b017-a32e3cd9203b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-ac68fd3a-0cf0-4fed-af02-a9432582a152,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-4bc26199-a2f4-492a-bfde-3e350a765129,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-b6ba7da3-0260-4ad2-96e5-d3c90e4e31c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ac9715ce-6589-4d3a-b8db-8217035b6055,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-34be39e0-ab7d-432f-8d17-20408a291f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-650b9f32-18cd-417c-a6c6-c492e1c8a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-c7ecf412-1917-4308-9c7c-5968af43c725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431745877-172.17.0.20-1598688596182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-97a163b2-4a63-4c58-ac11-e9d9672e019f,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-71136117-0dbb-429e-ab2b-5330d0778dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-772d177a-bac6-4827-ac06-dabc7986e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-00546da6-677f-4a9d-9386-24062c1c94c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-221abedd-4d5d-4088-a140-89578907895a,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-948049d1-794b-410f-9bd9-4477bc52dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c6f224d6-d0bc-4213-b00d-0b8f066da0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-62e3871c-9156-4097-a06f-b2d3eead9081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431745877-172.17.0.20-1598688596182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-97a163b2-4a63-4c58-ac11-e9d9672e019f,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-71136117-0dbb-429e-ab2b-5330d0778dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-772d177a-bac6-4827-ac06-dabc7986e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-00546da6-677f-4a9d-9386-24062c1c94c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-221abedd-4d5d-4088-a140-89578907895a,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-948049d1-794b-410f-9bd9-4477bc52dcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c6f224d6-d0bc-4213-b00d-0b8f066da0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-62e3871c-9156-4097-a06f-b2d3eead9081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867085653-172.17.0.20-1598688926682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-5c23b581-ed7c-42ad-9247-0130d7af9963,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-6f8d314c-e988-453b-904b-fb0603f29533,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-f2dda7ba-846b-4cf7-a452-08290fc00092,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-df023f03-c69c-45de-a03c-531d6fead5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f14d2252-3eb5-4916-992a-ba92712b7590,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e525a8ae-d01a-4ca8-9ff0-a58c8f26ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-62cf0184-f02e-4d0b-abd3-e9acdb1ec9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-2921f062-77b8-4926-9071-3d20555c8094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867085653-172.17.0.20-1598688926682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-5c23b581-ed7c-42ad-9247-0130d7af9963,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-6f8d314c-e988-453b-904b-fb0603f29533,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-f2dda7ba-846b-4cf7-a452-08290fc00092,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-df023f03-c69c-45de-a03c-531d6fead5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f14d2252-3eb5-4916-992a-ba92712b7590,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e525a8ae-d01a-4ca8-9ff0-a58c8f26ff97,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-62cf0184-f02e-4d0b-abd3-e9acdb1ec9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-2921f062-77b8-4926-9071-3d20555c8094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688698246-172.17.0.20-1598688961386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-e92f6664-c25c-43b9-81c4-69f04a408628,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-3c429f47-fd71-4437-aaaa-18b71ff48e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-d45b0928-8f1b-467f-b04e-71a520a34d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-024c0376-e0d8-44a6-b53e-366879e6314a,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-68c8d569-ce35-4133-b629-f8f75618d7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-d2b158a9-0c11-49e5-8fc8-ce9bf083a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-888fecc7-c6b0-439f-b749-6219a4f2cedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-80acb206-a9be-42e1-9486-7d04140b2f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688698246-172.17.0.20-1598688961386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-e92f6664-c25c-43b9-81c4-69f04a408628,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-3c429f47-fd71-4437-aaaa-18b71ff48e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-d45b0928-8f1b-467f-b04e-71a520a34d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-024c0376-e0d8-44a6-b53e-366879e6314a,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-68c8d569-ce35-4133-b629-f8f75618d7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-d2b158a9-0c11-49e5-8fc8-ce9bf083a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-888fecc7-c6b0-439f-b749-6219a4f2cedf,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-80acb206-a9be-42e1-9486-7d04140b2f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857507610-172.17.0.20-1598689351346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d342ff4a-2086-4dee-a119-73d089ff5974,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-a1deb702-5015-4f70-9744-724309404a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-eb7fb503-dfbf-4bc8-9a98-7c98d2c2a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-06002a9e-94cb-41a8-882c-ad387ab50d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-2f66da02-a761-4513-994d-e37c0ac89e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-755872e8-b379-421f-9720-9c2717b0e841,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-58088acf-a045-4dcc-90df-d221c1aadc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-b11afd49-9ab4-4626-9d9d-4caef675d366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857507610-172.17.0.20-1598689351346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d342ff4a-2086-4dee-a119-73d089ff5974,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-a1deb702-5015-4f70-9744-724309404a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-eb7fb503-dfbf-4bc8-9a98-7c98d2c2a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-06002a9e-94cb-41a8-882c-ad387ab50d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-2f66da02-a761-4513-994d-e37c0ac89e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-755872e8-b379-421f-9720-9c2717b0e841,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-58088acf-a045-4dcc-90df-d221c1aadc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-b11afd49-9ab4-4626-9d9d-4caef675d366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332180701-172.17.0.20-1598689388688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-6f95e14b-0677-472a-9826-b98b4c3f5333,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-93e5baaf-e110-4432-beb3-4cd7ca0d2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-86d201f2-063c-42d8-8a9d-618ad1451901,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-c0e227c9-aa78-4b9b-b0a7-9b53e2dbe7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-9cc007f8-e7db-46c0-aac4-bfea5aba104f,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b9be2b1c-fb83-4bcb-85bc-251c4c642078,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-33f3dc98-0303-42e6-99a5-971a40478497,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-27a9b244-a53e-420b-a589-f3f7b06946bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332180701-172.17.0.20-1598689388688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-6f95e14b-0677-472a-9826-b98b4c3f5333,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-93e5baaf-e110-4432-beb3-4cd7ca0d2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-86d201f2-063c-42d8-8a9d-618ad1451901,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-c0e227c9-aa78-4b9b-b0a7-9b53e2dbe7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-9cc007f8-e7db-46c0-aac4-bfea5aba104f,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-b9be2b1c-fb83-4bcb-85bc-251c4c642078,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-33f3dc98-0303-42e6-99a5-971a40478497,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-27a9b244-a53e-420b-a589-f3f7b06946bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 1200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522550333-172.17.0.20-1598689618262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-6501667e-936f-40d2-91e8-9a0847d9e4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-aea3cb9f-8fd4-440c-a21c-47abb88a0148,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-be0534a5-e39d-4d62-b8d3-5f319994bfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-a35ecf78-c837-47a3-9137-99795c8c85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-21cfc1f9-029a-436e-928b-0911470d0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-4fa143f5-33c9-4a94-95cb-5de71d0a9dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-be6ad45d-97b5-4238-b7c6-18a8586711e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4455d7bb-3d14-4deb-b7b5-002cd8d9142e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522550333-172.17.0.20-1598689618262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-6501667e-936f-40d2-91e8-9a0847d9e4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-aea3cb9f-8fd4-440c-a21c-47abb88a0148,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-be0534a5-e39d-4d62-b8d3-5f319994bfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-a35ecf78-c837-47a3-9137-99795c8c85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-21cfc1f9-029a-436e-928b-0911470d0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-4fa143f5-33c9-4a94-95cb-5de71d0a9dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-be6ad45d-97b5-4238-b7c6-18a8586711e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-4455d7bb-3d14-4deb-b7b5-002cd8d9142e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5447
