reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763644129-172.17.0.16-1598543251810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-8f06fb1a-82f0-4e33-a072-8f48c192074d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-41c1cf8b-54c3-4777-bdf4-98e9655ae666,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-41a6f112-cb4e-40c1-bd26-62ffe28ec4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-4b92db9c-747e-4fd1-8b84-c73754fa5038,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-bc774320-4e32-4ab4-b5ec-149bb431c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-fa75cb18-23d6-4c07-bdb0-cfc9c7fc844d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-c5840f88-b212-452a-b47b-9208c74f40da,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-ff155d45-2719-43c4-bcfc-d1839de9b2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763644129-172.17.0.16-1598543251810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-8f06fb1a-82f0-4e33-a072-8f48c192074d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-41c1cf8b-54c3-4777-bdf4-98e9655ae666,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-41a6f112-cb4e-40c1-bd26-62ffe28ec4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-4b92db9c-747e-4fd1-8b84-c73754fa5038,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-bc774320-4e32-4ab4-b5ec-149bb431c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-fa75cb18-23d6-4c07-bdb0-cfc9c7fc844d,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-c5840f88-b212-452a-b47b-9208c74f40da,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-ff155d45-2719-43c4-bcfc-d1839de9b2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134208908-172.17.0.16-1598543497288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-7dd0b2f2-c7b1-46bc-bd4b-122ed1e48e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-25686a75-31ab-48ea-bb18-265fdb13daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-69a5970d-5b3b-4632-9162-f9cb10ce2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-29614ee5-5300-4060-945f-0eecd1d4f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-57f7c104-0cc7-4e97-875f-822191368956,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-b98515f0-d961-496c-b145-671287c0c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-07fa6527-4473-4715-b6ce-f63a006a5801,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-b4e88e99-39d8-43c6-9be3-819323e19a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134208908-172.17.0.16-1598543497288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42128,DS-7dd0b2f2-c7b1-46bc-bd4b-122ed1e48e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-25686a75-31ab-48ea-bb18-265fdb13daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-69a5970d-5b3b-4632-9162-f9cb10ce2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-29614ee5-5300-4060-945f-0eecd1d4f3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-57f7c104-0cc7-4e97-875f-822191368956,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-b98515f0-d961-496c-b145-671287c0c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-07fa6527-4473-4715-b6ce-f63a006a5801,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-b4e88e99-39d8-43c6-9be3-819323e19a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517079377-172.17.0.16-1598543529536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-b2952702-2cde-4bc5-b700-811d329a55bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-514e1577-abe7-4ef9-9ab8-643c1e105ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-786c5965-045c-47f8-911b-7aa0da615ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-e5fccc36-2197-4dc5-a878-bbf3d485cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-652f939f-9cb6-4f7f-8582-39bfd1c84cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-b2f66432-be46-4fe0-ae4d-2d45e82389e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-5ca3b3e6-d0d2-4b04-87fc-d4e112e44f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-caaa3c7c-41c3-463d-87cb-6475c38f1887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517079377-172.17.0.16-1598543529536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-b2952702-2cde-4bc5-b700-811d329a55bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-514e1577-abe7-4ef9-9ab8-643c1e105ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-786c5965-045c-47f8-911b-7aa0da615ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-e5fccc36-2197-4dc5-a878-bbf3d485cbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-652f939f-9cb6-4f7f-8582-39bfd1c84cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-b2f66432-be46-4fe0-ae4d-2d45e82389e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-5ca3b3e6-d0d2-4b04-87fc-d4e112e44f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-caaa3c7c-41c3-463d-87cb-6475c38f1887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630113582-172.17.0.16-1598544184093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-8acf92b9-a1a5-4473-a0af-aa48b840b510,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-db351432-5a20-487c-8397-f0b3fd645798,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-3436b873-2e1b-4b80-89dd-ee6c833153c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-2c27d0ce-48d9-4ac4-af7a-c73aa1b17c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-8b53513d-3041-4c65-a410-5836614b29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-aac43f2c-7e7a-4f64-b6cc-1ef456b557a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-8a90d7cf-6860-4fe2-8e3e-6359c05899ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b13a7ad4-bb67-4671-8510-565debf7bb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630113582-172.17.0.16-1598544184093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-8acf92b9-a1a5-4473-a0af-aa48b840b510,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-db351432-5a20-487c-8397-f0b3fd645798,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-3436b873-2e1b-4b80-89dd-ee6c833153c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-2c27d0ce-48d9-4ac4-af7a-c73aa1b17c70,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-8b53513d-3041-4c65-a410-5836614b29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-aac43f2c-7e7a-4f64-b6cc-1ef456b557a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-8a90d7cf-6860-4fe2-8e3e-6359c05899ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b13a7ad4-bb67-4671-8510-565debf7bb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837672827-172.17.0.16-1598544278101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-cd3b8aa1-a63e-407b-9e68-bd1782403f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-58a930aa-c432-4f94-bc23-db359a575316,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-7cd055b9-e201-4e94-9ba8-23f1ed18fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-878d0b3f-f79a-4eec-9446-ead2877bdc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-105d7691-82c1-468e-8815-e2bed79c0404,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-293b47ee-aec4-4719-ae3b-1b793f4424c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-24aa6aa4-f3cb-4444-968c-984181ab1ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f1d3a0ac-b08f-46b1-83fa-b5948dc913af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837672827-172.17.0.16-1598544278101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-cd3b8aa1-a63e-407b-9e68-bd1782403f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-58a930aa-c432-4f94-bc23-db359a575316,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-7cd055b9-e201-4e94-9ba8-23f1ed18fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-878d0b3f-f79a-4eec-9446-ead2877bdc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-105d7691-82c1-468e-8815-e2bed79c0404,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-293b47ee-aec4-4719-ae3b-1b793f4424c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-24aa6aa4-f3cb-4444-968c-984181ab1ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f1d3a0ac-b08f-46b1-83fa-b5948dc913af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16819992-172.17.0.16-1598544440983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-14f68df1-79aa-4ee8-9082-953413af02fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-8afe7441-197c-4e3f-8506-e85efacd6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-316f34d3-201d-4658-a31f-e14fae4b15be,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-b514ca62-38b6-40aa-b1f4-1a86b24eb57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-40ed01f2-f61d-4fa3-8704-5e718aa6265e,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-953450c1-393e-4578-8750-b0dce452a019,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-a83e5e04-5f44-4968-b536-777ec5049462,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-56a50ca5-b1a7-4bd6-9a0d-e494c2a2201f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16819992-172.17.0.16-1598544440983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-14f68df1-79aa-4ee8-9082-953413af02fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-8afe7441-197c-4e3f-8506-e85efacd6b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-316f34d3-201d-4658-a31f-e14fae4b15be,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-b514ca62-38b6-40aa-b1f4-1a86b24eb57e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-40ed01f2-f61d-4fa3-8704-5e718aa6265e,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-953450c1-393e-4578-8750-b0dce452a019,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-a83e5e04-5f44-4968-b536-777ec5049462,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-56a50ca5-b1a7-4bd6-9a0d-e494c2a2201f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798881881-172.17.0.16-1598544516672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-17f60fbd-ddcf-43ea-ac8d-5b5c69d1d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-24336fb0-2114-497a-95cb-b68b76379bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-92668dfd-29b6-40d8-99da-e72ce7b6a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-fc36b33f-68f7-43e0-9619-6e90dd161436,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-24fc2dc2-9fba-4051-8282-8e9512c6ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-7a946656-9c0d-442e-a4fe-87f768e4405a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c3b1197e-b37e-43ea-9797-1addadcd6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-cb9905db-b5ea-4790-a2cb-a59a631f452e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798881881-172.17.0.16-1598544516672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-17f60fbd-ddcf-43ea-ac8d-5b5c69d1d27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-24336fb0-2114-497a-95cb-b68b76379bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-92668dfd-29b6-40d8-99da-e72ce7b6a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-fc36b33f-68f7-43e0-9619-6e90dd161436,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-24fc2dc2-9fba-4051-8282-8e9512c6ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-7a946656-9c0d-442e-a4fe-87f768e4405a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c3b1197e-b37e-43ea-9797-1addadcd6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-cb9905db-b5ea-4790-a2cb-a59a631f452e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130836555-172.17.0.16-1598544561652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-ff45d849-11eb-463a-b6b0-81c87dfa1518,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-b1e70f24-c7e3-4288-9201-89ba7be7e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-8c59d7bb-0f95-42dc-9d40-99ef38c2438f,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-d3ba5ba1-8132-4530-88ae-e95abe50b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-60b339e7-f423-447b-a268-6402a2945a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-37e64bb0-31bd-4998-b079-c20fb19317c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e36c440a-996c-4fcf-8d5b-b325723bf978,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-64b3ab85-f6c2-49af-89ad-3cfa121843a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130836555-172.17.0.16-1598544561652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-ff45d849-11eb-463a-b6b0-81c87dfa1518,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-b1e70f24-c7e3-4288-9201-89ba7be7e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-8c59d7bb-0f95-42dc-9d40-99ef38c2438f,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-d3ba5ba1-8132-4530-88ae-e95abe50b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-60b339e7-f423-447b-a268-6402a2945a58,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-37e64bb0-31bd-4998-b079-c20fb19317c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e36c440a-996c-4fcf-8d5b-b325723bf978,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-64b3ab85-f6c2-49af-89ad-3cfa121843a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337920965-172.17.0.16-1598545246789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-dee813e8-771c-438c-b830-4095a368e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8f2ccdce-678e-45ac-95c8-07c810c24ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2468abc9-a194-419d-95b3-cfb2d2515edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-00de6b28-f884-4424-99e5-4bb04f0e38e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-1f921743-18b7-48ec-a33c-8cf57ab7b790,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-fbbbea90-583f-4428-8906-4e592abeed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-5a95ea53-e8bd-4bcd-8d92-35ed557dd155,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-bf3f182b-4fc7-44f3-bff7-6a1af8a0b24f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337920965-172.17.0.16-1598545246789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-dee813e8-771c-438c-b830-4095a368e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8f2ccdce-678e-45ac-95c8-07c810c24ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2468abc9-a194-419d-95b3-cfb2d2515edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-00de6b28-f884-4424-99e5-4bb04f0e38e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-1f921743-18b7-48ec-a33c-8cf57ab7b790,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-fbbbea90-583f-4428-8906-4e592abeed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-5a95ea53-e8bd-4bcd-8d92-35ed557dd155,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-bf3f182b-4fc7-44f3-bff7-6a1af8a0b24f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85620310-172.17.0.16-1598545352634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-f26aa7a1-5cf3-432b-821e-e193242bb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-0d3e43de-96c7-4e8a-ba69-4e27bb874092,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8f742ed7-0061-4a7e-8880-38159c6c52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2e65eed5-0232-4833-8d0c-6c233a88d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-25424f8c-78b0-4084-9a7b-35ae51d75400,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-c1413df0-62b2-4a0b-b8f7-f629a4b492bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-127b6d9f-2876-4aa1-9091-25d56ccdb790,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-fc2e7732-bc85-460c-b130-2082e6325e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85620310-172.17.0.16-1598545352634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-f26aa7a1-5cf3-432b-821e-e193242bb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-0d3e43de-96c7-4e8a-ba69-4e27bb874092,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8f742ed7-0061-4a7e-8880-38159c6c52ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-2e65eed5-0232-4833-8d0c-6c233a88d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-25424f8c-78b0-4084-9a7b-35ae51d75400,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-c1413df0-62b2-4a0b-b8f7-f629a4b492bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-127b6d9f-2876-4aa1-9091-25d56ccdb790,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-fc2e7732-bc85-460c-b130-2082e6325e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125024469-172.17.0.16-1598545628911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36913,DS-d8326e9b-e19f-4448-ab02-89a9d4a82c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-d6ba11cb-8c47-4c4a-8963-3d2ae3f2af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-d778cdff-29b8-4a94-ac36-92b44bbac64f,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-2926a797-c839-4313-9ad8-96c3981173dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-bc23dddb-bdf2-4860-aa74-0ccb29a33efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-37355ef7-7430-497c-9f8a-58b944d3f315,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-5c1db6f3-4230-4617-a05c-16bce94d2721,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-813ca93e-a552-41ad-8304-3daf2ff69e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125024469-172.17.0.16-1598545628911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36913,DS-d8326e9b-e19f-4448-ab02-89a9d4a82c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-d6ba11cb-8c47-4c4a-8963-3d2ae3f2af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-d778cdff-29b8-4a94-ac36-92b44bbac64f,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-2926a797-c839-4313-9ad8-96c3981173dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-bc23dddb-bdf2-4860-aa74-0ccb29a33efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-37355ef7-7430-497c-9f8a-58b944d3f315,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-5c1db6f3-4230-4617-a05c-16bce94d2721,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-813ca93e-a552-41ad-8304-3daf2ff69e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559333963-172.17.0.16-1598545658181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-5049d257-cdcc-4d18-bb07-a6ee0e33fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-02e42712-b2cd-4b5b-8346-62a9890d8fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-33734378-4994-43bc-bf98-e47c3428b554,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-b9715e54-92ad-4d71-a8da-b65a1068c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-81b090e5-c081-493a-85b5-0f3dec023a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-c70e8940-20f6-4aac-af6e-39d909dbd9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-1c701656-db0d-47c6-aaa5-71565af3f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3a6b5232-53be-4524-a06b-d62069eacc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559333963-172.17.0.16-1598545658181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-5049d257-cdcc-4d18-bb07-a6ee0e33fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-02e42712-b2cd-4b5b-8346-62a9890d8fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-33734378-4994-43bc-bf98-e47c3428b554,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-b9715e54-92ad-4d71-a8da-b65a1068c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-81b090e5-c081-493a-85b5-0f3dec023a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-c70e8940-20f6-4aac-af6e-39d909dbd9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-1c701656-db0d-47c6-aaa5-71565af3f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3a6b5232-53be-4524-a06b-d62069eacc45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064200267-172.17.0.16-1598546209889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-dc632f97-65b4-4670-859d-5abc52456377,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-bb82c682-cfab-4a30-b661-0cca31de586a,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-ec325110-e393-4cde-b0a8-63a6f56aabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-664200b3-334b-43e5-9672-bd0c327825a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-cc4a3271-5439-490e-993b-cd4fbabec2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-99e90bb0-a6bc-4ba6-bfa2-4de4d1fa6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-ac369a61-f705-4d97-ba7b-13606d990b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-de3264ab-5f0d-4a5f-8201-a4c4f20734cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064200267-172.17.0.16-1598546209889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-dc632f97-65b4-4670-859d-5abc52456377,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-bb82c682-cfab-4a30-b661-0cca31de586a,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-ec325110-e393-4cde-b0a8-63a6f56aabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-664200b3-334b-43e5-9672-bd0c327825a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-cc4a3271-5439-490e-993b-cd4fbabec2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-99e90bb0-a6bc-4ba6-bfa2-4de4d1fa6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-ac369a61-f705-4d97-ba7b-13606d990b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-de3264ab-5f0d-4a5f-8201-a4c4f20734cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876428555-172.17.0.16-1598546369204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-7e69bf72-6025-4636-875b-9e7dbfd930e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-bbd42356-ad70-4966-b376-fc48845745f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-83539a46-eed4-4cb2-8492-5e9c4dfe148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-1fcdfb8c-eb58-4bb8-8a67-e626056a7b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-6ae6ee81-d2ce-43e9-a8a8-62d98c53490a,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-5d3de9f3-428a-4c26-9fb3-5f6aee8ea0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-d19ca894-202f-4368-b410-e4a960ebb5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-8fa7fd6f-b8fa-4afd-8cf8-f89f89b5ea42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876428555-172.17.0.16-1598546369204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-7e69bf72-6025-4636-875b-9e7dbfd930e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-bbd42356-ad70-4966-b376-fc48845745f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-83539a46-eed4-4cb2-8492-5e9c4dfe148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-1fcdfb8c-eb58-4bb8-8a67-e626056a7b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-6ae6ee81-d2ce-43e9-a8a8-62d98c53490a,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-5d3de9f3-428a-4c26-9fb3-5f6aee8ea0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-d19ca894-202f-4368-b410-e4a960ebb5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-8fa7fd6f-b8fa-4afd-8cf8-f89f89b5ea42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308323337-172.17.0.16-1598546450098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41650,DS-0a989d61-f166-4170-83e6-0012279bf14e,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-8cbd9ad5-717c-4522-9ab5-ad5a6a3a4d38,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-051e6de3-28e7-47a9-ace8-579d3bbf7351,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-079fcd87-7922-4d99-b43e-06f48bbacb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-c81e9426-db18-48f3-baf6-ef7d1f008c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-7401eb07-18de-4827-9896-5682c5463f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-f7705d2d-ba57-4a68-ab77-521fd35927b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-16e58d37-4089-44b3-ac3b-ba33f1073f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308323337-172.17.0.16-1598546450098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41650,DS-0a989d61-f166-4170-83e6-0012279bf14e,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-8cbd9ad5-717c-4522-9ab5-ad5a6a3a4d38,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-051e6de3-28e7-47a9-ace8-579d3bbf7351,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-079fcd87-7922-4d99-b43e-06f48bbacb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-c81e9426-db18-48f3-baf6-ef7d1f008c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-7401eb07-18de-4827-9896-5682c5463f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-f7705d2d-ba57-4a68-ab77-521fd35927b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-16e58d37-4089-44b3-ac3b-ba33f1073f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734620313-172.17.0.16-1598546491230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-399e5595-898e-4921-9238-ecdb75b87095,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-a8bdfec3-dcc2-4452-ac1e-1f14a3bd9929,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-c84b2b98-8aaf-4b40-8f62-5012c68ee54c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-ac2e4d49-c795-475c-8980-aff5156cbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-30c7a4e7-d8db-4bc0-a7a5-6652082ebb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5f486a1c-e7db-4e3d-8848-8b416286a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-64cb293e-1e2e-4b99-8b58-c568d96efe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-d13ffdb2-656f-40f9-9bfe-5077edb881fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734620313-172.17.0.16-1598546491230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44309,DS-399e5595-898e-4921-9238-ecdb75b87095,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-a8bdfec3-dcc2-4452-ac1e-1f14a3bd9929,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-c84b2b98-8aaf-4b40-8f62-5012c68ee54c,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-ac2e4d49-c795-475c-8980-aff5156cbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-30c7a4e7-d8db-4bc0-a7a5-6652082ebb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5f486a1c-e7db-4e3d-8848-8b416286a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-64cb293e-1e2e-4b99-8b58-c568d96efe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-d13ffdb2-656f-40f9-9bfe-5077edb881fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704699197-172.17.0.16-1598546607313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33264,DS-d8f4a012-285e-4b3b-be1f-2483ecebf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-73ac6319-78cc-4c80-b108-0fa29fefc17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-32863749-8f76-4f0e-ac4e-42016125d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c58b0cfd-6854-4150-9da9-b8dc6e64e629,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-60104dfb-069b-4657-9452-36846cb75065,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-b9606bf0-f56b-4c8e-8f50-eb690c4675e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-dadd6987-6766-475a-b300-6226cb259a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-cc6b474a-655a-4305-a779-8155c5c17205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704699197-172.17.0.16-1598546607313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33264,DS-d8f4a012-285e-4b3b-be1f-2483ecebf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-73ac6319-78cc-4c80-b108-0fa29fefc17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-32863749-8f76-4f0e-ac4e-42016125d06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c58b0cfd-6854-4150-9da9-b8dc6e64e629,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-60104dfb-069b-4657-9452-36846cb75065,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-b9606bf0-f56b-4c8e-8f50-eb690c4675e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-dadd6987-6766-475a-b300-6226cb259a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-cc6b474a-655a-4305-a779-8155c5c17205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294496828-172.17.0.16-1598547111399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-8ef85e7e-31a9-4de5-91da-1a353eb96bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-46c86971-d5bc-45be-b8e5-a463a6ea38f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-53dfa48a-d0ab-4c98-9c1c-04a6fa381893,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5a4d4e5d-39ff-4e8a-a501-949e275c0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-81b34687-a100-4cc0-9733-e86299bd9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b757a616-2c7a-483a-b25a-f78723815589,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-fc13f521-e656-473c-89e6-4a291c5d5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cf8b8f06-2d11-45ac-ba1f-66bc331c0bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294496828-172.17.0.16-1598547111399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-8ef85e7e-31a9-4de5-91da-1a353eb96bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-46c86971-d5bc-45be-b8e5-a463a6ea38f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-53dfa48a-d0ab-4c98-9c1c-04a6fa381893,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5a4d4e5d-39ff-4e8a-a501-949e275c0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-81b34687-a100-4cc0-9733-e86299bd9f10,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b757a616-2c7a-483a-b25a-f78723815589,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-fc13f521-e656-473c-89e6-4a291c5d5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-cf8b8f06-2d11-45ac-ba1f-66bc331c0bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253986313-172.17.0.16-1598547150675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e4bc6101-c55f-4a9c-ad2b-36ee1f6bdcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-43855fd1-994b-45bc-a50a-dcfec12af836,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-dfbc741c-cc92-4247-8ab1-14d11b80dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-98bcb673-cd0d-4e02-9709-f8b1380bd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-49f519bf-6d40-4b80-bbba-8152c24093a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-0f50f763-3670-45e9-9599-c38bf3d4854c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-28a4e9eb-3714-47d4-a803-8402d2333bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-d9633259-b9e7-471c-a6a4-c859d6aa8db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253986313-172.17.0.16-1598547150675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e4bc6101-c55f-4a9c-ad2b-36ee1f6bdcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-43855fd1-994b-45bc-a50a-dcfec12af836,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-dfbc741c-cc92-4247-8ab1-14d11b80dba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-98bcb673-cd0d-4e02-9709-f8b1380bd1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-49f519bf-6d40-4b80-bbba-8152c24093a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-0f50f763-3670-45e9-9599-c38bf3d4854c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-28a4e9eb-3714-47d4-a803-8402d2333bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-d9633259-b9e7-471c-a6a4-c859d6aa8db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884102730-172.17.0.16-1598547215137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-bd99e59f-0242-4514-a04a-747905a391b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-1400f620-0765-4cbe-8922-7fe14683a790,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-906673af-3025-471e-a41f-b05b02367ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-78bebd88-b2a4-43c2-80b4-69cdf841d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-0d58da72-c90a-4c3f-b1cb-fc0fb1f256d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-151f234a-6605-4b8b-99a7-829ee5563a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-3be0d483-03df-450d-aa6b-8b6585ee8c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-8436e84f-a0cd-4be9-ac0c-4ad35a5dc921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884102730-172.17.0.16-1598547215137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-bd99e59f-0242-4514-a04a-747905a391b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-1400f620-0765-4cbe-8922-7fe14683a790,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-906673af-3025-471e-a41f-b05b02367ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-78bebd88-b2a4-43c2-80b4-69cdf841d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-0d58da72-c90a-4c3f-b1cb-fc0fb1f256d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-151f234a-6605-4b8b-99a7-829ee5563a54,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-3be0d483-03df-450d-aa6b-8b6585ee8c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-8436e84f-a0cd-4be9-ac0c-4ad35a5dc921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068726595-172.17.0.16-1598547294346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-446d2f38-71d3-43e8-823f-6e8e7e97acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-75ebb439-84da-4e99-a560-aa2496fe3895,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-485a9c1a-2da7-46d3-b80d-c6190c7dc5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-87790aea-0bb7-443b-bbeb-34d0a05c5210,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-602fe43e-15a4-4416-b00c-2cfd7b053f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-2033a5b5-72d3-43e8-bfd7-32577b3a435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-b17bf908-c7dc-4a6d-ab2d-5421ddd43cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-01a41c43-d6bd-4cc2-9d6a-8b8f2cbd6343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068726595-172.17.0.16-1598547294346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-446d2f38-71d3-43e8-823f-6e8e7e97acd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-75ebb439-84da-4e99-a560-aa2496fe3895,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-485a9c1a-2da7-46d3-b80d-c6190c7dc5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-87790aea-0bb7-443b-bbeb-34d0a05c5210,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-602fe43e-15a4-4416-b00c-2cfd7b053f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-2033a5b5-72d3-43e8-bfd7-32577b3a435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-b17bf908-c7dc-4a6d-ab2d-5421ddd43cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-01a41c43-d6bd-4cc2-9d6a-8b8f2cbd6343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050448158-172.17.0.16-1598547330500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-bbafdbf0-e235-4146-a438-8baf297b7ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-e9aad678-9bf1-4930-a603-284b60947a75,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0f22f7ba-1b4d-4fda-a776-49726bae6a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-73b68ecc-7d51-432b-8ac8-5f21d8e74fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-3a5cb04e-2be7-40c0-906e-ff29f06c17c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-552a0751-ddb9-421b-867e-176f5814e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-e4074e8a-1e6a-47a8-9245-210aa1326443,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-399770f8-f0a1-4fed-9a71-222ebe522b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050448158-172.17.0.16-1598547330500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-bbafdbf0-e235-4146-a438-8baf297b7ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-e9aad678-9bf1-4930-a603-284b60947a75,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0f22f7ba-1b4d-4fda-a776-49726bae6a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-73b68ecc-7d51-432b-8ac8-5f21d8e74fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-3a5cb04e-2be7-40c0-906e-ff29f06c17c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-552a0751-ddb9-421b-867e-176f5814e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-e4074e8a-1e6a-47a8-9245-210aa1326443,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-399770f8-f0a1-4fed-9a71-222ebe522b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074836076-172.17.0.16-1598547415880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-ef2f1b05-d426-42e5-a7d3-6b14eb9e4f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-50711758-7bf8-4041-a00b-dea1f1f4d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a4d04c85-a4c5-402f-b833-73c35f042814,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-3f725d9b-0dbd-4806-82a8-45b52e1fdc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-465fb0ff-5eb6-4c35-8ffb-6c4070922aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-ea1de9d7-810d-468e-877f-5fdcee8bd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-d3ff4b6a-611f-44e4-8b5a-8f036905d213,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-baca9d3f-7a61-4b09-90f8-80dd5646cf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074836076-172.17.0.16-1598547415880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-ef2f1b05-d426-42e5-a7d3-6b14eb9e4f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-50711758-7bf8-4041-a00b-dea1f1f4d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-a4d04c85-a4c5-402f-b833-73c35f042814,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-3f725d9b-0dbd-4806-82a8-45b52e1fdc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-465fb0ff-5eb6-4c35-8ffb-6c4070922aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-ea1de9d7-810d-468e-877f-5fdcee8bd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-d3ff4b6a-611f-44e4-8b5a-8f036905d213,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-baca9d3f-7a61-4b09-90f8-80dd5646cf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820196868-172.17.0.16-1598547606786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42198,DS-68b26a8b-46c7-4e98-880c-77f2025be5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-a5651245-3dd0-4ef7-943e-dccf228b8385,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-55e43132-09f2-424c-861e-c23f8da38597,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-eb87c356-0d83-4101-b625-04a0fcadaff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-c6258a9b-bdf2-4289-a347-5f1a41b2218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-99228e9d-48ff-49dc-8bac-8e39dd54f41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-91422c25-6579-45bd-a113-4522697dacea,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-9c419517-c0ff-4cbd-ba43-36853cc63933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820196868-172.17.0.16-1598547606786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42198,DS-68b26a8b-46c7-4e98-880c-77f2025be5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-a5651245-3dd0-4ef7-943e-dccf228b8385,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-55e43132-09f2-424c-861e-c23f8da38597,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-eb87c356-0d83-4101-b625-04a0fcadaff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-c6258a9b-bdf2-4289-a347-5f1a41b2218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-99228e9d-48ff-49dc-8bac-8e39dd54f41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-91422c25-6579-45bd-a113-4522697dacea,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-9c419517-c0ff-4cbd-ba43-36853cc63933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669014113-172.17.0.16-1598547886149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-b0322bc5-4c92-4656-9811-f3bcceacf084,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-cfd2ba6f-3f08-496e-b14b-a5392a44e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-1e62a994-0fba-4def-865a-1783011dfd44,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-36ed0e4d-da96-46b8-9d2e-1f35f9c0f9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-4284b38a-dd39-406f-9b6c-1a296d7c62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-f0e48fd4-98bc-4c44-966a-aedb8d510f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-4f16dc3e-c6ab-43e4-bf22-2f9619c4a7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-5aafd42d-b7ae-4519-81f5-7f028c1544ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669014113-172.17.0.16-1598547886149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-b0322bc5-4c92-4656-9811-f3bcceacf084,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-cfd2ba6f-3f08-496e-b14b-a5392a44e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-1e62a994-0fba-4def-865a-1783011dfd44,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-36ed0e4d-da96-46b8-9d2e-1f35f9c0f9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-4284b38a-dd39-406f-9b6c-1a296d7c62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-f0e48fd4-98bc-4c44-966a-aedb8d510f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-4f16dc3e-c6ab-43e4-bf22-2f9619c4a7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-5aafd42d-b7ae-4519-81f5-7f028c1544ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260007931-172.17.0.16-1598548050844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-e0a077b5-4d41-4d6d-8e6e-01adf4807120,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-202f80d4-4782-414d-8cc0-9d3e0452588e,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-e177a114-3a43-4153-9391-dd114431da89,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-644cc285-73c7-4e5d-9ab4-044042111032,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-9837a957-ed25-4353-9095-096f47220c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-7f95204d-cdb6-4827-84af-074efe6d69fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-f1e7197c-585c-4974-90a9-d45656d786f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-b54631fc-422a-4d90-9a6f-d5fecfd47255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260007931-172.17.0.16-1598548050844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-e0a077b5-4d41-4d6d-8e6e-01adf4807120,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-202f80d4-4782-414d-8cc0-9d3e0452588e,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-e177a114-3a43-4153-9391-dd114431da89,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-644cc285-73c7-4e5d-9ab4-044042111032,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-9837a957-ed25-4353-9095-096f47220c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-7f95204d-cdb6-4827-84af-074efe6d69fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-f1e7197c-585c-4974-90a9-d45656d786f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-b54631fc-422a-4d90-9a6f-d5fecfd47255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643753962-172.17.0.16-1598548561170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-a23732b8-f799-4a84-bdee-b218cbd64506,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-30589fcb-9fc8-4527-8821-133ec2f30291,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-09178314-0139-4440-aec3-6c24f562ca32,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-d063c983-778c-426b-8d08-ea61b848f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-838da229-7620-44e8-8ff6-5e18d2cea69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-57698a3e-ef08-43cd-a65b-92b169d79c81,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-2d69bb65-c3c3-4be6-a820-ea015a74fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-5fab3a11-7207-47bd-b59a-6afe53f13538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643753962-172.17.0.16-1598548561170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-a23732b8-f799-4a84-bdee-b218cbd64506,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-30589fcb-9fc8-4527-8821-133ec2f30291,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-09178314-0139-4440-aec3-6c24f562ca32,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-d063c983-778c-426b-8d08-ea61b848f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-838da229-7620-44e8-8ff6-5e18d2cea69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-57698a3e-ef08-43cd-a65b-92b169d79c81,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-2d69bb65-c3c3-4be6-a820-ea015a74fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-5fab3a11-7207-47bd-b59a-6afe53f13538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5572
