reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753658950-172.17.0.16-1598521759196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-a20d30a8-f9eb-4ba6-a32d-c8a159029b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-668e3b7f-008c-4733-8d1b-87ff8bc4e200,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-de9c4084-bd1f-42a3-bc20-cdcb6ed8065b,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1f89b131-e0fa-4cd8-aee7-80be94d1a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-9a83530f-0f00-44d0-8655-cb551b64ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-5c1e2209-01aa-4c93-a8b2-89d3769fe532,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-abe76ca0-f1e8-44e7-aa5f-0cf365b6aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-bfab3523-fec0-46fc-8589-bed139a39680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753658950-172.17.0.16-1598521759196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-a20d30a8-f9eb-4ba6-a32d-c8a159029b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-668e3b7f-008c-4733-8d1b-87ff8bc4e200,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-de9c4084-bd1f-42a3-bc20-cdcb6ed8065b,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1f89b131-e0fa-4cd8-aee7-80be94d1a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-9a83530f-0f00-44d0-8655-cb551b64ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-5c1e2209-01aa-4c93-a8b2-89d3769fe532,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-abe76ca0-f1e8-44e7-aa5f-0cf365b6aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-bfab3523-fec0-46fc-8589-bed139a39680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057855820-172.17.0.16-1598521985589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-714d3f4a-dd48-4dca-9b8d-a06db7056605,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-e71d9f31-c280-4ee4-993e-f6c945c37aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-03b7aff8-9f46-4020-a411-ab01c4365125,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-8da2d308-0982-4ff2-80a1-007912849f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-5c60bb04-baec-4ba6-bc44-1975c5fc84bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-dfcc5689-9492-40e4-8e00-30aae56516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-72d8dd68-0d3d-4770-9f80-6314e481ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-3d2e353d-76b7-4df8-a9a5-9c11d1e22740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057855820-172.17.0.16-1598521985589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-714d3f4a-dd48-4dca-9b8d-a06db7056605,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-e71d9f31-c280-4ee4-993e-f6c945c37aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-03b7aff8-9f46-4020-a411-ab01c4365125,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-8da2d308-0982-4ff2-80a1-007912849f03,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-5c60bb04-baec-4ba6-bc44-1975c5fc84bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-dfcc5689-9492-40e4-8e00-30aae56516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-72d8dd68-0d3d-4770-9f80-6314e481ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-3d2e353d-76b7-4df8-a9a5-9c11d1e22740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455478452-172.17.0.16-1598522170891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-1686730d-3bcd-4ebd-8436-dc2a8c7bb3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-f6415504-b0ef-471c-8b54-06e502e326f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-9ee763e1-d7c3-458c-9440-16a9fbadde5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-73a73a5b-41f9-4e0d-8966-56684fba2d60,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-13c6b798-235a-4f19-a8f3-6b0e4c651ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-b554e8ad-aed1-4fd2-b96d-652eacc3909f,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-81faa262-988a-4aa5-8901-5964500f9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-b1cf71f9-87d8-4493-ac84-c375f1ebdb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455478452-172.17.0.16-1598522170891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-1686730d-3bcd-4ebd-8436-dc2a8c7bb3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-f6415504-b0ef-471c-8b54-06e502e326f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-9ee763e1-d7c3-458c-9440-16a9fbadde5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-73a73a5b-41f9-4e0d-8966-56684fba2d60,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-13c6b798-235a-4f19-a8f3-6b0e4c651ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-b554e8ad-aed1-4fd2-b96d-652eacc3909f,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-81faa262-988a-4aa5-8901-5964500f9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-b1cf71f9-87d8-4493-ac84-c375f1ebdb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419548958-172.17.0.16-1598522240991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-8056f0cb-752c-4e15-b584-8bbdcd5ba54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-1564d8f6-7ce3-4024-9388-8e1cc9760bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-6b6d6746-87cd-40d9-bb7e-a32af1bb94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-78a4c1e2-5161-4e7e-934e-2b2c218884dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-3f7eb99c-9fee-4701-a155-85d3f5302ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-60006a29-d2ad-44ab-8fe7-2db1d69355ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-cee8e715-556d-4a7d-8f84-319657f81c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-2d554036-deac-443f-9d50-fe518f1e8038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419548958-172.17.0.16-1598522240991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-8056f0cb-752c-4e15-b584-8bbdcd5ba54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-1564d8f6-7ce3-4024-9388-8e1cc9760bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-6b6d6746-87cd-40d9-bb7e-a32af1bb94d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-78a4c1e2-5161-4e7e-934e-2b2c218884dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-3f7eb99c-9fee-4701-a155-85d3f5302ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-60006a29-d2ad-44ab-8fe7-2db1d69355ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-cee8e715-556d-4a7d-8f84-319657f81c01,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-2d554036-deac-443f-9d50-fe518f1e8038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432614564-172.17.0.16-1598522395711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-e9826813-bb0b-4b17-88c3-418ccda07438,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-4e2d2b74-d2d2-42d1-9c0d-ddd2ab897a75,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-bcf409b6-d48f-4176-bc97-ffa8ba722103,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-5203ec00-02fc-42dd-9ff0-d2cc34a5d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-285a0b1e-d6d8-4ca0-93ac-e29e032b1127,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-35324ebd-a118-419d-a943-7829166d5bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-043942ec-3784-43a7-bbca-1f7bc096c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-ea51d985-a9eb-4123-9b15-67c9e565aa08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432614564-172.17.0.16-1598522395711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-e9826813-bb0b-4b17-88c3-418ccda07438,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-4e2d2b74-d2d2-42d1-9c0d-ddd2ab897a75,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-bcf409b6-d48f-4176-bc97-ffa8ba722103,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-5203ec00-02fc-42dd-9ff0-d2cc34a5d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-285a0b1e-d6d8-4ca0-93ac-e29e032b1127,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-35324ebd-a118-419d-a943-7829166d5bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-043942ec-3784-43a7-bbca-1f7bc096c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-ea51d985-a9eb-4123-9b15-67c9e565aa08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195687033-172.17.0.16-1598522887607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34136,DS-226b8b1c-08e5-48f6-95d8-ea3797c45f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-80efccb9-4b4e-48b4-a72c-4a6a9a0d7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-d32608e3-64c2-4db4-a111-44fd8ea27b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-5d90317f-8111-40d0-b89c-048446e32d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-ef9ff285-179d-46bc-82f8-bbc708f034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-a8e0fcf9-b8a4-42e6-bf90-28dedb4048fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-5e104424-80d5-4333-84a8-4dca81005d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-c1113e19-736e-4b64-ad55-a06517b80371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195687033-172.17.0.16-1598522887607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34136,DS-226b8b1c-08e5-48f6-95d8-ea3797c45f80,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-80efccb9-4b4e-48b4-a72c-4a6a9a0d7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-d32608e3-64c2-4db4-a111-44fd8ea27b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-5d90317f-8111-40d0-b89c-048446e32d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-ef9ff285-179d-46bc-82f8-bbc708f034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-a8e0fcf9-b8a4-42e6-bf90-28dedb4048fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-5e104424-80d5-4333-84a8-4dca81005d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-c1113e19-736e-4b64-ad55-a06517b80371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916300366-172.17.0.16-1598523365938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-577d7434-bfe2-4620-956a-d06754d76fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-c2d12343-56d9-4433-908b-9b3425905464,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-78675d18-244f-40df-a410-7d0e450f2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-9fdba64f-92ce-4bcc-a467-32cdc3a957f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-f158dba7-5575-46e8-92a6-90d814b27c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-848552e2-b248-4c77-b011-f14a6ba65491,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-2b38efe9-5a73-4bc6-adce-c6b91269ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-feaf8e57-f891-4fd3-a1ed-4e50709222d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916300366-172.17.0.16-1598523365938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-577d7434-bfe2-4620-956a-d06754d76fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-c2d12343-56d9-4433-908b-9b3425905464,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-78675d18-244f-40df-a410-7d0e450f2b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-9fdba64f-92ce-4bcc-a467-32cdc3a957f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-f158dba7-5575-46e8-92a6-90d814b27c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-848552e2-b248-4c77-b011-f14a6ba65491,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-2b38efe9-5a73-4bc6-adce-c6b91269ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-feaf8e57-f891-4fd3-a1ed-4e50709222d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202418214-172.17.0.16-1598523517593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-0b1b472c-7f93-4b19-ab43-56b1b49e28df,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a69961e1-7b85-45bf-be09-6c31f2afc89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b857b95d-842f-45f3-8239-4613edb40432,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-126fd1ed-5ef4-4569-b5f4-c8cb5e06648e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-deb61865-36d5-4c41-8747-d8ce7a3acafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-9ee4f316-ec15-4db8-ba5e-77ddcc70a7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6b8c8804-b45b-4ea0-95b8-3bea17f66ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-45416899-ac53-436c-ae0b-2bc9e023a884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202418214-172.17.0.16-1598523517593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-0b1b472c-7f93-4b19-ab43-56b1b49e28df,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a69961e1-7b85-45bf-be09-6c31f2afc89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b857b95d-842f-45f3-8239-4613edb40432,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-126fd1ed-5ef4-4569-b5f4-c8cb5e06648e,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-deb61865-36d5-4c41-8747-d8ce7a3acafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-9ee4f316-ec15-4db8-ba5e-77ddcc70a7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-6b8c8804-b45b-4ea0-95b8-3bea17f66ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-45416899-ac53-436c-ae0b-2bc9e023a884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551408944-172.17.0.16-1598523763908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-fefcaca3-5588-4bad-9f81-5b2d36a1a169,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-46ac9626-02bf-41ba-a71b-a8783af84c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-c4e356e2-208e-4837-924b-b5eff043fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-9022fc81-8c16-4bba-979b-504b75eb89db,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-ab6a2a4c-fe64-4221-be0e-ecb561709dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-dd83789f-adde-47f2-8a32-753e8d604a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-cf2aadb9-9df1-42c0-8972-e165c5b45a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-d43548a1-c241-4b0f-b0db-ea7a4596b8a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551408944-172.17.0.16-1598523763908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38474,DS-fefcaca3-5588-4bad-9f81-5b2d36a1a169,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-46ac9626-02bf-41ba-a71b-a8783af84c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-c4e356e2-208e-4837-924b-b5eff043fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-9022fc81-8c16-4bba-979b-504b75eb89db,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-ab6a2a4c-fe64-4221-be0e-ecb561709dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-dd83789f-adde-47f2-8a32-753e8d604a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-cf2aadb9-9df1-42c0-8972-e165c5b45a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-d43548a1-c241-4b0f-b0db-ea7a4596b8a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24153218-172.17.0.16-1598523979410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45455,DS-fb7d79bf-e64c-4d14-80a6-4a3b559a2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-d3d88094-d597-429e-866e-8122cc326f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d656b22f-67a1-4f68-b9ae-122329f257e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-980090a3-2eb4-4cf1-9e81-813c3ef52ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-35677f27-8bee-4543-aab4-196ab68ff121,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-2232caac-90fe-44cb-b7a5-c169d0c39ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-f1ac8ed4-2738-4c53-9a9e-5cf228a2d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-ccb2dbe8-e465-4496-9729-6c43d89dd389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24153218-172.17.0.16-1598523979410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45455,DS-fb7d79bf-e64c-4d14-80a6-4a3b559a2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-d3d88094-d597-429e-866e-8122cc326f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d656b22f-67a1-4f68-b9ae-122329f257e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-980090a3-2eb4-4cf1-9e81-813c3ef52ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-35677f27-8bee-4543-aab4-196ab68ff121,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-2232caac-90fe-44cb-b7a5-c169d0c39ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-f1ac8ed4-2738-4c53-9a9e-5cf228a2d3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-ccb2dbe8-e465-4496-9729-6c43d89dd389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632058400-172.17.0.16-1598524016174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-d1d3ffb5-72ed-4f6c-930c-29af2ccc52d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-256eaed7-4490-4382-939a-bf5e0afd87d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-fdc769d0-6ee9-412c-9f23-d74284370a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-894b4625-ada5-4570-b5ec-8fe38b1fa645,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-87f655d7-5535-492d-8f61-ed466b97067e,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-ea307c56-8f13-4766-9947-f80b08d734a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-091f7811-b373-46d4-b864-b5a3205540d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-90e12a27-3362-45ac-8976-6d60819e61e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-632058400-172.17.0.16-1598524016174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-d1d3ffb5-72ed-4f6c-930c-29af2ccc52d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-256eaed7-4490-4382-939a-bf5e0afd87d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-fdc769d0-6ee9-412c-9f23-d74284370a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-894b4625-ada5-4570-b5ec-8fe38b1fa645,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-87f655d7-5535-492d-8f61-ed466b97067e,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-ea307c56-8f13-4766-9947-f80b08d734a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-091f7811-b373-46d4-b864-b5a3205540d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-90e12a27-3362-45ac-8976-6d60819e61e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251007689-172.17.0.16-1598524310257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-cb314552-0a49-4507-ba29-c5c9b6e1ab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-c047c8ee-6566-43e2-8c5c-9997e00d79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-4b54f78d-beb4-41e2-bc95-9e9431eae000,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-44c3b6c7-2e7a-4d07-ad49-6b24e5a562e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-df725b74-a011-4134-8412-54ff4c210839,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d9b21906-5010-4650-ad72-549cddd82c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-efac53f2-7ea3-4154-964d-0034ab94e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-19396439-b52d-4000-8d75-e19c422ad9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251007689-172.17.0.16-1598524310257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-cb314552-0a49-4507-ba29-c5c9b6e1ab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-c047c8ee-6566-43e2-8c5c-9997e00d79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-4b54f78d-beb4-41e2-bc95-9e9431eae000,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-44c3b6c7-2e7a-4d07-ad49-6b24e5a562e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-df725b74-a011-4134-8412-54ff4c210839,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d9b21906-5010-4650-ad72-549cddd82c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-efac53f2-7ea3-4154-964d-0034ab94e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-19396439-b52d-4000-8d75-e19c422ad9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223196308-172.17.0.16-1598524659760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-db7250bb-c01b-4518-abf5-ca45f80b5ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-464cb2ee-170a-4483-8564-49217e62aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-a8320fb7-aeb3-4fa7-a53a-9e04c6f46804,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-7851861d-1e42-4af6-9862-ad4020e78f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-780e0fee-029b-417e-9906-c4b13e30265d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-9fe1ec25-2c06-4913-bbc1-8549a1323190,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-68ebcf2d-4ede-4604-a53b-852eb25e412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cecf2294-739d-40ed-a120-ee7a4edfb88e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223196308-172.17.0.16-1598524659760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-db7250bb-c01b-4518-abf5-ca45f80b5ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-464cb2ee-170a-4483-8564-49217e62aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-a8320fb7-aeb3-4fa7-a53a-9e04c6f46804,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-7851861d-1e42-4af6-9862-ad4020e78f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-780e0fee-029b-417e-9906-c4b13e30265d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-9fe1ec25-2c06-4913-bbc1-8549a1323190,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-68ebcf2d-4ede-4604-a53b-852eb25e412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cecf2294-739d-40ed-a120-ee7a4edfb88e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892862628-172.17.0.16-1598524694998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-ff0ecfe4-1143-42f4-a3ae-8c2688b759eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-228b138b-dd0d-4ffa-bbba-59c5915115b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-3d0cd47a-3a42-4ed8-aa26-371bee4584d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2443a6f9-d528-4ce6-a665-3d097330eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-d7d60be8-cda5-49aa-a947-b46a2543d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b012c28b-7fbe-49f0-b643-c4bac0fbae52,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-7ce0fb54-22f8-4609-8ef8-1bb92888753e,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-6db16ace-4407-4c4b-abdc-0e5b42d8d94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892862628-172.17.0.16-1598524694998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-ff0ecfe4-1143-42f4-a3ae-8c2688b759eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-228b138b-dd0d-4ffa-bbba-59c5915115b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-3d0cd47a-3a42-4ed8-aa26-371bee4584d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2443a6f9-d528-4ce6-a665-3d097330eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-d7d60be8-cda5-49aa-a947-b46a2543d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b012c28b-7fbe-49f0-b643-c4bac0fbae52,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-7ce0fb54-22f8-4609-8ef8-1bb92888753e,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-6db16ace-4407-4c4b-abdc-0e5b42d8d94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24129603-172.17.0.16-1598525186739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-cb4a820a-ba4c-4347-b26c-e8cbea577d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-d443e752-4b6f-46b5-83c6-6d1d94cddf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-5bc7ba03-b892-4232-87e8-960c9af58b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-0db55b77-ab6c-4a86-9607-90564f4f4695,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e19dc978-1f27-4999-a485-469d2931acb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-fbcaefd9-9e1d-416b-ab40-66d86d73105b,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b4b6585e-a7b6-49dc-93be-c2bc7e02fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7d02b840-ea78-4e57-89ba-6bf4041a7ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24129603-172.17.0.16-1598525186739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-cb4a820a-ba4c-4347-b26c-e8cbea577d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-d443e752-4b6f-46b5-83c6-6d1d94cddf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-5bc7ba03-b892-4232-87e8-960c9af58b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-0db55b77-ab6c-4a86-9607-90564f4f4695,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-e19dc978-1f27-4999-a485-469d2931acb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-fbcaefd9-9e1d-416b-ab40-66d86d73105b,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b4b6585e-a7b6-49dc-93be-c2bc7e02fd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7d02b840-ea78-4e57-89ba-6bf4041a7ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345412745-172.17.0.16-1598525371519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-85d8af60-03c7-41e8-ba1c-7d02e0e90a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-49df53fb-fda9-4d86-8386-4a0292f5dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-da103e73-67c7-450b-b58f-a7410d1ad2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-f8ddf94e-40df-4f83-bbb6-7490179b9891,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-0db3e30c-94a7-4e65-8de3-23ab982457f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-55d3b8ac-b626-4373-be8c-3468fb1ac374,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-a681ad11-37b8-4a24-accb-000814400950,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-f502e0ec-5aac-4b88-8998-83cb05e35c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345412745-172.17.0.16-1598525371519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-85d8af60-03c7-41e8-ba1c-7d02e0e90a05,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-49df53fb-fda9-4d86-8386-4a0292f5dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-da103e73-67c7-450b-b58f-a7410d1ad2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-f8ddf94e-40df-4f83-bbb6-7490179b9891,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-0db3e30c-94a7-4e65-8de3-23ab982457f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-55d3b8ac-b626-4373-be8c-3468fb1ac374,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-a681ad11-37b8-4a24-accb-000814400950,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-f502e0ec-5aac-4b88-8998-83cb05e35c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499764228-172.17.0.16-1598525681436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-3638085e-76c1-4fba-9f21-1f7d557073d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-82897162-0498-4078-b279-3cbbb26ba929,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-1af5cfc2-bc21-45a3-827b-2ff1c0a72aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-bd6bcf23-02fa-4259-b2e8-eb25549e99d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-d6dea02d-7d36-44e9-a763-9e617d0e1aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-73fdf42f-9a0b-426f-9f01-4196d2ed5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-cfec2eb6-0870-4b54-bd31-0d8edf32dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-90d8a3a0-b35e-4c46-af10-e4638a83eda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499764228-172.17.0.16-1598525681436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42667,DS-3638085e-76c1-4fba-9f21-1f7d557073d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-82897162-0498-4078-b279-3cbbb26ba929,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-1af5cfc2-bc21-45a3-827b-2ff1c0a72aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-bd6bcf23-02fa-4259-b2e8-eb25549e99d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-d6dea02d-7d36-44e9-a763-9e617d0e1aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-73fdf42f-9a0b-426f-9f01-4196d2ed5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-cfec2eb6-0870-4b54-bd31-0d8edf32dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-90d8a3a0-b35e-4c46-af10-e4638a83eda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364932663-172.17.0.16-1598525926124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-9643102b-5262-4c70-a9e5-854f30c55f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-151c78e9-408e-41c6-be3d-4802a592d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-38921e73-66d6-4941-8559-e040e50d1212,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-17270d69-10c1-4895-9711-004847a6ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-d56d60c0-72a9-4b0b-9a53-4fca8f67733e,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-0ed7ee33-a216-4eb3-b05c-f8dcdf2d5bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-9a513467-1e69-4c6b-b7a5-5d61591664ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-5d79691f-91f8-40f1-b636-f728d0f2988e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364932663-172.17.0.16-1598525926124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-9643102b-5262-4c70-a9e5-854f30c55f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-151c78e9-408e-41c6-be3d-4802a592d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-38921e73-66d6-4941-8559-e040e50d1212,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-17270d69-10c1-4895-9711-004847a6ea7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-d56d60c0-72a9-4b0b-9a53-4fca8f67733e,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-0ed7ee33-a216-4eb3-b05c-f8dcdf2d5bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-9a513467-1e69-4c6b-b7a5-5d61591664ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-5d79691f-91f8-40f1-b636-f728d0f2988e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556273065-172.17.0.16-1598525995406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44244,DS-9f4b150d-a4bc-4844-bed9-801f606ee23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-6ad7e3fe-c893-457d-870b-80b343c092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-9e8a9d47-6519-4c58-b1de-a0810fd3cfef,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-7d49cd5f-4919-48f9-82c7-d3a27a37693f,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-e079a194-c729-480a-bd48-992a5f42318a,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-496214dd-9dfb-4a7c-9c9d-fbb22a3a10c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-1c6638dc-b162-448e-9570-bc7be4a511c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-9c2d79c4-a4fc-4e36-9b4c-e7657a5e2c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556273065-172.17.0.16-1598525995406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44244,DS-9f4b150d-a4bc-4844-bed9-801f606ee23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-6ad7e3fe-c893-457d-870b-80b343c092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-9e8a9d47-6519-4c58-b1de-a0810fd3cfef,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-7d49cd5f-4919-48f9-82c7-d3a27a37693f,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-e079a194-c729-480a-bd48-992a5f42318a,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-496214dd-9dfb-4a7c-9c9d-fbb22a3a10c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-1c6638dc-b162-448e-9570-bc7be4a511c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-9c2d79c4-a4fc-4e36-9b4c-e7657a5e2c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976755410-172.17.0.16-1598526091140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-c5b7c5bc-8cff-415c-b087-6e48f27760fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-067e42bf-e3b4-4f69-9883-965f1634577a,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-c6f73bce-aacd-4fec-bd69-3e12106329e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-0f71e50b-472f-4e7f-9b78-fcfb4461dcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f33c67b3-69a2-4531-97f4-cfa2cdb3f602,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-454e3eb3-8f95-49dd-8d11-98909ab3a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-813284e2-d1de-4b45-9648-f375f779c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-87864d11-e5e1-4b63-a9ce-845ac6be132c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976755410-172.17.0.16-1598526091140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-c5b7c5bc-8cff-415c-b087-6e48f27760fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-067e42bf-e3b4-4f69-9883-965f1634577a,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-c6f73bce-aacd-4fec-bd69-3e12106329e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-0f71e50b-472f-4e7f-9b78-fcfb4461dcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f33c67b3-69a2-4531-97f4-cfa2cdb3f602,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-454e3eb3-8f95-49dd-8d11-98909ab3a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-813284e2-d1de-4b45-9648-f375f779c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-87864d11-e5e1-4b63-a9ce-845ac6be132c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952406076-172.17.0.16-1598526164714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-d9438d35-e6ae-4bd4-9782-65f2f71360e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-1fbc3778-b683-4b86-8a76-280523c06644,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-fcf265f5-18fc-4530-a4cd-32f979b25819,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-57337ec1-6a52-4af0-bf6f-72e010f91a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-aad5fe2a-7d5b-4b44-8fb1-faa12fc0903e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-ed1465f9-24bd-4535-90ff-2c09ba64992a,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-a30c44bc-bc69-4602-9323-83103f2fef37,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-981854f9-6c5c-4ba7-bee6-86b789ca27ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952406076-172.17.0.16-1598526164714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-d9438d35-e6ae-4bd4-9782-65f2f71360e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-1fbc3778-b683-4b86-8a76-280523c06644,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-fcf265f5-18fc-4530-a4cd-32f979b25819,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-57337ec1-6a52-4af0-bf6f-72e010f91a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-aad5fe2a-7d5b-4b44-8fb1-faa12fc0903e,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-ed1465f9-24bd-4535-90ff-2c09ba64992a,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-a30c44bc-bc69-4602-9323-83103f2fef37,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-981854f9-6c5c-4ba7-bee6-86b789ca27ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5334
