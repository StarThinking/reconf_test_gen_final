reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710236852-172.17.0.10-1598635742580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-fe3ade5a-b7d9-414f-8eac-2ade16a46738,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-a135b29a-dae0-485c-ae0f-f8d17ce27bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-e706e02a-31d5-44bc-a48d-295ce44cd57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-fa0f6f56-f55d-4f29-a0e1-c1eaa0840379,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-b2a760c6-0673-4468-8eb2-6e2d8f9b9e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-d5613141-d271-43a8-b939-dd4c01662600,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-31543df2-bc53-4e71-8475-e768223ddc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-f5192ec0-a68a-434d-b346-cd7a286e91a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710236852-172.17.0.10-1598635742580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-fe3ade5a-b7d9-414f-8eac-2ade16a46738,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-a135b29a-dae0-485c-ae0f-f8d17ce27bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-e706e02a-31d5-44bc-a48d-295ce44cd57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-fa0f6f56-f55d-4f29-a0e1-c1eaa0840379,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-b2a760c6-0673-4468-8eb2-6e2d8f9b9e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-d5613141-d271-43a8-b939-dd4c01662600,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-31543df2-bc53-4e71-8475-e768223ddc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-f5192ec0-a68a-434d-b346-cd7a286e91a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276818603-172.17.0.10-1598635892768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-65f6c994-8295-4058-88f5-0b7164e1aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-46fe4803-1b65-4c55-97e3-9586e4c397b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-d01e5806-2ccd-41a8-a915-f9c577e8fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-baa71703-ffe4-4e9a-89c8-8c7b0515bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-dceabcab-c031-4a50-8ef1-3a4732168841,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-3575c569-9732-4e15-ab29-2cc529ecaf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-94f69f16-3452-44cc-8e01-7858645e67af,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9ae4e4c1-f7fc-4642-ad8c-508ce0e1e332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276818603-172.17.0.10-1598635892768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33621,DS-65f6c994-8295-4058-88f5-0b7164e1aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-46fe4803-1b65-4c55-97e3-9586e4c397b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-d01e5806-2ccd-41a8-a915-f9c577e8fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-baa71703-ffe4-4e9a-89c8-8c7b0515bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-dceabcab-c031-4a50-8ef1-3a4732168841,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-3575c569-9732-4e15-ab29-2cc529ecaf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-94f69f16-3452-44cc-8e01-7858645e67af,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9ae4e4c1-f7fc-4642-ad8c-508ce0e1e332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349954800-172.17.0.10-1598635963901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43793,DS-6b7fb559-9eae-4b33-a965-9b1110841a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-cd95facf-1cac-494a-b174-1fac96e23d49,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-f2145517-c7cc-416e-ad1c-f8c028141a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-8fe13dc7-2fa7-425b-96e6-e7c5cc13dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-72259b77-c9fb-44bb-ad6d-adc5405b156a,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-73f0c3e1-adc6-46eb-984f-9fc5192aa63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-4ae8171e-4274-48f9-9d9c-11116daaabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-3cfccb93-6412-4843-9892-790be22aaef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349954800-172.17.0.10-1598635963901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43793,DS-6b7fb559-9eae-4b33-a965-9b1110841a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-cd95facf-1cac-494a-b174-1fac96e23d49,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-f2145517-c7cc-416e-ad1c-f8c028141a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-8fe13dc7-2fa7-425b-96e6-e7c5cc13dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-72259b77-c9fb-44bb-ad6d-adc5405b156a,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-73f0c3e1-adc6-46eb-984f-9fc5192aa63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-4ae8171e-4274-48f9-9d9c-11116daaabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-3cfccb93-6412-4843-9892-790be22aaef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089335702-172.17.0.10-1598636294093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-2a391de5-de13-47ce-9346-5a3dad524962,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-8eaa0878-4a2d-4704-a6ab-9561449cf201,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-c4774083-ff0f-4db1-aaff-597d46f837f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-afd15ba7-06e0-4c53-ae43-9a531953cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-31800ba6-e1e5-4a95-8555-6482d8c47a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-dd0ee17c-b16a-4275-8968-d915b781dbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-61141552-184e-4255-a712-19795e076d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-fd3d1d14-32d5-45cc-97a0-8fde88847ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089335702-172.17.0.10-1598636294093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-2a391de5-de13-47ce-9346-5a3dad524962,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-8eaa0878-4a2d-4704-a6ab-9561449cf201,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-c4774083-ff0f-4db1-aaff-597d46f837f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-afd15ba7-06e0-4c53-ae43-9a531953cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-31800ba6-e1e5-4a95-8555-6482d8c47a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-dd0ee17c-b16a-4275-8968-d915b781dbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-61141552-184e-4255-a712-19795e076d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-fd3d1d14-32d5-45cc-97a0-8fde88847ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244223152-172.17.0.10-1598636331091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-0ab2fc5a-2097-49c8-8faa-b3e0c2c3ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-1d2b404a-7e6a-4270-9305-8d05772da0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-afee4c30-ddae-4b59-a08d-941866cdfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-cb417d0d-2851-498f-bf6e-f32b1ab0b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-983eca89-ebee-4d90-9631-f15c6ff6f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-4a7c94c9-a198-476c-8724-24af37b172b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-d051c0ed-617e-442b-bc29-8da7a8fa305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-7634be4b-7c8c-42a0-bae5-9dd5973b786f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244223152-172.17.0.10-1598636331091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-0ab2fc5a-2097-49c8-8faa-b3e0c2c3ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-1d2b404a-7e6a-4270-9305-8d05772da0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-afee4c30-ddae-4b59-a08d-941866cdfc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-cb417d0d-2851-498f-bf6e-f32b1ab0b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-983eca89-ebee-4d90-9631-f15c6ff6f73d,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-4a7c94c9-a198-476c-8724-24af37b172b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-d051c0ed-617e-442b-bc29-8da7a8fa305c,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-7634be4b-7c8c-42a0-bae5-9dd5973b786f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426573169-172.17.0.10-1598636672269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-3a04d8e1-6dba-4906-a39a-e7c8280ea0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-77889a38-4d21-4799-8867-046d7a36ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6896d0af-a8be-4430-b3c4-550f50db1910,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-8cd4e6b4-a9d7-461c-be8d-75c4e321cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-f853bc02-5058-4a7a-b5af-83d7ee3d4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-50fa1730-6d39-4a6b-ad37-82fde11d2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-6eb2923f-1635-431d-85fd-cc2e17184837,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-137674ae-9421-40a0-a073-33b536de302e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426573169-172.17.0.10-1598636672269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-3a04d8e1-6dba-4906-a39a-e7c8280ea0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-77889a38-4d21-4799-8867-046d7a36ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6896d0af-a8be-4430-b3c4-550f50db1910,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-8cd4e6b4-a9d7-461c-be8d-75c4e321cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-f853bc02-5058-4a7a-b5af-83d7ee3d4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-50fa1730-6d39-4a6b-ad37-82fde11d2603,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-6eb2923f-1635-431d-85fd-cc2e17184837,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-137674ae-9421-40a0-a073-33b536de302e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849009632-172.17.0.10-1598636786889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-d11fe1b2-3e23-429d-8bb2-db39e8681796,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2a56fa4c-92f2-458f-915e-75a730de4aab,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-19c309e1-1e6b-46f9-a88d-32d38b68c64f,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-1584312b-7b5e-4601-9534-232a6f955bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-68822090-6ef7-4e31-9f44-dc6c0d16ff4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-e096fe0d-2a98-4598-b874-801379552dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-3773498c-8669-4d9f-b5e9-bd33588405c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-dd4d20d0-82a9-4a5d-b8d4-d0cf3858c6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849009632-172.17.0.10-1598636786889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-d11fe1b2-3e23-429d-8bb2-db39e8681796,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2a56fa4c-92f2-458f-915e-75a730de4aab,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-19c309e1-1e6b-46f9-a88d-32d38b68c64f,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-1584312b-7b5e-4601-9534-232a6f955bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-68822090-6ef7-4e31-9f44-dc6c0d16ff4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-e096fe0d-2a98-4598-b874-801379552dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-3773498c-8669-4d9f-b5e9-bd33588405c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-dd4d20d0-82a9-4a5d-b8d4-d0cf3858c6bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229613370-172.17.0.10-1598637223592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-5e915c6c-0e87-4b0c-908e-1ee6e40ff12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-2b9d77d5-0b50-42cc-a731-b8f21934ed80,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-317da149-867a-4b2f-91fa-7423382d328b,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-1d675c7e-9579-44eb-a919-82df8240a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-f354ba1e-f362-427e-b179-cf1e939c0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-7e57cc48-169f-444f-9516-555b25256d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b1787eea-3874-409a-a0d1-a2e2b7b0b700,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-16ad6afa-33d5-49aa-91ed-674bf8e6b619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229613370-172.17.0.10-1598637223592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-5e915c6c-0e87-4b0c-908e-1ee6e40ff12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-2b9d77d5-0b50-42cc-a731-b8f21934ed80,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-317da149-867a-4b2f-91fa-7423382d328b,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-1d675c7e-9579-44eb-a919-82df8240a7da,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-f354ba1e-f362-427e-b179-cf1e939c0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-7e57cc48-169f-444f-9516-555b25256d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b1787eea-3874-409a-a0d1-a2e2b7b0b700,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-16ad6afa-33d5-49aa-91ed-674bf8e6b619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825080462-172.17.0.10-1598637339062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-42bfd614-5f60-4e8b-bb65-20562662b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-29f58dab-e4bd-4396-9785-3e9119d1a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-24113afe-ad5d-4433-b138-65965fd7ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-c2c3519e-30eb-4088-a7ce-4fd375c1b2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-5cea7a8f-2ed4-4b01-b6b8-f85f0e8b0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-735dd971-349a-4aa0-9b21-db7dd871d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-6fc641ce-3a8c-4ee9-a022-704040c1699e,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-28944a96-d0a0-4708-81ce-506b6c6261c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825080462-172.17.0.10-1598637339062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-42bfd614-5f60-4e8b-bb65-20562662b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-29f58dab-e4bd-4396-9785-3e9119d1a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-24113afe-ad5d-4433-b138-65965fd7ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-c2c3519e-30eb-4088-a7ce-4fd375c1b2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-5cea7a8f-2ed4-4b01-b6b8-f85f0e8b0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-735dd971-349a-4aa0-9b21-db7dd871d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-6fc641ce-3a8c-4ee9-a022-704040c1699e,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-28944a96-d0a0-4708-81ce-506b6c6261c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952156690-172.17.0.10-1598637675353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-371d27cf-b2c8-46b3-8347-312d426da6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-b50a6130-c028-46e4-a7f6-bbb785f588ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-7cfce0ff-f18c-47a0-82df-162a71a5d9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-fa28e037-417a-4a7b-861b-39c26ca91711,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-143775c9-e0cf-4ac1-afaf-10e891751afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-3a2d42e7-a233-405d-a3f9-6bf2109f629d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-afae0f36-ebf6-4d1e-9a30-553799c41fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-5da5da68-be1e-4db1-abe3-c609a68baac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952156690-172.17.0.10-1598637675353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-371d27cf-b2c8-46b3-8347-312d426da6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-b50a6130-c028-46e4-a7f6-bbb785f588ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-7cfce0ff-f18c-47a0-82df-162a71a5d9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-fa28e037-417a-4a7b-861b-39c26ca91711,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-143775c9-e0cf-4ac1-afaf-10e891751afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-3a2d42e7-a233-405d-a3f9-6bf2109f629d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-afae0f36-ebf6-4d1e-9a30-553799c41fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-5da5da68-be1e-4db1-abe3-c609a68baac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235369648-172.17.0.10-1598638212786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-1e99efd9-3987-4dc8-a9c6-a8fdaed6a021,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-565c3c86-8dba-479f-b536-c0ede781ca1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-f46205eb-5d2f-4fd9-9639-79b7263d7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2b25313e-962e-448b-9e5e-f07a64e4861a,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-04d80203-2196-4dee-aae1-859964240a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-635887c6-86ac-4775-89f0-99b9221d6323,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b1478e18-9dcd-42cd-84f0-495daf295048,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-1df2ab3f-5f02-4863-8690-267ee2e6c0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235369648-172.17.0.10-1598638212786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-1e99efd9-3987-4dc8-a9c6-a8fdaed6a021,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-565c3c86-8dba-479f-b536-c0ede781ca1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-f46205eb-5d2f-4fd9-9639-79b7263d7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-2b25313e-962e-448b-9e5e-f07a64e4861a,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-04d80203-2196-4dee-aae1-859964240a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-635887c6-86ac-4775-89f0-99b9221d6323,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b1478e18-9dcd-42cd-84f0-495daf295048,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-1df2ab3f-5f02-4863-8690-267ee2e6c0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685447212-172.17.0.10-1598638360278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-d5bb025a-8495-4f60-841f-29de2492ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-4d5008ba-47c5-45b6-b6bc-a351b79d48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-7a5a6897-b4c1-4929-89e4-d52196d1579e,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8e886671-ae46-4344-847a-b29b883cdaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-5086435c-0541-4181-8dce-04f7be30306d,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-78943d91-152b-494c-87fc-fcc894c4f3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-3b53b0c8-edcb-4134-8825-78d0e5cbf90f,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-7a71d76f-dd81-4b02-9b9c-dd3401c54efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685447212-172.17.0.10-1598638360278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35753,DS-d5bb025a-8495-4f60-841f-29de2492ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-4d5008ba-47c5-45b6-b6bc-a351b79d48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-7a5a6897-b4c1-4929-89e4-d52196d1579e,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-8e886671-ae46-4344-847a-b29b883cdaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-5086435c-0541-4181-8dce-04f7be30306d,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-78943d91-152b-494c-87fc-fcc894c4f3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-3b53b0c8-edcb-4134-8825-78d0e5cbf90f,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-7a71d76f-dd81-4b02-9b9c-dd3401c54efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645001130-172.17.0.10-1598638399063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-d42dc9c0-cbea-4cd5-adcc-467f4e95a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-8ddf1de3-e622-4db6-9a1b-8d53f57cb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-5212617a-137a-4061-8c42-3f06e8fcea90,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-11b6abd4-fc80-4b55-9e60-3ba0d41fa451,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-b87bcf54-a853-4c93-b89f-732bf1109b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-c8271462-398b-4a44-b657-8c540ebae9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-b06b7c48-8d66-4de2-b319-c07c984efea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-25349669-6f00-4d91-a54b-62c2a7d2d532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645001130-172.17.0.10-1598638399063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-d42dc9c0-cbea-4cd5-adcc-467f4e95a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-8ddf1de3-e622-4db6-9a1b-8d53f57cb3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-5212617a-137a-4061-8c42-3f06e8fcea90,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-11b6abd4-fc80-4b55-9e60-3ba0d41fa451,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-b87bcf54-a853-4c93-b89f-732bf1109b86,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-c8271462-398b-4a44-b657-8c540ebae9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-b06b7c48-8d66-4de2-b319-c07c984efea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-25349669-6f00-4d91-a54b-62c2a7d2d532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135528609-172.17.0.10-1598639149860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-30e62445-e98f-4dd7-a7f0-780e6239c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-9eece781-2be0-4f00-8c8f-75d8a91fd379,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-41921395-4c5a-4bee-a4b2-e5c7bcc1d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-90f1f577-1011-41dd-bc60-0203ed169ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c74d8afc-8a48-4a8f-9cb4-8493ffb21961,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-23f7ea82-9c1a-4162-9ca3-4c62ee6c2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-b19275c6-04c4-41db-962f-f0ce14b27648,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-4f1c3887-62c2-4b51-9dee-4481f928f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135528609-172.17.0.10-1598639149860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-30e62445-e98f-4dd7-a7f0-780e6239c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-9eece781-2be0-4f00-8c8f-75d8a91fd379,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-41921395-4c5a-4bee-a4b2-e5c7bcc1d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-90f1f577-1011-41dd-bc60-0203ed169ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-c74d8afc-8a48-4a8f-9cb4-8493ffb21961,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-23f7ea82-9c1a-4162-9ca3-4c62ee6c2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-b19275c6-04c4-41db-962f-f0ce14b27648,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-4f1c3887-62c2-4b51-9dee-4481f928f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938798691-172.17.0.10-1598639216703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-4e649c00-5b28-4539-8172-8db984af4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-dfebfe66-32de-4fdf-a767-20f12b3ba35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-2eb1141a-6342-4e58-bf72-d4d91a9ad0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-6d50a223-5b9b-40b6-ac76-6fc2e9233208,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-609141bc-6970-435e-9c80-b3e981ad1451,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2675981e-467b-4787-9102-ba983e5be85c,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-abcf612b-917b-47a2-adf9-7e3ff124ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-74614a14-f481-4b80-810d-ab6f4fb67e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938798691-172.17.0.10-1598639216703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40021,DS-4e649c00-5b28-4539-8172-8db984af4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-dfebfe66-32de-4fdf-a767-20f12b3ba35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-2eb1141a-6342-4e58-bf72-d4d91a9ad0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-6d50a223-5b9b-40b6-ac76-6fc2e9233208,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-609141bc-6970-435e-9c80-b3e981ad1451,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2675981e-467b-4787-9102-ba983e5be85c,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-abcf612b-917b-47a2-adf9-7e3ff124ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-74614a14-f481-4b80-810d-ab6f4fb67e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674273913-172.17.0.10-1598639553812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-b57f5bab-4d65-460a-9180-4eb8347cf317,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-97480496-9be3-4b1a-8436-3bb588c04a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5345f59a-70dd-435e-abac-53b2bdc9bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-753a30bc-3cce-4429-bfda-681fd0f16ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-7fdeabfd-08da-49c5-aede-10188c76645f,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-a9eb7f40-fffb-4354-bbfe-a7c49150a886,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-47f88275-3351-4eec-a3e7-69c1327ba6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-6aaa274a-208d-412b-96dd-121c6ac64d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674273913-172.17.0.10-1598639553812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35672,DS-b57f5bab-4d65-460a-9180-4eb8347cf317,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-97480496-9be3-4b1a-8436-3bb588c04a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-5345f59a-70dd-435e-abac-53b2bdc9bd61,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-753a30bc-3cce-4429-bfda-681fd0f16ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-7fdeabfd-08da-49c5-aede-10188c76645f,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-a9eb7f40-fffb-4354-bbfe-a7c49150a886,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-47f88275-3351-4eec-a3e7-69c1327ba6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-6aaa274a-208d-412b-96dd-121c6ac64d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565237318-172.17.0.10-1598639960052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-49435f5e-b75f-45c7-9981-47e61382bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-aee025fb-5ffa-4e42-95f0-c8bdf56533a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-11c4c242-ed97-47a0-b588-1f70f803084d,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-be2e1f72-3827-4ae3-83b9-45f2acec154b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-47b0ec77-99a0-467c-b35e-292dc9aafcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-37d0e7bf-3c1c-41ab-868a-12d9cc1e57e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-3b4edd6a-acac-4931-b8f6-b87e7671cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-72ed1dd9-34e1-4f66-9b6d-7428e01ad4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565237318-172.17.0.10-1598639960052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-49435f5e-b75f-45c7-9981-47e61382bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-aee025fb-5ffa-4e42-95f0-c8bdf56533a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-11c4c242-ed97-47a0-b588-1f70f803084d,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-be2e1f72-3827-4ae3-83b9-45f2acec154b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-47b0ec77-99a0-467c-b35e-292dc9aafcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-37d0e7bf-3c1c-41ab-868a-12d9cc1e57e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-3b4edd6a-acac-4931-b8f6-b87e7671cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-72ed1dd9-34e1-4f66-9b6d-7428e01ad4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29618094-172.17.0.10-1598640032947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45887,DS-3ab5f6ad-fdb3-45b8-8780-fdc50b5e1676,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-12b73d32-485c-404b-972d-5a040c22ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-bee50fd0-0b7b-4437-8924-ce4c8403c201,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-8e31f84c-2e56-4a5a-8637-80198767475c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-2880b1ab-88de-4fe2-844f-ee0f9837453a,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-e08ccf44-79bc-43ad-80b3-98b314688c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-8d8ea7a4-a27f-48a9-8962-9a0fef14391b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-3687373b-f83b-4ed3-bdd8-e8009f176c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29618094-172.17.0.10-1598640032947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45887,DS-3ab5f6ad-fdb3-45b8-8780-fdc50b5e1676,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-12b73d32-485c-404b-972d-5a040c22ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-bee50fd0-0b7b-4437-8924-ce4c8403c201,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-8e31f84c-2e56-4a5a-8637-80198767475c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-2880b1ab-88de-4fe2-844f-ee0f9837453a,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-e08ccf44-79bc-43ad-80b3-98b314688c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-8d8ea7a4-a27f-48a9-8962-9a0fef14391b,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-3687373b-f83b-4ed3-bdd8-e8009f176c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596089706-172.17.0.10-1598640582704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-20e1536c-382f-408e-8f90-be15ff3b46e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-9f781b93-5758-460f-b6a8-295b32b17031,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a5d3b6c5-5bcb-482a-b0e6-88c93c425ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-6d46f383-cbfe-4d36-a378-4d5ce81dfbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-ee513013-471c-4147-9325-cfe602b9de0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-78de061b-f4ee-4f94-933e-3d8f08880e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-6daef5fa-f810-47a5-a663-71f35fc09aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-18a0cab3-7346-400c-b1a9-5d5f93870a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596089706-172.17.0.10-1598640582704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-20e1536c-382f-408e-8f90-be15ff3b46e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-9f781b93-5758-460f-b6a8-295b32b17031,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a5d3b6c5-5bcb-482a-b0e6-88c93c425ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-6d46f383-cbfe-4d36-a378-4d5ce81dfbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-ee513013-471c-4147-9325-cfe602b9de0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-78de061b-f4ee-4f94-933e-3d8f08880e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-6daef5fa-f810-47a5-a663-71f35fc09aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-18a0cab3-7346-400c-b1a9-5d5f93870a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430042402-172.17.0.10-1598640694615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-0583ec04-acda-4cae-8ea9-b37e37e436e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-cc13406b-291a-433d-ab8b-b0f42ba5a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-0884c63d-4f19-4db5-b23c-1c76f8ab039d,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-16868e82-c4bb-423c-9107-b92da547a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-492a8653-935e-46ac-a005-f2861541bdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-906de070-71e2-4fae-8642-dfa079947ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-c0257561-1e82-4234-b055-4a7fe0e0adda,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-d1f56b9b-eb80-4d79-a73a-de6f2b9d6f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430042402-172.17.0.10-1598640694615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-0583ec04-acda-4cae-8ea9-b37e37e436e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-cc13406b-291a-433d-ab8b-b0f42ba5a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-0884c63d-4f19-4db5-b23c-1c76f8ab039d,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-16868e82-c4bb-423c-9107-b92da547a4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-492a8653-935e-46ac-a005-f2861541bdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-906de070-71e2-4fae-8642-dfa079947ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-c0257561-1e82-4234-b055-4a7fe0e0adda,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-d1f56b9b-eb80-4d79-a73a-de6f2b9d6f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222277118-172.17.0.10-1598640733831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-78e4dbbd-012e-4033-a395-2c64b658fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-d24722c7-7403-40fe-a7c2-2247b7c342a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-06db47a5-856c-40d5-b93d-e46b1812be86,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-7861b95a-1e8d-413c-a6f9-5fd048eac74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ac36bdab-4657-42c1-93bb-c2441baa90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-1b180ad0-f71d-4350-9b43-a0d9e0d2e9be,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-34d59486-a5d7-4a71-a8fa-79b4a014a280,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0f245805-c2b6-4cb3-a12b-33ad8f8bd10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222277118-172.17.0.10-1598640733831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-78e4dbbd-012e-4033-a395-2c64b658fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-d24722c7-7403-40fe-a7c2-2247b7c342a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-06db47a5-856c-40d5-b93d-e46b1812be86,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-7861b95a-1e8d-413c-a6f9-5fd048eac74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ac36bdab-4657-42c1-93bb-c2441baa90d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-1b180ad0-f71d-4350-9b43-a0d9e0d2e9be,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-34d59486-a5d7-4a71-a8fa-79b4a014a280,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0f245805-c2b6-4cb3-a12b-33ad8f8bd10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95923641-172.17.0.10-1598640761637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-a0b2a235-fa9a-4688-86cf-f3db37be3a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e904ca0b-2efd-4002-a7f6-09e5401be23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-472330d8-55d8-4c66-94ea-a29920c1baab,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-9f3899fd-f07b-4fb8-a3ee-b55ab0f9a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e13e4be1-1364-4916-a219-65ce818a78d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-0576d7fc-896c-477a-8a5e-78f60885309e,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7194038b-bf18-431a-8a6a-ab7be699779d,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e9dcc6dd-d8e6-47d8-9096-524f40965074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95923641-172.17.0.10-1598640761637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-a0b2a235-fa9a-4688-86cf-f3db37be3a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-e904ca0b-2efd-4002-a7f6-09e5401be23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-472330d8-55d8-4c66-94ea-a29920c1baab,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-9f3899fd-f07b-4fb8-a3ee-b55ab0f9a6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e13e4be1-1364-4916-a219-65ce818a78d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-0576d7fc-896c-477a-8a5e-78f60885309e,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7194038b-bf18-431a-8a6a-ab7be699779d,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-e9dcc6dd-d8e6-47d8-9096-524f40965074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5476
