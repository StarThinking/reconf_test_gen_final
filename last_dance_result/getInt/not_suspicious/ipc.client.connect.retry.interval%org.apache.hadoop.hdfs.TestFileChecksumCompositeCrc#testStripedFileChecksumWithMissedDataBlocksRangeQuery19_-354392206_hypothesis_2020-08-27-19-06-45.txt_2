reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540242851-172.17.0.5-1598555428726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-58cd68ed-1ac5-4a90-8c49-12b443162b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-38af35f7-dfff-4653-92eb-22a66b6ace9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-c01f74a0-7053-4f17-8299-91ad58629090,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-4cad75d1-6961-4bb7-b619-576a9c2fd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-4eea4037-20d9-4fce-9df3-c0e9664287cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-c4029f9c-62c2-40da-82f5-c048369b4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-287cdb97-4a8a-49aa-8119-5d0b891ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b6cca180-4c52-4599-8fa9-9091503fc11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540242851-172.17.0.5-1598555428726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-58cd68ed-1ac5-4a90-8c49-12b443162b07,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-38af35f7-dfff-4653-92eb-22a66b6ace9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-c01f74a0-7053-4f17-8299-91ad58629090,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-4cad75d1-6961-4bb7-b619-576a9c2fd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-4eea4037-20d9-4fce-9df3-c0e9664287cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-c4029f9c-62c2-40da-82f5-c048369b4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-287cdb97-4a8a-49aa-8119-5d0b891ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-b6cca180-4c52-4599-8fa9-9091503fc11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327563819-172.17.0.5-1598555597785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-61668311-a635-46bb-ad14-63344d9ab8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-1460d4a5-74d5-4252-8e91-8cee0bf740c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-25c2daf0-b931-4a2a-bea3-a5c6a107e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-6ae5696a-5e29-4c0e-bfae-ccf4f2978191,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ca9bba43-18a4-4ca1-ad8f-bec0f1fc7fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-44d419ec-7aca-49c2-a12e-c0b24b555782,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-d13b1125-dc46-449f-b21e-fb0bccbfbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-c269db16-6560-4139-b7ad-2913964b9ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327563819-172.17.0.5-1598555597785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-61668311-a635-46bb-ad14-63344d9ab8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-1460d4a5-74d5-4252-8e91-8cee0bf740c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-25c2daf0-b931-4a2a-bea3-a5c6a107e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-6ae5696a-5e29-4c0e-bfae-ccf4f2978191,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ca9bba43-18a4-4ca1-ad8f-bec0f1fc7fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-44d419ec-7aca-49c2-a12e-c0b24b555782,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-d13b1125-dc46-449f-b21e-fb0bccbfbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-c269db16-6560-4139-b7ad-2913964b9ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415474987-172.17.0.5-1598556416727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-976e6ed3-199e-4c10-bd4f-bf3ac0cc4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-74e52546-4b61-4971-9555-3f1ff10f576f,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-beb11bdc-7b44-4ae4-8a9c-2d881f785c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-979786bf-7728-4b83-b43d-da91b51c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-461701df-e6ad-44bf-8c41-b8bb12a738dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-0734e4ec-62cc-4d90-b5c1-ef4627654ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-308057f3-1e90-4471-9caa-1e355dbf5b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-e97d1b3c-e6cb-478f-98d2-383b122e1158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415474987-172.17.0.5-1598556416727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38674,DS-976e6ed3-199e-4c10-bd4f-bf3ac0cc4af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-74e52546-4b61-4971-9555-3f1ff10f576f,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-beb11bdc-7b44-4ae4-8a9c-2d881f785c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-979786bf-7728-4b83-b43d-da91b51c65a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-461701df-e6ad-44bf-8c41-b8bb12a738dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-0734e4ec-62cc-4d90-b5c1-ef4627654ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-308057f3-1e90-4471-9caa-1e355dbf5b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-e97d1b3c-e6cb-478f-98d2-383b122e1158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983190377-172.17.0.5-1598556529855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-e568187c-924c-42a6-9c56-52e442a09786,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-e1566eae-c344-4ecd-b247-3bcc1041e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-58db5592-e8f6-46aa-9a2a-3235e99f23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-34985d45-c391-4b0b-bf40-3b7aaea33f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-bbd357e8-408d-43c9-bbd1-df6aea059062,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-e8595c03-6c1f-46cd-bb92-df5e4b6d8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ead83e46-63ed-4d32-b6f3-af0179c01158,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-62bd1898-07ba-4b17-b809-1a1466659bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983190377-172.17.0.5-1598556529855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-e568187c-924c-42a6-9c56-52e442a09786,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-e1566eae-c344-4ecd-b247-3bcc1041e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-58db5592-e8f6-46aa-9a2a-3235e99f23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-34985d45-c391-4b0b-bf40-3b7aaea33f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-bbd357e8-408d-43c9-bbd1-df6aea059062,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-e8595c03-6c1f-46cd-bb92-df5e4b6d8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ead83e46-63ed-4d32-b6f3-af0179c01158,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-62bd1898-07ba-4b17-b809-1a1466659bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235729713-172.17.0.5-1598556703312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-3d6f11bc-53e5-4ba1-a29c-7378e5a58348,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-e38a07b9-a0b4-4ede-8658-c93e8306bae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-26f35728-edd9-4641-bfab-250a3f535339,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-2e0831d4-f957-49c5-ae5c-8f934a294fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7738261f-d292-4402-859d-459bd4290564,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-22bf9114-517a-4451-8069-3a55518c3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-b2810764-24f9-4eea-8c1e-b2150676b524,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-1f767cf6-63f8-47ff-999b-74bf874705f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235729713-172.17.0.5-1598556703312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-3d6f11bc-53e5-4ba1-a29c-7378e5a58348,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-e38a07b9-a0b4-4ede-8658-c93e8306bae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-26f35728-edd9-4641-bfab-250a3f535339,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-2e0831d4-f957-49c5-ae5c-8f934a294fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7738261f-d292-4402-859d-459bd4290564,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-22bf9114-517a-4451-8069-3a55518c3b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-b2810764-24f9-4eea-8c1e-b2150676b524,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-1f767cf6-63f8-47ff-999b-74bf874705f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211131682-172.17.0.5-1598557421885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41431,DS-b989da18-1e28-4428-b25d-82367d0cebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-ef4c74b1-bfac-45da-a425-cd73e321c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e020a8bf-9385-4ef5-9707-ae8dd607b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-3f31fa44-b875-44c5-ba1e-d2807cf74173,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-9f038a55-691c-4d35-a094-9001b02e7028,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-820757b2-ed6d-4706-a6d3-e07cf39f6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-ff062219-8d06-465e-a76c-873d477c4a25,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d47e2b15-acce-46ff-9d95-f9850c909a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211131682-172.17.0.5-1598557421885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41431,DS-b989da18-1e28-4428-b25d-82367d0cebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-ef4c74b1-bfac-45da-a425-cd73e321c39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e020a8bf-9385-4ef5-9707-ae8dd607b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-3f31fa44-b875-44c5-ba1e-d2807cf74173,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-9f038a55-691c-4d35-a094-9001b02e7028,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-820757b2-ed6d-4706-a6d3-e07cf39f6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-ff062219-8d06-465e-a76c-873d477c4a25,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-d47e2b15-acce-46ff-9d95-f9850c909a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509965258-172.17.0.5-1598557938237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-6ed43441-37fa-43dd-9cc2-9786ace86533,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-28149fd4-a99c-4464-938e-5ed003a211d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-e0a06e5b-9696-4cf2-a23b-ab8da653f554,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-c24ecaac-53f8-4807-a530-8fe9fb2ceb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-62478ec5-8438-4076-ab00-118475e4b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-863062ed-82b4-4b6c-bb08-91fb0769b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-3ac6f5d5-1235-4131-b791-640b03e2c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-f7a4249f-971a-42cd-885a-d4fd569f6f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509965258-172.17.0.5-1598557938237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-6ed43441-37fa-43dd-9cc2-9786ace86533,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-28149fd4-a99c-4464-938e-5ed003a211d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-e0a06e5b-9696-4cf2-a23b-ab8da653f554,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-c24ecaac-53f8-4807-a530-8fe9fb2ceb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-62478ec5-8438-4076-ab00-118475e4b3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-863062ed-82b4-4b6c-bb08-91fb0769b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-3ac6f5d5-1235-4131-b791-640b03e2c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-f7a4249f-971a-42cd-885a-d4fd569f6f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002309259-172.17.0.5-1598558416143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-800af9f9-f4c0-4821-ac8f-41fb5ad38b65,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-83aad921-f254-4fdc-a00c-9c1128824a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-9cbb3b4d-43b1-4786-a8c7-784cd52f86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-9e86d723-258e-4aa9-8f68-c6fa3b92bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-31c9e319-073a-4ee4-868f-0bb364c88f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-275ce1d5-0f24-46fb-b690-f4209145ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-b8d29b9c-21ff-4e5d-81d6-03e64c9e2c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-1210c25f-9962-4b3f-b16f-ea2f43b78f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002309259-172.17.0.5-1598558416143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-800af9f9-f4c0-4821-ac8f-41fb5ad38b65,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-83aad921-f254-4fdc-a00c-9c1128824a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-9cbb3b4d-43b1-4786-a8c7-784cd52f86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-9e86d723-258e-4aa9-8f68-c6fa3b92bbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-31c9e319-073a-4ee4-868f-0bb364c88f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-275ce1d5-0f24-46fb-b690-f4209145ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-b8d29b9c-21ff-4e5d-81d6-03e64c9e2c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-1210c25f-9962-4b3f-b16f-ea2f43b78f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858660474-172.17.0.5-1598558603844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-ee36d247-2d5b-47e2-94a2-a0f356399047,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-56023461-8d31-44fe-b625-2b4850097431,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-0cace3ba-8bb6-4fa1-af4b-fe44a1fbb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-f68aca00-0670-4eeb-ac22-8cf73d738864,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-3a6bf69a-9f1b-475a-a281-1ad5c44a936b,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-8ec85458-b671-42ef-a6bf-93e980194e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f24cec73-ceb1-443a-9e6e-f87c86d76b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-46257fea-b658-4b64-b819-0a75f92d5a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858660474-172.17.0.5-1598558603844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-ee36d247-2d5b-47e2-94a2-a0f356399047,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-56023461-8d31-44fe-b625-2b4850097431,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-0cace3ba-8bb6-4fa1-af4b-fe44a1fbb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-f68aca00-0670-4eeb-ac22-8cf73d738864,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-3a6bf69a-9f1b-475a-a281-1ad5c44a936b,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-8ec85458-b671-42ef-a6bf-93e980194e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f24cec73-ceb1-443a-9e6e-f87c86d76b80,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-46257fea-b658-4b64-b819-0a75f92d5a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207118351-172.17.0.5-1598558969479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-a5ad89bb-8ef7-4be3-9fb9-9e0a60910b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-04e95d46-b2c0-4f66-8004-988c08eda24b,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-739399bc-8737-406b-a526-8e77192c6412,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-42f40c4f-b293-4f7c-9b29-27215158879e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0304cf6d-e2f9-49b4-bd32-c82e232472f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-d1c1da12-0d9a-4270-aec9-d915521f2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-52471f41-94f9-4926-8a47-e6f05898d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-59ecbe5b-2c17-48e1-84a9-b96b0582d4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207118351-172.17.0.5-1598558969479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-a5ad89bb-8ef7-4be3-9fb9-9e0a60910b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-04e95d46-b2c0-4f66-8004-988c08eda24b,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-739399bc-8737-406b-a526-8e77192c6412,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-42f40c4f-b293-4f7c-9b29-27215158879e,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-0304cf6d-e2f9-49b4-bd32-c82e232472f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-d1c1da12-0d9a-4270-aec9-d915521f2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-52471f41-94f9-4926-8a47-e6f05898d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-59ecbe5b-2c17-48e1-84a9-b96b0582d4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785473339-172.17.0.5-1598559332929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-80f074e7-3e75-43be-ad58-f322a55938b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-40b136c3-aa43-4193-a2db-0a16759dcbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-24593c3d-f348-4389-8994-6f27dc697d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2a4be4ad-c713-4003-aadf-9522b5ce557f,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-25af91d8-9fdd-4974-9803-32cdae1e3328,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-c47f3028-b62e-4928-b24a-df3967339db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-9e7e4837-fb54-4cff-bbf2-25a24a126529,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-d66e02ba-1f31-4f57-929a-8eb50c720e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785473339-172.17.0.5-1598559332929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-80f074e7-3e75-43be-ad58-f322a55938b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-40b136c3-aa43-4193-a2db-0a16759dcbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-24593c3d-f348-4389-8994-6f27dc697d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-2a4be4ad-c713-4003-aadf-9522b5ce557f,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-25af91d8-9fdd-4974-9803-32cdae1e3328,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-c47f3028-b62e-4928-b24a-df3967339db5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-9e7e4837-fb54-4cff-bbf2-25a24a126529,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-d66e02ba-1f31-4f57-929a-8eb50c720e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853352374-172.17.0.5-1598559724834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-41854efc-bee7-4434-a55e-9b4c98021920,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-3e1ab446-2c5f-4eb9-97ec-29b55eb794bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-23e966d0-2763-4364-bcac-32a2de7700d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-68aa32dc-b067-40a0-86fd-35850020b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-8ed8f585-9cc1-4c9a-bdfa-70899df73719,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-e95686a0-6a64-411f-8a04-138f27573c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-fca0b2b8-efd9-4a1c-98ea-e6d65522e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-380ab338-d482-4a41-b204-9d4bbd98f0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853352374-172.17.0.5-1598559724834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-41854efc-bee7-4434-a55e-9b4c98021920,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-3e1ab446-2c5f-4eb9-97ec-29b55eb794bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-23e966d0-2763-4364-bcac-32a2de7700d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-68aa32dc-b067-40a0-86fd-35850020b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-8ed8f585-9cc1-4c9a-bdfa-70899df73719,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-e95686a0-6a64-411f-8a04-138f27573c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-fca0b2b8-efd9-4a1c-98ea-e6d65522e20d,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-380ab338-d482-4a41-b204-9d4bbd98f0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5240
