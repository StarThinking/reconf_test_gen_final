reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753795568-172.17.0.7-1598600685835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-9ae4f53a-5e2c-4fe9-9788-4f0d2ac155c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-31eca7a7-7340-4e98-b4cb-73b3bc4569c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9c62f864-cbe7-4522-979b-4707f09eb147,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-e9d2c551-9538-4df0-ab48-993482d98b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-228f729f-2472-4a08-98f4-9ef4dd7649bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-682601c8-8301-43cf-84b2-4edd1b6b027d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-b9ab484c-7f5d-4c39-86f3-f240537aaff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-bf1ccaed-2742-4b27-8c28-eccde3a9cec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753795568-172.17.0.7-1598600685835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-9ae4f53a-5e2c-4fe9-9788-4f0d2ac155c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-31eca7a7-7340-4e98-b4cb-73b3bc4569c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-9c62f864-cbe7-4522-979b-4707f09eb147,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-e9d2c551-9538-4df0-ab48-993482d98b00,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-228f729f-2472-4a08-98f4-9ef4dd7649bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-682601c8-8301-43cf-84b2-4edd1b6b027d,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-b9ab484c-7f5d-4c39-86f3-f240537aaff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-bf1ccaed-2742-4b27-8c28-eccde3a9cec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687479585-172.17.0.7-1598600810512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-e6b187b5-6e6e-442b-9ebc-aa1a673eb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-b06ba2dc-b6a7-46ba-a27b-9258bbfa9cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-797a42ac-035c-4142-8c3d-d0690aa24bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-4a60f9db-d542-48e5-838c-716793d654bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bab2670e-2686-4253-a64e-2db47cf1fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-b0996851-aed4-4dc4-aad1-68c816a45c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0914b2ca-405d-4cff-b949-caa1ddf3f55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-1320aae0-ec4b-4679-b017-7ce0364f98e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687479585-172.17.0.7-1598600810512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-e6b187b5-6e6e-442b-9ebc-aa1a673eb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-b06ba2dc-b6a7-46ba-a27b-9258bbfa9cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-797a42ac-035c-4142-8c3d-d0690aa24bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-4a60f9db-d542-48e5-838c-716793d654bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-bab2670e-2686-4253-a64e-2db47cf1fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-b0996851-aed4-4dc4-aad1-68c816a45c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0914b2ca-405d-4cff-b949-caa1ddf3f55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-1320aae0-ec4b-4679-b017-7ce0364f98e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763884917-172.17.0.7-1598601114655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-977fcf57-1092-497d-baa9-53bde292b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-86e5317b-df13-40e3-a69e-c4d978920409,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-53a3431b-489a-43e8-bbaa-0f0e142bce46,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-30a3d978-accb-47a8-a446-2160da50a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-b0bef5a2-069c-4fe4-8d1a-2dc5dbd03398,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-3bd9ba3b-cfed-4e9e-9c05-1bdb85c97aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-463759ed-4c50-48c3-bdcf-c0dcf0ad5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-1744b2f9-fdca-45bb-bf9e-7bb598dffeae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763884917-172.17.0.7-1598601114655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-977fcf57-1092-497d-baa9-53bde292b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-86e5317b-df13-40e3-a69e-c4d978920409,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-53a3431b-489a-43e8-bbaa-0f0e142bce46,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-30a3d978-accb-47a8-a446-2160da50a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-b0bef5a2-069c-4fe4-8d1a-2dc5dbd03398,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-3bd9ba3b-cfed-4e9e-9c05-1bdb85c97aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-463759ed-4c50-48c3-bdcf-c0dcf0ad5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-1744b2f9-fdca-45bb-bf9e-7bb598dffeae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464325678-172.17.0.7-1598601262478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35971,DS-5bc3f914-1735-4e2f-886f-8fdbd9ccae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-22b93511-2c66-463a-8b27-00b71b8fb75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a7358afd-761f-4dab-baea-a9f4c86e5959,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-4deb2c4a-cdca-4dba-acc1-70ffb2686864,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-15dbe1cf-8d86-43e1-b8fc-f176c71fe6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-7c869908-ec92-439c-9cf3-aeb772b5bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a9ac61b2-193a-4294-9371-114e4331568c,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-adeab8d3-af42-4961-af7e-43448517517f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464325678-172.17.0.7-1598601262478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35971,DS-5bc3f914-1735-4e2f-886f-8fdbd9ccae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-22b93511-2c66-463a-8b27-00b71b8fb75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-a7358afd-761f-4dab-baea-a9f4c86e5959,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-4deb2c4a-cdca-4dba-acc1-70ffb2686864,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-15dbe1cf-8d86-43e1-b8fc-f176c71fe6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-7c869908-ec92-439c-9cf3-aeb772b5bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-a9ac61b2-193a-4294-9371-114e4331568c,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-adeab8d3-af42-4961-af7e-43448517517f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109382430-172.17.0.7-1598601304961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-51938fd8-a15f-46ba-a890-083610c5523b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c80e6742-8f4f-4d70-8649-d1a3e5643a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-e6598acf-c527-4c5d-8f23-3b62572113ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-1c10a214-bb70-4b23-a420-d44c08b344f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-1beebde2-987b-4b21-991e-e6a67b7e6783,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-4c5aaa22-5b86-4d04-b8bb-d32f1978b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-48f76598-a7b7-4183-821e-6e7e2aafba00,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-58f3e5ea-aac9-4d78-9f5c-175d4940b1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109382430-172.17.0.7-1598601304961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-51938fd8-a15f-46ba-a890-083610c5523b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c80e6742-8f4f-4d70-8649-d1a3e5643a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-e6598acf-c527-4c5d-8f23-3b62572113ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-1c10a214-bb70-4b23-a420-d44c08b344f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-1beebde2-987b-4b21-991e-e6a67b7e6783,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-4c5aaa22-5b86-4d04-b8bb-d32f1978b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-48f76598-a7b7-4183-821e-6e7e2aafba00,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-58f3e5ea-aac9-4d78-9f5c-175d4940b1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34234253-172.17.0.7-1598601377561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-f32c65bf-69d9-48ff-8d56-372319d9e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-310bf575-f766-4e37-9b9f-1019cce6f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-c921a372-fff7-4224-820e-5dd851fc7002,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-5b05036e-fbc8-4eaf-bcd1-937db708b336,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-bfd37d02-12ca-4507-b56c-60cf0ad8adb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-ec62de11-f47d-4db7-ac01-8f8da2c0891a,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-c7cc2c21-c2d2-4045-b16c-8b058258bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-dc4ee709-c7ad-4655-a0e8-17b3be4d44c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34234253-172.17.0.7-1598601377561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-f32c65bf-69d9-48ff-8d56-372319d9e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-310bf575-f766-4e37-9b9f-1019cce6f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-c921a372-fff7-4224-820e-5dd851fc7002,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-5b05036e-fbc8-4eaf-bcd1-937db708b336,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-bfd37d02-12ca-4507-b56c-60cf0ad8adb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-ec62de11-f47d-4db7-ac01-8f8da2c0891a,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-c7cc2c21-c2d2-4045-b16c-8b058258bb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-dc4ee709-c7ad-4655-a0e8-17b3be4d44c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001856015-172.17.0.7-1598601503265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-cb2fb65e-fbb9-4af8-81a5-5488c85c5047,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-61360ae5-d178-465a-93c2-3f8c4e05c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-49ccd364-f60e-49e4-a95b-989d6e7c19d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-49b94fa5-68a5-4ea9-95a0-dc12da311b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-68e9652a-4d21-4364-8406-c55a4e20e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-3b5912d2-6ed8-41e0-8a7e-013b9655f920,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-1c134438-40d9-4174-ba82-df0b3eb5e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-915c47a9-d334-4432-82d9-6520e68a85c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001856015-172.17.0.7-1598601503265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-cb2fb65e-fbb9-4af8-81a5-5488c85c5047,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-61360ae5-d178-465a-93c2-3f8c4e05c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-49ccd364-f60e-49e4-a95b-989d6e7c19d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-49b94fa5-68a5-4ea9-95a0-dc12da311b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-68e9652a-4d21-4364-8406-c55a4e20e04c,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-3b5912d2-6ed8-41e0-8a7e-013b9655f920,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-1c134438-40d9-4174-ba82-df0b3eb5e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-915c47a9-d334-4432-82d9-6520e68a85c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943466734-172.17.0.7-1598601617591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-7fcf7807-020d-4175-978e-0e79ed5de13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-6eb4fe4e-5b61-45e7-84e3-0671854b90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-9ede2c1f-ab82-4f62-81c5-cf55cdc1c327,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-63adc938-0386-476f-8636-cfe446fed881,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-a06806fb-7d81-402d-a393-272a639c0941,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-984009d7-87ae-4b6e-96a8-a0144e8699fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-5528878a-4dcc-4bd5-b8ec-0fb804420a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-1afee373-4b3e-411f-b48f-135385ed1bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943466734-172.17.0.7-1598601617591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34342,DS-7fcf7807-020d-4175-978e-0e79ed5de13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-6eb4fe4e-5b61-45e7-84e3-0671854b90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-9ede2c1f-ab82-4f62-81c5-cf55cdc1c327,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-63adc938-0386-476f-8636-cfe446fed881,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-a06806fb-7d81-402d-a393-272a639c0941,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-984009d7-87ae-4b6e-96a8-a0144e8699fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-5528878a-4dcc-4bd5-b8ec-0fb804420a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-1afee373-4b3e-411f-b48f-135385ed1bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001108601-172.17.0.7-1598601904640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33634,DS-cd82bb7f-fd5d-4ebb-923a-2eeb98a3ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-d7c41025-3e25-4077-b016-f2c534635a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-ae3272e2-8760-440d-be96-242ad209cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-8c3735c6-a6d7-4458-9b6e-521e15d19fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-627b2049-b718-43d7-998f-5ac06c33e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-21b3f72c-6448-480f-bb1f-9c0c9b7c02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-15192133-3b3a-423d-a5af-4fa6fa93de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-71c6e49a-cb92-4148-a68f-98fc650f3ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001108601-172.17.0.7-1598601904640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33634,DS-cd82bb7f-fd5d-4ebb-923a-2eeb98a3ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-d7c41025-3e25-4077-b016-f2c534635a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-ae3272e2-8760-440d-be96-242ad209cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-8c3735c6-a6d7-4458-9b6e-521e15d19fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-627b2049-b718-43d7-998f-5ac06c33e44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-21b3f72c-6448-480f-bb1f-9c0c9b7c02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-15192133-3b3a-423d-a5af-4fa6fa93de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-71c6e49a-cb92-4148-a68f-98fc650f3ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457794832-172.17.0.7-1598601988780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-48b4e9ea-5dd5-43bc-b76d-edca243c2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-42ebfc1a-03b2-4ea0-9e02-39d00c98e0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-98586bb6-0882-4f64-bf4f-fa1bb9f1cab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-1f87043e-a119-42ff-bfc4-f92a6f83e2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ca821fea-af7a-41f1-b81e-cdacefa68252,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-528d2dc4-bdf9-470d-8e1f-3133495392e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-9e0afacd-05d8-4d44-b1bf-ba7d28a13c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-49f65f17-23ae-4363-8ed3-4b35ea8f294f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457794832-172.17.0.7-1598601988780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-48b4e9ea-5dd5-43bc-b76d-edca243c2e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-42ebfc1a-03b2-4ea0-9e02-39d00c98e0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-98586bb6-0882-4f64-bf4f-fa1bb9f1cab2,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-1f87043e-a119-42ff-bfc4-f92a6f83e2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ca821fea-af7a-41f1-b81e-cdacefa68252,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-528d2dc4-bdf9-470d-8e1f-3133495392e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-9e0afacd-05d8-4d44-b1bf-ba7d28a13c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-49f65f17-23ae-4363-8ed3-4b35ea8f294f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538811243-172.17.0.7-1598602711209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-9cc18a74-de3e-454e-8ea9-e5bb0b71ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-cc6e8003-d18c-439a-833e-441e9bb74755,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-7f97ed66-6c46-4f3a-9b9f-711611eeb982,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-e36ff2c2-3ce4-4d85-b6e3-2295baa1e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-cc614785-69eb-451c-8016-b8aac6e4ad89,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-eaa48b6a-c1fc-4df1-b8fa-0188200f43a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-6bbfa78a-13c9-4ed7-8bf5-4e58b83ed6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-f60cdce9-0060-4aee-befa-b436dbb50028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1538811243-172.17.0.7-1598602711209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-9cc18a74-de3e-454e-8ea9-e5bb0b71ef2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-cc6e8003-d18c-439a-833e-441e9bb74755,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-7f97ed66-6c46-4f3a-9b9f-711611eeb982,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-e36ff2c2-3ce4-4d85-b6e3-2295baa1e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-cc614785-69eb-451c-8016-b8aac6e4ad89,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-eaa48b6a-c1fc-4df1-b8fa-0188200f43a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-6bbfa78a-13c9-4ed7-8bf5-4e58b83ed6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-f60cdce9-0060-4aee-befa-b436dbb50028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565477722-172.17.0.7-1598603173393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-7cec6b5e-3248-4e9a-9f65-0d809337969d,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-67243375-5815-4ce6-8f9e-7763a36ba5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-a8dc9229-fc7a-4fa5-86c5-2914c2f2b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-3b642396-2168-448e-b075-f2d48075bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-e761f5c1-a667-47a1-82b0-38b5bccbd6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-5c2088ab-2b6c-4db4-adf2-fbb639c03edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-c590b2eb-eb6a-4b71-b0cf-69beecdac0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-e1bd443c-2c1c-4576-b559-bb086de66fce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565477722-172.17.0.7-1598603173393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45709,DS-7cec6b5e-3248-4e9a-9f65-0d809337969d,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-67243375-5815-4ce6-8f9e-7763a36ba5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-a8dc9229-fc7a-4fa5-86c5-2914c2f2b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-3b642396-2168-448e-b075-f2d48075bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-e761f5c1-a667-47a1-82b0-38b5bccbd6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-5c2088ab-2b6c-4db4-adf2-fbb639c03edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-c590b2eb-eb6a-4b71-b0cf-69beecdac0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-e1bd443c-2c1c-4576-b559-bb086de66fce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854170986-172.17.0.7-1598603247776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-c343d028-0a33-4979-8f44-11df3f9fb844,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-840429d7-6f98-4000-b749-1228b80ad3be,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-4602fe47-8a78-4634-a56a-76165abe5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-8412568b-179e-4f4a-b7a1-d44f3935d452,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-510ed5a9-4334-4c06-8053-41c479953d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-da7bef8e-ce30-4bd7-b30e-9f2dbb48279c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-d07a7115-3f52-47b0-ab0b-b66f0ae42a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-a089b258-acb6-4ab6-a5cf-378afa50e4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854170986-172.17.0.7-1598603247776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-c343d028-0a33-4979-8f44-11df3f9fb844,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-840429d7-6f98-4000-b749-1228b80ad3be,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-4602fe47-8a78-4634-a56a-76165abe5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-8412568b-179e-4f4a-b7a1-d44f3935d452,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-510ed5a9-4334-4c06-8053-41c479953d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-da7bef8e-ce30-4bd7-b30e-9f2dbb48279c,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-d07a7115-3f52-47b0-ab0b-b66f0ae42a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-a089b258-acb6-4ab6-a5cf-378afa50e4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917381746-172.17.0.7-1598604069070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33284,DS-8692fd5c-59dc-4114-ae77-5e0a05f04f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-b2819972-7e0e-4452-946f-aa5edd75a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-f505dafe-cb6d-4351-bdd8-4639dbcc5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-2247af4a-5f72-4af3-85a0-22dd271a5718,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-5804f7b6-78d1-468a-b52a-10db93c894f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-cce39183-ebd9-4247-a1cd-f3d8b07359ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-f9d6f619-d185-40dc-aa92-9b1673fab92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-74bf6b39-8415-41f8-a2c2-29cf710937db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917381746-172.17.0.7-1598604069070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33284,DS-8692fd5c-59dc-4114-ae77-5e0a05f04f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-b2819972-7e0e-4452-946f-aa5edd75a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-f505dafe-cb6d-4351-bdd8-4639dbcc5d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-2247af4a-5f72-4af3-85a0-22dd271a5718,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-5804f7b6-78d1-468a-b52a-10db93c894f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-cce39183-ebd9-4247-a1cd-f3d8b07359ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-f9d6f619-d185-40dc-aa92-9b1673fab92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-74bf6b39-8415-41f8-a2c2-29cf710937db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685480490-172.17.0.7-1598604472650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-ba3216b1-8dab-41ad-ad7c-588fb04b41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-2ba652d8-6309-4121-953d-ec4a81b200dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-9f336c2d-a47c-4f7e-87ad-74341b4f1946,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-11d794a8-6dd6-44a9-a33a-a0a5cf6f289e,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-73c6f8fd-b6cb-4da7-83e7-ae19507f325a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-51815c46-60ef-451f-b857-4d2ed861f165,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-eda7fbb2-2435-4742-9184-80ccf53100ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-33ed8691-f6f6-418f-b704-bd7d70a4de6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685480490-172.17.0.7-1598604472650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38940,DS-ba3216b1-8dab-41ad-ad7c-588fb04b41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-2ba652d8-6309-4121-953d-ec4a81b200dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-9f336c2d-a47c-4f7e-87ad-74341b4f1946,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-11d794a8-6dd6-44a9-a33a-a0a5cf6f289e,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-73c6f8fd-b6cb-4da7-83e7-ae19507f325a,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-51815c46-60ef-451f-b857-4d2ed861f165,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-eda7fbb2-2435-4742-9184-80ccf53100ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-33ed8691-f6f6-418f-b704-bd7d70a4de6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269958475-172.17.0.7-1598604697843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-c1ea56ac-40fe-4fe3-b166-a73ca4165719,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-83a0d819-a4ca-4ed2-b4ef-ea9eaa584267,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-8e18622d-8af2-4054-8de4-2ca49e221a27,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-da4444fe-62a1-4e60-a6ca-be5259141b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-19fb2aad-378a-425a-a157-0d3181ec123c,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-8a9ad5dc-0077-4f4d-adac-22aee0419356,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-f69b4bdf-42cc-49d3-9396-e8d3aeec166f,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f02770a3-14ed-4fd5-8905-02805ea485b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269958475-172.17.0.7-1598604697843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-c1ea56ac-40fe-4fe3-b166-a73ca4165719,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-83a0d819-a4ca-4ed2-b4ef-ea9eaa584267,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-8e18622d-8af2-4054-8de4-2ca49e221a27,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-da4444fe-62a1-4e60-a6ca-be5259141b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-19fb2aad-378a-425a-a157-0d3181ec123c,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-8a9ad5dc-0077-4f4d-adac-22aee0419356,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-f69b4bdf-42cc-49d3-9396-e8d3aeec166f,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f02770a3-14ed-4fd5-8905-02805ea485b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894957049-172.17.0.7-1598604734667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33411,DS-f6c3240f-7ef7-4636-aa73-3d912dadbb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-41348667-f5a0-4605-8762-38d1e539c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b67e986f-caad-40b1-86f6-75cc41abb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-3d4219cd-51ab-4eb6-ad5b-79a411d2be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-b1706758-9cfe-46fc-bccf-4bdea4a10937,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-d4766b2e-ba70-48be-94a3-e398f9cdb63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8035b14d-49bc-44c6-8e00-2badf0b98cad,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-388e79f7-6649-454f-8db1-753f3d01f079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894957049-172.17.0.7-1598604734667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33411,DS-f6c3240f-7ef7-4636-aa73-3d912dadbb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-41348667-f5a0-4605-8762-38d1e539c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b67e986f-caad-40b1-86f6-75cc41abb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-3d4219cd-51ab-4eb6-ad5b-79a411d2be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-b1706758-9cfe-46fc-bccf-4bdea4a10937,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-d4766b2e-ba70-48be-94a3-e398f9cdb63d,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-8035b14d-49bc-44c6-8e00-2badf0b98cad,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-388e79f7-6649-454f-8db1-753f3d01f079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510353209-172.17.0.7-1598605624086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-c78d2f89-5e90-4fe4-9fcd-af852df00f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-1467a31f-f2e8-41a2-a96f-5656868c1e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-dc2c8946-150d-497f-8dc1-dd58a5b5f413,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-4e3c934b-7a33-4999-8d16-f5ccb66d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-bca33c9f-b4e4-48b8-8574-a862d1fc0e80,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-8d9bc96b-b479-4b61-abe4-b38995338d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-4c9ca1bf-1fd8-4fad-9ca9-016619b71127,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-d9fca4bb-b6e7-4a32-9850-1972130e45c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510353209-172.17.0.7-1598605624086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-c78d2f89-5e90-4fe4-9fcd-af852df00f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-1467a31f-f2e8-41a2-a96f-5656868c1e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-dc2c8946-150d-497f-8dc1-dd58a5b5f413,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-4e3c934b-7a33-4999-8d16-f5ccb66d0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-bca33c9f-b4e4-48b8-8574-a862d1fc0e80,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-8d9bc96b-b479-4b61-abe4-b38995338d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-4c9ca1bf-1fd8-4fad-9ca9-016619b71127,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-d9fca4bb-b6e7-4a32-9850-1972130e45c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5571
