reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367907534-172.17.0.20-1598608617288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38545,DS-816afc68-e49e-4e73-add9-ff62f0236101,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-58fc85f3-6174-4341-b5d5-0066d58b91ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-22dfc817-3b6f-4235-aff4-d4cd46992be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-6ae834f0-3a2a-4e46-af50-c7b733d80f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-db02c123-1b5b-41a4-8c1b-fe6218b0cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-00e08e26-ce9b-444c-9899-a7c40ffb39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-86fec561-3226-43f8-9997-3599c81aaa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-1fafdb1f-4d76-48cb-8f4e-fab53c26bd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367907534-172.17.0.20-1598608617288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38545,DS-816afc68-e49e-4e73-add9-ff62f0236101,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-58fc85f3-6174-4341-b5d5-0066d58b91ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-22dfc817-3b6f-4235-aff4-d4cd46992be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-6ae834f0-3a2a-4e46-af50-c7b733d80f47,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-db02c123-1b5b-41a4-8c1b-fe6218b0cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-00e08e26-ce9b-444c-9899-a7c40ffb39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-86fec561-3226-43f8-9997-3599c81aaa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-1fafdb1f-4d76-48cb-8f4e-fab53c26bd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055146988-172.17.0.20-1598608727981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-e24d88b5-d511-4f6f-accc-bb2c9636c153,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-ff0d49e8-52c8-4bfa-8f16-6051a8a6ecde,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-1a80e5d3-5843-433f-8345-745401c7f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ef46ea57-90d5-4be5-88f2-5f58768b3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-e37d8d27-5533-4762-8444-fa207ca03bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-8c5c0909-f354-4884-88ee-0c5e6c45daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7e60fbf0-bfd1-4000-aa04-d9d1f5e962f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-9ae43e1a-50ca-47b8-bd49-b2b84ce16b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055146988-172.17.0.20-1598608727981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-e24d88b5-d511-4f6f-accc-bb2c9636c153,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-ff0d49e8-52c8-4bfa-8f16-6051a8a6ecde,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-1a80e5d3-5843-433f-8345-745401c7f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ef46ea57-90d5-4be5-88f2-5f58768b3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-e37d8d27-5533-4762-8444-fa207ca03bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-8c5c0909-f354-4884-88ee-0c5e6c45daa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-7e60fbf0-bfd1-4000-aa04-d9d1f5e962f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-9ae43e1a-50ca-47b8-bd49-b2b84ce16b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63855022-172.17.0.20-1598608928147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-b43693a7-77a0-4cca-afc9-0b5fb4985ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-effd2448-ec08-404f-bb0b-033865a88031,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1cff33e6-5a6a-4428-ad0a-93d5648e712a,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-fbdb54f6-19a9-4085-b458-82f14778296d,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-1245e458-6b41-4048-b013-17ad590fbc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d5c9f8f3-19c2-479a-9bd1-3fc6790daa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-7a90a3b2-97b8-47be-b84e-69ff9e23a151,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-9e293480-00c1-470b-bf18-98c0f7ff6c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63855022-172.17.0.20-1598608928147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-b43693a7-77a0-4cca-afc9-0b5fb4985ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-effd2448-ec08-404f-bb0b-033865a88031,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1cff33e6-5a6a-4428-ad0a-93d5648e712a,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-fbdb54f6-19a9-4085-b458-82f14778296d,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-1245e458-6b41-4048-b013-17ad590fbc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d5c9f8f3-19c2-479a-9bd1-3fc6790daa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-7a90a3b2-97b8-47be-b84e-69ff9e23a151,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-9e293480-00c1-470b-bf18-98c0f7ff6c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207354710-172.17.0.20-1598609065889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45266,DS-94288896-23ad-4d81-bcb8-caff6cd2fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0e5b710c-0905-465b-8af0-9adc48835ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-9d4bf440-3a71-4e87-8498-29078634ba71,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-b2cf5870-7b9f-494e-a760-0306c389974e,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-069da2c4-80e0-4e5c-a631-1c0fad3c3883,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-835ddd07-070c-4a95-8ebe-c70aedcc6916,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-07aed0c7-684d-472c-a42c-c0ac8b757cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-47f0884c-19da-4d56-a99c-fe6c45d32d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207354710-172.17.0.20-1598609065889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45266,DS-94288896-23ad-4d81-bcb8-caff6cd2fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-0e5b710c-0905-465b-8af0-9adc48835ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-9d4bf440-3a71-4e87-8498-29078634ba71,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-b2cf5870-7b9f-494e-a760-0306c389974e,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-069da2c4-80e0-4e5c-a631-1c0fad3c3883,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-835ddd07-070c-4a95-8ebe-c70aedcc6916,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-07aed0c7-684d-472c-a42c-c0ac8b757cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-47f0884c-19da-4d56-a99c-fe6c45d32d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808204328-172.17.0.20-1598609133133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-2c8129d8-dc13-466f-888d-b0f990cffd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-6ba5d5f6-75a7-458e-836c-684fcab066d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-68ed2138-d547-429d-9d90-0f303dd06fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-5959b4b2-107f-42fb-9994-d6e471236aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-af616959-454a-41c5-b07f-108ac20c395c,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-69d612b5-2ba9-438a-aa02-d985d98735bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-99943d4e-94c2-4a83-ab1e-6e0a7117d651,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-ec6bef66-58c6-437a-99ce-bee5274679da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808204328-172.17.0.20-1598609133133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33707,DS-2c8129d8-dc13-466f-888d-b0f990cffd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-6ba5d5f6-75a7-458e-836c-684fcab066d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-68ed2138-d547-429d-9d90-0f303dd06fad,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-5959b4b2-107f-42fb-9994-d6e471236aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-af616959-454a-41c5-b07f-108ac20c395c,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-69d612b5-2ba9-438a-aa02-d985d98735bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-99943d4e-94c2-4a83-ab1e-6e0a7117d651,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-ec6bef66-58c6-437a-99ce-bee5274679da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635008659-172.17.0.20-1598609273245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-b027aeb8-d67a-44ac-994a-ab01f79b5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-098008b4-4a74-4b86-9a72-0afd9f82c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b9d6384b-ed0b-4816-9fdb-898a8c9a7665,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-5eee7ff7-a339-4f00-b624-224a13cf0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-10a483f2-3697-4712-ba9d-3e3cfc448635,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-d2b67b29-9635-4888-9680-80d2bd9a30a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-f24cab65-f998-47fd-a591-175ede9655fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-39882a7a-1611-482b-b2bb-ca1c05174217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635008659-172.17.0.20-1598609273245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-b027aeb8-d67a-44ac-994a-ab01f79b5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-098008b4-4a74-4b86-9a72-0afd9f82c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b9d6384b-ed0b-4816-9fdb-898a8c9a7665,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-5eee7ff7-a339-4f00-b624-224a13cf0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-10a483f2-3697-4712-ba9d-3e3cfc448635,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-d2b67b29-9635-4888-9680-80d2bd9a30a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-f24cab65-f998-47fd-a591-175ede9655fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-39882a7a-1611-482b-b2bb-ca1c05174217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741780714-172.17.0.20-1598609310977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-4136d2bc-2796-45af-9225-ac19a3d2baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-cab54961-5ccb-4e2d-beab-b537ad3ababa,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-5d45d621-5082-4e69-8117-85dc8f0561c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-6ba1db90-7ffc-423f-8666-6cb63dc5f394,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-c9298ce9-f961-4e31-b201-1742a6ef1ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-1b012a37-2533-4748-bb46-9177fac49b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-9cf7ce8e-c7c9-43be-85f6-6eb1614c4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7193a047-7a9a-436f-8cb7-7b66352ad83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741780714-172.17.0.20-1598609310977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-4136d2bc-2796-45af-9225-ac19a3d2baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-cab54961-5ccb-4e2d-beab-b537ad3ababa,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-5d45d621-5082-4e69-8117-85dc8f0561c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-6ba1db90-7ffc-423f-8666-6cb63dc5f394,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-c9298ce9-f961-4e31-b201-1742a6ef1ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-1b012a37-2533-4748-bb46-9177fac49b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-9cf7ce8e-c7c9-43be-85f6-6eb1614c4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-7193a047-7a9a-436f-8cb7-7b66352ad83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016927632-172.17.0.20-1598609673228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-6441c168-0d6e-4c8a-8c81-e3574563a182,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-089eab60-cd6e-4fb6-a9ed-1429439b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-25282749-e05d-4ec5-ab6d-002bb11a8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-b5099231-066e-4a3d-a86e-72a0a77e2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-a2ffc3c8-3087-4f61-a1b9-315c52459579,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-5c2d1b54-e76d-4217-821a-fef5726fe2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-09284374-489f-4995-94ca-df00d56b0dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9b68986b-0357-4476-90f3-5817d7c0abe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016927632-172.17.0.20-1598609673228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-6441c168-0d6e-4c8a-8c81-e3574563a182,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-089eab60-cd6e-4fb6-a9ed-1429439b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-25282749-e05d-4ec5-ab6d-002bb11a8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-b5099231-066e-4a3d-a86e-72a0a77e2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-a2ffc3c8-3087-4f61-a1b9-315c52459579,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-5c2d1b54-e76d-4217-821a-fef5726fe2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-09284374-489f-4995-94ca-df00d56b0dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9b68986b-0357-4476-90f3-5817d7c0abe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182101597-172.17.0.20-1598609946250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42696,DS-2e44fdac-fd84-48e6-83ae-07cbd896744d,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-0482250a-63a8-48c5-b791-63b06a09b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-44dfb62b-c795-4d3a-8cc9-0412de1ba9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-6dc16a7f-5d96-48a6-b251-50755ffec481,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b75c9633-8527-407e-af18-24e2b0d143eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-b86c8998-253e-46bf-a960-c8bb2e17621a,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-21911220-e41c-4e7f-b638-c67d684b2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-3c28c4f3-e859-4e20-aae3-2888c3d7ec9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182101597-172.17.0.20-1598609946250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42696,DS-2e44fdac-fd84-48e6-83ae-07cbd896744d,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-0482250a-63a8-48c5-b791-63b06a09b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-44dfb62b-c795-4d3a-8cc9-0412de1ba9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-6dc16a7f-5d96-48a6-b251-50755ffec481,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b75c9633-8527-407e-af18-24e2b0d143eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-b86c8998-253e-46bf-a960-c8bb2e17621a,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-21911220-e41c-4e7f-b638-c67d684b2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-3c28c4f3-e859-4e20-aae3-2888c3d7ec9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624924798-172.17.0.20-1598610202439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-2806858a-8b8f-4143-98b7-bfa4094166c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-60194158-d14b-4723-ae74-2fc099d875fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-eda9d88d-ed2e-43b0-aa4a-32c04f7b5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-7720a214-7f4a-46ee-843b-fd0113db29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-424bfbac-fce4-43eb-a50f-c2db4cf13f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-363568c1-e4d4-445f-8f26-f0a097eacb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-824af1cd-cf45-4389-872f-e4d95dd3d735,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-f4b85fff-7c35-4ad4-b37b-be7559230233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624924798-172.17.0.20-1598610202439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-2806858a-8b8f-4143-98b7-bfa4094166c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-60194158-d14b-4723-ae74-2fc099d875fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-eda9d88d-ed2e-43b0-aa4a-32c04f7b5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-7720a214-7f4a-46ee-843b-fd0113db29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-424bfbac-fce4-43eb-a50f-c2db4cf13f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-363568c1-e4d4-445f-8f26-f0a097eacb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-824af1cd-cf45-4389-872f-e4d95dd3d735,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-f4b85fff-7c35-4ad4-b37b-be7559230233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314661804-172.17.0.20-1598610599822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-906daa76-b408-43b9-9965-3ff67a8a4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-b28277d6-a97d-4423-b2fa-c1272aa0e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-4547f2ab-763e-4da3-a747-a9641f27212e,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0c5a5d6d-4cb8-49dd-a50f-5f8e05a89671,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-21c05970-1764-4c57-a299-f0841b9a73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-b9560de4-cf0b-4b16-8189-6f8199b319e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-652c9601-5e7f-4c13-8080-fd7850d6631f,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-bf48ede4-3d78-4c05-8d65-7d6cb3f6fa0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314661804-172.17.0.20-1598610599822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-906daa76-b408-43b9-9965-3ff67a8a4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-b28277d6-a97d-4423-b2fa-c1272aa0e2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-4547f2ab-763e-4da3-a747-a9641f27212e,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-0c5a5d6d-4cb8-49dd-a50f-5f8e05a89671,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-21c05970-1764-4c57-a299-f0841b9a73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-b9560de4-cf0b-4b16-8189-6f8199b319e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-652c9601-5e7f-4c13-8080-fd7850d6631f,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-bf48ede4-3d78-4c05-8d65-7d6cb3f6fa0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361509387-172.17.0.20-1598610637660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-022098c5-b103-47ae-bdaa-e5da028da6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-2a4bc82e-4682-4fd3-b7e0-7a329a64b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-b71e389b-0575-41ea-9ac8-6dce70572821,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-fc2e03a3-9061-4197-a3bd-2a4d72f0fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-770a098c-a32c-441d-916d-e2ff9a053f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-716eaba0-2e79-44bc-badf-690a7bb0e428,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-158799d4-dabf-4dcf-9156-8fcece3cce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-b1c92176-e129-43ca-9170-076134895169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361509387-172.17.0.20-1598610637660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40785,DS-022098c5-b103-47ae-bdaa-e5da028da6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-2a4bc82e-4682-4fd3-b7e0-7a329a64b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-b71e389b-0575-41ea-9ac8-6dce70572821,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-fc2e03a3-9061-4197-a3bd-2a4d72f0fa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-770a098c-a32c-441d-916d-e2ff9a053f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-716eaba0-2e79-44bc-badf-690a7bb0e428,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-158799d4-dabf-4dcf-9156-8fcece3cce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-b1c92176-e129-43ca-9170-076134895169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818502539-172.17.0.20-1598611104460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-f6533af8-14be-44bc-a681-24c05c15d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-5f448b33-dd33-4a76-8901-03de93f0a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-24a8c082-12d1-4b13-be59-9ee5d93ade47,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-0574e44b-24eb-4bcd-8217-d84790110755,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-53149cd6-a024-45ee-aa37-fc0b64651579,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-30215536-5420-4297-8048-c4d532e33f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6d6b8cd0-ade5-4830-b652-6a0dd16b261c,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-1ddcb88c-c25a-422e-bacf-77793db915eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818502539-172.17.0.20-1598611104460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-f6533af8-14be-44bc-a681-24c05c15d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-5f448b33-dd33-4a76-8901-03de93f0a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-24a8c082-12d1-4b13-be59-9ee5d93ade47,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-0574e44b-24eb-4bcd-8217-d84790110755,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-53149cd6-a024-45ee-aa37-fc0b64651579,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-30215536-5420-4297-8048-c4d532e33f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-6d6b8cd0-ade5-4830-b652-6a0dd16b261c,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-1ddcb88c-c25a-422e-bacf-77793db915eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919989509-172.17.0.20-1598611453675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-0c83f990-fc8f-4bf3-ac59-16fe3fcbaecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-220353bb-5a2b-4a44-b48f-5b419dc28a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-0f83b24f-bf9f-45fc-b1fa-2eae4c019831,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-7bc33739-204e-4010-9250-1bd37597f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-81ee7010-d92d-48a2-9fda-c7ad6bd49c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-7c762fc5-f0f0-4c8b-b6ff-f6ebffb7ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4c08daff-d0dd-4008-a27b-520d3894a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-6877dab2-40c7-460f-912a-4bf38058bb6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919989509-172.17.0.20-1598611453675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-0c83f990-fc8f-4bf3-ac59-16fe3fcbaecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-220353bb-5a2b-4a44-b48f-5b419dc28a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-0f83b24f-bf9f-45fc-b1fa-2eae4c019831,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-7bc33739-204e-4010-9250-1bd37597f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-81ee7010-d92d-48a2-9fda-c7ad6bd49c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-7c762fc5-f0f0-4c8b-b6ff-f6ebffb7ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4c08daff-d0dd-4008-a27b-520d3894a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-6877dab2-40c7-460f-912a-4bf38058bb6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603858254-172.17.0.20-1598611811347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-672793cd-c43e-44f1-87e7-e1fd0a71cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f8db2e84-a1eb-4bf7-a101-c96076a600cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-e091acd5-bd28-4f3d-84ca-67c29a78d761,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-d0fc03af-846d-4f5f-b7b2-d37a6a4f70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-b783467e-8292-44c9-94a4-c6ebafdf8375,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-67e0fd97-b3a4-466e-b7d5-8e7d0ca91a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-0bf960b3-1a22-42e6-abfb-35ea4608f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-4edcbc3f-4511-4ccc-b4f9-2e82233e153a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603858254-172.17.0.20-1598611811347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-672793cd-c43e-44f1-87e7-e1fd0a71cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f8db2e84-a1eb-4bf7-a101-c96076a600cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-e091acd5-bd28-4f3d-84ca-67c29a78d761,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-d0fc03af-846d-4f5f-b7b2-d37a6a4f70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-b783467e-8292-44c9-94a4-c6ebafdf8375,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-67e0fd97-b3a4-466e-b7d5-8e7d0ca91a57,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-0bf960b3-1a22-42e6-abfb-35ea4608f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-4edcbc3f-4511-4ccc-b4f9-2e82233e153a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057828854-172.17.0.20-1598612359911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35885,DS-bfdc55f1-47cd-4eda-a77b-6764e20c34cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-ca2fcd45-a6aa-47b7-8ad4-fda3c649d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-f4be4893-9a70-4e4f-bd7e-860421e54bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-92318281-23c4-489c-8a73-6edde779c683,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-f6856335-5e9f-4630-bffe-84b6a4ab09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-5bb443b6-f1dd-4c4f-ad58-084f787ced48,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-9ef33280-bdf3-4b69-94c6-7f9ce951c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-653d7cc5-b0af-47f7-a837-56c234c5e26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057828854-172.17.0.20-1598612359911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35885,DS-bfdc55f1-47cd-4eda-a77b-6764e20c34cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-ca2fcd45-a6aa-47b7-8ad4-fda3c649d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-f4be4893-9a70-4e4f-bd7e-860421e54bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-92318281-23c4-489c-8a73-6edde779c683,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-f6856335-5e9f-4630-bffe-84b6a4ab09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-5bb443b6-f1dd-4c4f-ad58-084f787ced48,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-9ef33280-bdf3-4b69-94c6-7f9ce951c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-653d7cc5-b0af-47f7-a837-56c234c5e26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586217804-172.17.0.20-1598612883629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-cf710c68-509c-4993-8431-6e76a5d5ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2dd2cbee-3f2f-4e6e-8fb8-ab44add89226,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-81067c95-4eb7-4ab3-8643-9e0024d7546a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8b0f743e-a18b-4a04-8c7d-e5aedeb6a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-cac6aed0-3f8f-4666-86bf-de308ba32e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-ce2b62f6-f411-4877-8ccf-a4fc8bb6c098,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-0d1f138c-0a6d-4a4a-9cc7-3c938d7178f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-b6c2d852-e64e-4874-a5ea-a2d0921911ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586217804-172.17.0.20-1598612883629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-cf710c68-509c-4993-8431-6e76a5d5ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-2dd2cbee-3f2f-4e6e-8fb8-ab44add89226,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-81067c95-4eb7-4ab3-8643-9e0024d7546a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-8b0f743e-a18b-4a04-8c7d-e5aedeb6a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-cac6aed0-3f8f-4666-86bf-de308ba32e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-ce2b62f6-f411-4877-8ccf-a4fc8bb6c098,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-0d1f138c-0a6d-4a4a-9cc7-3c938d7178f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-b6c2d852-e64e-4874-a5ea-a2d0921911ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903498874-172.17.0.20-1598612923411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-72cafca6-d98d-4d2f-8418-e48a387b1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-92a3d44e-0ff5-49f3-b7f8-79aa7c0504df,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5a5accb7-23b0-43dd-a981-5d2b5aaf8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-43c80881-6ecf-438d-92a5-b00fb1c1e473,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-16bc2ae1-b136-4542-8980-e39ff9ddabbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-ffa6be5c-d30a-4e26-b18d-bdc86e9792f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c90eea6a-3b90-4f9f-936f-2a7120796333,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-be263931-562c-43ed-a4e1-dd2dfaa77455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903498874-172.17.0.20-1598612923411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-72cafca6-d98d-4d2f-8418-e48a387b1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-92a3d44e-0ff5-49f3-b7f8-79aa7c0504df,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5a5accb7-23b0-43dd-a981-5d2b5aaf8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-43c80881-6ecf-438d-92a5-b00fb1c1e473,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-16bc2ae1-b136-4542-8980-e39ff9ddabbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-ffa6be5c-d30a-4e26-b18d-bdc86e9792f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c90eea6a-3b90-4f9f-936f-2a7120796333,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-be263931-562c-43ed-a4e1-dd2dfaa77455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167259715-172.17.0.20-1598613769165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35563,DS-1ae812d9-3e96-4283-9ca7-c8f8f0fccbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-8f200522-c4fa-45d2-a14a-98b6a2f08cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-8dcd7846-e8c0-493b-800c-6040c7265912,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0654dd50-2cad-4a95-b3c2-fc3cc14892eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-9e0d31ec-09bb-4b52-b4ad-cfef18fcf189,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-eaee3924-5dd5-412a-9683-082231d3b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-645e0233-7a09-4901-80aa-3de6e9e94369,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-e9e17aa8-8688-4caf-a748-2df3bffa7aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167259715-172.17.0.20-1598613769165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35563,DS-1ae812d9-3e96-4283-9ca7-c8f8f0fccbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-8f200522-c4fa-45d2-a14a-98b6a2f08cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-8dcd7846-e8c0-493b-800c-6040c7265912,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-0654dd50-2cad-4a95-b3c2-fc3cc14892eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-9e0d31ec-09bb-4b52-b4ad-cfef18fcf189,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-eaee3924-5dd5-412a-9683-082231d3b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-645e0233-7a09-4901-80aa-3de6e9e94369,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-e9e17aa8-8688-4caf-a748-2df3bffa7aa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93733748-172.17.0.20-1598613912033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46747,DS-b3944ba5-06f4-49c0-b279-b5b831a83205,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-5b68ddc3-768c-4883-9c3f-a7dc948a75ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-8a97f312-c82c-4586-b6bc-db71c64931e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-43a69fb0-3aa9-41e5-92e9-ac21c577e192,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-63876d57-1565-4acc-835e-cea5fd4972e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-8466bc75-db77-4847-b003-a2fe592f044b,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-f33309df-1286-4551-86e9-d8520c33faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-6250fa82-0133-4772-b85f-db007a1c81c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93733748-172.17.0.20-1598613912033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46747,DS-b3944ba5-06f4-49c0-b279-b5b831a83205,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-5b68ddc3-768c-4883-9c3f-a7dc948a75ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-8a97f312-c82c-4586-b6bc-db71c64931e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-43a69fb0-3aa9-41e5-92e9-ac21c577e192,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-63876d57-1565-4acc-835e-cea5fd4972e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-8466bc75-db77-4847-b003-a2fe592f044b,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-f33309df-1286-4551-86e9-d8520c33faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-6250fa82-0133-4772-b85f-db007a1c81c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5532
