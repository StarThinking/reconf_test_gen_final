reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899652693-172.17.0.11-1598512473615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-6f587b64-5856-4502-b9b8-55362c980b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-da43af89-e9fb-4358-8c9e-ad2439743786,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-d4530f9b-d1d7-4d11-a5ee-cc007bf5ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-fdfff2b2-22b6-4c4b-91d2-03282615180a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-bd6e76a1-e63a-4de8-a886-66d89b7f0458,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-0de047f9-faf4-48b7-9c0c-016e8c9406c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-0d481146-7dac-4ab5-99ea-3b2c77f90cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c2e62a90-12e4-4c2f-8951-0deb563c5684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899652693-172.17.0.11-1598512473615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-6f587b64-5856-4502-b9b8-55362c980b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-da43af89-e9fb-4358-8c9e-ad2439743786,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-d4530f9b-d1d7-4d11-a5ee-cc007bf5ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-fdfff2b2-22b6-4c4b-91d2-03282615180a,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-bd6e76a1-e63a-4de8-a886-66d89b7f0458,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-0de047f9-faf4-48b7-9c0c-016e8c9406c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-0d481146-7dac-4ab5-99ea-3b2c77f90cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c2e62a90-12e4-4c2f-8951-0deb563c5684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051773155-172.17.0.11-1598513419205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-ff555a7e-1338-4342-80b4-1fcaed405d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a7e47333-5412-4b1e-b3ee-a549603aa4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d687864-48d4-4f60-8e85-fccb86b652dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-2f881cf2-12e8-4113-87ed-87f09417c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-f322a1d9-2e43-4183-8ecf-0250545992f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-9f96a1f5-90d6-4985-b5e2-d32b7dc7ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-1176010a-fc34-414e-88ba-b7e522d11ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-ffc0aeff-9b0e-4f2a-b02b-605c2132295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051773155-172.17.0.11-1598513419205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-ff555a7e-1338-4342-80b4-1fcaed405d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a7e47333-5412-4b1e-b3ee-a549603aa4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-0d687864-48d4-4f60-8e85-fccb86b652dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-2f881cf2-12e8-4113-87ed-87f09417c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-f322a1d9-2e43-4183-8ecf-0250545992f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-9f96a1f5-90d6-4985-b5e2-d32b7dc7ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-1176010a-fc34-414e-88ba-b7e522d11ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-ffc0aeff-9b0e-4f2a-b02b-605c2132295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723933463-172.17.0.11-1598513700654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-b89b1427-93a6-4bcf-b1d9-9aa7ec0c3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-5b9766ee-8733-46e5-af8e-7a7e9ad746e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0823444-3b3f-48f3-8ffd-26cfc2411f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-6613a6eb-db56-4cf8-81ee-1b18b3bdcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-3160e81f-f4f9-43fe-82ba-febaf57c72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-2c831d68-b045-45c2-ad0a-f9feea682bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a2958244-f40f-4fa7-9db8-24cea46daf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-9131beb4-0554-4124-8d70-d8e5d1016273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723933463-172.17.0.11-1598513700654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-b89b1427-93a6-4bcf-b1d9-9aa7ec0c3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-5b9766ee-8733-46e5-af8e-7a7e9ad746e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-e0823444-3b3f-48f3-8ffd-26cfc2411f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-6613a6eb-db56-4cf8-81ee-1b18b3bdcf76,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-3160e81f-f4f9-43fe-82ba-febaf57c72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-2c831d68-b045-45c2-ad0a-f9feea682bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-a2958244-f40f-4fa7-9db8-24cea46daf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-9131beb4-0554-4124-8d70-d8e5d1016273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010140381-172.17.0.11-1598514065718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38872,DS-ab84b68c-42f2-46cd-b692-f2475d366f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-15e12f96-e66b-4844-9545-f529730deafc,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-c698152d-75ec-4ebc-aa78-0006559366ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-0a71219a-bd74-4441-8141-81042b6c58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-afe93e3f-d42b-4ba3-93c1-d0645c418d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-4bdd9995-5314-4d55-a6c7-f1194ba26c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-323f43df-461c-44da-bcd0-fe6453d6d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-5638db5d-15f7-43c4-b090-9be24e92fdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010140381-172.17.0.11-1598514065718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38872,DS-ab84b68c-42f2-46cd-b692-f2475d366f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-15e12f96-e66b-4844-9545-f529730deafc,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-c698152d-75ec-4ebc-aa78-0006559366ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-0a71219a-bd74-4441-8141-81042b6c58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-afe93e3f-d42b-4ba3-93c1-d0645c418d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-4bdd9995-5314-4d55-a6c7-f1194ba26c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-323f43df-461c-44da-bcd0-fe6453d6d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-5638db5d-15f7-43c4-b090-9be24e92fdbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720402350-172.17.0.11-1598514998765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-2a749701-8692-4a35-b935-2c26a5f3a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-3afa9157-69ce-4e6f-abf2-a55a0ad35128,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-50e113bd-c51c-4ca7-8578-420a946193f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-09d744fd-b4ff-42ba-92e2-31d6de535f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-9ff19fb5-57b0-4a20-a865-845a960826cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-76548972-fe74-467f-b5f7-2d72d993e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-60ff81e6-91a8-4434-b957-b55ee633319b,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9c26d9c1-31cb-4be7-861c-8774f7027c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720402350-172.17.0.11-1598514998765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-2a749701-8692-4a35-b935-2c26a5f3a856,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-3afa9157-69ce-4e6f-abf2-a55a0ad35128,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-50e113bd-c51c-4ca7-8578-420a946193f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-09d744fd-b4ff-42ba-92e2-31d6de535f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-9ff19fb5-57b0-4a20-a865-845a960826cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-76548972-fe74-467f-b5f7-2d72d993e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-60ff81e6-91a8-4434-b957-b55ee633319b,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9c26d9c1-31cb-4be7-861c-8774f7027c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125201334-172.17.0.11-1598515143628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-71c1338f-a59b-4188-a8c5-200aa0d8bc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-ebe3a3e9-b364-4b11-957d-bb7398bfd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-f54bcafa-cec8-4c86-8535-48d20cd23c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-8a153719-df7d-4eb9-9076-ceba4dc103ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-08c1e0b5-d2be-4271-b91c-a577d4abec6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-41f8dcf3-1492-47ae-8ea8-6467e44e9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-289501ed-349a-4642-905e-2be8f1228096,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-09b8b380-84ed-405b-93e5-3b03e93f382b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125201334-172.17.0.11-1598515143628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-71c1338f-a59b-4188-a8c5-200aa0d8bc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-ebe3a3e9-b364-4b11-957d-bb7398bfd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-f54bcafa-cec8-4c86-8535-48d20cd23c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-8a153719-df7d-4eb9-9076-ceba4dc103ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-08c1e0b5-d2be-4271-b91c-a577d4abec6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-41f8dcf3-1492-47ae-8ea8-6467e44e9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-289501ed-349a-4642-905e-2be8f1228096,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-09b8b380-84ed-405b-93e5-3b03e93f382b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457592501-172.17.0.11-1598515214086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-c955b744-27c9-4610-8da9-562aa7f382c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-57b7780e-3582-444d-8227-7bfdc7a26f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-dc2b2fc3-15fe-4d57-bbdc-0cfe3efca905,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-1d545798-4bb2-431f-89bf-d49aa71a0166,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-76517dad-e2e6-49f5-ae11-8cf702be1ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-50c15e05-db3d-4bba-82cf-df87beb949f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-dc1cd12b-18f5-4540-97ac-d037c575e210,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7b140a92-2d03-4dfd-a18b-8651fac53828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457592501-172.17.0.11-1598515214086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39985,DS-c955b744-27c9-4610-8da9-562aa7f382c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-57b7780e-3582-444d-8227-7bfdc7a26f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-dc2b2fc3-15fe-4d57-bbdc-0cfe3efca905,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-1d545798-4bb2-431f-89bf-d49aa71a0166,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-76517dad-e2e6-49f5-ae11-8cf702be1ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-50c15e05-db3d-4bba-82cf-df87beb949f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-dc1cd12b-18f5-4540-97ac-d037c575e210,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7b140a92-2d03-4dfd-a18b-8651fac53828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677098364-172.17.0.11-1598515250264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-4feafda8-8371-48b4-8e09-28fd0409244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-52bf3315-e47c-4127-894d-0e13e09bc0df,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-05452e04-700c-4f6e-b158-5993c54b5ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-0a6e77b5-f1cf-476d-b3ad-f2b701fb5b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-e14f8cae-fe55-40d1-9ee4-5767dfd6cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-019b7e47-9b40-465c-bf04-9e278cb7e218,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-b8ee0a3a-c42c-4443-b40c-985fce90f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-7b8c6434-39da-4eff-a428-de1e7b0e48f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677098364-172.17.0.11-1598515250264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-4feafda8-8371-48b4-8e09-28fd0409244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-52bf3315-e47c-4127-894d-0e13e09bc0df,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-05452e04-700c-4f6e-b158-5993c54b5ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-0a6e77b5-f1cf-476d-b3ad-f2b701fb5b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-e14f8cae-fe55-40d1-9ee4-5767dfd6cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-019b7e47-9b40-465c-bf04-9e278cb7e218,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-b8ee0a3a-c42c-4443-b40c-985fce90f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-7b8c6434-39da-4eff-a428-de1e7b0e48f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261854968-172.17.0.11-1598515405523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40338,DS-0948d932-4534-41b8-804f-383f315db3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ff4ab51f-e674-4b9b-922a-960b2ca6b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-7e5fc215-fdf3-48df-8d77-6c92599a47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-8df69e4c-c6c3-440b-b9b4-43c6a574fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-1dd53c3e-c734-4228-9a89-deb53ea5ec0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2cec045f-82b4-4916-a6df-95aef7d52785,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-6ac23499-5bf7-4c02-b6a6-580d2eb94f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-d52033f5-044d-403a-9e48-55de0a0afe70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261854968-172.17.0.11-1598515405523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40338,DS-0948d932-4534-41b8-804f-383f315db3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-ff4ab51f-e674-4b9b-922a-960b2ca6b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-7e5fc215-fdf3-48df-8d77-6c92599a47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-8df69e4c-c6c3-440b-b9b4-43c6a574fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-1dd53c3e-c734-4228-9a89-deb53ea5ec0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-2cec045f-82b4-4916-a6df-95aef7d52785,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-6ac23499-5bf7-4c02-b6a6-580d2eb94f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-d52033f5-044d-403a-9e48-55de0a0afe70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315417638-172.17.0.11-1598516324733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-8a74096f-a84a-4a8d-b96d-2cab5ba292d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-9b5b2ea7-372c-4a1c-8f43-0f1fd79bced0,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-cf5a4fbf-9b43-4031-92f6-2bc016009521,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-3ee72490-f612-4191-aac6-3c3629b27984,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-cdf91025-ecee-4500-9c73-0c51cf7ab04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b79d3474-beae-469b-b4ef-6344da023ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d54e213a-53cc-4ea5-a136-db0b17cf8a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-e90a9e5a-a44f-4d13-896a-201b0404cfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315417638-172.17.0.11-1598516324733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-8a74096f-a84a-4a8d-b96d-2cab5ba292d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-9b5b2ea7-372c-4a1c-8f43-0f1fd79bced0,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-cf5a4fbf-9b43-4031-92f6-2bc016009521,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-3ee72490-f612-4191-aac6-3c3629b27984,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-cdf91025-ecee-4500-9c73-0c51cf7ab04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b79d3474-beae-469b-b4ef-6344da023ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d54e213a-53cc-4ea5-a136-db0b17cf8a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-e90a9e5a-a44f-4d13-896a-201b0404cfcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586497793-172.17.0.11-1598516356652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-210376c2-c32e-45ab-84b5-e9f0c16d95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-140a9216-1f95-4e42-912d-45ad3620645f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-8970c8c8-f5a7-4516-b246-72a4cbd0afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-8a1c7001-498e-4686-a73d-7a7592cef505,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-046c8dd2-a965-4338-9155-e2b15055f362,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-4c6c9b65-212a-4671-be6f-3ce7f6c7e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-b1f431da-0eed-47db-aa4c-4c022656ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ed6943bb-82f8-41ba-967f-517190747cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586497793-172.17.0.11-1598516356652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34970,DS-210376c2-c32e-45ab-84b5-e9f0c16d95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-140a9216-1f95-4e42-912d-45ad3620645f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-8970c8c8-f5a7-4516-b246-72a4cbd0afa0,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-8a1c7001-498e-4686-a73d-7a7592cef505,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-046c8dd2-a965-4338-9155-e2b15055f362,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-4c6c9b65-212a-4671-be6f-3ce7f6c7e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-b1f431da-0eed-47db-aa4c-4c022656ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ed6943bb-82f8-41ba-967f-517190747cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969777101-172.17.0.11-1598517189730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-f8be2835-7d3a-4f54-9cba-073eb7074664,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-6dd3241d-84cc-4175-80a3-1394587da67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-0063a6a9-f5f1-4071-aa88-e11d377fb9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a4342b12-240d-4a5d-8d20-a7c33a148745,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-503e088e-f8b7-44c1-80ca-45b53967e717,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-be16cb01-5e4a-45f7-b6eb-2bef9e966870,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-ba7137ed-b56d-44ab-8b51-ebed5ea62ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-fc632970-e289-4f15-aa8a-d855c9b87549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969777101-172.17.0.11-1598517189730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-f8be2835-7d3a-4f54-9cba-073eb7074664,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-6dd3241d-84cc-4175-80a3-1394587da67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-0063a6a9-f5f1-4071-aa88-e11d377fb9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-a4342b12-240d-4a5d-8d20-a7c33a148745,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-503e088e-f8b7-44c1-80ca-45b53967e717,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-be16cb01-5e4a-45f7-b6eb-2bef9e966870,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-ba7137ed-b56d-44ab-8b51-ebed5ea62ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-fc632970-e289-4f15-aa8a-d855c9b87549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822481944-172.17.0.11-1598517230698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-c5201fb5-6e54-43b3-bb47-2fb8f9c113be,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-a0cef073-d5d2-4ff5-929d-3fb1b955d8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-f3aada82-8715-44d8-8d6b-6d80b5c70de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-80723819-aba4-4ea6-aede-f44d2251ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-76275256-1eef-4d4e-a7b0-e71cc8cc6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-3c56f692-d353-443f-8c76-94c356822fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-6e2c78b9-ac9f-4452-84f9-e7bf7eaa8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-e0025434-5cfc-4114-943a-823633875d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822481944-172.17.0.11-1598517230698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-c5201fb5-6e54-43b3-bb47-2fb8f9c113be,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-a0cef073-d5d2-4ff5-929d-3fb1b955d8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-f3aada82-8715-44d8-8d6b-6d80b5c70de3,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-80723819-aba4-4ea6-aede-f44d2251ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-76275256-1eef-4d4e-a7b0-e71cc8cc6a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-3c56f692-d353-443f-8c76-94c356822fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-6e2c78b9-ac9f-4452-84f9-e7bf7eaa8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-e0025434-5cfc-4114-943a-823633875d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015340610-172.17.0.11-1598517471615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-c21279ef-bc36-41d5-bcaf-d6d978224fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-7dc1baf3-711a-4c1e-a1d1-a49d24ae21de,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-2c920dba-ab4c-476d-94ae-083c4525168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-38b8d779-3928-4f14-85e1-e9a539df4522,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-17b53c45-1851-4671-a5e0-c97a2676a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-17227ea5-78b2-4bb4-a1b8-f82bbc9cbc02,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-c5470fb6-9813-47e2-8d07-2cbf8857985c,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-e698f217-5349-4d0f-9dab-abe2a06df3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015340610-172.17.0.11-1598517471615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-c21279ef-bc36-41d5-bcaf-d6d978224fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-7dc1baf3-711a-4c1e-a1d1-a49d24ae21de,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-2c920dba-ab4c-476d-94ae-083c4525168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-38b8d779-3928-4f14-85e1-e9a539df4522,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-17b53c45-1851-4671-a5e0-c97a2676a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-17227ea5-78b2-4bb4-a1b8-f82bbc9cbc02,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-c5470fb6-9813-47e2-8d07-2cbf8857985c,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-e698f217-5349-4d0f-9dab-abe2a06df3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5286
