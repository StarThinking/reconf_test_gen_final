reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272497113-172.17.0.9-1598493773071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44853,DS-b65bd89e-83de-4b89-a773-f42c51a01bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-25b1a2d5-a633-4665-a444-22bf3440ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-2e46bdb3-23e2-480f-a356-909713f7b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-ee3ebf0f-528d-49fa-a8f7-c7340da7eab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-af5990eb-7588-4075-ae1b-8ee3b75b2d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-f62d040a-4526-4b81-9ea7-1788efaae584,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-e6c78f13-1c7f-4cdb-b033-4227bc3be8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-cac552c3-d05f-4a49-812f-c562a0396ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272497113-172.17.0.9-1598493773071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44853,DS-b65bd89e-83de-4b89-a773-f42c51a01bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-25b1a2d5-a633-4665-a444-22bf3440ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-2e46bdb3-23e2-480f-a356-909713f7b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-ee3ebf0f-528d-49fa-a8f7-c7340da7eab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-af5990eb-7588-4075-ae1b-8ee3b75b2d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-f62d040a-4526-4b81-9ea7-1788efaae584,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-e6c78f13-1c7f-4cdb-b033-4227bc3be8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-cac552c3-d05f-4a49-812f-c562a0396ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780590232-172.17.0.9-1598494084345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-80a99a1e-3ac2-4824-b2db-2fd541d9b581,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-3fd63bcf-1c75-487f-842e-8f16a8cf9cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-3a12dd78-a654-48b2-ad10-25e4743c5b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2145dd07-ecc6-4780-88ba-a100f0dc80d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fb38c802-94b8-4395-9302-8a3650a94388,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-7845187c-f11c-47aa-8bfb-2eef860d9971,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-9dc645f8-7ba1-4fc7-82e7-ce4d454232e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-afed0d5a-c20b-46dc-9c45-39180f078425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780590232-172.17.0.9-1598494084345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-80a99a1e-3ac2-4824-b2db-2fd541d9b581,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-3fd63bcf-1c75-487f-842e-8f16a8cf9cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-3a12dd78-a654-48b2-ad10-25e4743c5b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2145dd07-ecc6-4780-88ba-a100f0dc80d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fb38c802-94b8-4395-9302-8a3650a94388,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-7845187c-f11c-47aa-8bfb-2eef860d9971,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-9dc645f8-7ba1-4fc7-82e7-ce4d454232e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-afed0d5a-c20b-46dc-9c45-39180f078425,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362169109-172.17.0.9-1598494187385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-e2818427-a18f-42cf-85b7-3fefd3320039,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-962db3d9-e931-465b-ad2c-745b318ed7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-60a56f7e-f111-4f68-9dba-780c155d1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-2bf92f75-a3b4-4dd8-90eb-a48944526ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-4e0480ff-c2b3-433c-bc21-29bd511c33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-96c5d80e-f97c-4670-ae59-42bcf437a485,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-799bba4e-0b2c-4fb7-8afa-6a1ca9bb87f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-98f3737a-cc08-4039-8470-fd8aca42e034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362169109-172.17.0.9-1598494187385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37313,DS-e2818427-a18f-42cf-85b7-3fefd3320039,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-962db3d9-e931-465b-ad2c-745b318ed7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-60a56f7e-f111-4f68-9dba-780c155d1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-2bf92f75-a3b4-4dd8-90eb-a48944526ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-4e0480ff-c2b3-433c-bc21-29bd511c33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-96c5d80e-f97c-4670-ae59-42bcf437a485,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-799bba4e-0b2c-4fb7-8afa-6a1ca9bb87f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-98f3737a-cc08-4039-8470-fd8aca42e034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55361208-172.17.0.9-1598494659595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-fcc4d057-b85f-4a9e-8eff-ec728eb4a534,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-04cc6d79-e1a4-4f1a-a233-5d17757e2a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-bf1144fe-33e1-4d02-8b5e-e1e9d50cefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-cfbcc53d-2769-44a1-80e6-4774c4f72e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f6a055e7-2f0c-4779-aca3-673a8ea1d494,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-2aa9e11f-e979-4cf5-b8c4-57561a918178,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a929319a-bb3a-4bb7-8d0c-ea8c1ec4a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-afc7e0f3-f7e1-4893-a127-3ef54fb6685c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55361208-172.17.0.9-1598494659595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-fcc4d057-b85f-4a9e-8eff-ec728eb4a534,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-04cc6d79-e1a4-4f1a-a233-5d17757e2a13,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-bf1144fe-33e1-4d02-8b5e-e1e9d50cefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-cfbcc53d-2769-44a1-80e6-4774c4f72e38,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-f6a055e7-2f0c-4779-aca3-673a8ea1d494,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-2aa9e11f-e979-4cf5-b8c4-57561a918178,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-a929319a-bb3a-4bb7-8d0c-ea8c1ec4a91d,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-afc7e0f3-f7e1-4893-a127-3ef54fb6685c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637480347-172.17.0.9-1598494687049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-cd370e8a-242c-47c9-ae58-361a8d4d604c,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-74a8bdee-4ccd-43b4-a876-4cd7a7cdf9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-4adb0fce-d0a7-430c-8e5c-8dfe23d6b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-705bd892-4ea8-430e-99b6-06c3880f4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-c167be9e-e8be-43e2-80ce-7534111a3283,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-8801ed2d-2355-4125-a1df-1acbb3560d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-af1326a4-7e68-4e59-b168-0db7cc8ea218,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-eafee77b-7644-45ab-928f-ab7ecfdf825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637480347-172.17.0.9-1598494687049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-cd370e8a-242c-47c9-ae58-361a8d4d604c,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-74a8bdee-4ccd-43b4-a876-4cd7a7cdf9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-4adb0fce-d0a7-430c-8e5c-8dfe23d6b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-705bd892-4ea8-430e-99b6-06c3880f4b86,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-c167be9e-e8be-43e2-80ce-7534111a3283,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-8801ed2d-2355-4125-a1df-1acbb3560d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-af1326a4-7e68-4e59-b168-0db7cc8ea218,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-eafee77b-7644-45ab-928f-ab7ecfdf825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553420823-172.17.0.9-1598494825973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-20111654-05ca-40d5-b1cc-e403a04284dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-6a0e84ed-ec44-4c81-b464-479159206efd,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-4256a30e-fd31-40b2-84a8-d551e8fe7c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-974b6630-6999-4e05-b59a-be43876d35af,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-90e8cc66-6970-4ecf-94b1-3504047442e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-07219e8b-7bc3-4a49-ba4d-1302811fc342,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-5377f560-8ee8-4a5e-9f74-031621ca24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-742d2c44-493e-4f60-b6f7-e40f697bd4a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553420823-172.17.0.9-1598494825973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-20111654-05ca-40d5-b1cc-e403a04284dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-6a0e84ed-ec44-4c81-b464-479159206efd,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-4256a30e-fd31-40b2-84a8-d551e8fe7c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-974b6630-6999-4e05-b59a-be43876d35af,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-90e8cc66-6970-4ecf-94b1-3504047442e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-07219e8b-7bc3-4a49-ba4d-1302811fc342,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-5377f560-8ee8-4a5e-9f74-031621ca24ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-742d2c44-493e-4f60-b6f7-e40f697bd4a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557890149-172.17.0.9-1598494973448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-e5fc4d41-d41e-4ba3-8425-01e644e45cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-6f6c3b0d-fd4c-4a1b-89ed-d6b9d56ee752,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-47bd47f2-80b9-4a43-a24f-f2d300bbdca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-321a9230-08c4-465d-a0e2-9f8b78467afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8f1d7680-348c-4ddb-af54-d0d4b1c0cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-915bca9e-fe79-4c22-9f4d-12fb850f6356,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ed991a26-686c-4bc0-ad97-0815c1560567,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-20d7a1c0-38ca-4a05-b60b-f27e63088316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557890149-172.17.0.9-1598494973448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34023,DS-e5fc4d41-d41e-4ba3-8425-01e644e45cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-6f6c3b0d-fd4c-4a1b-89ed-d6b9d56ee752,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-47bd47f2-80b9-4a43-a24f-f2d300bbdca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-321a9230-08c4-465d-a0e2-9f8b78467afb,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8f1d7680-348c-4ddb-af54-d0d4b1c0cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-915bca9e-fe79-4c22-9f4d-12fb850f6356,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ed991a26-686c-4bc0-ad97-0815c1560567,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-20d7a1c0-38ca-4a05-b60b-f27e63088316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390428812-172.17.0.9-1598495087568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-74446b67-d225-448d-8019-2c0f7aa86cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f1eb1c80-b4a9-46a3-a7f2-a95e41fc1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-76fe913a-e959-4ce7-9e32-12d1b86db834,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-a493920b-33d3-43d2-93e0-7b21db3fb0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-85815bc4-c215-485f-86af-8d8ddd7fb35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-8514d21b-9e9e-447f-aa76-c0623d63b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-eee942e5-4ddb-4a6c-9186-92788155228c,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-2b4df7db-0090-4493-b671-0bf6abf82f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390428812-172.17.0.9-1598495087568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-74446b67-d225-448d-8019-2c0f7aa86cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-f1eb1c80-b4a9-46a3-a7f2-a95e41fc1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-76fe913a-e959-4ce7-9e32-12d1b86db834,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-a493920b-33d3-43d2-93e0-7b21db3fb0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-85815bc4-c215-485f-86af-8d8ddd7fb35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-8514d21b-9e9e-447f-aa76-c0623d63b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-eee942e5-4ddb-4a6c-9186-92788155228c,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-2b4df7db-0090-4493-b671-0bf6abf82f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098411375-172.17.0.9-1598495746206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-042a6cd5-d058-468c-a296-2e0c453bcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-66bc8230-b87a-4c47-bf92-58931c75f346,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-a2aba206-b205-46b6-8468-4accb907006c,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f77b849b-0cd9-4521-bb1d-8779b6d4c656,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-55b148a4-d676-42e3-be06-cfbec1c09e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-32de862d-4b06-4323-8a90-b9901fbe1d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-1d293831-1d28-4d17-9519-ed2ac50b6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-8c480616-373b-472f-999c-7d16ca7bcc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098411375-172.17.0.9-1598495746206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41644,DS-042a6cd5-d058-468c-a296-2e0c453bcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-66bc8230-b87a-4c47-bf92-58931c75f346,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-a2aba206-b205-46b6-8468-4accb907006c,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f77b849b-0cd9-4521-bb1d-8779b6d4c656,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-55b148a4-d676-42e3-be06-cfbec1c09e01,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-32de862d-4b06-4323-8a90-b9901fbe1d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-1d293831-1d28-4d17-9519-ed2ac50b6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-8c480616-373b-472f-999c-7d16ca7bcc8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586628909-172.17.0.9-1598496273166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38939,DS-a67b9c65-52a1-4032-81d5-cbf803b7764d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-fad0f21a-c952-498f-8924-2e1f177f6d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-f66beda7-b5fa-4cb4-968d-e25a9c2c6859,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-d3d2a8af-4dca-4e20-9abd-92be1cd6a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-eb1d3fdc-d25a-4057-b20d-e2599da4c786,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e5bb171f-df3e-4aa5-8034-03cd70e93dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-d8fd7b08-a366-4001-84ae-221065a8d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-4713d007-ef4d-410a-9cd9-7a86289ce7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586628909-172.17.0.9-1598496273166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38939,DS-a67b9c65-52a1-4032-81d5-cbf803b7764d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-fad0f21a-c952-498f-8924-2e1f177f6d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-f66beda7-b5fa-4cb4-968d-e25a9c2c6859,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-d3d2a8af-4dca-4e20-9abd-92be1cd6a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-eb1d3fdc-d25a-4057-b20d-e2599da4c786,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-e5bb171f-df3e-4aa5-8034-03cd70e93dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-d8fd7b08-a366-4001-84ae-221065a8d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-4713d007-ef4d-410a-9cd9-7a86289ce7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22935468-172.17.0.9-1598496659083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-793bf5f3-0d3f-4e38-aa3a-5e8c6a520fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-ea39f28f-46cf-4177-a565-16522e9038fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-c5902998-7f01-4586-b10f-3e20091fb184,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-2c2490bb-c0d4-4e2f-bdd8-5054e9c1d796,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-b00b8c60-ad03-4c63-87f3-4268eae903fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3bd55dfd-4597-4b63-8638-69f1af7c2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-e2ba4a63-2f62-4f5b-89a5-309cc53cf907,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2238d68f-d3da-455f-84cb-24c5d0bcdd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22935468-172.17.0.9-1598496659083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-793bf5f3-0d3f-4e38-aa3a-5e8c6a520fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-ea39f28f-46cf-4177-a565-16522e9038fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-c5902998-7f01-4586-b10f-3e20091fb184,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-2c2490bb-c0d4-4e2f-bdd8-5054e9c1d796,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-b00b8c60-ad03-4c63-87f3-4268eae903fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-3bd55dfd-4597-4b63-8638-69f1af7c2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-e2ba4a63-2f62-4f5b-89a5-309cc53cf907,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2238d68f-d3da-455f-84cb-24c5d0bcdd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485918550-172.17.0.9-1598496737197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42227,DS-7ff29c02-a2f6-4f28-a6df-2186f6460ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-7af36096-60c8-41b5-89af-d1b4b6edefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-fe30ce47-c06f-4e4b-a59f-816647a72092,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-18695ea8-189a-4ef0-b1e3-25c02d2222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-94c88fa3-67c9-4b88-a16e-12f0acec5444,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8c05d2b7-3032-482f-b3c7-0bf8616c0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-58dba298-ac4a-45fc-9d66-a340ac2be246,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-74c850aa-e220-416a-b0ea-437c3c33c078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485918550-172.17.0.9-1598496737197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42227,DS-7ff29c02-a2f6-4f28-a6df-2186f6460ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-7af36096-60c8-41b5-89af-d1b4b6edefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-fe30ce47-c06f-4e4b-a59f-816647a72092,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-18695ea8-189a-4ef0-b1e3-25c02d2222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-94c88fa3-67c9-4b88-a16e-12f0acec5444,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8c05d2b7-3032-482f-b3c7-0bf8616c0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-58dba298-ac4a-45fc-9d66-a340ac2be246,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-74c850aa-e220-416a-b0ea-437c3c33c078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34130658-172.17.0.9-1598497150725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-ebc8d63c-d991-4dd6-8914-2d4445ab41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-00ce3881-ee5e-4dc0-ad13-0e1b0faaf783,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-eb232d56-f018-40de-9ded-7b369cd62638,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-a33cde6d-81ef-4823-a7fd-3810b2fe56e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-7a456af4-c12e-4a7e-b866-0b0593510c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-5cfb9512-df43-4658-8e25-caca6b10d966,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-71ffb174-aab2-4049-b12d-f2ccf5bf79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-885bf8a8-52c3-44b5-8ebd-182670ae235b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34130658-172.17.0.9-1598497150725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-ebc8d63c-d991-4dd6-8914-2d4445ab41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-00ce3881-ee5e-4dc0-ad13-0e1b0faaf783,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-eb232d56-f018-40de-9ded-7b369cd62638,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-a33cde6d-81ef-4823-a7fd-3810b2fe56e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-7a456af4-c12e-4a7e-b866-0b0593510c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-5cfb9512-df43-4658-8e25-caca6b10d966,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-71ffb174-aab2-4049-b12d-f2ccf5bf79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-885bf8a8-52c3-44b5-8ebd-182670ae235b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895369318-172.17.0.9-1598497815321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-7426316b-de89-44cc-a69a-f68f5000c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-81dcb234-c605-40d6-b174-3a978583065c,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-7e6fb9b9-d2ec-466e-b1b2-e2513705d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-16ad924e-b97f-4212-8a3b-6da0299a799a,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-763d0816-d274-43ef-a5c5-d40373d71d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-2e1ad727-6f38-408a-a591-53e9b4ad610b,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-7d884cec-9308-48ff-92fa-37b47189e911,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-eccf2d30-5744-4447-a5f5-bc3cc0062f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895369318-172.17.0.9-1598497815321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-7426316b-de89-44cc-a69a-f68f5000c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-81dcb234-c605-40d6-b174-3a978583065c,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-7e6fb9b9-d2ec-466e-b1b2-e2513705d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-16ad924e-b97f-4212-8a3b-6da0299a799a,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-763d0816-d274-43ef-a5c5-d40373d71d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-2e1ad727-6f38-408a-a591-53e9b4ad610b,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-7d884cec-9308-48ff-92fa-37b47189e911,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-eccf2d30-5744-4447-a5f5-bc3cc0062f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352070963-172.17.0.9-1598497992843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44632,DS-31d1f616-ccbf-45bc-9834-34c88bc86658,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-b701c633-288e-45da-abf0-1ac3b272a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-4dfa1e89-0513-4ed8-8b20-7c2556cb4695,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-20b2a109-8043-41cd-b8f5-5cd3c1c27f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-4060a42c-efa8-449f-9f26-9203ae313a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-2436db84-60ba-4cba-a7ed-523c796e2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-9a092567-11d0-4af4-8775-dd7574133c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-3b5bfbf7-feca-4341-9073-2847c9a5ada9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352070963-172.17.0.9-1598497992843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44632,DS-31d1f616-ccbf-45bc-9834-34c88bc86658,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-b701c633-288e-45da-abf0-1ac3b272a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-4dfa1e89-0513-4ed8-8b20-7c2556cb4695,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-20b2a109-8043-41cd-b8f5-5cd3c1c27f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-4060a42c-efa8-449f-9f26-9203ae313a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-2436db84-60ba-4cba-a7ed-523c796e2d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-9a092567-11d0-4af4-8775-dd7574133c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-3b5bfbf7-feca-4341-9073-2847c9a5ada9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379664771-172.17.0.9-1598498525727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-f3c3aab5-bac1-4806-9dea-49906e015e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-b03f480e-0c35-4bb9-97fb-6781dd9d7279,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-47172602-10df-423a-b78f-04854765c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-ba73b4b1-b527-4dc3-8254-129e261ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f072dd97-cf13-493e-be7a-21993c4b7418,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-f217371a-8511-4c3f-a9c2-c93430633000,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-8bc769ff-d4a8-442c-9db3-8b078090f797,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-dc4ca6c7-0fa6-48ee-80f6-c796f7dda009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379664771-172.17.0.9-1598498525727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-f3c3aab5-bac1-4806-9dea-49906e015e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-b03f480e-0c35-4bb9-97fb-6781dd9d7279,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-47172602-10df-423a-b78f-04854765c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-ba73b4b1-b527-4dc3-8254-129e261ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f072dd97-cf13-493e-be7a-21993c4b7418,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-f217371a-8511-4c3f-a9c2-c93430633000,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-8bc769ff-d4a8-442c-9db3-8b078090f797,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-dc4ca6c7-0fa6-48ee-80f6-c796f7dda009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468425546-172.17.0.9-1598498600954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42351,DS-fd9651ba-9c20-4d1a-878a-fa8def44843b,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-0310b7b3-ab95-4984-afb8-2fc9cfa3993b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-314a2d9a-045c-4a4e-9b73-5ed5a83a9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-d41ff3fd-584d-4b26-8dfa-30e525deef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-c6046076-976d-4c0a-b8b9-ad02870c4e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-0dff1aa8-eff2-4e00-bf36-a5b5a7346dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-e4f15e8f-26c7-4d2d-ac64-971ab1f94c02,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0c73f295-10c9-4e84-b3ef-96e3918430d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468425546-172.17.0.9-1598498600954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42351,DS-fd9651ba-9c20-4d1a-878a-fa8def44843b,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-0310b7b3-ab95-4984-afb8-2fc9cfa3993b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-314a2d9a-045c-4a4e-9b73-5ed5a83a9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-d41ff3fd-584d-4b26-8dfa-30e525deef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-c6046076-976d-4c0a-b8b9-ad02870c4e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-0dff1aa8-eff2-4e00-bf36-a5b5a7346dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-e4f15e8f-26c7-4d2d-ac64-971ab1f94c02,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0c73f295-10c9-4e84-b3ef-96e3918430d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5526
