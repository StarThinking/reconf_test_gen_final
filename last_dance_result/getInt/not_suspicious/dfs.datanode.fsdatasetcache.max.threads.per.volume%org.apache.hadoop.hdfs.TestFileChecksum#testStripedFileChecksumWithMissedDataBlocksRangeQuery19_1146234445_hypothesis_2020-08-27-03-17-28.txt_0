reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438140331-172.17.0.16-1598498266598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-61a14667-7365-4337-9545-247d779dc2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-464608e4-40a9-4321-b7dd-617aaae80e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-4b892581-bec1-469d-b01a-26c883005815,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-c4810503-c7f9-4c42-a63e-ff2fb9c06fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-4f93c8d5-5ba8-4a99-a2b7-9170908a5f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2dcc357a-6b5a-40f7-9358-4ef126a5c931,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-3c0aa8ba-52fa-42e8-9b83-fea0d08afced,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3959669e-e63b-4746-acbc-0484f7605c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-438140331-172.17.0.16-1598498266598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-61a14667-7365-4337-9545-247d779dc2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-464608e4-40a9-4321-b7dd-617aaae80e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-4b892581-bec1-469d-b01a-26c883005815,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-c4810503-c7f9-4c42-a63e-ff2fb9c06fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-4f93c8d5-5ba8-4a99-a2b7-9170908a5f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2dcc357a-6b5a-40f7-9358-4ef126a5c931,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-3c0aa8ba-52fa-42e8-9b83-fea0d08afced,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3959669e-e63b-4746-acbc-0484f7605c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444220635-172.17.0.16-1598498614978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-b5b1ac75-a80e-482c-98f7-1de58d59a620,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-6798dbb8-c021-47d5-861c-bb816f30c525,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0253c12e-5805-4176-b298-103aa7116ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-deb8d497-503a-4ce5-9bea-87d1cb7dacd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-2007cba1-c21c-4652-a1e9-876523d3f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-f643130a-4007-42f4-8835-c3a82dde399f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-076e679c-8248-47e3-a4a5-8349bc771fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-72a30244-fa94-441c-bb55-ad25a4d977d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1444220635-172.17.0.16-1598498614978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-b5b1ac75-a80e-482c-98f7-1de58d59a620,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-6798dbb8-c021-47d5-861c-bb816f30c525,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0253c12e-5805-4176-b298-103aa7116ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-deb8d497-503a-4ce5-9bea-87d1cb7dacd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-2007cba1-c21c-4652-a1e9-876523d3f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-f643130a-4007-42f4-8835-c3a82dde399f,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-076e679c-8248-47e3-a4a5-8349bc771fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-72a30244-fa94-441c-bb55-ad25a4d977d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249544686-172.17.0.16-1598498953608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-e80f7800-ada8-4827-a0c2-17d898ac2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-1a4e138a-ea2c-4239-b3ce-0580092dad24,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67216be9-f6b5-4633-8faf-971a9d79e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-b7bd4240-b921-4353-9664-d591fb61c103,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-e67d78f0-88d7-4e62-ae65-5983f00cd92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-c3baf635-8078-4579-8992-07c8ef2103d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-b820fd6a-e0fc-4278-87c0-e40b2a7aa887,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2c5b5411-a879-4b6e-9b92-42e87e8706b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249544686-172.17.0.16-1598498953608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-e80f7800-ada8-4827-a0c2-17d898ac2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-1a4e138a-ea2c-4239-b3ce-0580092dad24,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67216be9-f6b5-4633-8faf-971a9d79e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-b7bd4240-b921-4353-9664-d591fb61c103,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-e67d78f0-88d7-4e62-ae65-5983f00cd92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-c3baf635-8078-4579-8992-07c8ef2103d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-b820fd6a-e0fc-4278-87c0-e40b2a7aa887,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2c5b5411-a879-4b6e-9b92-42e87e8706b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427272811-172.17.0.16-1598499846411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-6d667d37-63df-4764-90b1-17939b8b98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-33c83ed9-a1b0-446c-a416-a9f1e52e2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b3cf23a8-6c13-4346-a4e5-063621a2d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-4b88bee9-0ee1-4e35-a210-30e7b4cd3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-24763084-a33f-426f-ae89-d47f4c9b3f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-da691805-6e22-40d2-9c2a-afa3a1c9db79,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-82535b82-28a5-4717-809e-cfb3eabfffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-42a2b1ad-b51e-4ebb-8f62-ca399ea42c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427272811-172.17.0.16-1598499846411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37526,DS-6d667d37-63df-4764-90b1-17939b8b98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-33c83ed9-a1b0-446c-a416-a9f1e52e2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b3cf23a8-6c13-4346-a4e5-063621a2d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-4b88bee9-0ee1-4e35-a210-30e7b4cd3d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-24763084-a33f-426f-ae89-d47f4c9b3f25,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-da691805-6e22-40d2-9c2a-afa3a1c9db79,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-82535b82-28a5-4717-809e-cfb3eabfffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-42a2b1ad-b51e-4ebb-8f62-ca399ea42c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602884769-172.17.0.16-1598499884803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-7abb9083-0fe6-4cee-81a7-83b7b36983ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-201ac23d-36bc-467a-bba8-09609bfab79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-7a4a6162-3a63-4dd3-ada3-8b04d970eff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e25cb047-23b3-4844-87a4-7cd4c93de92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-cb89194c-9f59-4abd-969e-267a83d70997,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-901d33b7-1e83-47d8-8b19-3e9d30b8e7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d278d72e-21a4-4081-b3dc-cbe76f68831b,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-ec94532f-082b-470a-a37c-1027cc929c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602884769-172.17.0.16-1598499884803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-7abb9083-0fe6-4cee-81a7-83b7b36983ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-201ac23d-36bc-467a-bba8-09609bfab79b,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-7a4a6162-3a63-4dd3-ada3-8b04d970eff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e25cb047-23b3-4844-87a4-7cd4c93de92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-cb89194c-9f59-4abd-969e-267a83d70997,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-901d33b7-1e83-47d8-8b19-3e9d30b8e7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-d278d72e-21a4-4081-b3dc-cbe76f68831b,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-ec94532f-082b-470a-a37c-1027cc929c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624386187-172.17.0.16-1598500027399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-26da047c-d3c9-4126-bebd-09538a93beaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-b20c0d2b-6be6-46c2-8898-4803eca01b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-d0472305-22f7-4076-8b31-e55ec2dff7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a2e74f2a-2bce-4ae2-bb15-773bc0e19af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-8b6ba96f-d2c2-4ae2-ae00-e3dc4382f617,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-d80a25ae-cc57-438c-8908-35721c879900,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-18d7835e-7e77-47d5-955f-1d08990080d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-986e413f-6638-45f1-a4a8-08718b570013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624386187-172.17.0.16-1598500027399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-26da047c-d3c9-4126-bebd-09538a93beaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-b20c0d2b-6be6-46c2-8898-4803eca01b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-d0472305-22f7-4076-8b31-e55ec2dff7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-a2e74f2a-2bce-4ae2-bb15-773bc0e19af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-8b6ba96f-d2c2-4ae2-ae00-e3dc4382f617,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-d80a25ae-cc57-438c-8908-35721c879900,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-18d7835e-7e77-47d5-955f-1d08990080d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-986e413f-6638-45f1-a4a8-08718b570013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241877462-172.17.0.16-1598500234660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-5667def6-cf81-493c-be32-12a9e6bd25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-8d757000-5acb-4e91-926a-9ce6696bb409,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-6779e6ab-4f80-41d8-816e-8b865b7653c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-29632791-6a30-4771-b9aa-46fc1be58f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fa8cf298-4f7d-4a3d-98da-c58bb3c94004,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-2c4bf075-0a2f-4daf-8c64-8561609bee56,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-485fb4d1-b15b-48bf-87aa-160b7e26b803,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-6c514c46-4da3-4361-b6e1-ac29002e7e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241877462-172.17.0.16-1598500234660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-5667def6-cf81-493c-be32-12a9e6bd25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-8d757000-5acb-4e91-926a-9ce6696bb409,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-6779e6ab-4f80-41d8-816e-8b865b7653c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-29632791-6a30-4771-b9aa-46fc1be58f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fa8cf298-4f7d-4a3d-98da-c58bb3c94004,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-2c4bf075-0a2f-4daf-8c64-8561609bee56,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-485fb4d1-b15b-48bf-87aa-160b7e26b803,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-6c514c46-4da3-4361-b6e1-ac29002e7e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538955994-172.17.0.16-1598500977034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-113afe9d-bf72-4ab8-a623-37526da1dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-92b51520-9c76-4bdf-ba08-d75adcebb90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-8293bb4d-db82-4542-8b94-8e58a8875e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-2407a018-8c2b-4b45-9f48-d5fe5389d612,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-605192fe-8253-4df2-8bf7-c9d4c58bbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-dc43b075-aa7f-4dca-be51-a9cce964889a,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-53e362be-029f-4c2d-bda4-22683be0250b,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-1dc2e9ed-d865-4833-a758-dbd99a4c1566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538955994-172.17.0.16-1598500977034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35384,DS-113afe9d-bf72-4ab8-a623-37526da1dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-92b51520-9c76-4bdf-ba08-d75adcebb90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-8293bb4d-db82-4542-8b94-8e58a8875e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-2407a018-8c2b-4b45-9f48-d5fe5389d612,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-605192fe-8253-4df2-8bf7-c9d4c58bbed2,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-dc43b075-aa7f-4dca-be51-a9cce964889a,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-53e362be-029f-4c2d-bda4-22683be0250b,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-1dc2e9ed-d865-4833-a758-dbd99a4c1566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362536107-172.17.0.16-1598501122469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-46391ae3-2e88-4754-9872-8940fc105149,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-7a5b1af3-6ec0-4579-8f7c-e587214e53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-86ec2dbb-68c0-48a1-813c-8bd4f7bb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-73bb49a8-d66a-43d8-a992-ec3001b96cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-9b1ce746-f325-4239-a75a-9cb2445de87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-560d3bf6-6160-4044-9a91-58c961fe89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-cb6bb093-369c-4f71-82e5-8d4bba0452a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-a5dc6243-6dcc-4fc1-9459-5df7897cb318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362536107-172.17.0.16-1598501122469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45888,DS-46391ae3-2e88-4754-9872-8940fc105149,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-7a5b1af3-6ec0-4579-8f7c-e587214e53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-86ec2dbb-68c0-48a1-813c-8bd4f7bb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-73bb49a8-d66a-43d8-a992-ec3001b96cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-9b1ce746-f325-4239-a75a-9cb2445de87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-560d3bf6-6160-4044-9a91-58c961fe89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-cb6bb093-369c-4f71-82e5-8d4bba0452a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-a5dc6243-6dcc-4fc1-9459-5df7897cb318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318334556-172.17.0.16-1598501158467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-9fbb678c-59a0-4b82-a2a4-b4379d23035c,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-7138a37f-207f-4340-95c1-a925f99185ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-1b3b82e0-ad8f-48fa-a42a-8fc8a41f0493,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-fd2f7893-df3e-4cb7-9afa-dab783baca26,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-bfcf0396-0b6b-436a-b648-f6a983bd9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-af39cbfc-d050-4444-a76f-0e98a0ad4981,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d37a0b06-d2e4-41f8-8254-de9e2c4f182f,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-31966375-047c-408d-9646-011a9debc369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1318334556-172.17.0.16-1598501158467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-9fbb678c-59a0-4b82-a2a4-b4379d23035c,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-7138a37f-207f-4340-95c1-a925f99185ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-1b3b82e0-ad8f-48fa-a42a-8fc8a41f0493,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-fd2f7893-df3e-4cb7-9afa-dab783baca26,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-bfcf0396-0b6b-436a-b648-f6a983bd9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-af39cbfc-d050-4444-a76f-0e98a0ad4981,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d37a0b06-d2e4-41f8-8254-de9e2c4f182f,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-31966375-047c-408d-9646-011a9debc369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836779735-172.17.0.16-1598502111155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35105,DS-51b71194-44e6-408b-a5d5-593c855b19e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-e2e8b714-be08-489d-840a-d4786a240d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-06c04961-f281-4bea-8d45-1304a290785c,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-2d7fa88f-da13-459f-8dd9-08aad5af58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-279b4030-757a-44fb-bc8b-d10619f3826e,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-36f93abe-4877-4fe4-b79a-3f9d9ca15b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d405ef4a-2f3c-4377-872b-f62eb2a13d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-b8d94152-9354-4558-84e6-0beb826cc38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836779735-172.17.0.16-1598502111155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35105,DS-51b71194-44e6-408b-a5d5-593c855b19e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-e2e8b714-be08-489d-840a-d4786a240d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-06c04961-f281-4bea-8d45-1304a290785c,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-2d7fa88f-da13-459f-8dd9-08aad5af58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-279b4030-757a-44fb-bc8b-d10619f3826e,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-36f93abe-4877-4fe4-b79a-3f9d9ca15b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d405ef4a-2f3c-4377-872b-f62eb2a13d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-b8d94152-9354-4558-84e6-0beb826cc38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160118910-172.17.0.16-1598502220167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-e41f409f-c447-4493-8d79-c0a5d5258a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-0bce20cf-a14c-4c6f-9144-2fc8a332bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-aaa8937a-2445-48d9-b0d2-16b08ccb16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-a62c69df-353b-47d0-9dd4-1cbc5f690aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-f9cb84db-50f0-48ed-8f7a-422644ffbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-1cc6adee-699c-493b-b7e2-97a759a2427b,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-ccc961f8-a2bc-4a89-8d81-022fdd9ca976,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-a876cea6-5052-43f7-8014-cd05df36d840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160118910-172.17.0.16-1598502220167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-e41f409f-c447-4493-8d79-c0a5d5258a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-0bce20cf-a14c-4c6f-9144-2fc8a332bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-aaa8937a-2445-48d9-b0d2-16b08ccb16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-a62c69df-353b-47d0-9dd4-1cbc5f690aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-f9cb84db-50f0-48ed-8f7a-422644ffbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-1cc6adee-699c-493b-b7e2-97a759a2427b,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-ccc961f8-a2bc-4a89-8d81-022fdd9ca976,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-a876cea6-5052-43f7-8014-cd05df36d840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212247234-172.17.0.16-1598502336767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-cdb7a604-b49a-4fc4-8f43-6689b39446dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-7e14ce54-1070-4e42-8b65-64872f001eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-bc24430d-a4e7-42ad-9beb-7db5729fbe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-29f6cdac-5e52-41f9-88ca-571ebd723c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-22131e75-87e7-47da-8cdc-4514668ca99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-d69a03cc-2bb7-4ec7-b024-c5d8ece702ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-7d46c2f7-c30b-40bc-9f2c-955357900d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-95132c6f-b5a5-4150-a330-041848010122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212247234-172.17.0.16-1598502336767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40088,DS-cdb7a604-b49a-4fc4-8f43-6689b39446dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-7e14ce54-1070-4e42-8b65-64872f001eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-bc24430d-a4e7-42ad-9beb-7db5729fbe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-29f6cdac-5e52-41f9-88ca-571ebd723c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-22131e75-87e7-47da-8cdc-4514668ca99d,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-d69a03cc-2bb7-4ec7-b024-c5d8ece702ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-7d46c2f7-c30b-40bc-9f2c-955357900d29,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-95132c6f-b5a5-4150-a330-041848010122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731303218-172.17.0.16-1598502368909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-461be9d0-9aca-433c-8ed4-bcd8d0e48715,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-8d22eb32-554f-4944-91e3-0e2bfdf07396,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7911c5a2-e4ea-4d69-a936-3324545af2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-82cec17d-9e7f-4166-80c0-332dd6a753b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-17cebe95-b3d0-42ed-a22a-d5be884065da,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-a259668b-8251-4ac1-bf5a-bc3ada7595bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-087c8e5f-1a15-40f9-a3b1-9ed81408bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-61f8ed65-0063-44d3-a178-714f219a60e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731303218-172.17.0.16-1598502368909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42963,DS-461be9d0-9aca-433c-8ed4-bcd8d0e48715,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-8d22eb32-554f-4944-91e3-0e2bfdf07396,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-7911c5a2-e4ea-4d69-a936-3324545af2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-82cec17d-9e7f-4166-80c0-332dd6a753b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-17cebe95-b3d0-42ed-a22a-d5be884065da,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-a259668b-8251-4ac1-bf5a-bc3ada7595bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-087c8e5f-1a15-40f9-a3b1-9ed81408bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-61f8ed65-0063-44d3-a178-714f219a60e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756806501-172.17.0.16-1598502594163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-d943e3e4-8583-4a56-9cdb-17606666d942,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-badaecfd-b1c4-43d9-bad3-80483b33e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e9209fda-1c78-4a58-b01f-8b422e57a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-fe905382-04ce-4841-9e0d-356e491d0805,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-f5ca8f94-ec04-4adf-bd27-66b85e88b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-c2c729d9-ec62-4c27-a1e6-62086022e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-af2d3d52-c693-44dc-bd19-cffb5d2a8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-d72d2da4-0471-4d4d-aed7-c4c383adee91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756806501-172.17.0.16-1598502594163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-d943e3e4-8583-4a56-9cdb-17606666d942,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-badaecfd-b1c4-43d9-bad3-80483b33e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e9209fda-1c78-4a58-b01f-8b422e57a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-fe905382-04ce-4841-9e0d-356e491d0805,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-f5ca8f94-ec04-4adf-bd27-66b85e88b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-c2c729d9-ec62-4c27-a1e6-62086022e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-af2d3d52-c693-44dc-bd19-cffb5d2a8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-d72d2da4-0471-4d4d-aed7-c4c383adee91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20783104-172.17.0.16-1598502703218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-92f54b59-be66-49fd-8b4a-26b51f171d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-10075578-a0b2-492e-9d9d-19542dc90398,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-0641c282-053c-4844-baf1-ac9a667bf7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-fa3d1673-2ea2-422e-9965-274ab5b7a8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-28cf6e28-d587-4c28-9490-043934b50df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-91069ace-8833-476b-a6be-cf7c99099b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-8c996fa1-3f50-4f23-b549-c3571f78af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-55a852ff-cdae-44f8-b2c9-94d1d3133615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20783104-172.17.0.16-1598502703218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-92f54b59-be66-49fd-8b4a-26b51f171d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-10075578-a0b2-492e-9d9d-19542dc90398,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-0641c282-053c-4844-baf1-ac9a667bf7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-fa3d1673-2ea2-422e-9965-274ab5b7a8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-28cf6e28-d587-4c28-9490-043934b50df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-91069ace-8833-476b-a6be-cf7c99099b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-8c996fa1-3f50-4f23-b549-c3571f78af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-55a852ff-cdae-44f8-b2c9-94d1d3133615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097431730-172.17.0.16-1598503410070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-6902ba43-d493-4665-a970-59674165d876,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-ebd8504d-d4aa-4e8d-9c17-7dc7954374ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-44007ce9-f56f-4f71-a27e-665a10e62f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-d6fb799d-203e-4328-9e8d-940a748a3512,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c19c8bab-8b13-4c71-890b-ae10f6945d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-1305b589-ac09-4eeb-949b-0dd765f2fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-6c298fc0-56f9-4949-9760-28b797c285d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-4c9726c0-776d-4437-92b7-30ac66f04ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097431730-172.17.0.16-1598503410070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-6902ba43-d493-4665-a970-59674165d876,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-ebd8504d-d4aa-4e8d-9c17-7dc7954374ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-44007ce9-f56f-4f71-a27e-665a10e62f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-d6fb799d-203e-4328-9e8d-940a748a3512,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c19c8bab-8b13-4c71-890b-ae10f6945d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-1305b589-ac09-4eeb-949b-0dd765f2fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-6c298fc0-56f9-4949-9760-28b797c285d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-4c9726c0-776d-4437-92b7-30ac66f04ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032050389-172.17.0.16-1598503607177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-376a5e73-9ed6-49a9-a4d3-2a7eaa16b964,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-b6109120-d698-4f76-9392-0c5d7c23f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-2c05e37b-451a-468a-9e0e-7fb443deeae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-86716903-4932-4afe-9cf2-1094c8ab770c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-00283557-a69c-4a5d-a852-a3dfb54fc189,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6aec22b5-b92b-4f15-ac24-2df9b8d1e006,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-8b15c185-91f2-45ef-83dc-1f6d3bcf92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-1ec74ecd-cd26-4e57-9320-6e9544dc48e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032050389-172.17.0.16-1598503607177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-376a5e73-9ed6-49a9-a4d3-2a7eaa16b964,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-b6109120-d698-4f76-9392-0c5d7c23f36a,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-2c05e37b-451a-468a-9e0e-7fb443deeae1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-86716903-4932-4afe-9cf2-1094c8ab770c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-00283557-a69c-4a5d-a852-a3dfb54fc189,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6aec22b5-b92b-4f15-ac24-2df9b8d1e006,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-8b15c185-91f2-45ef-83dc-1f6d3bcf92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-1ec74ecd-cd26-4e57-9320-6e9544dc48e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5493
