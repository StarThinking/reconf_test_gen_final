reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767353937-172.17.0.12-1598490737825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-0033dceb-0fff-4d43-9932-0edd82465256,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-4c3cd325-a5d3-4789-9170-ea4d35070ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-8ccd6c98-df62-4a19-b47c-119278c29374,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-5556a88e-d36b-4e4d-a527-e911e8d414b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-47e47384-829d-451c-88de-61c406830fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-7a8de4fc-a973-4ab6-90d3-31706879ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c011f4d2-0c81-4fc3-ae83-ea9ff3b184d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-32bdef44-42de-47b9-b147-cec7c397305d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767353937-172.17.0.12-1598490737825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-0033dceb-0fff-4d43-9932-0edd82465256,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-4c3cd325-a5d3-4789-9170-ea4d35070ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-8ccd6c98-df62-4a19-b47c-119278c29374,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-5556a88e-d36b-4e4d-a527-e911e8d414b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-47e47384-829d-451c-88de-61c406830fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-7a8de4fc-a973-4ab6-90d3-31706879ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c011f4d2-0c81-4fc3-ae83-ea9ff3b184d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-32bdef44-42de-47b9-b147-cec7c397305d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673234938-172.17.0.12-1598491365655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-4ffc3aa8-68f4-4196-acb5-bc0db3507da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-4281f584-b917-4417-b233-c7e7d213ccbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-501fc432-b6fb-4762-9412-fbbbf94eef81,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-78151196-fe33-438b-af0a-d7b80c5952b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-03d8cd1b-b75d-4e05-b28c-ec0778e7d258,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-46c0bc48-5044-4d53-94ac-6cfa32568410,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-20350337-ab01-4a36-9e29-d4a2449d209d,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-a9a1a1ee-4bea-4749-b703-505e4703c08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673234938-172.17.0.12-1598491365655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-4ffc3aa8-68f4-4196-acb5-bc0db3507da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-4281f584-b917-4417-b233-c7e7d213ccbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-501fc432-b6fb-4762-9412-fbbbf94eef81,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-78151196-fe33-438b-af0a-d7b80c5952b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-03d8cd1b-b75d-4e05-b28c-ec0778e7d258,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-46c0bc48-5044-4d53-94ac-6cfa32568410,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-20350337-ab01-4a36-9e29-d4a2449d209d,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-a9a1a1ee-4bea-4749-b703-505e4703c08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977450272-172.17.0.12-1598493065607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-cfeda747-f367-4328-bd49-7606c00c9a50,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6e9bdbb8-eb97-402f-bfc2-7452f8333b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-7f714fba-a0d2-4ec4-8db4-1b4bcbd8cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8429b2b2-c835-4bba-b6b3-61d423859fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-f008231d-c261-411b-9ac2-4c4182004270,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-87fe4b45-9f21-494e-af32-50659d497790,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-1513cfb7-1f30-4028-815d-d4f5f4f77ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-67e9c657-f45c-4f14-8880-16f8b48b0007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977450272-172.17.0.12-1598493065607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-cfeda747-f367-4328-bd49-7606c00c9a50,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6e9bdbb8-eb97-402f-bfc2-7452f8333b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-7f714fba-a0d2-4ec4-8db4-1b4bcbd8cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8429b2b2-c835-4bba-b6b3-61d423859fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-f008231d-c261-411b-9ac2-4c4182004270,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-87fe4b45-9f21-494e-af32-50659d497790,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-1513cfb7-1f30-4028-815d-d4f5f4f77ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-67e9c657-f45c-4f14-8880-16f8b48b0007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899379227-172.17.0.12-1598493104606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-48e93634-af67-4ffb-b686-e929ac1325ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-041299fa-3711-4b62-bfef-4d5912181f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-bac2debe-5d20-4c93-b243-aad4c6427a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-be3d6957-ad72-4d47-a660-dbd892981bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-7f90d6ac-e22d-4772-8f22-3e2b07071899,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-082f27f4-3f6d-4f44-8b16-1e11d9fb6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-bf45c1fc-11bc-4b01-bc3e-c0f5966ece6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-4ce765d7-d9aa-4a96-96f0-12de74aae6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899379227-172.17.0.12-1598493104606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-48e93634-af67-4ffb-b686-e929ac1325ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-041299fa-3711-4b62-bfef-4d5912181f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-bac2debe-5d20-4c93-b243-aad4c6427a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-be3d6957-ad72-4d47-a660-dbd892981bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-7f90d6ac-e22d-4772-8f22-3e2b07071899,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-082f27f4-3f6d-4f44-8b16-1e11d9fb6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-bf45c1fc-11bc-4b01-bc3e-c0f5966ece6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-4ce765d7-d9aa-4a96-96f0-12de74aae6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176975658-172.17.0.12-1598493356515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f3189253-9199-4dc5-9b9f-a16cd5fad1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-aac6cf03-97ea-408c-99d3-d2b60cb7c284,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-83096211-9cd7-4598-aebe-5db88e3d019a,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-97403742-9af8-4ced-941f-09832f0dbe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-d44e9841-bc7e-4ef7-bd9a-a7f432d5eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-5d3110a6-756e-44f0-a4a8-70ef5a07a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-a566fa47-1dd7-45a8-8dda-086ea5b47af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-29f31468-3c8e-45fc-9e5e-67fd3521dcf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176975658-172.17.0.12-1598493356515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f3189253-9199-4dc5-9b9f-a16cd5fad1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-aac6cf03-97ea-408c-99d3-d2b60cb7c284,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-83096211-9cd7-4598-aebe-5db88e3d019a,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-97403742-9af8-4ced-941f-09832f0dbe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-d44e9841-bc7e-4ef7-bd9a-a7f432d5eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-5d3110a6-756e-44f0-a4a8-70ef5a07a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-a566fa47-1dd7-45a8-8dda-086ea5b47af3,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-29f31468-3c8e-45fc-9e5e-67fd3521dcf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156391622-172.17.0.12-1598493428321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-4e37c5ff-ce6b-4d9e-ab7a-10dc54e0dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-6b4f032b-ea54-465a-8272-9bd3b32ae02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-c47c70aa-48e3-4dde-be10-7e27170f6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-aae5d7f4-a586-4c46-8c24-41a7001f6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-22284795-73d6-48e4-a31a-57a81e598e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-397fd35f-6d77-409b-87a6-bc43594ba55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-f04d3202-365c-4ce5-82e3-613ac772211c,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-79a43d69-7a4b-4254-ac72-6a40facc7d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156391622-172.17.0.12-1598493428321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-4e37c5ff-ce6b-4d9e-ab7a-10dc54e0dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-6b4f032b-ea54-465a-8272-9bd3b32ae02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-c47c70aa-48e3-4dde-be10-7e27170f6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-aae5d7f4-a586-4c46-8c24-41a7001f6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-22284795-73d6-48e4-a31a-57a81e598e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-397fd35f-6d77-409b-87a6-bc43594ba55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-f04d3202-365c-4ce5-82e3-613ac772211c,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-79a43d69-7a4b-4254-ac72-6a40facc7d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996012391-172.17.0.12-1598493724793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-5ca09605-c5bd-401b-8e8c-41ca592c1615,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-57581215-0ebc-4bdc-984c-39bd5dd7eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-8ea0300f-73e5-4b57-a310-9cf8b4801c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-50dd96fc-e026-4108-a945-18b66b5ea2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-26e723ea-7e06-4f40-a816-4ac4c48b61a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-77f9bd63-a492-4030-83f4-d4b2c5d0112b,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-18622328-f2ea-4c47-9849-58e0b9fa9571,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-87592145-33d7-467c-95ad-2c0126e14ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996012391-172.17.0.12-1598493724793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-5ca09605-c5bd-401b-8e8c-41ca592c1615,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-57581215-0ebc-4bdc-984c-39bd5dd7eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-8ea0300f-73e5-4b57-a310-9cf8b4801c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-50dd96fc-e026-4108-a945-18b66b5ea2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-26e723ea-7e06-4f40-a816-4ac4c48b61a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-77f9bd63-a492-4030-83f4-d4b2c5d0112b,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-18622328-f2ea-4c47-9849-58e0b9fa9571,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-87592145-33d7-467c-95ad-2c0126e14ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746813352-172.17.0.12-1598493834799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-3767c005-f3f8-4b99-bd2f-26a2b7f59409,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-400c5e04-d33b-4632-b00b-2541fbbc888c,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e3ece329-0fea-498b-afa5-073ad0916bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-ccc5727f-f554-4f43-8c30-99c7366f4c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c9cd6d09-2fce-4e00-8e23-a69eb4909ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-da1cd4b7-91be-4487-a940-74fa313e1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-858b938d-fcac-4a1d-b4b7-dda9dbaef8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-fd235c8f-1f39-4249-b8b8-3e043e95a2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746813352-172.17.0.12-1598493834799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-3767c005-f3f8-4b99-bd2f-26a2b7f59409,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-400c5e04-d33b-4632-b00b-2541fbbc888c,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e3ece329-0fea-498b-afa5-073ad0916bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-ccc5727f-f554-4f43-8c30-99c7366f4c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c9cd6d09-2fce-4e00-8e23-a69eb4909ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-da1cd4b7-91be-4487-a940-74fa313e1c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-858b938d-fcac-4a1d-b4b7-dda9dbaef8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-fd235c8f-1f39-4249-b8b8-3e043e95a2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373285652-172.17.0.12-1598494641712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46483,DS-2382eaa6-eeff-4404-820f-4dba77aa6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-59349bc6-6fbd-4910-849a-3b24a167966b,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-6ab44696-0ecc-4517-98e5-8a0a25ff6664,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-856969bd-392e-4bc9-ba43-7dbc6c1655e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-97e522f3-2669-4019-82ed-d49573f29ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-60dd0da1-335b-4099-9ae7-9b12f3249190,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-ceb7caa3-5d4a-4686-9011-0050925fd52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-2d0bd9f3-59af-4a6b-a8c1-8a71d04b315f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373285652-172.17.0.12-1598494641712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46483,DS-2382eaa6-eeff-4404-820f-4dba77aa6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-59349bc6-6fbd-4910-849a-3b24a167966b,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-6ab44696-0ecc-4517-98e5-8a0a25ff6664,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-856969bd-392e-4bc9-ba43-7dbc6c1655e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-97e522f3-2669-4019-82ed-d49573f29ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-60dd0da1-335b-4099-9ae7-9b12f3249190,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-ceb7caa3-5d4a-4686-9011-0050925fd52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-2d0bd9f3-59af-4a6b-a8c1-8a71d04b315f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301068081-172.17.0.12-1598494858423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-1a1aba80-01cf-4dda-ad04-d209691fa12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-9b9a0bb0-2e80-479c-a3d6-d43ebbd67a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-e08677ca-b082-479f-8405-704ee29086c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-cf651ec9-fc51-4c4f-9337-ad455b9237cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-9188ca14-f04d-4730-91f8-23192324b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-5edd6a91-9b64-4195-ae8f-acc9677a56b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-55bf12d9-2873-417c-b45e-62b5470a6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-61ff88e5-7886-4f26-bed9-22a79906ec95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301068081-172.17.0.12-1598494858423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-1a1aba80-01cf-4dda-ad04-d209691fa12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-9b9a0bb0-2e80-479c-a3d6-d43ebbd67a66,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-e08677ca-b082-479f-8405-704ee29086c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-cf651ec9-fc51-4c4f-9337-ad455b9237cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-9188ca14-f04d-4730-91f8-23192324b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-5edd6a91-9b64-4195-ae8f-acc9677a56b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-55bf12d9-2873-417c-b45e-62b5470a6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-61ff88e5-7886-4f26-bed9-22a79906ec95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5359
