reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761673915-172.17.0.11-1598572367516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-ef35dc34-6fe6-4dce-96b8-2efce40e0389,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b9decdc4-465a-499a-82ba-acc5e0612589,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-72a3a723-1cff-4695-b992-0a636958db11,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-66b8f750-146f-485d-aed7-3a046c5b2bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-162ccf95-273a-496a-b8de-4f6ce7427854,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-2e001f3f-e0f2-4025-8117-9e19dc91a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-c3cd6cde-a59a-4150-80b6-dc79bd61acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-458288e0-2a51-412b-947c-ca4994699d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761673915-172.17.0.11-1598572367516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34168,DS-ef35dc34-6fe6-4dce-96b8-2efce40e0389,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b9decdc4-465a-499a-82ba-acc5e0612589,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-72a3a723-1cff-4695-b992-0a636958db11,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-66b8f750-146f-485d-aed7-3a046c5b2bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-162ccf95-273a-496a-b8de-4f6ce7427854,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-2e001f3f-e0f2-4025-8117-9e19dc91a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-c3cd6cde-a59a-4150-80b6-dc79bd61acdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-458288e0-2a51-412b-947c-ca4994699d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495697742-172.17.0.11-1598572693079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38972,DS-0de56846-c95c-4046-9f15-82d41b7cfbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-b6d03d69-fc10-4605-9487-cdfdc146fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-1510dbb7-4e6b-4091-a54b-14e652d8d424,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-7aaafd1e-4684-47ed-8020-37a83bd6e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-2f35615e-c35e-42e1-85d9-7cc456305a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-672d0f12-dac9-44f4-9fd7-fdd9ae9b95a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-b583d169-f3c3-41cf-bb6a-0cdace31fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-d26e3c9b-0f41-4f76-9f31-f48a672a5e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495697742-172.17.0.11-1598572693079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38972,DS-0de56846-c95c-4046-9f15-82d41b7cfbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-b6d03d69-fc10-4605-9487-cdfdc146fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-1510dbb7-4e6b-4091-a54b-14e652d8d424,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-7aaafd1e-4684-47ed-8020-37a83bd6e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-2f35615e-c35e-42e1-85d9-7cc456305a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-672d0f12-dac9-44f4-9fd7-fdd9ae9b95a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-b583d169-f3c3-41cf-bb6a-0cdace31fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-d26e3c9b-0f41-4f76-9f31-f48a672a5e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484335444-172.17.0.11-1598572731926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-510037ab-a96b-463f-bedf-ea99f80da8be,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-b6627e31-d781-4d33-ae88-806273e9f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-62891b40-0e0c-41a9-bdd9-a167f637467b,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-2bd56c4b-edc8-47a3-bb18-25ec7e4dd705,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ee16c2b4-a3a6-4d17-8cb3-ca00c2b9a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-3695a142-cfbd-484b-84a3-4051b8422759,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-212fbf12-2718-453d-a135-de10a825329a,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-ec501eef-6ad7-4ce5-8ca2-e7fe5b264436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484335444-172.17.0.11-1598572731926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-510037ab-a96b-463f-bedf-ea99f80da8be,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-b6627e31-d781-4d33-ae88-806273e9f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-62891b40-0e0c-41a9-bdd9-a167f637467b,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-2bd56c4b-edc8-47a3-bb18-25ec7e4dd705,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-ee16c2b4-a3a6-4d17-8cb3-ca00c2b9a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-3695a142-cfbd-484b-84a3-4051b8422759,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-212fbf12-2718-453d-a135-de10a825329a,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-ec501eef-6ad7-4ce5-8ca2-e7fe5b264436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703426179-172.17.0.11-1598572919579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41167,DS-2d05cf20-d4f4-46ea-ad9d-01bc2d16a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b835f840-a815-4c76-be3b-0370a5c32ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-d7b73408-76b9-4664-a1a2-9feae5a97953,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-50e8d928-9598-4b2e-b820-7c5db181da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-152220ca-e750-49fb-9238-8a9d8a3df25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-63ad2925-159b-47a8-a41a-e3b505520123,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-d562e393-56e2-41ba-b212-fbbc174133fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-db5554b5-84bb-4bce-b7d5-e607d34864be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703426179-172.17.0.11-1598572919579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41167,DS-2d05cf20-d4f4-46ea-ad9d-01bc2d16a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b835f840-a815-4c76-be3b-0370a5c32ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-d7b73408-76b9-4664-a1a2-9feae5a97953,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-50e8d928-9598-4b2e-b820-7c5db181da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-152220ca-e750-49fb-9238-8a9d8a3df25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-63ad2925-159b-47a8-a41a-e3b505520123,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-d562e393-56e2-41ba-b212-fbbc174133fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-db5554b5-84bb-4bce-b7d5-e607d34864be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380904639-172.17.0.11-1598573666905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-fa1f3c3c-da63-4be2-af7a-430b73064156,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-591481e7-f003-4b15-a291-26b6d103b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-ea8be010-ba4d-4f5c-8ae5-ebea091ff8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6744ee0c-50a8-46a8-a233-296d38d2ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-b0805d56-d53f-42c4-b9e3-5e962768c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-f90dce5e-34b2-4dc5-80a0-5e7df8d532cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-ea76e377-358a-4bf2-afda-86bb7443a161,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ea70d516-144d-4b74-81be-40a52910c1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380904639-172.17.0.11-1598573666905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-fa1f3c3c-da63-4be2-af7a-430b73064156,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-591481e7-f003-4b15-a291-26b6d103b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-ea8be010-ba4d-4f5c-8ae5-ebea091ff8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6744ee0c-50a8-46a8-a233-296d38d2ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-b0805d56-d53f-42c4-b9e3-5e962768c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-f90dce5e-34b2-4dc5-80a0-5e7df8d532cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-ea76e377-358a-4bf2-afda-86bb7443a161,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ea70d516-144d-4b74-81be-40a52910c1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836104261-172.17.0.11-1598573915114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-c17a2c67-810b-4f99-bbaa-2fc7b395bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-45879eac-a054-4d6e-93ac-cf3aa0573518,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-1d4c9378-237b-4ca2-9fba-f73a6633e095,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-bf264967-5c29-4fc6-9926-09cae7ad98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0eb3d92d-efa4-41bb-be31-b751bd0a57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-749f032f-ee56-4e5b-8af4-83c772763b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-30fcd160-e598-41fb-8756-61de3436b967,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-109b7177-592a-4236-8133-0753cc574d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836104261-172.17.0.11-1598573915114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-c17a2c67-810b-4f99-bbaa-2fc7b395bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-45879eac-a054-4d6e-93ac-cf3aa0573518,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-1d4c9378-237b-4ca2-9fba-f73a6633e095,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-bf264967-5c29-4fc6-9926-09cae7ad98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-0eb3d92d-efa4-41bb-be31-b751bd0a57d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-749f032f-ee56-4e5b-8af4-83c772763b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-30fcd160-e598-41fb-8756-61de3436b967,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-109b7177-592a-4236-8133-0753cc574d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291112045-172.17.0.11-1598574354007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-485b3821-a73c-4a9e-a555-49ad23b49617,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-d33970b2-bc28-49c5-93f3-c5ff5c8b52ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-1419e937-9e79-40c7-8663-d944d6f02d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-6e2e013a-1726-437e-9813-80bee7bfa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-977911ce-8bf1-4c5e-abd6-9795d9d067fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-d743cc7b-94ef-4733-ab89-8132e467a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-26e21bec-94f8-4e5b-b9de-d905519fb6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-70cdca77-a658-451e-9bac-00eaffe64abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291112045-172.17.0.11-1598574354007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-485b3821-a73c-4a9e-a555-49ad23b49617,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-d33970b2-bc28-49c5-93f3-c5ff5c8b52ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-1419e937-9e79-40c7-8663-d944d6f02d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-6e2e013a-1726-437e-9813-80bee7bfa5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-977911ce-8bf1-4c5e-abd6-9795d9d067fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-d743cc7b-94ef-4733-ab89-8132e467a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-26e21bec-94f8-4e5b-b9de-d905519fb6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-70cdca77-a658-451e-9bac-00eaffe64abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283814549-172.17.0.11-1598574672474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-c1773478-9201-4742-b014-0d49f2bf221f,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-344e790d-3d0b-4c46-9462-e42f2eaf1042,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0518d492-541a-43aa-86cb-3976521a029c,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-d8bde271-d38d-41f6-8164-5a225a4e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-d1a3cf7b-f6b4-42c6-9872-8cc4a333181a,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-e275d4df-5816-441e-828c-e37a7b9219fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-9319194b-a70c-4db6-8f28-21bb9d320a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-8f7575e2-50c0-458f-83fc-0e0b44e7c2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283814549-172.17.0.11-1598574672474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-c1773478-9201-4742-b014-0d49f2bf221f,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-344e790d-3d0b-4c46-9462-e42f2eaf1042,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0518d492-541a-43aa-86cb-3976521a029c,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-d8bde271-d38d-41f6-8164-5a225a4e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-d1a3cf7b-f6b4-42c6-9872-8cc4a333181a,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-e275d4df-5816-441e-828c-e37a7b9219fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-9319194b-a70c-4db6-8f28-21bb9d320a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-8f7575e2-50c0-458f-83fc-0e0b44e7c2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446433409-172.17.0.11-1598574921641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-21f50378-be26-445c-92ad-6a136ee072f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-dd0f7a49-4dc7-49bb-ac1a-2070ad04db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-2ee3a5a9-7985-4e98-9600-b2154ce85c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-1f67e4db-61e5-4022-8bb2-7d4b3061f297,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-caceef14-6c1c-4e45-a1a4-402bb8bcee07,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-33f716fe-ad53-403e-8961-ff5ff57378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c4e837f9-b402-4df6-bda9-ba85d0e66bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-efc30707-a196-4bd5-aa82-b31985e433d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446433409-172.17.0.11-1598574921641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-21f50378-be26-445c-92ad-6a136ee072f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-dd0f7a49-4dc7-49bb-ac1a-2070ad04db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-2ee3a5a9-7985-4e98-9600-b2154ce85c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-1f67e4db-61e5-4022-8bb2-7d4b3061f297,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-caceef14-6c1c-4e45-a1a4-402bb8bcee07,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-33f716fe-ad53-403e-8961-ff5ff57378f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c4e837f9-b402-4df6-bda9-ba85d0e66bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-efc30707-a196-4bd5-aa82-b31985e433d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163358170-172.17.0.11-1598574990789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-912e9654-57ae-40cc-af3c-04e137a63aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-9a4c5f05-8cc3-4436-ae1d-19cafd5f8b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-6de2eb6f-e9de-46a4-bbec-9cbaf6da99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b1848902-6aaf-45c9-8d0d-80b99a56a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-5cdfe306-81b7-4259-a2e5-c889d166e832,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-4cb3b497-1772-44a2-9cf3-06f3feb4fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-57630fee-0a4b-496a-b3c0-587e6b83babf,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-53558172-c127-4924-9f9d-50f585876190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163358170-172.17.0.11-1598574990789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-912e9654-57ae-40cc-af3c-04e137a63aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-9a4c5f05-8cc3-4436-ae1d-19cafd5f8b91,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-6de2eb6f-e9de-46a4-bbec-9cbaf6da99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b1848902-6aaf-45c9-8d0d-80b99a56a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-5cdfe306-81b7-4259-a2e5-c889d166e832,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-4cb3b497-1772-44a2-9cf3-06f3feb4fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-57630fee-0a4b-496a-b3c0-587e6b83babf,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-53558172-c127-4924-9f9d-50f585876190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664257194-172.17.0.11-1598575383022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-a93c4ae2-d8b3-4e8b-9ed7-6ab55b6d56e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-824e65f3-1f9b-47d3-ae23-292c4a549129,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-4cb12036-dbb3-4606-9965-af27254df191,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-939d5f55-7c2a-4e1a-963c-bb50866287ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-afd89575-90ce-451b-8ac6-10fb73c3c400,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0ec86b81-8e00-48e4-a753-cadc2e6935fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-bade1150-553d-4466-a647-b0be0affce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c4053ee9-38d9-476f-9976-27b0afef3064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664257194-172.17.0.11-1598575383022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-a93c4ae2-d8b3-4e8b-9ed7-6ab55b6d56e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-824e65f3-1f9b-47d3-ae23-292c4a549129,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-4cb12036-dbb3-4606-9965-af27254df191,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-939d5f55-7c2a-4e1a-963c-bb50866287ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-afd89575-90ce-451b-8ac6-10fb73c3c400,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0ec86b81-8e00-48e4-a753-cadc2e6935fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-bade1150-553d-4466-a647-b0be0affce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c4053ee9-38d9-476f-9976-27b0afef3064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611354296-172.17.0.11-1598575552430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-ff5afb50-bfdd-4f9f-be14-f1b9ab234511,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-910848b5-5b08-403e-87f7-eac12eac5720,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-2aff1492-7c43-40c9-aa34-078f41c6659a,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-3da73d69-cb2a-4bd4-9f27-95cff60cb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-83e5e38b-3907-4fbb-9afb-b2a2f93c7fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-7531eb48-3fe5-43f9-9919-13b4e17578fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-35bfb9e7-cac2-4877-9be2-b6f8f5a34075,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-8b196dc9-1dd6-4851-815d-dc2884930c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1611354296-172.17.0.11-1598575552430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40260,DS-ff5afb50-bfdd-4f9f-be14-f1b9ab234511,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-910848b5-5b08-403e-87f7-eac12eac5720,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-2aff1492-7c43-40c9-aa34-078f41c6659a,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-3da73d69-cb2a-4bd4-9f27-95cff60cb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-83e5e38b-3907-4fbb-9afb-b2a2f93c7fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-7531eb48-3fe5-43f9-9919-13b4e17578fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-35bfb9e7-cac2-4877-9be2-b6f8f5a34075,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-8b196dc9-1dd6-4851-815d-dc2884930c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808791556-172.17.0.11-1598575961631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-8596f669-80c8-497c-b347-08b49a212322,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-cefefc6b-ed40-4277-b009-c684e379679c,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-fa934fca-6122-46cf-9a29-c12ccb8e98d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-6db79dab-8c03-4e9c-813d-a4dc7ae5d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-63b5ab70-5fd3-4eef-bd7b-0cac2abda0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-f6125e01-8d35-4c22-9bc8-cc4fffed0fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-22e1cee6-5fc9-41cc-8471-1a1e73ecf095,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-f2f05b26-825f-43d8-8509-e574aa6f01ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808791556-172.17.0.11-1598575961631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-8596f669-80c8-497c-b347-08b49a212322,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-cefefc6b-ed40-4277-b009-c684e379679c,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-fa934fca-6122-46cf-9a29-c12ccb8e98d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-6db79dab-8c03-4e9c-813d-a4dc7ae5d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-63b5ab70-5fd3-4eef-bd7b-0cac2abda0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-f6125e01-8d35-4c22-9bc8-cc4fffed0fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-22e1cee6-5fc9-41cc-8471-1a1e73ecf095,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-f2f05b26-825f-43d8-8509-e574aa6f01ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085595692-172.17.0.11-1598576003632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-35907885-8784-4c98-9be5-c0dd2cf2b9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7df5f8e6-acb5-4850-842b-57686eb2376c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-1ef0f29d-9f48-4117-96dc-189426bfd78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-93a1a45e-910f-4b77-8959-7a321b7adf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5cc81b02-2fdc-4a70-8b18-9fe92fa8f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-a57e95ca-cd25-4a8c-bc31-f5013e497e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-762cc704-ee15-48fa-ae23-6ab2839a1220,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-4f465132-3c95-41f8-8e4d-c2748fbc5b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085595692-172.17.0.11-1598576003632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-35907885-8784-4c98-9be5-c0dd2cf2b9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-7df5f8e6-acb5-4850-842b-57686eb2376c,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-1ef0f29d-9f48-4117-96dc-189426bfd78f,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-93a1a45e-910f-4b77-8959-7a321b7adf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5cc81b02-2fdc-4a70-8b18-9fe92fa8f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-a57e95ca-cd25-4a8c-bc31-f5013e497e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-762cc704-ee15-48fa-ae23-6ab2839a1220,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-4f465132-3c95-41f8-8e4d-c2748fbc5b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577027326-172.17.0.11-1598576840726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34884,DS-428974b9-b3d3-40f8-aadc-6fa5f618b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-232622b2-2c45-4c0a-8ac9-82a916c88c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-92f50192-4266-40d1-a2a6-aed0981265d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-8a004bcd-83d1-4d97-a697-b7f13d9d3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-6f3b9843-a48c-4ea5-acf0-c461249e3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-8684c0e1-4216-4628-9f99-512a96981467,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-78ba3da7-4631-46c1-a2f7-38e5bba82142,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-fcc22547-127c-46a2-b6f1-0b8fec8ca86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577027326-172.17.0.11-1598576840726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34884,DS-428974b9-b3d3-40f8-aadc-6fa5f618b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-232622b2-2c45-4c0a-8ac9-82a916c88c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-92f50192-4266-40d1-a2a6-aed0981265d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-8a004bcd-83d1-4d97-a697-b7f13d9d3dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-6f3b9843-a48c-4ea5-acf0-c461249e3c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-8684c0e1-4216-4628-9f99-512a96981467,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-78ba3da7-4631-46c1-a2f7-38e5bba82142,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-fcc22547-127c-46a2-b6f1-0b8fec8ca86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188713096-172.17.0.11-1598576939348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-cb5a07e0-b850-4674-9772-f0ce31b43fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-c8b70c2d-1a87-46fb-9e1c-46e2e40f4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-abb81552-41bb-4952-97c1-046ed6735cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-f4e78dbc-3a02-4112-a0dd-03fdbff61057,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-de3c84b2-4756-4374-a45a-21b26c02aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-0b4be346-f1ff-43e5-aa91-372bb0e086a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d7ef746f-6fae-4f3f-b62a-1ac03d355fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-cba4743e-b00d-4c5b-a8e1-e7f6d5c812ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188713096-172.17.0.11-1598576939348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-cb5a07e0-b850-4674-9772-f0ce31b43fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-c8b70c2d-1a87-46fb-9e1c-46e2e40f4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-abb81552-41bb-4952-97c1-046ed6735cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-f4e78dbc-3a02-4112-a0dd-03fdbff61057,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-de3c84b2-4756-4374-a45a-21b26c02aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-0b4be346-f1ff-43e5-aa91-372bb0e086a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-d7ef746f-6fae-4f3f-b62a-1ac03d355fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-cba4743e-b00d-4c5b-a8e1-e7f6d5c812ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860651848-172.17.0.11-1598576979595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-1a6665a4-3456-4372-a9be-15129ded3bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6f0960b6-b7d6-45e9-8262-904a53d32f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-6041dd83-121e-4d36-b57a-0161d82916d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-00a5374e-882e-4eb6-9525-3ef8ad19c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-2a5f5d75-a36a-4308-b973-72a5a81ccdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d8977b26-058b-403f-9632-88dc36ff0c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-a061f981-3fee-44ba-b84c-66034cf1b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-3b61459f-64e3-4725-b518-61a19bebda7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860651848-172.17.0.11-1598576979595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-1a6665a4-3456-4372-a9be-15129ded3bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-6f0960b6-b7d6-45e9-8262-904a53d32f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-6041dd83-121e-4d36-b57a-0161d82916d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-00a5374e-882e-4eb6-9525-3ef8ad19c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-2a5f5d75-a36a-4308-b973-72a5a81ccdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d8977b26-058b-403f-9632-88dc36ff0c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-a061f981-3fee-44ba-b84c-66034cf1b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-3b61459f-64e3-4725-b518-61a19bebda7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5360
