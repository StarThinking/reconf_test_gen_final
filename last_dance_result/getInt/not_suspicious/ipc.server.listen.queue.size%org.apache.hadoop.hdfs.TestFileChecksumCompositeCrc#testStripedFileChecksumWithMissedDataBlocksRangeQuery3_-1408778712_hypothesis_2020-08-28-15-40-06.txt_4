reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776687047-172.17.0.15-1598629361792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36452,DS-550f818b-50fd-4f23-80b5-53e1fdaa6113,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-d4af01f3-9d31-4ba3-8aba-bb0770de8434,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-fb027499-200b-432d-af80-209516825c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1ef3f224-7b66-4f1c-9c72-87795a0f4504,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-c9b6c402-1976-44f9-88a1-2b2351b1e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-bbf67d9c-4fd5-49ae-9b4c-df14646c7084,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-4b8c6449-b3ae-4726-a45a-d5c9fe874f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-283b3717-775f-44b3-ad34-d1cb79cd8b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776687047-172.17.0.15-1598629361792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36452,DS-550f818b-50fd-4f23-80b5-53e1fdaa6113,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-d4af01f3-9d31-4ba3-8aba-bb0770de8434,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-fb027499-200b-432d-af80-209516825c81,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-1ef3f224-7b66-4f1c-9c72-87795a0f4504,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-c9b6c402-1976-44f9-88a1-2b2351b1e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-bbf67d9c-4fd5-49ae-9b4c-df14646c7084,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-4b8c6449-b3ae-4726-a45a-d5c9fe874f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-283b3717-775f-44b3-ad34-d1cb79cd8b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478911409-172.17.0.15-1598629481511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-5ec92ca2-bc59-493f-8eff-01a331e4c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-045a934a-a109-42b5-a452-6a909b1bd95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-feceb232-d010-447e-9596-87dc67bd3986,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-d3c3bdc3-15d3-4214-a26d-3726487c45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-17310612-3c55-4330-9c09-d7337423b828,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-0f4c61d2-b9a7-47ec-8b76-777d4a84c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-c56ad041-867e-46e5-a898-21aa9cec050a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-3a7929de-3499-467f-8d1a-f68c884545d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478911409-172.17.0.15-1598629481511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-5ec92ca2-bc59-493f-8eff-01a331e4c62d,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-045a934a-a109-42b5-a452-6a909b1bd95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-feceb232-d010-447e-9596-87dc67bd3986,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-d3c3bdc3-15d3-4214-a26d-3726487c45fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-17310612-3c55-4330-9c09-d7337423b828,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-0f4c61d2-b9a7-47ec-8b76-777d4a84c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-c56ad041-867e-46e5-a898-21aa9cec050a,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-3a7929de-3499-467f-8d1a-f68c884545d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315404571-172.17.0.15-1598629638690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-8f12947f-f7cf-4592-bd88-065986b7c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-cd67e636-a03c-4fff-9678-7c7ca1794864,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-366b3668-3bd8-4e55-9d07-54047fc02d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bbce5d08-3c4a-4cd8-b35c-ae0c56db17d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5192591c-e1f8-4495-829f-36540cd9a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-12bf1c8c-032b-480a-a4f9-9c7a9f0249a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9b75ac39-e959-4e82-a14e-ed29b4f8a116,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-e926e3bd-1e09-476b-974b-5e1631efa673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315404571-172.17.0.15-1598629638690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-8f12947f-f7cf-4592-bd88-065986b7c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-cd67e636-a03c-4fff-9678-7c7ca1794864,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-366b3668-3bd8-4e55-9d07-54047fc02d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-bbce5d08-3c4a-4cd8-b35c-ae0c56db17d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5192591c-e1f8-4495-829f-36540cd9a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-12bf1c8c-032b-480a-a4f9-9c7a9f0249a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9b75ac39-e959-4e82-a14e-ed29b4f8a116,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-e926e3bd-1e09-476b-974b-5e1631efa673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029420101-172.17.0.15-1598629859185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-ff7ac43a-b75c-4c34-97b2-f5698a8e21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-1f8b10bd-6eb0-4c6f-b21d-6842605d44e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-d9917534-d9c2-48cd-a376-be2149a6b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-b37f1e69-990d-42bc-8070-6be58e1a7ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-327929c5-bc3d-4d92-8d21-bb4ac2d263c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-4deb5abc-9ed1-4072-8cc2-e42b85c2e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-1084b3b4-207a-439f-9f7c-5870cee7b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-c1f55155-a518-4555-80a3-2cc6f424bc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029420101-172.17.0.15-1598629859185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-ff7ac43a-b75c-4c34-97b2-f5698a8e21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-1f8b10bd-6eb0-4c6f-b21d-6842605d44e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-d9917534-d9c2-48cd-a376-be2149a6b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-b37f1e69-990d-42bc-8070-6be58e1a7ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-327929c5-bc3d-4d92-8d21-bb4ac2d263c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-4deb5abc-9ed1-4072-8cc2-e42b85c2e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-1084b3b4-207a-439f-9f7c-5870cee7b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-c1f55155-a518-4555-80a3-2cc6f424bc0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448712845-172.17.0.15-1598629976755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-19ff876b-325d-41dd-9c75-7570b600b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-28608c1b-0b15-4f03-aa6d-669a7af8a4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-e799a691-d20a-40cd-8d57-682d66cc2748,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-e02c185e-f9e0-43b6-9c9a-a4b01d05cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-4d18d540-3702-4a1b-9c8e-38b55dd9b407,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-f44dbd71-05db-4d55-8fc4-c7db257738d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-892c3b65-a12f-4f34-b3e3-9c933dddb4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-7a1e9f54-c9f8-4c17-871f-85a9a9510c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448712845-172.17.0.15-1598629976755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-19ff876b-325d-41dd-9c75-7570b600b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-28608c1b-0b15-4f03-aa6d-669a7af8a4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-e799a691-d20a-40cd-8d57-682d66cc2748,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-e02c185e-f9e0-43b6-9c9a-a4b01d05cd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-4d18d540-3702-4a1b-9c8e-38b55dd9b407,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-f44dbd71-05db-4d55-8fc4-c7db257738d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-892c3b65-a12f-4f34-b3e3-9c933dddb4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-7a1e9f54-c9f8-4c17-871f-85a9a9510c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30537563-172.17.0.15-1598630126603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-fde5fe67-0d3f-41b0-945d-69d66daf27e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-26c2f75a-d192-4479-a466-b7e49304d2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-20b3b881-2b45-4580-bbfb-7e9d1060eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-a5cac522-5360-480e-922c-82dedcaae1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0fe9375e-8f0f-4da6-81b4-3b211c6777d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-6fc047cc-e7e4-4a96-bbe2-b10e1dec5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-15688bef-3591-4d48-9475-0f3374bb358d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-bc462bac-a782-478d-b5da-213cf70efc9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30537563-172.17.0.15-1598630126603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-fde5fe67-0d3f-41b0-945d-69d66daf27e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-26c2f75a-d192-4479-a466-b7e49304d2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-20b3b881-2b45-4580-bbfb-7e9d1060eb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-a5cac522-5360-480e-922c-82dedcaae1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0fe9375e-8f0f-4da6-81b4-3b211c6777d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-6fc047cc-e7e4-4a96-bbe2-b10e1dec5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-15688bef-3591-4d48-9475-0f3374bb358d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-bc462bac-a782-478d-b5da-213cf70efc9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483926380-172.17.0.15-1598630307644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-19430470-99ab-4842-94a7-afbc0087179f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-13adc450-9d2a-41f7-98e6-8dcf03a12944,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-36f8418b-20e8-4b2f-9752-367ff69b1475,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-0fa09473-8b5d-405f-884c-864791b4bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-0f8c6617-5878-4eeb-8ca2-1b6bdbf41eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bb281426-e90e-4103-9793-13af0d7e27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-cca52b66-7952-422c-b36d-a5b4e23ca1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-212eccd5-482f-4d8d-9270-65649440e060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483926380-172.17.0.15-1598630307644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-19430470-99ab-4842-94a7-afbc0087179f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-13adc450-9d2a-41f7-98e6-8dcf03a12944,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-36f8418b-20e8-4b2f-9752-367ff69b1475,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-0fa09473-8b5d-405f-884c-864791b4bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-0f8c6617-5878-4eeb-8ca2-1b6bdbf41eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bb281426-e90e-4103-9793-13af0d7e27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-cca52b66-7952-422c-b36d-a5b4e23ca1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-212eccd5-482f-4d8d-9270-65649440e060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745567523-172.17.0.15-1598630389647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-438f667d-b037-448f-9fd8-8243c441a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f77ce460-398b-4f70-bc5a-9febe6cf9713,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-034dbd63-a2bb-4542-a9b1-6ca620b1bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-10262207-a6cf-41e0-8b3c-b679c9b22ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-062e4c9d-a570-4048-97ae-b75ca73ac401,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-2e1cd8c3-eacf-4a79-81be-4ac3fe708a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-35bc415c-f7a3-4d53-ab20-aeac3d1992f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2e16c7b3-d46c-48de-994d-9634a85274c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745567523-172.17.0.15-1598630389647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-438f667d-b037-448f-9fd8-8243c441a5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-f77ce460-398b-4f70-bc5a-9febe6cf9713,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-034dbd63-a2bb-4542-a9b1-6ca620b1bed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-10262207-a6cf-41e0-8b3c-b679c9b22ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-062e4c9d-a570-4048-97ae-b75ca73ac401,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-2e1cd8c3-eacf-4a79-81be-4ac3fe708a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-35bc415c-f7a3-4d53-ab20-aeac3d1992f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2e16c7b3-d46c-48de-994d-9634a85274c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475839212-172.17.0.15-1598630589028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-c797dc0e-9512-4c27-9046-eb2c335e0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-325af6f9-1b24-4591-a780-a5b0079d742f,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-f12003fa-d87a-46de-a6f5-ee9bb1ced5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-03685f72-f99f-43a4-930c-a39266dad3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-49df2447-1676-4c6c-8e78-3669e390b0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-18d65f86-bd9d-4c2e-97db-4ee855d3a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-a98f6d38-3060-4bd8-b009-59cc22ed4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-e835f66f-a267-4b04-bff9-133b71764541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475839212-172.17.0.15-1598630589028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-c797dc0e-9512-4c27-9046-eb2c335e0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-325af6f9-1b24-4591-a780-a5b0079d742f,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-f12003fa-d87a-46de-a6f5-ee9bb1ced5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-03685f72-f99f-43a4-930c-a39266dad3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-49df2447-1676-4c6c-8e78-3669e390b0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-18d65f86-bd9d-4c2e-97db-4ee855d3a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-a98f6d38-3060-4bd8-b009-59cc22ed4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-e835f66f-a267-4b04-bff9-133b71764541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519401409-172.17.0.15-1598630629279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-4f441b75-d65e-4d05-9c42-e7ed3facca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-59a793e0-5a4a-4de7-9bbc-44b388f1a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-da921cf0-9ba1-40c3-822a-62ea09300111,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-62b753f4-8955-47e7-8a96-e2db91a16f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-6a975ba3-c1dc-46b4-aa67-5df236c58bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-2e05947d-66b3-4db1-b2b9-49d7e35a94d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-6a189542-ff6e-4130-8b68-b216512269ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-a5ff7faa-5c26-4225-a3e4-1a5a1f35cfcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519401409-172.17.0.15-1598630629279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38427,DS-4f441b75-d65e-4d05-9c42-e7ed3facca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-59a793e0-5a4a-4de7-9bbc-44b388f1a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-da921cf0-9ba1-40c3-822a-62ea09300111,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-62b753f4-8955-47e7-8a96-e2db91a16f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-6a975ba3-c1dc-46b4-aa67-5df236c58bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-2e05947d-66b3-4db1-b2b9-49d7e35a94d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-6a189542-ff6e-4130-8b68-b216512269ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-a5ff7faa-5c26-4225-a3e4-1a5a1f35cfcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606920134-172.17.0.15-1598630962321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-3da90ede-feca-4545-81de-d7cce6036cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-eea7f17f-088a-4a2b-a522-72d2accd73f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d55bb910-79d8-4d38-8697-dd3669b913ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9e25a738-5f07-461d-8330-2a2ec3a2a855,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-016cf951-1a71-45f0-b594-28ec7b5b5edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-02499b65-519a-4291-a64c-d9a72012b305,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-283878b3-cfbc-4cf9-ac2a-9aac9f6709a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-460d688f-7874-4db2-b8e7-aa2e0140739c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606920134-172.17.0.15-1598630962321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43770,DS-3da90ede-feca-4545-81de-d7cce6036cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-eea7f17f-088a-4a2b-a522-72d2accd73f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d55bb910-79d8-4d38-8697-dd3669b913ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9e25a738-5f07-461d-8330-2a2ec3a2a855,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-016cf951-1a71-45f0-b594-28ec7b5b5edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-02499b65-519a-4291-a64c-d9a72012b305,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-283878b3-cfbc-4cf9-ac2a-9aac9f6709a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-460d688f-7874-4db2-b8e7-aa2e0140739c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756659813-172.17.0.15-1598631271095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-db4b915e-c986-42b2-8f54-af9279775f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-32309bbe-c0a7-408e-b3f7-35a7c614f602,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-c3124e43-826f-4688-8e57-e94f5a09cb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-bdc60bb5-240e-4348-8503-e4ca75f066a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-7ddc1152-fc67-4000-bf6c-7f29eb597fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-651bba2f-dc3f-4c19-8c55-8fee441fa370,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-672e71af-26db-4202-9481-bc3a25eb3405,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-661a2305-ebb5-40b2-a201-87ff5701ec55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756659813-172.17.0.15-1598631271095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-db4b915e-c986-42b2-8f54-af9279775f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-32309bbe-c0a7-408e-b3f7-35a7c614f602,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-c3124e43-826f-4688-8e57-e94f5a09cb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-bdc60bb5-240e-4348-8503-e4ca75f066a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-7ddc1152-fc67-4000-bf6c-7f29eb597fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-651bba2f-dc3f-4c19-8c55-8fee441fa370,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-672e71af-26db-4202-9481-bc3a25eb3405,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-661a2305-ebb5-40b2-a201-87ff5701ec55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667938557-172.17.0.15-1598631569687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-ade6499a-57e1-4eb9-8196-0bb5e3638278,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-55ad4108-7b26-45b7-8280-52566b3821b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-be96df29-717b-4e12-b006-3bcf48067157,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-3d6cabd2-12a2-42d2-b694-cd11ff9df8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-857f0cf1-c59f-4f58-86da-168d75b17cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-e0010644-4184-4c19-8fe2-66fd0adbdd29,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-73a19bfd-835c-4859-b450-3c92be89a700,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-37711633-17aa-462b-9613-9a0240824f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667938557-172.17.0.15-1598631569687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38126,DS-ade6499a-57e1-4eb9-8196-0bb5e3638278,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-55ad4108-7b26-45b7-8280-52566b3821b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-be96df29-717b-4e12-b006-3bcf48067157,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-3d6cabd2-12a2-42d2-b694-cd11ff9df8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-857f0cf1-c59f-4f58-86da-168d75b17cec,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-e0010644-4184-4c19-8fe2-66fd0adbdd29,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-73a19bfd-835c-4859-b450-3c92be89a700,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-37711633-17aa-462b-9613-9a0240824f7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095253446-172.17.0.15-1598631980519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-0ff550f4-3b77-42b9-a44c-4f038ca305a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-461b4571-5154-421c-922b-532676815e70,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-cfb31240-57f3-4f9c-806c-43252ccafb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-44bde352-51bd-4c35-afbc-3dfb03fdadae,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e57dea52-0359-4e9e-bf20-343fb09977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-1dd46a73-d0b0-4195-9682-4e665928bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-a4d59ec3-f0e5-4dc4-b541-83c9a1929d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-51fbc0bf-a8ea-4f6d-9ef6-9e50989e9115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095253446-172.17.0.15-1598631980519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-0ff550f4-3b77-42b9-a44c-4f038ca305a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-461b4571-5154-421c-922b-532676815e70,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-cfb31240-57f3-4f9c-806c-43252ccafb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-44bde352-51bd-4c35-afbc-3dfb03fdadae,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e57dea52-0359-4e9e-bf20-343fb09977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-1dd46a73-d0b0-4195-9682-4e665928bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-a4d59ec3-f0e5-4dc4-b541-83c9a1929d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-51fbc0bf-a8ea-4f6d-9ef6-9e50989e9115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364724526-172.17.0.15-1598632251442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-be2bced2-eb8b-49a6-81ff-f99de3533a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7453cd51-ab35-4c61-bff5-f07608fd60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2885bd14-fceb-42f0-97e2-39bd709624be,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-5b85479f-ec52-4e05-bf40-fcb8e3bd3590,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-e605e422-5c37-4ae4-9f6a-b0bf51e2428e,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-095ff510-bbc8-4dab-9ce1-df948b2a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-055788fa-3006-4da5-8bc4-a0b5b50db709,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-a807563b-3e79-445c-b20d-330deacba7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364724526-172.17.0.15-1598632251442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46451,DS-be2bced2-eb8b-49a6-81ff-f99de3533a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7453cd51-ab35-4c61-bff5-f07608fd60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2885bd14-fceb-42f0-97e2-39bd709624be,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-5b85479f-ec52-4e05-bf40-fcb8e3bd3590,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-e605e422-5c37-4ae4-9f6a-b0bf51e2428e,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-095ff510-bbc8-4dab-9ce1-df948b2a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-055788fa-3006-4da5-8bc4-a0b5b50db709,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-a807563b-3e79-445c-b20d-330deacba7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584153022-172.17.0.15-1598632405612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-60036a80-b744-48b1-927b-7a99bcc64371,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-cba39be6-63e8-4c8b-bbd8-fc298300147f,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-572f9db4-d7ae-4b43-9a5b-a0ea27830e87,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-920a8e54-aaf2-4ade-9e8f-539cb9e8b740,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-22aaf3ec-d1f1-44d5-81ab-93852e029782,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-84c74d22-3fcb-4ece-8b6f-72b99363948b,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-e56e62f7-c74e-46ae-9722-e4cfaa3fc1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2beaf275-2158-4a2c-bcd0-3adab41f6f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584153022-172.17.0.15-1598632405612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-60036a80-b744-48b1-927b-7a99bcc64371,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-cba39be6-63e8-4c8b-bbd8-fc298300147f,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-572f9db4-d7ae-4b43-9a5b-a0ea27830e87,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-920a8e54-aaf2-4ade-9e8f-539cb9e8b740,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-22aaf3ec-d1f1-44d5-81ab-93852e029782,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-84c74d22-3fcb-4ece-8b6f-72b99363948b,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-e56e62f7-c74e-46ae-9722-e4cfaa3fc1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-2beaf275-2158-4a2c-bcd0-3adab41f6f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769558190-172.17.0.15-1598632664275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-58e4c42a-0d50-4508-9e49-7f8d6774f260,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-b2588614-b236-4c5f-80cb-5302037bc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-f947e9a1-be48-473c-9cd9-b66c6dc4bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d3a950d5-fcab-4a63-b987-fd0e3422d555,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-9a3e8f4c-8a90-4e99-9e6c-fffab6f809af,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-b7c501ba-c081-4f61-b65c-ba1e33b71cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-ab086cf0-18ca-460d-b9cd-ade4c114d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-60c8a65b-0e42-4d75-8717-6e8dbafc0d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769558190-172.17.0.15-1598632664275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-58e4c42a-0d50-4508-9e49-7f8d6774f260,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-b2588614-b236-4c5f-80cb-5302037bc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-f947e9a1-be48-473c-9cd9-b66c6dc4bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d3a950d5-fcab-4a63-b987-fd0e3422d555,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-9a3e8f4c-8a90-4e99-9e6c-fffab6f809af,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-b7c501ba-c081-4f61-b65c-ba1e33b71cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-ab086cf0-18ca-460d-b9cd-ade4c114d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-60c8a65b-0e42-4d75-8717-6e8dbafc0d37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069690755-172.17.0.15-1598632843466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-b6616a9d-840d-451f-9935-2625c75fb5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-4f61feca-ee62-4898-9d9c-10b11f6d0cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-20f0d792-6d58-4d2f-8116-823bd4382b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-6eba7573-a629-4ca7-ae5b-ab5f1007b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-6cb95346-4621-473a-999a-3131840c896a,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-a8f1d5db-fbda-472d-9f78-9669a88e88c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-23c95596-5991-4417-a757-20381fc917a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-f6b8211c-93b3-47fe-a749-89e5fb5049a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069690755-172.17.0.15-1598632843466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42244,DS-b6616a9d-840d-451f-9935-2625c75fb5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-4f61feca-ee62-4898-9d9c-10b11f6d0cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-20f0d792-6d58-4d2f-8116-823bd4382b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-6eba7573-a629-4ca7-ae5b-ab5f1007b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-6cb95346-4621-473a-999a-3131840c896a,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-a8f1d5db-fbda-472d-9f78-9669a88e88c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-23c95596-5991-4417-a757-20381fc917a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-f6b8211c-93b3-47fe-a749-89e5fb5049a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333765110-172.17.0.15-1598633297556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-a4ed3ae5-2dd4-43d6-94bc-277e73a3d828,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-6802cc80-5616-4142-94cc-77074896e94e,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-d118c1e2-c7f7-43e9-82cf-a77d5682458d,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-30474d05-5db7-427b-8c6d-9dcd040f3d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-d07783e0-642b-4187-b65f-e9123d2254d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-45229791-58ed-4972-a27d-5d6c4c6d8e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-c3a79ea9-2d02-4d97-af63-d3bae2e58816,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-6469ad37-0905-4930-8dce-f277697529d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333765110-172.17.0.15-1598633297556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-a4ed3ae5-2dd4-43d6-94bc-277e73a3d828,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-6802cc80-5616-4142-94cc-77074896e94e,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-d118c1e2-c7f7-43e9-82cf-a77d5682458d,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-30474d05-5db7-427b-8c6d-9dcd040f3d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-d07783e0-642b-4187-b65f-e9123d2254d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-45229791-58ed-4972-a27d-5d6c4c6d8e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-c3a79ea9-2d02-4d97-af63-d3bae2e58816,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-6469ad37-0905-4930-8dce-f277697529d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100108040-172.17.0.15-1598633327843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-92fdef6e-4d8a-4729-9c84-489757b60ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-c467dd29-af21-43e7-8f49-4f5b5bf4c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-44f685f5-ca32-435b-b1de-de5ac486645e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-75f3f54c-0b38-4dc8-963e-84431c471af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b619426a-cb6f-42c7-ad8e-f568601e352e,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-0870625a-eb17-4ef2-8e6f-6c6595474e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-7eb5fcae-d2a5-423d-805d-ca5f6e5f6383,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-d13f7784-97aa-42fe-8a45-3200a001eba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100108040-172.17.0.15-1598633327843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-92fdef6e-4d8a-4729-9c84-489757b60ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-c467dd29-af21-43e7-8f49-4f5b5bf4c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-44f685f5-ca32-435b-b1de-de5ac486645e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-75f3f54c-0b38-4dc8-963e-84431c471af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b619426a-cb6f-42c7-ad8e-f568601e352e,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-0870625a-eb17-4ef2-8e6f-6c6595474e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-7eb5fcae-d2a5-423d-805d-ca5f6e5f6383,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-d13f7784-97aa-42fe-8a45-3200a001eba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959892766-172.17.0.15-1598633652114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-cfd3bdd8-d936-4f8f-b4f0-4199efa23260,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-516a41f3-483b-4f59-aa23-8e82574f9009,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-2832642c-4962-4473-936f-d5a22730c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-6d114ded-4237-45e4-bae0-2ff0005ebf56,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-8ad043df-5e37-4115-a146-18bcb6eb7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-3c542e58-099d-461d-bee6-6f94ca669f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-82adec61-7e48-4433-aa5d-05f1811c196e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-2558c2b3-4492-4699-8b5d-f3c765198012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959892766-172.17.0.15-1598633652114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-cfd3bdd8-d936-4f8f-b4f0-4199efa23260,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-516a41f3-483b-4f59-aa23-8e82574f9009,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-2832642c-4962-4473-936f-d5a22730c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-6d114ded-4237-45e4-bae0-2ff0005ebf56,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-8ad043df-5e37-4115-a146-18bcb6eb7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-3c542e58-099d-461d-bee6-6f94ca669f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-82adec61-7e48-4433-aa5d-05f1811c196e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-2558c2b3-4492-4699-8b5d-f3c765198012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595286136-172.17.0.15-1598633688155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-a97660f2-7070-4656-8139-8512f0fe7122,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e92798fe-fc79-4c78-9b3a-1eaaddb38e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-897e0bd6-2c8a-455b-afc8-5a8eeaf14b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-94ddadc7-2cca-44aa-a9a7-3b5cf4a888be,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-f8908888-75fe-4593-bc90-dbdf60874b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-6b3cbcba-a982-40af-b2ce-d7cd865fcfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-bd59a6d0-4a4d-49f1-88fc-18de5d9bb32f,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-3638c86f-1da6-4d10-b677-38b38b7bd525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595286136-172.17.0.15-1598633688155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37835,DS-a97660f2-7070-4656-8139-8512f0fe7122,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e92798fe-fc79-4c78-9b3a-1eaaddb38e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-897e0bd6-2c8a-455b-afc8-5a8eeaf14b84,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-94ddadc7-2cca-44aa-a9a7-3b5cf4a888be,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-f8908888-75fe-4593-bc90-dbdf60874b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-6b3cbcba-a982-40af-b2ce-d7cd865fcfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-bd59a6d0-4a4d-49f1-88fc-18de5d9bb32f,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-3638c86f-1da6-4d10-b677-38b38b7bd525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075494796-172.17.0.15-1598633725351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-ca3e83da-3b7c-4ef2-b002-420e3655e111,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-c85d150e-edc5-407a-90b2-56a41da7e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f8064636-dbe6-4749-85d0-1e027db6b972,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-3f0eb926-595e-4026-ac84-209c9581f7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-3e456e75-a2ca-4969-9bf0-428d27f25ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-3df5aace-dee9-4faf-b135-68baf648b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-97be6fea-0803-4250-9fa0-442e177a7f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-6b32545f-b9e7-4c3c-866b-e21d5da17830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075494796-172.17.0.15-1598633725351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35859,DS-ca3e83da-3b7c-4ef2-b002-420e3655e111,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-c85d150e-edc5-407a-90b2-56a41da7e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f8064636-dbe6-4749-85d0-1e027db6b972,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-3f0eb926-595e-4026-ac84-209c9581f7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-3e456e75-a2ca-4969-9bf0-428d27f25ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-3df5aace-dee9-4faf-b135-68baf648b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-97be6fea-0803-4250-9fa0-442e177a7f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-6b32545f-b9e7-4c3c-866b-e21d5da17830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74988381-172.17.0.15-1598633840080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-6be21c9f-c066-46e3-8189-c4dd82998412,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9b9fb9d3-e8d2-4ef5-b03b-c1bea00ed040,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-94ca60be-2fd3-44bd-b10c-d754e87b483a,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-5fe9a693-edfd-4ff6-820f-e9801e31f489,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-3b26ea97-275a-4471-8388-3dfb1cbe88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-3e4d716d-f46a-49bc-ad46-c9184a598fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-10fe7da9-7c55-4716-a169-548daae12267,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-74aab176-395e-42fc-8036-282993b25639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74988381-172.17.0.15-1598633840080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-6be21c9f-c066-46e3-8189-c4dd82998412,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9b9fb9d3-e8d2-4ef5-b03b-c1bea00ed040,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-94ca60be-2fd3-44bd-b10c-d754e87b483a,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-5fe9a693-edfd-4ff6-820f-e9801e31f489,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-3b26ea97-275a-4471-8388-3dfb1cbe88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-3e4d716d-f46a-49bc-ad46-c9184a598fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-10fe7da9-7c55-4716-a169-548daae12267,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-74aab176-395e-42fc-8036-282993b25639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052454390-172.17.0.15-1598634566954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0a62cc3a-0c3a-4484-b97f-c5c4e05ccedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-5362e1c2-9943-453c-b7a7-caa28dfed6de,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-6e16d8e3-57e6-407b-ab21-49e2ad3b914e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-49de863a-f0d9-4630-bad7-28390586c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-4800bf7e-9e47-44d3-9427-9530c108b022,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-88cc5914-c770-4d64-b947-6c66626a797a,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c9b08347-4e67-47af-80dc-162d0f60ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-142c5e22-0a2b-4d62-812d-697fa9ee3330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052454390-172.17.0.15-1598634566954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39180,DS-0a62cc3a-0c3a-4484-b97f-c5c4e05ccedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-5362e1c2-9943-453c-b7a7-caa28dfed6de,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-6e16d8e3-57e6-407b-ab21-49e2ad3b914e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-49de863a-f0d9-4630-bad7-28390586c7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-4800bf7e-9e47-44d3-9427-9530c108b022,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-88cc5914-c770-4d64-b947-6c66626a797a,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c9b08347-4e67-47af-80dc-162d0f60ddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-142c5e22-0a2b-4d62-812d-697fa9ee3330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5419
