reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875953502-172.17.0.7-1598639851166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-574c7b89-d2f4-48af-85a4-1d1c56f1ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-7a3bbef1-2f5f-40a3-b1f5-13c85f70dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-3a2a6853-d1a9-42d7-ac3c-983e9ddfd394,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-4249b816-842d-4dbf-8f53-84f6c49556db,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-17dc6e9d-2393-44a6-89d0-1be076a6a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e3ddd407-e009-48b0-bb3f-b2173db896a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-921ce9f4-49e1-49cf-ac3d-54a732f84774,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-27d58a58-a72f-4a4b-b8e7-97d301daf21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875953502-172.17.0.7-1598639851166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-574c7b89-d2f4-48af-85a4-1d1c56f1ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-7a3bbef1-2f5f-40a3-b1f5-13c85f70dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-3a2a6853-d1a9-42d7-ac3c-983e9ddfd394,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-4249b816-842d-4dbf-8f53-84f6c49556db,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-17dc6e9d-2393-44a6-89d0-1be076a6a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e3ddd407-e009-48b0-bb3f-b2173db896a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-921ce9f4-49e1-49cf-ac3d-54a732f84774,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-27d58a58-a72f-4a4b-b8e7-97d301daf21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821171258-172.17.0.7-1598640291021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34743,DS-5431b929-2b65-4c43-b7c7-43843fd57fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b14023ea-b38f-4800-9dce-ba1905833320,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-d93e2cba-0216-4e8f-afb7-523ac2d52311,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-4a5194fa-d0f3-4cfb-9245-64d45c6ac4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-164105fc-75c6-42c9-89ac-6674a608444f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f70b3426-8f4e-404f-9495-c83a7673cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-dbd91b9e-1a34-4c75-a751-a6e942de5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-31dda9ff-7a4b-4de3-95d7-c9d9c8a6c493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821171258-172.17.0.7-1598640291021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34743,DS-5431b929-2b65-4c43-b7c7-43843fd57fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b14023ea-b38f-4800-9dce-ba1905833320,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-d93e2cba-0216-4e8f-afb7-523ac2d52311,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-4a5194fa-d0f3-4cfb-9245-64d45c6ac4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-164105fc-75c6-42c9-89ac-6674a608444f,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f70b3426-8f4e-404f-9495-c83a7673cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-dbd91b9e-1a34-4c75-a751-a6e942de5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-31dda9ff-7a4b-4de3-95d7-c9d9c8a6c493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132000012-172.17.0.7-1598640723963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-6a4ce4d2-b88d-4cd6-a990-985760192e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-49c4f21b-cee7-40f1-8d5c-3f009dfc5168,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-4d32d9f1-411f-49b3-bc6d-5e45a6809f77,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-8252fb85-13da-41f0-ae16-acbf7d6f7371,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-8ca8c4ee-9fcb-44aa-91c3-4c5039c699aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-9d9fe6ed-3fa2-4a60-a1c4-3d1850b32cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-ff5b0e11-fc1e-4724-9ee5-d2e259f0c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-6184e80d-3d1b-4f23-b060-0b7476b549f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132000012-172.17.0.7-1598640723963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34725,DS-6a4ce4d2-b88d-4cd6-a990-985760192e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-49c4f21b-cee7-40f1-8d5c-3f009dfc5168,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-4d32d9f1-411f-49b3-bc6d-5e45a6809f77,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-8252fb85-13da-41f0-ae16-acbf7d6f7371,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-8ca8c4ee-9fcb-44aa-91c3-4c5039c699aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-9d9fe6ed-3fa2-4a60-a1c4-3d1850b32cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-ff5b0e11-fc1e-4724-9ee5-d2e259f0c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-6184e80d-3d1b-4f23-b060-0b7476b549f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360239029-172.17.0.7-1598641070596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-c54e7c58-48b3-48d2-97fe-d6a48e2f36a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4bf1a64a-8543-428b-8474-8b8b0f9e1121,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-e0bcc141-dce0-48e2-bc2f-ad38a533226b,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-1ef9305d-00eb-4171-b01a-c828f0065f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f68203d3-fe1b-4208-83fe-5a2c05811725,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-40c7bc03-0a17-4b2a-8a8b-0b5c41789d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-884646d8-ce67-4ea1-afda-c5a861f5bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-a2a68b74-f9b0-4037-9b9d-0abb8e4dd852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360239029-172.17.0.7-1598641070596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-c54e7c58-48b3-48d2-97fe-d6a48e2f36a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4bf1a64a-8543-428b-8474-8b8b0f9e1121,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-e0bcc141-dce0-48e2-bc2f-ad38a533226b,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-1ef9305d-00eb-4171-b01a-c828f0065f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f68203d3-fe1b-4208-83fe-5a2c05811725,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-40c7bc03-0a17-4b2a-8a8b-0b5c41789d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-884646d8-ce67-4ea1-afda-c5a861f5bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-a2a68b74-f9b0-4037-9b9d-0abb8e4dd852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147449111-172.17.0.7-1598641261905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34903,DS-060aedba-c2f7-4bf9-807d-067f583a234d,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-dbdfe086-bf93-4e50-99bb-903559f17248,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b60a20fe-c9ea-4762-80a3-a3869eace253,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0592c869-f47f-4969-a941-702d2f80c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-46e6d9d9-ca51-4eda-a7d2-d4255833ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-12b9fb52-ef97-487b-a8c9-e866969bdd60,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b6341f71-4709-4d26-b513-70d46bdcae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-4de5cac5-1dee-48a5-ac11-dbd7beb82857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147449111-172.17.0.7-1598641261905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34903,DS-060aedba-c2f7-4bf9-807d-067f583a234d,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-dbdfe086-bf93-4e50-99bb-903559f17248,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b60a20fe-c9ea-4762-80a3-a3869eace253,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0592c869-f47f-4969-a941-702d2f80c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-46e6d9d9-ca51-4eda-a7d2-d4255833ab75,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-12b9fb52-ef97-487b-a8c9-e866969bdd60,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b6341f71-4709-4d26-b513-70d46bdcae9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-4de5cac5-1dee-48a5-ac11-dbd7beb82857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577287343-172.17.0.7-1598641370558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-cb780620-a16f-434e-a26e-cdec976d4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-63dc6053-19b3-49c4-8194-4044cd4a421d,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-eff5d291-6553-4164-b089-79878b5a9f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-ea37c5d9-8215-4c44-b0a2-60a880c5026d,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-f57dca51-6892-4e1e-ac6c-419120afd9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-dcc61ff7-9d0c-4f2a-954d-3f1c5e84dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-0f3caf8a-8b1d-4ed5-a5e8-c35229cad4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-cdb60f3d-3d51-4811-bc2a-063131321b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577287343-172.17.0.7-1598641370558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-cb780620-a16f-434e-a26e-cdec976d4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-63dc6053-19b3-49c4-8194-4044cd4a421d,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-eff5d291-6553-4164-b089-79878b5a9f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-ea37c5d9-8215-4c44-b0a2-60a880c5026d,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-f57dca51-6892-4e1e-ac6c-419120afd9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-dcc61ff7-9d0c-4f2a-954d-3f1c5e84dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-0f3caf8a-8b1d-4ed5-a5e8-c35229cad4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-cdb60f3d-3d51-4811-bc2a-063131321b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406145164-172.17.0.7-1598641635297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-9239140c-dfb1-4815-9b18-c64cf18ae710,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-5bec4804-3378-4d24-903f-a2c4a3cdd711,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-ffd0a1f4-04ab-40e4-9aad-ed758d26f0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-53bae09b-b0af-482c-9444-a394a1db5080,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-cf224fef-b582-4a07-89ab-9bf81393be98,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-41a448aa-6845-42ec-a831-9eb7c9aedaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-e49e81bd-7c99-4d1e-b4a2-45658662d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-15d71207-3901-47aa-9a0a-2b33a90e4853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406145164-172.17.0.7-1598641635297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40668,DS-9239140c-dfb1-4815-9b18-c64cf18ae710,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-5bec4804-3378-4d24-903f-a2c4a3cdd711,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-ffd0a1f4-04ab-40e4-9aad-ed758d26f0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-53bae09b-b0af-482c-9444-a394a1db5080,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-cf224fef-b582-4a07-89ab-9bf81393be98,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-41a448aa-6845-42ec-a831-9eb7c9aedaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-e49e81bd-7c99-4d1e-b4a2-45658662d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-15d71207-3901-47aa-9a0a-2b33a90e4853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948732813-172.17.0.7-1598641676937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-74059dce-fd01-459a-8c09-40b0029d817c,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-c705816d-7611-4e28-b29d-f1607a9cb3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-83687c53-c304-4639-a1d1-829c7ee99cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-ce5c584f-6b5f-45b5-977c-ee6bd47fc496,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-31c37c52-073e-4a1f-8d57-786b5f201336,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-3b46959d-2477-476a-bf37-ce6f8039eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-bf62003f-69cb-4e51-bf27-e140e0d84b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-38744c2f-bff9-4f48-b6b2-0fe21358e6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948732813-172.17.0.7-1598641676937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-74059dce-fd01-459a-8c09-40b0029d817c,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-c705816d-7611-4e28-b29d-f1607a9cb3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-83687c53-c304-4639-a1d1-829c7ee99cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-ce5c584f-6b5f-45b5-977c-ee6bd47fc496,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-31c37c52-073e-4a1f-8d57-786b5f201336,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-3b46959d-2477-476a-bf37-ce6f8039eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-bf62003f-69cb-4e51-bf27-e140e0d84b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-38744c2f-bff9-4f48-b6b2-0fe21358e6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727809444-172.17.0.7-1598642442526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-9791797d-3fc0-422a-b661-0d94b74c6769,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-cf2961a5-0276-4969-bd0c-f5d2d976bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-791a4467-9eb2-4c8e-9775-2f9b719f3f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-27436a05-c3d1-45ba-b6ef-b3e175f25c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-0b79e0cf-8801-48c2-9e20-67e28e09103c,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-5875aa80-4ed2-4efe-8671-3141c797dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-93133035-2cf2-4bb4-b45f-6c6c6e75fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-f370b07e-903e-4b62-bffb-af0d1c6b2286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727809444-172.17.0.7-1598642442526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-9791797d-3fc0-422a-b661-0d94b74c6769,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-cf2961a5-0276-4969-bd0c-f5d2d976bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-791a4467-9eb2-4c8e-9775-2f9b719f3f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-27436a05-c3d1-45ba-b6ef-b3e175f25c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-0b79e0cf-8801-48c2-9e20-67e28e09103c,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-5875aa80-4ed2-4efe-8671-3141c797dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-93133035-2cf2-4bb4-b45f-6c6c6e75fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-f370b07e-903e-4b62-bffb-af0d1c6b2286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010531480-172.17.0.7-1598642996836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-5d239b24-e4d4-4037-898e-7eed81840da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-796b5ab8-ad57-4c73-9c65-9b01e94e1099,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-8e46574c-4fd2-448c-8f32-f7c38f2d0138,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-f959187c-025b-4a79-adeb-2c93f3155c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-222f982d-401b-472b-90de-91729fe31548,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-c6e59966-fa39-4025-9648-58266bca92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-e4db10ed-8ba8-4877-b96b-f0783a6023dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-014e4f57-689f-49c4-86ac-79bdc3805c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010531480-172.17.0.7-1598642996836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-5d239b24-e4d4-4037-898e-7eed81840da4,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-796b5ab8-ad57-4c73-9c65-9b01e94e1099,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-8e46574c-4fd2-448c-8f32-f7c38f2d0138,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-f959187c-025b-4a79-adeb-2c93f3155c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-222f982d-401b-472b-90de-91729fe31548,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-c6e59966-fa39-4025-9648-58266bca92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-e4db10ed-8ba8-4877-b96b-f0783a6023dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-014e4f57-689f-49c4-86ac-79bdc3805c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042180775-172.17.0.7-1598643188267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-2f726b1f-1c3c-4121-80d1-da2d3ef5a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-90f5a7be-6b40-4627-b941-bc84f809e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-06000dee-fc80-45be-9057-1643399fe8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-02edf76e-1545-45fc-b73c-0425517a6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-735a73fd-f850-434b-bce1-c86df9880404,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-dc590cb7-f0af-4293-b352-a942d70b81b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-a1d76591-255d-4d8a-8295-41a3f173d678,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-619a43f7-8f8b-4d78-a743-77987d7d2472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042180775-172.17.0.7-1598643188267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-2f726b1f-1c3c-4121-80d1-da2d3ef5a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-90f5a7be-6b40-4627-b941-bc84f809e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-06000dee-fc80-45be-9057-1643399fe8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-02edf76e-1545-45fc-b73c-0425517a6a16,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-735a73fd-f850-434b-bce1-c86df9880404,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-dc590cb7-f0af-4293-b352-a942d70b81b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-a1d76591-255d-4d8a-8295-41a3f173d678,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-619a43f7-8f8b-4d78-a743-77987d7d2472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176897305-172.17.0.7-1598643293511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-6ec8baf9-1991-4579-a0c7-17617a988cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-99427bb7-d47f-4527-9555-017b365b62c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-202e20ab-6fd8-4647-b49a-b46439800629,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-e9a632b3-83e5-42aa-8c28-dd75ab299a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c6b634c7-339d-41dc-a3d7-349db1f44014,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-a3adb9ab-dbf2-468d-9a72-9a623db71642,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-26ea6e6b-85a0-4bf0-9f91-4c2ab1a96e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ab6d833f-c512-4bf0-a74d-d193b70427a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176897305-172.17.0.7-1598643293511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37745,DS-6ec8baf9-1991-4579-a0c7-17617a988cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-99427bb7-d47f-4527-9555-017b365b62c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-202e20ab-6fd8-4647-b49a-b46439800629,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-e9a632b3-83e5-42aa-8c28-dd75ab299a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c6b634c7-339d-41dc-a3d7-349db1f44014,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-a3adb9ab-dbf2-468d-9a72-9a623db71642,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-26ea6e6b-85a0-4bf0-9f91-4c2ab1a96e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-ab6d833f-c512-4bf0-a74d-d193b70427a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607405888-172.17.0.7-1598643329074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-b2b49037-3d7a-4c16-acd3-55e4fe08b118,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cc8d27ed-30b1-4b04-be72-ddd4aeff1738,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-0bbb7ddf-4733-4904-8d08-39afe0025b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-2ec790b2-39b2-4e5b-896e-efe44d26d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-c3eda8e3-292a-44ce-9f5f-89cf62ca00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-b57745b3-a8c1-4b73-a353-e710d07e0765,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-3d39afca-ad79-4c86-8cd8-3a75ea0b4657,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-6173f9c2-54ca-45fe-814e-2b62556a6145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607405888-172.17.0.7-1598643329074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-b2b49037-3d7a-4c16-acd3-55e4fe08b118,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cc8d27ed-30b1-4b04-be72-ddd4aeff1738,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-0bbb7ddf-4733-4904-8d08-39afe0025b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-2ec790b2-39b2-4e5b-896e-efe44d26d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-c3eda8e3-292a-44ce-9f5f-89cf62ca00c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-b57745b3-a8c1-4b73-a353-e710d07e0765,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-3d39afca-ad79-4c86-8cd8-3a75ea0b4657,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-6173f9c2-54ca-45fe-814e-2b62556a6145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434873246-172.17.0.7-1598645065332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-42e5f22f-6909-439c-8a9f-f57073ddc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-c3b41721-4c7a-4ddd-8f35-b892ef79482c,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-2c473ffa-582a-454c-98cb-5cba92e1b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-716431d9-4a47-4038-9bd2-1bf5f50034e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-dfea40e5-9836-4b25-89aa-369665272db1,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-479228e4-2187-4d93-95b7-0affbfff41a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-242eee9a-e019-4875-8c5c-92d2aa5ad838,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-87418d64-e5b0-4d50-a3a4-17e92eb15275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434873246-172.17.0.7-1598645065332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41980,DS-42e5f22f-6909-439c-8a9f-f57073ddc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-c3b41721-4c7a-4ddd-8f35-b892ef79482c,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-2c473ffa-582a-454c-98cb-5cba92e1b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-716431d9-4a47-4038-9bd2-1bf5f50034e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-dfea40e5-9836-4b25-89aa-369665272db1,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-479228e4-2187-4d93-95b7-0affbfff41a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-242eee9a-e019-4875-8c5c-92d2aa5ad838,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-87418d64-e5b0-4d50-a3a4-17e92eb15275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5610
