reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429001366-172.17.0.3-1598485494278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-2cbcfdc5-0e76-49c1-9bd9-59240f438f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-67d32314-1ce4-407d-831e-e0a2afa17a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-821f351f-86f4-479f-b30b-e30961d240fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-f415962a-5dea-4c77-ba57-8cc3035a64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c209de30-ed5d-4f2e-ac34-7b47462098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-aa7095a0-ed43-43ff-8e49-c351abead4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-35d88840-28a1-4f08-afb6-351e6e15dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-3ec3e05f-d602-4d6c-b00f-e54a4dd099a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429001366-172.17.0.3-1598485494278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-2cbcfdc5-0e76-49c1-9bd9-59240f438f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-67d32314-1ce4-407d-831e-e0a2afa17a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-821f351f-86f4-479f-b30b-e30961d240fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-f415962a-5dea-4c77-ba57-8cc3035a64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c209de30-ed5d-4f2e-ac34-7b47462098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-aa7095a0-ed43-43ff-8e49-c351abead4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-35d88840-28a1-4f08-afb6-351e6e15dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-3ec3e05f-d602-4d6c-b00f-e54a4dd099a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582037342-172.17.0.3-1598485797542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-95eab606-a56c-499f-9e9f-17b05d8bb6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-ba6f5b15-5014-4966-ad05-26d615e8c339,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-3552ed0d-1627-4b25-bc2f-78af5aff2571,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-6ff1f99d-4e1d-4022-8ca0-a505fa1aebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-b0fd56da-2fe8-4b35-870d-510f62dd91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-2d4ddb7e-7806-42a6-84c9-9f4a5c0ffe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b3ba1c76-827a-47f3-9414-d4ff034e4649,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-6908b34c-1775-400b-ad0a-18c9053acbbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582037342-172.17.0.3-1598485797542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-95eab606-a56c-499f-9e9f-17b05d8bb6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-ba6f5b15-5014-4966-ad05-26d615e8c339,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-3552ed0d-1627-4b25-bc2f-78af5aff2571,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-6ff1f99d-4e1d-4022-8ca0-a505fa1aebb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-b0fd56da-2fe8-4b35-870d-510f62dd91ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-2d4ddb7e-7806-42a6-84c9-9f4a5c0ffe99,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b3ba1c76-827a-47f3-9414-d4ff034e4649,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-6908b34c-1775-400b-ad0a-18c9053acbbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079859603-172.17.0.3-1598486186614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-a4bcb142-48b6-4951-9eb1-fa6fd3093a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-baad3831-57d9-4739-ba40-954c1b4ac618,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-0954b743-8d69-41a9-b7ee-a02b96e8fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-bf4f7c56-0f21-4a02-92f2-6c6273d6542a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-1c6912c6-f4f7-4f48-9905-6f1708de6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-527bf4cb-7e0d-4aa4-88b0-c91d879d5208,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-615c3497-4b6c-4db3-88a4-78a4342fe701,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-24d2fb22-0b7d-4cb1-9665-383f4a0b9451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079859603-172.17.0.3-1598486186614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-a4bcb142-48b6-4951-9eb1-fa6fd3093a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-baad3831-57d9-4739-ba40-954c1b4ac618,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-0954b743-8d69-41a9-b7ee-a02b96e8fa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-bf4f7c56-0f21-4a02-92f2-6c6273d6542a,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-1c6912c6-f4f7-4f48-9905-6f1708de6b37,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-527bf4cb-7e0d-4aa4-88b0-c91d879d5208,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-615c3497-4b6c-4db3-88a4-78a4342fe701,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-24d2fb22-0b7d-4cb1-9665-383f4a0b9451,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637896575-172.17.0.3-1598486262003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-4688ff98-b510-4dc9-983e-556e1c230acc,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-b29ab8ab-2f65-4d99-b68e-e3499d9ac50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-b09cbfbf-2af3-45bd-88f8-6fcabd7789e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-d4836352-ab8b-4fd4-afd3-2333e052471c,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-9c39efef-3b1c-455b-95fa-38b5a8cf07ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-65847d2f-641c-45f9-9f15-e5ab0177940f,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-79604e3e-7d14-4f7e-b59d-d15c453d1e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-fe792ad3-a28a-4f7e-8e5e-258c5b8aeaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637896575-172.17.0.3-1598486262003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-4688ff98-b510-4dc9-983e-556e1c230acc,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-b29ab8ab-2f65-4d99-b68e-e3499d9ac50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-b09cbfbf-2af3-45bd-88f8-6fcabd7789e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-d4836352-ab8b-4fd4-afd3-2333e052471c,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-9c39efef-3b1c-455b-95fa-38b5a8cf07ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-65847d2f-641c-45f9-9f15-e5ab0177940f,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-79604e3e-7d14-4f7e-b59d-d15c453d1e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-fe792ad3-a28a-4f7e-8e5e-258c5b8aeaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631973061-172.17.0.3-1598486342156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44795,DS-6c76b3ee-5213-49e4-a568-b1b57403e920,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-68aca9a7-2c1d-4e04-a37e-dfa9debd358d,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-fc7f68e1-552f-40b1-b586-337a8da83185,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-0745c234-5f11-4ccc-a397-ff6c931316a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-1ddb0bac-8062-4f4a-973a-4407d19cf8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-18fc1a48-9d92-43c5-b541-79c8b1c21d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-b1a4b639-4002-4e91-bd8e-862cefa381ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-b3668388-3aed-47af-a53a-c4ae0b6e062b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631973061-172.17.0.3-1598486342156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44795,DS-6c76b3ee-5213-49e4-a568-b1b57403e920,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-68aca9a7-2c1d-4e04-a37e-dfa9debd358d,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-fc7f68e1-552f-40b1-b586-337a8da83185,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-0745c234-5f11-4ccc-a397-ff6c931316a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-1ddb0bac-8062-4f4a-973a-4407d19cf8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-18fc1a48-9d92-43c5-b541-79c8b1c21d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-b1a4b639-4002-4e91-bd8e-862cefa381ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-b3668388-3aed-47af-a53a-c4ae0b6e062b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463038955-172.17.0.3-1598486674997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-c96b7a4e-e066-4ce2-8e53-10f8c4d04df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-259d03fc-39f7-4671-9d80-38e9114a253e,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ae2b0f7e-296b-40be-bd12-f066aad26429,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-950faed7-e0ba-4dac-832d-12be04fb2375,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-1a766529-2101-498b-8021-60304aa3f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-11e1c020-4243-4376-82bd-24d880d2bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-d681233e-d391-4c3e-8cdb-889f1288e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-395a9c89-9c88-4be0-a112-b5c4da7bfd0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463038955-172.17.0.3-1598486674997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-c96b7a4e-e066-4ce2-8e53-10f8c4d04df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-259d03fc-39f7-4671-9d80-38e9114a253e,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ae2b0f7e-296b-40be-bd12-f066aad26429,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-950faed7-e0ba-4dac-832d-12be04fb2375,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-1a766529-2101-498b-8021-60304aa3f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-11e1c020-4243-4376-82bd-24d880d2bb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-d681233e-d391-4c3e-8cdb-889f1288e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-395a9c89-9c88-4be0-a112-b5c4da7bfd0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069144312-172.17.0.3-1598487229740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-39458c76-d3f6-467e-986c-67e8f46b5e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-d309fc30-8c75-4cf4-af9c-e69b96721baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-7c494148-dac8-41f5-98f3-45793fa8dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-36a2ce29-0da7-4683-afce-718e3a4d6986,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-93d70b01-d29c-4a5d-b3e1-3bcbf02b3636,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-57405bda-bf54-426f-bdea-aa6bb0367eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-aee1fb05-58be-466b-b9df-151f138b9939,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4891d015-d047-47f6-ba24-8c43db6ec1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069144312-172.17.0.3-1598487229740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-39458c76-d3f6-467e-986c-67e8f46b5e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-d309fc30-8c75-4cf4-af9c-e69b96721baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-7c494148-dac8-41f5-98f3-45793fa8dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-36a2ce29-0da7-4683-afce-718e3a4d6986,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-93d70b01-d29c-4a5d-b3e1-3bcbf02b3636,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-57405bda-bf54-426f-bdea-aa6bb0367eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-aee1fb05-58be-466b-b9df-151f138b9939,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4891d015-d047-47f6-ba24-8c43db6ec1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669415618-172.17.0.3-1598487458484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-de842522-b940-4412-81df-99f88caccd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-e417e40b-838b-4094-aad7-7724c084e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-b4b99fc5-ab42-4340-a2cc-aa63c99773da,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-8421ec60-090e-4f43-8a5b-997f2d039374,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-e644227b-0006-469b-9642-0ab690196f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-f1ec41e2-4456-4f26-87aa-7b3ec9fb7d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-0ab83191-8b24-49f5-88e0-0108e035c251,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-b4456605-abdd-47d9-8337-a098fbf32285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669415618-172.17.0.3-1598487458484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-de842522-b940-4412-81df-99f88caccd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-e417e40b-838b-4094-aad7-7724c084e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-b4b99fc5-ab42-4340-a2cc-aa63c99773da,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-8421ec60-090e-4f43-8a5b-997f2d039374,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-e644227b-0006-469b-9642-0ab690196f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-f1ec41e2-4456-4f26-87aa-7b3ec9fb7d00,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-0ab83191-8b24-49f5-88e0-0108e035c251,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-b4456605-abdd-47d9-8337-a098fbf32285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888570611-172.17.0.3-1598487953004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-5dda097c-88c1-4633-90b0-67352ae1e189,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-3f17c5d9-5e9e-4e89-86e1-176cdf4477be,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-2b4a6fa9-7331-4299-8cfd-808d2f05528f,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-9a73f2f9-840a-4c16-8ba5-e0b36e580af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9c8c7c84-14f2-46b4-a8ae-e14379a2da48,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-8d034ac1-3430-4c26-8c3f-051a9bba6cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-7cbee2e0-e5a2-46b7-a20e-db13b76a869d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-12c0659f-dd70-4da3-b85f-966ac34b3cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888570611-172.17.0.3-1598487953004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-5dda097c-88c1-4633-90b0-67352ae1e189,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-3f17c5d9-5e9e-4e89-86e1-176cdf4477be,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-2b4a6fa9-7331-4299-8cfd-808d2f05528f,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-9a73f2f9-840a-4c16-8ba5-e0b36e580af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-9c8c7c84-14f2-46b4-a8ae-e14379a2da48,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-8d034ac1-3430-4c26-8c3f-051a9bba6cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-7cbee2e0-e5a2-46b7-a20e-db13b76a869d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-12c0659f-dd70-4da3-b85f-966ac34b3cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373055331-172.17.0.3-1598488311061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36778,DS-d449f607-a9c7-4905-8c4e-d5953249f655,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-f05b6477-1b13-4ea2-bdab-f2db28bcc49c,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-eea1b98a-5f1d-42d1-b830-d5923a917bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-9da10cc6-c3e1-4c5a-925c-b64934dcf53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-817075fc-00eb-4089-be3d-05d146e034e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-e319d64f-be1e-48d1-8953-af04893cf7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-62c1d714-d233-4229-9f56-f87a84e5efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-439110c6-8313-4653-a75f-dc9519a3ce18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373055331-172.17.0.3-1598488311061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36778,DS-d449f607-a9c7-4905-8c4e-d5953249f655,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-f05b6477-1b13-4ea2-bdab-f2db28bcc49c,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-eea1b98a-5f1d-42d1-b830-d5923a917bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-9da10cc6-c3e1-4c5a-925c-b64934dcf53f,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-817075fc-00eb-4089-be3d-05d146e034e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-e319d64f-be1e-48d1-8953-af04893cf7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-62c1d714-d233-4229-9f56-f87a84e5efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-439110c6-8313-4653-a75f-dc9519a3ce18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215395681-172.17.0.3-1598490282997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33508,DS-e55535d7-9f3f-4f75-8b95-3b0c848fe529,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-c81b6671-2412-4696-b6f7-a04b01402150,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-9887e0f5-2a36-4837-900a-e54ff3f23be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-1d03ec25-6c4b-40e7-ab35-f56ad4da2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-47473432-144b-48ee-958b-964e64fe849b,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-65b802d9-2c86-4662-8b92-ad9730cdab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b1682eb3-76fe-43e4-8bfe-5baa8cb1ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-83bb69c1-be43-4fe8-ace3-52d3624485b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215395681-172.17.0.3-1598490282997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33508,DS-e55535d7-9f3f-4f75-8b95-3b0c848fe529,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-c81b6671-2412-4696-b6f7-a04b01402150,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-9887e0f5-2a36-4837-900a-e54ff3f23be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-1d03ec25-6c4b-40e7-ab35-f56ad4da2bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-47473432-144b-48ee-958b-964e64fe849b,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-65b802d9-2c86-4662-8b92-ad9730cdab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b1682eb3-76fe-43e4-8bfe-5baa8cb1ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-83bb69c1-be43-4fe8-ace3-52d3624485b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346873273-172.17.0.3-1598490479121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-ea725a2d-90e7-4deb-bb86-c70e96d006e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-f09e42ca-34ef-4263-9b3f-3e51a63c529c,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-2eb5d53f-21ea-4616-ad65-34a542bb6a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ae697e53-31ab-41ad-8a5a-f02fa34e7e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-b79a16f7-cda7-496e-97b7-8f95c3dfaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-03a31b68-7704-49a8-b3ac-6ca6d6cd2d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-1fad61f1-bd3a-451f-8467-2a230574c544,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-d3a59cf3-6131-45c3-a08f-ba473cc8f06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346873273-172.17.0.3-1598490479121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-ea725a2d-90e7-4deb-bb86-c70e96d006e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-f09e42ca-34ef-4263-9b3f-3e51a63c529c,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-2eb5d53f-21ea-4616-ad65-34a542bb6a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ae697e53-31ab-41ad-8a5a-f02fa34e7e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-b79a16f7-cda7-496e-97b7-8f95c3dfaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-03a31b68-7704-49a8-b3ac-6ca6d6cd2d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-1fad61f1-bd3a-451f-8467-2a230574c544,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-d3a59cf3-6131-45c3-a08f-ba473cc8f06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5693
