reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535596609-172.17.0.3-1598566609294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-9011a27d-d5fd-4d65-9e82-8309827aaf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9ecdcc74-f2ab-45a9-8062-42fdd3ed040e,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-c7eb1b16-61e7-49b9-9218-1b6378b092d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-39ca7c86-0336-4796-b46b-fc67d037deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-69f146dc-4607-4d55-97f9-a6e39481bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-6b146df5-d9f3-46f9-903a-762a7feea952,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-9ebdead0-e08a-4e67-ad3e-bea71a931046,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-2c64e8bc-8164-4d2c-9eee-358eaf568c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535596609-172.17.0.3-1598566609294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-9011a27d-d5fd-4d65-9e82-8309827aaf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-9ecdcc74-f2ab-45a9-8062-42fdd3ed040e,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-c7eb1b16-61e7-49b9-9218-1b6378b092d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-39ca7c86-0336-4796-b46b-fc67d037deb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-69f146dc-4607-4d55-97f9-a6e39481bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-6b146df5-d9f3-46f9-903a-762a7feea952,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-9ebdead0-e08a-4e67-ad3e-bea71a931046,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-2c64e8bc-8164-4d2c-9eee-358eaf568c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717535697-172.17.0.3-1598567606615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-ed5ac743-baa3-41b6-97e3-3abeb74f18ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-e8e1e545-4d6c-4415-9632-3873f7489bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-d74f8261-c1ba-4795-9735-18ba5a2974a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b6f266a4-4450-4e4f-bcc3-4b1a28a9565f,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-390d9eb5-7956-4a0c-a31e-0bb0dc02256b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e555cf6e-15ac-4be1-9471-1d4d8350355d,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-853c54eb-6395-4fcc-9deb-65b52447c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-a79d9a3c-6a06-42ec-860f-f8e04fa8f9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717535697-172.17.0.3-1598567606615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-ed5ac743-baa3-41b6-97e3-3abeb74f18ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-e8e1e545-4d6c-4415-9632-3873f7489bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-d74f8261-c1ba-4795-9735-18ba5a2974a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b6f266a4-4450-4e4f-bcc3-4b1a28a9565f,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-390d9eb5-7956-4a0c-a31e-0bb0dc02256b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-e555cf6e-15ac-4be1-9471-1d4d8350355d,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-853c54eb-6395-4fcc-9deb-65b52447c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-a79d9a3c-6a06-42ec-860f-f8e04fa8f9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832810567-172.17.0.3-1598567984814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-01ee8c90-e602-400c-8ed3-62da04efd7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-ea1f18d9-62f8-4ba0-974c-6a2e4a460109,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-44492752-5406-41f3-bea6-506ea82b6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-5085fd85-78bc-4aa0-8c86-6ccb96a0cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-5a386415-6caa-4f72-be08-81311c14934a,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-c36d6c9b-ce35-47d3-8487-73af5fdd1468,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-48cdcc6b-c7cf-4c4a-a28a-9101a3bdcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b65e8f36-9668-4f0a-bee5-1ee7e42e2570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832810567-172.17.0.3-1598567984814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-01ee8c90-e602-400c-8ed3-62da04efd7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-ea1f18d9-62f8-4ba0-974c-6a2e4a460109,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-44492752-5406-41f3-bea6-506ea82b6a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-5085fd85-78bc-4aa0-8c86-6ccb96a0cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-5a386415-6caa-4f72-be08-81311c14934a,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-c36d6c9b-ce35-47d3-8487-73af5fdd1468,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-48cdcc6b-c7cf-4c4a-a28a-9101a3bdcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b65e8f36-9668-4f0a-bee5-1ee7e42e2570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895813483-172.17.0.3-1598568053689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-723887e4-188c-4459-95ae-6da9c427f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-feb3182d-b745-4fd9-8b54-adadbfaf009e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e91f6fd6-962b-4064-afdf-d0fe3970d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-640cc172-8e12-402a-aa8f-648311ec74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-dab02111-e96b-45fb-a5f8-affef7c5da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-35447aec-55eb-43b1-ba48-1dd2d47e924f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-47a73d7c-9863-4bd7-9e0c-ef37b43b4231,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-bdae3d49-29cd-49f0-b71b-09b3f004bee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895813483-172.17.0.3-1598568053689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-723887e4-188c-4459-95ae-6da9c427f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-feb3182d-b745-4fd9-8b54-adadbfaf009e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-e91f6fd6-962b-4064-afdf-d0fe3970d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-640cc172-8e12-402a-aa8f-648311ec74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-dab02111-e96b-45fb-a5f8-affef7c5da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-35447aec-55eb-43b1-ba48-1dd2d47e924f,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-47a73d7c-9863-4bd7-9e0c-ef37b43b4231,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-bdae3d49-29cd-49f0-b71b-09b3f004bee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328038029-172.17.0.3-1598568430712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-73ac65d1-9338-4ee5-bf16-1c06622d1eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-28724c43-13a1-4f7a-83eb-77c0f413a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-ec79209c-8cc0-4ff1-9e5e-5426f4914c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-3519ab14-ecb1-46d9-abb1-6117fb8cd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6662ecec-73a4-408c-b7a4-441c8212ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-f3eeb98d-0668-4ae4-8355-230477e5867d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-f7c1b8cc-b4d9-4d90-bf81-9287cdda737d,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-9863f775-efc2-4cee-969d-bbee640b7fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328038029-172.17.0.3-1598568430712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-73ac65d1-9338-4ee5-bf16-1c06622d1eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-28724c43-13a1-4f7a-83eb-77c0f413a38e,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-ec79209c-8cc0-4ff1-9e5e-5426f4914c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-3519ab14-ecb1-46d9-abb1-6117fb8cd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6662ecec-73a4-408c-b7a4-441c8212ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-f3eeb98d-0668-4ae4-8355-230477e5867d,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-f7c1b8cc-b4d9-4d90-bf81-9287cdda737d,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-9863f775-efc2-4cee-969d-bbee640b7fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986736468-172.17.0.3-1598568722140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-7152c25d-b910-40f9-965a-124a483c7e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8da5172f-7f35-4eb7-910a-df293ae8146e,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-611f4083-56fb-4217-93e6-48c64e915664,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-21803274-7c77-4618-a5ba-eae50dd8b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-07d7db90-6607-4136-9e57-3bf26760e791,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-299ca703-c9c1-4ccd-bc4e-55182c208322,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-107ea244-db70-4e2b-a9b2-e4c40e8a9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-4bd76166-9c93-4bfa-be15-b8a7e1bf08f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986736468-172.17.0.3-1598568722140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38203,DS-7152c25d-b910-40f9-965a-124a483c7e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8da5172f-7f35-4eb7-910a-df293ae8146e,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-611f4083-56fb-4217-93e6-48c64e915664,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-21803274-7c77-4618-a5ba-eae50dd8b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-07d7db90-6607-4136-9e57-3bf26760e791,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-299ca703-c9c1-4ccd-bc4e-55182c208322,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-107ea244-db70-4e2b-a9b2-e4c40e8a9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-4bd76166-9c93-4bfa-be15-b8a7e1bf08f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218302455-172.17.0.3-1598568756361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-058edfc0-19b2-4a43-b4b3-57e6ce2fce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-306017c8-b14d-4a3d-bf09-effd5ecfaca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-6ffc26b9-91b7-4c9b-bf0f-1176e3d20c80,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ac27ea87-114a-4328-955a-032e09732f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-2ea4bc78-aa64-41f4-972a-da08dc74c675,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-22571570-8106-4c65-b6f4-9eb4c56418ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55dd0777-3b54-4df6-8653-8e846ba661b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-2035bc14-730d-4a66-8bcb-7946501af4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218302455-172.17.0.3-1598568756361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-058edfc0-19b2-4a43-b4b3-57e6ce2fce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-306017c8-b14d-4a3d-bf09-effd5ecfaca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-6ffc26b9-91b7-4c9b-bf0f-1176e3d20c80,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ac27ea87-114a-4328-955a-032e09732f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-2ea4bc78-aa64-41f4-972a-da08dc74c675,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-22571570-8106-4c65-b6f4-9eb4c56418ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55dd0777-3b54-4df6-8653-8e846ba661b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-2035bc14-730d-4a66-8bcb-7946501af4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306076311-172.17.0.3-1598569651491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33678,DS-04d9ad24-39dd-40c0-bd07-d2e7967d5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-c56adc15-df19-4c0c-bd7c-efebefbe6b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-59db5da6-4e78-44f1-8add-e57f2f86ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-08bf4c5f-36c4-48ed-a8df-0bd26eb75747,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-d153e951-ef2e-4293-8835-9e509e38f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-fe69adc9-f6dd-485a-acdf-57f50349cb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-8aa4154c-88e9-4572-b6e9-d73e4d2fb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-a4b9530b-469d-4651-80d7-5b0af0496b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306076311-172.17.0.3-1598569651491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33678,DS-04d9ad24-39dd-40c0-bd07-d2e7967d5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-c56adc15-df19-4c0c-bd7c-efebefbe6b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-59db5da6-4e78-44f1-8add-e57f2f86ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-08bf4c5f-36c4-48ed-a8df-0bd26eb75747,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-d153e951-ef2e-4293-8835-9e509e38f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-fe69adc9-f6dd-485a-acdf-57f50349cb72,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-8aa4154c-88e9-4572-b6e9-d73e4d2fb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-a4b9530b-469d-4651-80d7-5b0af0496b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513265340-172.17.0.3-1598569755637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-079a2ba6-27e9-4b0c-851d-67b63d9bd9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-e765f0f5-2f59-4d64-900a-2e8ee82e58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-aea11f19-0484-4e94-8593-023ca6c22da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-eaa08b28-38b1-437b-bfde-82e113d1437c,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-4020ca4e-f1d6-4207-926f-285a4c4bada7,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-7e727c4d-986f-45c8-b82a-211f6be8df46,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-936ed309-700f-4d67-abc8-cf516dc23edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-4d1a1680-801b-49bb-a361-8a3159ce5952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513265340-172.17.0.3-1598569755637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-079a2ba6-27e9-4b0c-851d-67b63d9bd9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-e765f0f5-2f59-4d64-900a-2e8ee82e58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-aea11f19-0484-4e94-8593-023ca6c22da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-eaa08b28-38b1-437b-bfde-82e113d1437c,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-4020ca4e-f1d6-4207-926f-285a4c4bada7,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-7e727c4d-986f-45c8-b82a-211f6be8df46,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-936ed309-700f-4d67-abc8-cf516dc23edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-4d1a1680-801b-49bb-a361-8a3159ce5952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196739203-172.17.0.3-1598569861152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-7b63b745-f1c1-46c2-8462-11ea8f16ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-1628dd1e-b737-4a5a-af81-bdfefeb6bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-906c0a2b-2eb6-4641-b927-e7fcdf4fb2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-83c9cd32-27c6-4cc7-8df8-c194199ad70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-bf6bd58e-b1f4-4038-b127-222fccc58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-2f222169-af62-4e1d-874e-a8584cae4d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-9691333d-17a1-4090-a14a-ab41ac9aaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-74ea71ae-551a-4320-8bf2-f601ada8909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196739203-172.17.0.3-1598569861152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-7b63b745-f1c1-46c2-8462-11ea8f16ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-1628dd1e-b737-4a5a-af81-bdfefeb6bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-906c0a2b-2eb6-4641-b927-e7fcdf4fb2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-83c9cd32-27c6-4cc7-8df8-c194199ad70c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-bf6bd58e-b1f4-4038-b127-222fccc58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-2f222169-af62-4e1d-874e-a8584cae4d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-9691333d-17a1-4090-a14a-ab41ac9aaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-74ea71ae-551a-4320-8bf2-f601ada8909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164674523-172.17.0.3-1598570231350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-f9528c5c-f43f-4b57-8efb-92e282436cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-426ae366-0f60-4dcc-a348-d58b0266669e,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-fe94df12-6eda-4edf-a472-e245c08161d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-316544bf-3d8d-43f1-a61e-1802a52fa966,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-695cf383-e44b-41f7-90a3-4cd7059aceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-2b5dfc9d-2fd6-440a-80b3-8b8a1cbb4bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-25412092-a0c1-4da7-a886-3d905de07660,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-f211499d-a43b-4119-8d8f-7be0a29ff444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164674523-172.17.0.3-1598570231350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-f9528c5c-f43f-4b57-8efb-92e282436cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-426ae366-0f60-4dcc-a348-d58b0266669e,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-fe94df12-6eda-4edf-a472-e245c08161d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-316544bf-3d8d-43f1-a61e-1802a52fa966,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-695cf383-e44b-41f7-90a3-4cd7059aceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-2b5dfc9d-2fd6-440a-80b3-8b8a1cbb4bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-25412092-a0c1-4da7-a886-3d905de07660,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-f211499d-a43b-4119-8d8f-7be0a29ff444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317549152-172.17.0.3-1598570756149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-0029644a-8066-4b30-8d10-1c8111f79075,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-1ed6ca75-35a1-4f2e-a1ae-58c874e9680e,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-9347d85f-31fd-4358-9746-69a28431c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2ed62020-fd50-4616-8914-1b5818841c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-67bdf3bf-c38d-47c6-9047-433a02378246,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-984da631-11de-48df-8c04-0e5ce37168fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-232f5471-51b7-41b4-9dc8-f7b4b273789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-5c2f0775-ca79-4564-b74d-af9efb1efe56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317549152-172.17.0.3-1598570756149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-0029644a-8066-4b30-8d10-1c8111f79075,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-1ed6ca75-35a1-4f2e-a1ae-58c874e9680e,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-9347d85f-31fd-4358-9746-69a28431c69a,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2ed62020-fd50-4616-8914-1b5818841c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-67bdf3bf-c38d-47c6-9047-433a02378246,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-984da631-11de-48df-8c04-0e5ce37168fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-232f5471-51b7-41b4-9dc8-f7b4b273789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-5c2f0775-ca79-4564-b74d-af9efb1efe56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729423175-172.17.0.3-1598570897725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-5f06238f-0b37-401d-9e14-310d76ee1bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-ea55ef55-4eec-434a-a2f2-5c1e140600c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-3e1f1bc2-13cb-493b-a414-fb5e3ccbfc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-88946419-751e-42f0-8113-b8fec55e8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-776b4318-64bc-4dd7-9936-d0ca5cd70676,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-eebb7853-cd65-45a4-b1b3-a55212474c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c988318d-8a3e-4b68-9ee8-9eb586c35df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-62e560c1-f75b-4943-86dd-8d93c0d9538b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729423175-172.17.0.3-1598570897725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-5f06238f-0b37-401d-9e14-310d76ee1bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-ea55ef55-4eec-434a-a2f2-5c1e140600c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-3e1f1bc2-13cb-493b-a414-fb5e3ccbfc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-88946419-751e-42f0-8113-b8fec55e8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-776b4318-64bc-4dd7-9936-d0ca5cd70676,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-eebb7853-cd65-45a4-b1b3-a55212474c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-c988318d-8a3e-4b68-9ee8-9eb586c35df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-62e560c1-f75b-4943-86dd-8d93c0d9538b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140150785-172.17.0.3-1598571084456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-9e729a6d-ff30-4278-9a53-af85e1c31192,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-9967b342-eaab-45f5-ba82-479cc9d3386f,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-8b406b64-a594-4284-b510-9f7bf382af07,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-e8c7daa4-12d0-4195-8de5-08a9661c59a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1298cdaf-bbf6-41fc-81d3-ba19436e1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-ce3b6e14-68b6-40fb-a39c-2a8876698c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-757804ea-51a2-428a-981d-da1fc86c3d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-df128e2e-7226-45f2-9267-929dee78a9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140150785-172.17.0.3-1598571084456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-9e729a6d-ff30-4278-9a53-af85e1c31192,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-9967b342-eaab-45f5-ba82-479cc9d3386f,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-8b406b64-a594-4284-b510-9f7bf382af07,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-e8c7daa4-12d0-4195-8de5-08a9661c59a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1298cdaf-bbf6-41fc-81d3-ba19436e1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-ce3b6e14-68b6-40fb-a39c-2a8876698c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-757804ea-51a2-428a-981d-da1fc86c3d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-df128e2e-7226-45f2-9267-929dee78a9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111914817-172.17.0.3-1598571190499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-fd5ddaff-96b7-4c0f-a600-f94d71ff9093,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-dcee9b6f-8ff0-4c22-9d08-cecda7c267e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-cf5b2a4d-3135-4030-862d-93d3bc7e8a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-7c1fe400-e381-4cbd-9212-d76b9cc6d628,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-20e5b149-df38-4ae9-ad9f-233a7a3ec9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-f87cb066-9d63-44f5-973e-ec6f0c11cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cf7102fc-a191-4631-bb59-01d54460e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-13d86611-8fdd-4926-b669-51fa8faf991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111914817-172.17.0.3-1598571190499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-fd5ddaff-96b7-4c0f-a600-f94d71ff9093,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-dcee9b6f-8ff0-4c22-9d08-cecda7c267e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-cf5b2a4d-3135-4030-862d-93d3bc7e8a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-7c1fe400-e381-4cbd-9212-d76b9cc6d628,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-20e5b149-df38-4ae9-ad9f-233a7a3ec9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-f87cb066-9d63-44f5-973e-ec6f0c11cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-cf7102fc-a191-4631-bb59-01d54460e88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-13d86611-8fdd-4926-b669-51fa8faf991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228713820-172.17.0.3-1598571282153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-67125186-2ed1-4fa4-b1c6-4f652b0a5ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-63eeafe4-d30d-45b2-a075-5d10d0d3b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-d1321957-9960-40c9-8290-b323d7ebd151,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-248abb53-9bf9-4bd6-a762-e8a5ff4699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-02de64d0-7966-4cdb-b34b-ee74217a2254,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-80076548-669f-4ff4-a3f7-4df85c37d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-c8496883-04f8-4f8b-ba2e-65e603f57a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-8f640ab7-99f8-44c2-88c5-1eea0fe21a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228713820-172.17.0.3-1598571282153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-67125186-2ed1-4fa4-b1c6-4f652b0a5ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-63eeafe4-d30d-45b2-a075-5d10d0d3b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-d1321957-9960-40c9-8290-b323d7ebd151,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-248abb53-9bf9-4bd6-a762-e8a5ff4699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-02de64d0-7966-4cdb-b34b-ee74217a2254,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-80076548-669f-4ff4-a3f7-4df85c37d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-c8496883-04f8-4f8b-ba2e-65e603f57a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-8f640ab7-99f8-44c2-88c5-1eea0fe21a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5206
