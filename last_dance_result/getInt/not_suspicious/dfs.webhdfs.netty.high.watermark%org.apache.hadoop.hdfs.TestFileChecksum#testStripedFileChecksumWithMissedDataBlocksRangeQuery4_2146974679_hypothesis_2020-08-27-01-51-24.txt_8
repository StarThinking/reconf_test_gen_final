reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674480863-172.17.0.9-1598493183522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-3d534d57-66cf-4d8e-875e-0deaa8f65afb,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-75a5db51-ef0d-4983-bd8b-2e54e2030916,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-a979ee6c-9db0-4b5a-8edb-18da4acb4c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-610f8c81-5f6e-468f-b607-3988f27128d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-1530583f-9bd3-439c-8f41-e4fc6dfc4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7d766367-9882-4552-9e76-eb8f172ceafe,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-70fcb802-db4d-4a1f-88a6-162e313c17ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-9c5b5515-6eef-4abf-a0f6-39c8ce227a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674480863-172.17.0.9-1598493183522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-3d534d57-66cf-4d8e-875e-0deaa8f65afb,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-75a5db51-ef0d-4983-bd8b-2e54e2030916,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-a979ee6c-9db0-4b5a-8edb-18da4acb4c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-610f8c81-5f6e-468f-b607-3988f27128d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-1530583f-9bd3-439c-8f41-e4fc6dfc4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-7d766367-9882-4552-9e76-eb8f172ceafe,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-70fcb802-db4d-4a1f-88a6-162e313c17ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-9c5b5515-6eef-4abf-a0f6-39c8ce227a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582161677-172.17.0.9-1598493299578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-07b00155-7067-43df-b7be-966661d167fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-f1234e7d-f92d-4dae-b45e-3e0dc366e976,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-f368ca0d-e538-4793-acd3-b9d1bc96bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-4149319c-a45e-47e7-a3cb-1c48977bc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-68c8c868-4fe8-4913-a2f4-94dfe02d3096,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-9ef2b43d-6f5d-4a1b-9872-23866a37c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-375f0bb0-b6bc-4c23-9fd0-70d77da1c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-eb8463c4-d7b6-46d8-aa3e-c45a642b6aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582161677-172.17.0.9-1598493299578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38619,DS-07b00155-7067-43df-b7be-966661d167fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-f1234e7d-f92d-4dae-b45e-3e0dc366e976,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-f368ca0d-e538-4793-acd3-b9d1bc96bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-4149319c-a45e-47e7-a3cb-1c48977bc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-68c8c868-4fe8-4913-a2f4-94dfe02d3096,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-9ef2b43d-6f5d-4a1b-9872-23866a37c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-375f0bb0-b6bc-4c23-9fd0-70d77da1c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-eb8463c4-d7b6-46d8-aa3e-c45a642b6aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350570989-172.17.0.9-1598493413295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-6e42427d-e388-4668-bc7a-cafd00db8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9e0fb220-7ac3-42a3-968c-ba0556e8cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-442207f0-4009-4275-b5e7-eb5311109331,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-d3c92a8a-d29f-4bda-9e69-e4b0c614473b,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-35bd491c-8ef9-4bd5-a482-d575ecdd5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-2b75d1ce-f594-401a-b1c7-3ea9435edc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-c300d33e-f6fa-4b5b-a9f0-bc609a8c510e,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b94134a8-e05e-4bc5-93b1-9863fb374854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350570989-172.17.0.9-1598493413295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45249,DS-6e42427d-e388-4668-bc7a-cafd00db8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9e0fb220-7ac3-42a3-968c-ba0556e8cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-442207f0-4009-4275-b5e7-eb5311109331,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-d3c92a8a-d29f-4bda-9e69-e4b0c614473b,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-35bd491c-8ef9-4bd5-a482-d575ecdd5abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-2b75d1ce-f594-401a-b1c7-3ea9435edc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-c300d33e-f6fa-4b5b-a9f0-bc609a8c510e,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b94134a8-e05e-4bc5-93b1-9863fb374854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994732310-172.17.0.9-1598493575230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-c1796390-57b0-4484-b4ce-fa2735e01fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-f44e3fc5-1ab5-41ca-b7c9-c45a166e4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-78a9b1d8-c128-42e6-aace-48e15dabc237,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-034f9609-b5e1-4c96-914e-3ef94e483281,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-2a27ad8b-50c4-43e6-aecc-874497da0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-793f560c-3d77-4887-80fc-670abcb3ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-c21a2277-648c-469b-8e9b-79ce81263d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-d4f346c2-78ef-4687-8830-a62b2cb772ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994732310-172.17.0.9-1598493575230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-c1796390-57b0-4484-b4ce-fa2735e01fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-f44e3fc5-1ab5-41ca-b7c9-c45a166e4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-78a9b1d8-c128-42e6-aace-48e15dabc237,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-034f9609-b5e1-4c96-914e-3ef94e483281,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-2a27ad8b-50c4-43e6-aecc-874497da0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-793f560c-3d77-4887-80fc-670abcb3ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-c21a2277-648c-469b-8e9b-79ce81263d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-d4f346c2-78ef-4687-8830-a62b2cb772ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466825409-172.17.0.9-1598494330096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-04e0701d-cb15-4960-bea6-3d00a1a9c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-5b2f0468-1a2f-42d8-9463-50bb7af6e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-45c9f4b4-c816-4faa-9cb2-342d20cb801d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-03bb578e-2705-4d36-9f23-f578d6fa0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ca6ab8ad-805e-495d-9ef6-f2e062a40894,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-f7cfec4d-e7fd-4a96-8bc0-eb9ff54b8328,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-dde35426-71b1-48b8-944d-3ec7c331e036,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d92b405e-9ed3-4d58-9cae-25bcf27ef3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466825409-172.17.0.9-1598494330096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-04e0701d-cb15-4960-bea6-3d00a1a9c2df,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-5b2f0468-1a2f-42d8-9463-50bb7af6e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-45c9f4b4-c816-4faa-9cb2-342d20cb801d,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-03bb578e-2705-4d36-9f23-f578d6fa0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ca6ab8ad-805e-495d-9ef6-f2e062a40894,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-f7cfec4d-e7fd-4a96-8bc0-eb9ff54b8328,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-dde35426-71b1-48b8-944d-3ec7c331e036,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-d92b405e-9ed3-4d58-9cae-25bcf27ef3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230440960-172.17.0.9-1598494446444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-c22b8b90-2abf-4541-8914-5ea9c264ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-6b5a7e36-88d8-4013-966f-7c55a1bf7a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-945dc5e1-85d0-465a-80c4-a446bd71d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-65c488e5-04c4-462a-961a-b4f7e3680aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-9d56b292-2532-4b56-8399-eddff78c1e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-0f4a055a-248c-4352-a033-268291d33b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-33813162-bc8d-4534-831c-75e857dadf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-395a9edc-9343-403f-8982-8de94635beb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230440960-172.17.0.9-1598494446444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45866,DS-c22b8b90-2abf-4541-8914-5ea9c264ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-6b5a7e36-88d8-4013-966f-7c55a1bf7a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-945dc5e1-85d0-465a-80c4-a446bd71d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-65c488e5-04c4-462a-961a-b4f7e3680aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-9d56b292-2532-4b56-8399-eddff78c1e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-0f4a055a-248c-4352-a033-268291d33b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-33813162-bc8d-4534-831c-75e857dadf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-395a9edc-9343-403f-8982-8de94635beb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169434-172.17.0.9-1598494486105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-2f88800a-e43e-4f98-8e28-33bd9f2cfa24,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-f8780ddb-81a3-4f13-8c1a-26503fb164d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-200371b2-27de-4ca0-8e1b-b33d42bb31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-81e573c1-3101-41b5-8122-510411af9549,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-fd781d97-23c3-48ae-914c-1c16cd99cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-0c20fb89-ec9b-46ec-a38b-573016247ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-2d90a0fc-3276-46c5-976f-761502742239,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-b9dab9fb-6082-4dcf-976e-fcfabdde65a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169434-172.17.0.9-1598494486105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-2f88800a-e43e-4f98-8e28-33bd9f2cfa24,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-f8780ddb-81a3-4f13-8c1a-26503fb164d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-200371b2-27de-4ca0-8e1b-b33d42bb31c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-81e573c1-3101-41b5-8122-510411af9549,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-fd781d97-23c3-48ae-914c-1c16cd99cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-0c20fb89-ec9b-46ec-a38b-573016247ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-2d90a0fc-3276-46c5-976f-761502742239,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-b9dab9fb-6082-4dcf-976e-fcfabdde65a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473222728-172.17.0.9-1598494665920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-004c79f7-206e-4298-827f-cf0a3744e5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-2c2fd018-c646-47b6-9840-ca58feac65c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b07b22ba-c95c-4aac-bc2f-0f667a13d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-2745e91b-7225-45e5-a19b-cc7d2749771a,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e1602aba-f1fb-4b6b-aaca-639f8ffd0550,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-01c51630-92ce-4e4a-af88-32c03bcfb453,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-af147c46-fc18-4fc8-9cc3-a78fcafd2699,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-57135508-9131-4c95-b958-f9a76b108d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473222728-172.17.0.9-1598494665920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-004c79f7-206e-4298-827f-cf0a3744e5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-2c2fd018-c646-47b6-9840-ca58feac65c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b07b22ba-c95c-4aac-bc2f-0f667a13d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-2745e91b-7225-45e5-a19b-cc7d2749771a,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e1602aba-f1fb-4b6b-aaca-639f8ffd0550,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-01c51630-92ce-4e4a-af88-32c03bcfb453,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-af147c46-fc18-4fc8-9cc3-a78fcafd2699,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-57135508-9131-4c95-b958-f9a76b108d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062490608-172.17.0.9-1598495315624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-7bff4bfb-4a59-4d3f-95d7-777362175e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-19532a04-e399-4a5f-8303-2562fd20e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-ac105dc2-f1e8-4c35-9414-2e8fffd656ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-a0985315-687a-420f-8d27-34da8574d609,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-9b59b0ed-2caf-481b-88e2-3c5874000166,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d901ddae-ab29-4038-96b9-2d4ab0f122f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-104ba47b-5607-48c2-bfef-a430319c4302,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-076f296f-e51e-4929-b62a-749400457f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062490608-172.17.0.9-1598495315624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-7bff4bfb-4a59-4d3f-95d7-777362175e97,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-19532a04-e399-4a5f-8303-2562fd20e3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-ac105dc2-f1e8-4c35-9414-2e8fffd656ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-a0985315-687a-420f-8d27-34da8574d609,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-9b59b0ed-2caf-481b-88e2-3c5874000166,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-d901ddae-ab29-4038-96b9-2d4ab0f122f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-104ba47b-5607-48c2-bfef-a430319c4302,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-076f296f-e51e-4929-b62a-749400457f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256525344-172.17.0.9-1598496344477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-5f489a2d-a1d7-4679-860e-51bf2e09bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-486be122-0520-4e1c-b702-c6d2758de431,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-3d0fffa1-3cd4-467b-833f-0ef93429eac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-3c36379b-ea7f-445d-addb-682353f587ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-35a702b0-9aea-4a5d-ab12-d48e9793abad,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b2652e60-f880-47f6-9c2a-999cc07ba086,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-b783be1b-064b-4a8f-81e7-57cad07e2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-3e9886ac-cb9f-4a04-9b92-6787c876d877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256525344-172.17.0.9-1598496344477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-5f489a2d-a1d7-4679-860e-51bf2e09bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-486be122-0520-4e1c-b702-c6d2758de431,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-3d0fffa1-3cd4-467b-833f-0ef93429eac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-3c36379b-ea7f-445d-addb-682353f587ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-35a702b0-9aea-4a5d-ab12-d48e9793abad,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b2652e60-f880-47f6-9c2a-999cc07ba086,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-b783be1b-064b-4a8f-81e7-57cad07e2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-3e9886ac-cb9f-4a04-9b92-6787c876d877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476573999-172.17.0.9-1598496744430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34424,DS-f3ca87d6-84c8-4b3b-b7e4-ae6d31e3162c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-dc959de4-dd25-409d-9e31-0be73a9c2754,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-7bb78a56-e9dd-4338-a626-b29fea80cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-a168cfaf-73df-44c0-8a26-2bb32f1af308,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-faaaf7a2-300a-46a1-b042-cf7e13d925ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-664ec57a-8052-41bf-920e-8e650aad4445,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-8e780dd9-80ac-4a99-b840-c851e053af54,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-2f352c56-b5a3-43fd-9a3b-b4edabb2f3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476573999-172.17.0.9-1598496744430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34424,DS-f3ca87d6-84c8-4b3b-b7e4-ae6d31e3162c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-dc959de4-dd25-409d-9e31-0be73a9c2754,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-7bb78a56-e9dd-4338-a626-b29fea80cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-a168cfaf-73df-44c0-8a26-2bb32f1af308,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-faaaf7a2-300a-46a1-b042-cf7e13d925ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-664ec57a-8052-41bf-920e-8e650aad4445,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-8e780dd9-80ac-4a99-b840-c851e053af54,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-2f352c56-b5a3-43fd-9a3b-b4edabb2f3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752266876-172.17.0.9-1598496961597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-09741e74-5d20-42b5-ad01-6e9c65468766,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-73cbe727-d36f-4c3a-bd6d-71f143764e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-c0207f93-0a6d-403b-aa2e-41d49b2b7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-4a802a56-9eab-430f-abfb-c64839137a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-8550ff9b-5195-4f4d-ba33-56922196c255,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-a446a438-83fb-4626-9eca-e3589a70f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-fccba65f-978b-4633-9001-0f3d774ac852,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-6b99cf11-78e8-4b51-8fa3-c0c2455dd10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752266876-172.17.0.9-1598496961597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39016,DS-09741e74-5d20-42b5-ad01-6e9c65468766,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-73cbe727-d36f-4c3a-bd6d-71f143764e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-c0207f93-0a6d-403b-aa2e-41d49b2b7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-4a802a56-9eab-430f-abfb-c64839137a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-8550ff9b-5195-4f4d-ba33-56922196c255,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-a446a438-83fb-4626-9eca-e3589a70f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-fccba65f-978b-4633-9001-0f3d774ac852,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-6b99cf11-78e8-4b51-8fa3-c0c2455dd10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836392271-172.17.0.9-1598497407875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-1e4bfcff-d78a-40cd-a802-326de545ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-3f963f6a-ab30-4486-a807-3da5753a9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-bf1dcd8d-9a41-4514-a4bb-db2d59234d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-5af1b1d1-8553-43e7-863b-4ea8049c8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9ea820a8-39bb-4190-ba52-910a3c526e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-52488820-0873-44c6-a070-44f92f35f273,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-2063d8c2-8945-48a0-9b07-27878c2ff95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-0d2fc531-00e6-4e8f-a1e1-a7e47ca09907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836392271-172.17.0.9-1598497407875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-1e4bfcff-d78a-40cd-a802-326de545ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-3f963f6a-ab30-4486-a807-3da5753a9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-bf1dcd8d-9a41-4514-a4bb-db2d59234d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-5af1b1d1-8553-43e7-863b-4ea8049c8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9ea820a8-39bb-4190-ba52-910a3c526e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-52488820-0873-44c6-a070-44f92f35f273,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-2063d8c2-8945-48a0-9b07-27878c2ff95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-0d2fc531-00e6-4e8f-a1e1-a7e47ca09907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147318284-172.17.0.9-1598497480443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37446,DS-b7fa53fa-e88b-44df-90bb-5ad0ffe10198,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-90d16506-ca59-4550-b38e-554996cd6b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-622a59ec-a351-4926-a9b9-3705dcf1ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-c88f8d0a-c202-45df-9873-3508c4629ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-2846299f-e738-443c-a662-e19b4af27bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-8db3a907-bbd8-43c8-bea4-d13dc0a69e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-0ac88c2b-48a1-479a-92aa-318b65d68544,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-8ec67808-3bd4-4145-8b30-6bfef1fd1861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147318284-172.17.0.9-1598497480443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37446,DS-b7fa53fa-e88b-44df-90bb-5ad0ffe10198,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-90d16506-ca59-4550-b38e-554996cd6b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-622a59ec-a351-4926-a9b9-3705dcf1ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-c88f8d0a-c202-45df-9873-3508c4629ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-2846299f-e738-443c-a662-e19b4af27bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-8db3a907-bbd8-43c8-bea4-d13dc0a69e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-0ac88c2b-48a1-479a-92aa-318b65d68544,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-8ec67808-3bd4-4145-8b30-6bfef1fd1861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028458635-172.17.0.9-1598498106960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-99b8a036-16af-46b6-b045-23a891a33d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-035ec067-ad5d-404e-be56-a44e1d7993bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-37f2a110-cfec-43cc-8988-548a01caf35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5957a485-79cb-4754-be3a-94b0c95a63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-f904950e-71fa-42c3-85ec-3456c7a9811d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f1e90c77-fc37-4c7d-9682-bb942a7af544,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-ea6608ab-a86a-4223-ad27-d5e32ff06f20,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-41b8fb95-a6dd-4c10-b338-ef86003b417a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028458635-172.17.0.9-1598498106960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-99b8a036-16af-46b6-b045-23a891a33d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-035ec067-ad5d-404e-be56-a44e1d7993bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-37f2a110-cfec-43cc-8988-548a01caf35f,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5957a485-79cb-4754-be3a-94b0c95a63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-f904950e-71fa-42c3-85ec-3456c7a9811d,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f1e90c77-fc37-4c7d-9682-bb942a7af544,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-ea6608ab-a86a-4223-ad27-d5e32ff06f20,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-41b8fb95-a6dd-4c10-b338-ef86003b417a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089748787-172.17.0.9-1598498179338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-c5c30822-e631-4308-83c8-0e7d0f8f18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-7cb425ef-3578-45fc-8808-620fc6edf0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-5368832c-3772-4f8f-84c6-0ae3d28f0503,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ad237072-ff3c-4f96-8cf5-3329364dfb02,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-57ae1178-1041-4316-8f3c-53284a40b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-293b6e45-d76c-4a13-91cd-7d7896f0fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-e5a58673-7781-4228-bb35-e011478d987c,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-7e871bc8-6b0b-4c0b-8459-3554503a0f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089748787-172.17.0.9-1598498179338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-c5c30822-e631-4308-83c8-0e7d0f8f18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-7cb425ef-3578-45fc-8808-620fc6edf0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-5368832c-3772-4f8f-84c6-0ae3d28f0503,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ad237072-ff3c-4f96-8cf5-3329364dfb02,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-57ae1178-1041-4316-8f3c-53284a40b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-293b6e45-d76c-4a13-91cd-7d7896f0fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-e5a58673-7781-4228-bb35-e011478d987c,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-7e871bc8-6b0b-4c0b-8459-3554503a0f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5502
