reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900178745-172.17.0.15-1598526880024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-7e5047ef-4aa5-4c88-804d-3c3c3233dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-b09c2f57-3989-4cd1-838a-b3f5dc4ea9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-53e396ae-d218-45bf-b724-d2201ef0f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-fbae8514-5c35-415d-8723-8d6f827a4876,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ce326f99-1174-425e-8c10-e0d001a32e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d14e2d2a-6133-40c1-a6c8-ce6678d95c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-f2dcb8d7-0d0c-4918-be21-9ed63c7d42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-b3c7f754-ed2f-44ee-acd8-4176a1769fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900178745-172.17.0.15-1598526880024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-7e5047ef-4aa5-4c88-804d-3c3c3233dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-b09c2f57-3989-4cd1-838a-b3f5dc4ea9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-53e396ae-d218-45bf-b724-d2201ef0f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-fbae8514-5c35-415d-8723-8d6f827a4876,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-ce326f99-1174-425e-8c10-e0d001a32e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-d14e2d2a-6133-40c1-a6c8-ce6678d95c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-f2dcb8d7-0d0c-4918-be21-9ed63c7d42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-b3c7f754-ed2f-44ee-acd8-4176a1769fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016626551-172.17.0.15-1598527346955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-8fe52554-5df2-4995-b309-84cace5c13e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-e766161e-664c-49d9-b444-062bc4b49f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-631379c7-0c8a-44fe-956d-777e069c4025,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-eb5322d9-db38-40fa-934f-65591dd21836,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a8a626d6-7dd8-4335-a951-d71f4c738374,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-1144b824-b681-46b0-8669-8a0418765722,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-09c1a195-be8d-493d-8d5c-ca4d9feeb321,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-ccd2589f-8820-4a18-9152-4535b1eaca2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016626551-172.17.0.15-1598527346955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-8fe52554-5df2-4995-b309-84cace5c13e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-e766161e-664c-49d9-b444-062bc4b49f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-631379c7-0c8a-44fe-956d-777e069c4025,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-eb5322d9-db38-40fa-934f-65591dd21836,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a8a626d6-7dd8-4335-a951-d71f4c738374,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-1144b824-b681-46b0-8669-8a0418765722,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-09c1a195-be8d-493d-8d5c-ca4d9feeb321,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-ccd2589f-8820-4a18-9152-4535b1eaca2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108806374-172.17.0.15-1598527424462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-d91b85eb-6b94-461e-b976-b1e14203cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-29281abc-f2ac-4f8d-8381-b73452ff5c26,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-ed034c00-7f50-45f7-a6e3-5f615fc936cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-e9b39279-2188-4b69-a3f9-12e5d11d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-2be1f6b1-9953-4ad7-b210-ae9289025c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-39530474-0da1-4a2c-a774-b478903391a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-f967ca11-08c8-4155-9f18-fc52a70116bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-2e3db100-4eba-4f4a-a6d4-9470996b4154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108806374-172.17.0.15-1598527424462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-d91b85eb-6b94-461e-b976-b1e14203cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-29281abc-f2ac-4f8d-8381-b73452ff5c26,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-ed034c00-7f50-45f7-a6e3-5f615fc936cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-e9b39279-2188-4b69-a3f9-12e5d11d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-2be1f6b1-9953-4ad7-b210-ae9289025c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-39530474-0da1-4a2c-a774-b478903391a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-f967ca11-08c8-4155-9f18-fc52a70116bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-2e3db100-4eba-4f4a-a6d4-9470996b4154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501735107-172.17.0.15-1598527504002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-ef54782d-5880-4bee-aea3-d291f1d6395c,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-94fc4fa5-d028-431a-b318-6941a4de2026,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6de1fa5e-db89-40a8-8e13-aca78124e966,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-e4c18799-ba29-44d5-ad0d-09ff9c2143a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-47749672-7209-4da7-9e2f-1206154bd47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-b42fc90e-06be-4fe4-9ba6-f169e682948b,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-099117c2-a2e1-4c42-af3b-1be436f7e279,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-87210304-8b1f-48b3-84b9-927a1a043485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501735107-172.17.0.15-1598527504002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-ef54782d-5880-4bee-aea3-d291f1d6395c,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-94fc4fa5-d028-431a-b318-6941a4de2026,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6de1fa5e-db89-40a8-8e13-aca78124e966,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-e4c18799-ba29-44d5-ad0d-09ff9c2143a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-47749672-7209-4da7-9e2f-1206154bd47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-b42fc90e-06be-4fe4-9ba6-f169e682948b,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-099117c2-a2e1-4c42-af3b-1be436f7e279,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-87210304-8b1f-48b3-84b9-927a1a043485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203141413-172.17.0.15-1598528409611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-fc059117-dc56-461f-8445-b971b986f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-aa88ab07-432d-470c-bfb2-ea2daccf237a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ffb0ce27-03c1-40aa-ba8c-cc4dc803c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-09d2566b-04b5-4c33-8bd7-d67db39946d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-911ea158-6dc7-4fbd-8dc2-911b2e6052fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-4a76b27e-6540-4723-895f-1b7243302d99,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-0e66d538-6af6-4e51-9b45-d9f910367869,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-97ad3c1a-65d5-4846-85b0-684e64bcee4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203141413-172.17.0.15-1598528409611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-fc059117-dc56-461f-8445-b971b986f5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-aa88ab07-432d-470c-bfb2-ea2daccf237a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ffb0ce27-03c1-40aa-ba8c-cc4dc803c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-09d2566b-04b5-4c33-8bd7-d67db39946d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-911ea158-6dc7-4fbd-8dc2-911b2e6052fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-4a76b27e-6540-4723-895f-1b7243302d99,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-0e66d538-6af6-4e51-9b45-d9f910367869,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-97ad3c1a-65d5-4846-85b0-684e64bcee4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270223344-172.17.0.15-1598528550333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-32a9180a-8fb0-451b-a2da-090a9f5692bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-ca81fca9-ff51-4ccf-a858-bf769b07d45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-3c541b5d-27f1-43e7-b580-398addaf847b,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-068b2cce-4466-4276-9aa7-35ef3041190e,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-c6e4a845-6a0d-4cf8-8f09-06a75b46f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-6801b565-9545-4b9d-b961-922affe1e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-27893197-e38d-4471-9200-e56bad4224a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-453c238a-657b-4cd4-aa0b-2aa60b685038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270223344-172.17.0.15-1598528550333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-32a9180a-8fb0-451b-a2da-090a9f5692bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-ca81fca9-ff51-4ccf-a858-bf769b07d45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-3c541b5d-27f1-43e7-b580-398addaf847b,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-068b2cce-4466-4276-9aa7-35ef3041190e,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-c6e4a845-6a0d-4cf8-8f09-06a75b46f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-6801b565-9545-4b9d-b961-922affe1e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-27893197-e38d-4471-9200-e56bad4224a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-453c238a-657b-4cd4-aa0b-2aa60b685038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119081045-172.17.0.15-1598528634887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-e81469eb-7f32-40f9-b505-e2ca921e5397,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-5a791f60-43f2-4068-ac3c-1274706f18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-65da6189-9751-4f38-93a6-02eb3b607842,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-2cc6dd53-8ff7-44de-9800-d772b62b4296,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-83c93cee-1e32-40b7-951f-b2018f176df0,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-0e529b7a-3f8c-4f4c-bd3b-06e944f48d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1adce2ff-735d-4660-9c03-7ac91e6fa5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6991e677-9f4e-4bff-9ae4-8476595b5706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119081045-172.17.0.15-1598528634887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-e81469eb-7f32-40f9-b505-e2ca921e5397,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-5a791f60-43f2-4068-ac3c-1274706f18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-65da6189-9751-4f38-93a6-02eb3b607842,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-2cc6dd53-8ff7-44de-9800-d772b62b4296,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-83c93cee-1e32-40b7-951f-b2018f176df0,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-0e529b7a-3f8c-4f4c-bd3b-06e944f48d27,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-1adce2ff-735d-4660-9c03-7ac91e6fa5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-6991e677-9f4e-4bff-9ae4-8476595b5706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930350292-172.17.0.15-1598528677403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-bcabc820-ffe3-47eb-93d7-6cfae10eba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c1ada115-9265-4c9f-bf03-595b54215743,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5259f8f0-be11-4ea4-8bc9-79eddf2c05b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-4ae7f3da-97f2-4483-999d-2571ef7a6410,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-859b1165-fdf8-4043-94e9-c10b1efa3c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-1c870106-ed56-4730-aac4-7a510ccf280a,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-c32574ec-0643-4493-ac52-08d0d19fe8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-648ad620-7650-4651-b7a6-5233b58a6c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930350292-172.17.0.15-1598528677403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38310,DS-bcabc820-ffe3-47eb-93d7-6cfae10eba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c1ada115-9265-4c9f-bf03-595b54215743,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5259f8f0-be11-4ea4-8bc9-79eddf2c05b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-4ae7f3da-97f2-4483-999d-2571ef7a6410,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-859b1165-fdf8-4043-94e9-c10b1efa3c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-1c870106-ed56-4730-aac4-7a510ccf280a,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-c32574ec-0643-4493-ac52-08d0d19fe8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-648ad620-7650-4651-b7a6-5233b58a6c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386659893-172.17.0.15-1598528833565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-7cf1210c-f4c2-4290-84e2-b6a69f879f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e70517fa-e850-4531-be24-03ff31b6df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-c941409c-f622-4a36-add2-d6bc9b18e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-91260bb8-5539-4c64-9697-e0e420305372,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-4c7c3cb8-c406-46a0-84cf-2b405b1b5766,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-53c83cf6-7e61-47bc-b7a0-9e607428a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-7b554cd2-7d90-4528-9cef-9eae2aa77e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-8550d2ab-5798-42bc-8f05-ea198bfa39ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386659893-172.17.0.15-1598528833565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-7cf1210c-f4c2-4290-84e2-b6a69f879f88,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e70517fa-e850-4531-be24-03ff31b6df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-c941409c-f622-4a36-add2-d6bc9b18e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-91260bb8-5539-4c64-9697-e0e420305372,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-4c7c3cb8-c406-46a0-84cf-2b405b1b5766,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-53c83cf6-7e61-47bc-b7a0-9e607428a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-7b554cd2-7d90-4528-9cef-9eae2aa77e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-8550d2ab-5798-42bc-8f05-ea198bfa39ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537787102-172.17.0.15-1598529606408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-8252dfea-2361-4e93-a937-105a9f05b88f,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-0f818b47-2dde-4390-b2b7-a31015672c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-29e94ba9-d9f6-474a-8d13-814a5e3cf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-59d29a5f-eff8-48e9-953e-aac6304848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-cf2ded1e-fab7-4d2b-a77f-0f5c2d034cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-8a730e51-1287-4745-bf91-24ac563869be,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-d24c53dc-ace5-4e48-a7b4-312845056bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-40f16b4e-d024-45aa-93a7-5dde70827a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537787102-172.17.0.15-1598529606408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-8252dfea-2361-4e93-a937-105a9f05b88f,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-0f818b47-2dde-4390-b2b7-a31015672c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-29e94ba9-d9f6-474a-8d13-814a5e3cf2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-59d29a5f-eff8-48e9-953e-aac6304848a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-cf2ded1e-fab7-4d2b-a77f-0f5c2d034cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-8a730e51-1287-4745-bf91-24ac563869be,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-d24c53dc-ace5-4e48-a7b4-312845056bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-40f16b4e-d024-45aa-93a7-5dde70827a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826560004-172.17.0.15-1598529640649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-b1a701a8-195b-4ffe-b291-13703d467ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-ed5fca21-db1c-44cc-81be-ad00bd4a7355,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9b4b0af9-42f9-4c87-949d-fff4a51dc145,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b3acc883-482e-42e4-859f-93f1c0cd1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-3f2c7c8a-b618-4633-9ff2-e97568765cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-f7950a00-1cc2-46f6-81d2-933090bed240,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-06cb62fb-76af-412a-8c5c-4859bf3bb181,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-5093e2e2-628f-4f62-bd8e-c50be61a48cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826560004-172.17.0.15-1598529640649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-b1a701a8-195b-4ffe-b291-13703d467ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-ed5fca21-db1c-44cc-81be-ad00bd4a7355,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9b4b0af9-42f9-4c87-949d-fff4a51dc145,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b3acc883-482e-42e4-859f-93f1c0cd1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-3f2c7c8a-b618-4633-9ff2-e97568765cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-f7950a00-1cc2-46f6-81d2-933090bed240,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-06cb62fb-76af-412a-8c5c-4859bf3bb181,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-5093e2e2-628f-4f62-bd8e-c50be61a48cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077868052-172.17.0.15-1598529741451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-1d1bb353-8966-49e8-8c33-ed7b2166520e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2e0af752-4586-4592-8653-af3ad628e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-3492abbb-e2e5-42a2-8a7d-418e58069096,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-c19bb9f9-3e52-4d8e-9b9e-1c1259659c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-d0d7f2ed-f9e0-43fa-bc9c-7f39ecaf6786,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2e94df76-48d1-4c61-b13a-37ab7354e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-30145ca9-5cff-48b4-9dfd-97e858e0e678,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d138bcce-0d6e-430d-80c5-abcfa8e1a99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077868052-172.17.0.15-1598529741451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-1d1bb353-8966-49e8-8c33-ed7b2166520e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2e0af752-4586-4592-8653-af3ad628e1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-3492abbb-e2e5-42a2-8a7d-418e58069096,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-c19bb9f9-3e52-4d8e-9b9e-1c1259659c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-d0d7f2ed-f9e0-43fa-bc9c-7f39ecaf6786,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-2e94df76-48d1-4c61-b13a-37ab7354e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-30145ca9-5cff-48b4-9dfd-97e858e0e678,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d138bcce-0d6e-430d-80c5-abcfa8e1a99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150977422-172.17.0.15-1598530019545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41895,DS-d56ed875-099e-414c-9b7b-967b71e861f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f62756a1-fa5c-426e-9c9b-e107758a1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-b34c45bd-e264-4a41-840d-5d7e31d9830d,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-cb10beaf-cbd3-4815-80e9-08876574e097,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d14a70a1-9886-446b-a793-62e7cf75c123,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-791413d2-2982-4853-8d0d-c6dd46091b36,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-ea2204a5-5f0b-4a74-8cf6-cfe027b4fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-c95a717c-ae14-4734-9f65-4ff7be45de79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150977422-172.17.0.15-1598530019545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41895,DS-d56ed875-099e-414c-9b7b-967b71e861f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f62756a1-fa5c-426e-9c9b-e107758a1b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-b34c45bd-e264-4a41-840d-5d7e31d9830d,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-cb10beaf-cbd3-4815-80e9-08876574e097,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d14a70a1-9886-446b-a793-62e7cf75c123,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-791413d2-2982-4853-8d0d-c6dd46091b36,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-ea2204a5-5f0b-4a74-8cf6-cfe027b4fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-c95a717c-ae14-4734-9f65-4ff7be45de79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512207779-172.17.0.15-1598530257736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-b69cfc0a-1af7-4329-a3db-c41afb539618,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-2a65db29-9cbd-4b47-86d4-fd9dcbb64731,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-795afa23-4217-436d-ada8-ef5b557654aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-57b9209a-838a-4c5e-8b55-d7eaf19d01a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-40fa502e-97df-4fef-851e-ea3a4af91743,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-c0a7016e-0ec5-40e2-8bc9-03baba36ed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-352a69f7-ff00-4a0a-81dd-68257636664c,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-d7b13b63-a083-43e3-a4af-8cbffc3d2308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512207779-172.17.0.15-1598530257736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-b69cfc0a-1af7-4329-a3db-c41afb539618,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-2a65db29-9cbd-4b47-86d4-fd9dcbb64731,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-795afa23-4217-436d-ada8-ef5b557654aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-57b9209a-838a-4c5e-8b55-d7eaf19d01a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-40fa502e-97df-4fef-851e-ea3a4af91743,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-c0a7016e-0ec5-40e2-8bc9-03baba36ed3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-352a69f7-ff00-4a0a-81dd-68257636664c,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-d7b13b63-a083-43e3-a4af-8cbffc3d2308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317827941-172.17.0.15-1598530416463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-523eacc5-0a4a-406b-9375-4171273d21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-121e5217-4dd6-4c29-b90f-ecd9cf5563c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-6fe7426c-0d23-4a40-ab5d-97a9100c1717,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-672f359e-44ea-476b-9157-e943cee83529,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-10e7d012-c781-4e6d-9042-f54ddb2c63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-030a2a0d-6afd-48d5-afba-5e741882bb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-efffd785-df95-467f-8dca-4243abb7984c,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-2bb61a84-0ed9-4916-ba4c-5097a281cdb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-317827941-172.17.0.15-1598530416463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-523eacc5-0a4a-406b-9375-4171273d21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-121e5217-4dd6-4c29-b90f-ecd9cf5563c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-6fe7426c-0d23-4a40-ab5d-97a9100c1717,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-672f359e-44ea-476b-9157-e943cee83529,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-10e7d012-c781-4e6d-9042-f54ddb2c63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-030a2a0d-6afd-48d5-afba-5e741882bb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-efffd785-df95-467f-8dca-4243abb7984c,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-2bb61a84-0ed9-4916-ba4c-5097a281cdb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971780375-172.17.0.15-1598530614876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-518ae49d-f023-442d-8220-00c1937abea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b65550ee-c083-453c-b7a9-3e8e3b4d7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-7d3be7be-88ea-491b-acf4-80e9e885d6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-af248fe6-ae36-4fb9-9e18-09dffc4b2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-03c96622-823b-46e1-96d3-20a1bf9ef49c,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-54a7126b-32dc-4b4e-b266-f29798727719,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-a1d08991-89d0-40e8-8ded-60fa26a225cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-83bfe2d2-2a4b-411e-b772-f971218db326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971780375-172.17.0.15-1598530614876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-518ae49d-f023-442d-8220-00c1937abea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b65550ee-c083-453c-b7a9-3e8e3b4d7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-7d3be7be-88ea-491b-acf4-80e9e885d6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-af248fe6-ae36-4fb9-9e18-09dffc4b2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-03c96622-823b-46e1-96d3-20a1bf9ef49c,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-54a7126b-32dc-4b4e-b266-f29798727719,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-a1d08991-89d0-40e8-8ded-60fa26a225cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-83bfe2d2-2a4b-411e-b772-f971218db326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614874822-172.17.0.15-1598530709013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-f323f728-fcb7-4ddc-a2ef-da4ef4d88188,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-073057a5-e194-480c-8259-9084e9dc963a,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-3c07ea1e-a635-4cae-90e2-7e50baefa1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-41a766ab-0323-48ae-99c7-05f8bea9548d,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-cbd9595c-873a-407a-8690-282a90e757ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-54dd1511-9737-48f3-8a1e-d3946cdfa151,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-51d5d02d-a2f7-4e26-ab4b-702447a3fc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f50345e3-cabd-41a7-8ca0-ba0ec565e404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614874822-172.17.0.15-1598530709013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-f323f728-fcb7-4ddc-a2ef-da4ef4d88188,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-073057a5-e194-480c-8259-9084e9dc963a,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-3c07ea1e-a635-4cae-90e2-7e50baefa1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-41a766ab-0323-48ae-99c7-05f8bea9548d,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-cbd9595c-873a-407a-8690-282a90e757ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-54dd1511-9737-48f3-8a1e-d3946cdfa151,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-51d5d02d-a2f7-4e26-ab4b-702447a3fc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f50345e3-cabd-41a7-8ca0-ba0ec565e404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199061254-172.17.0.15-1598531000767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-4d11ff09-dfb3-47d6-881b-fbe3350f98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-4dde55ce-129a-4373-b1cb-9d89609a1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-cdc4731d-e82d-407a-bb54-2edb815634bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2d1f8418-5099-4a0e-afa3-765bfae981ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-7d99db99-f7c0-4c54-81c6-fa7b63bd0891,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1bb5a45d-cb9e-423f-bd04-691b0ae3e501,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-a4b2d82a-a13f-492d-85fc-32dfc1c4508c,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-807bc917-c1d2-4ed1-a620-ab6f1d25c359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199061254-172.17.0.15-1598531000767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-4d11ff09-dfb3-47d6-881b-fbe3350f98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-4dde55ce-129a-4373-b1cb-9d89609a1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-cdc4731d-e82d-407a-bb54-2edb815634bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2d1f8418-5099-4a0e-afa3-765bfae981ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-7d99db99-f7c0-4c54-81c6-fa7b63bd0891,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-1bb5a45d-cb9e-423f-bd04-691b0ae3e501,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-a4b2d82a-a13f-492d-85fc-32dfc1c4508c,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-807bc917-c1d2-4ed1-a620-ab6f1d25c359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673051830-172.17.0.15-1598531071020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-ad2f1c82-c3eb-4146-8d87-84a7fe3e411e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-b0211b8c-48ff-49a1-a041-b99cb899f835,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-75b86373-628f-4cff-a5e2-38dc9d295952,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-e99958b5-e13f-421a-84e9-f171c4a00ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-a9e95ecb-0289-4a84-94eb-1f6a54d60bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-411cacf9-b820-41c7-beac-a9b2bf7ec64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-039513a7-b9ad-4b5d-acd3-5c0327438830,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-bfe4a6c4-6f3a-4f57-89b9-0e897cea7b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673051830-172.17.0.15-1598531071020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-ad2f1c82-c3eb-4146-8d87-84a7fe3e411e,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-b0211b8c-48ff-49a1-a041-b99cb899f835,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-75b86373-628f-4cff-a5e2-38dc9d295952,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-e99958b5-e13f-421a-84e9-f171c4a00ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-a9e95ecb-0289-4a84-94eb-1f6a54d60bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-411cacf9-b820-41c7-beac-a9b2bf7ec64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-039513a7-b9ad-4b5d-acd3-5c0327438830,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-bfe4a6c4-6f3a-4f57-89b9-0e897cea7b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250231370-172.17.0.15-1598531694956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-a7763b02-a73b-4202-be62-40d9e18c0a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-afaae44a-a92e-4efe-ae60-bf3e886035ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-7a054256-3b2a-4e40-9fa2-6db62cd4f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-3362d198-57e6-4728-a5d4-cb9c29da90a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-89348d1f-e0ea-4a03-980c-0f92a5ed1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-aa088c95-a920-41cd-b23d-89123144bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-5032a446-a87e-4ca1-8912-477419b4b729,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-5d6bda20-7b9e-42af-8e65-f0fd67db1a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250231370-172.17.0.15-1598531694956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-a7763b02-a73b-4202-be62-40d9e18c0a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-afaae44a-a92e-4efe-ae60-bf3e886035ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-7a054256-3b2a-4e40-9fa2-6db62cd4f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-3362d198-57e6-4728-a5d4-cb9c29da90a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-89348d1f-e0ea-4a03-980c-0f92a5ed1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-aa088c95-a920-41cd-b23d-89123144bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-5032a446-a87e-4ca1-8912-477419b4b729,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-5d6bda20-7b9e-42af-8e65-f0fd67db1a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5241
