reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408875969-172.17.0.4-1598584242076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-8a024562-b54b-4706-a148-d21103145585,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-af79d9b2-bfe4-46cf-aec4-459f639af724,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-e48f27f8-4fda-4487-a58d-4616fe4c57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-9ce00ebc-5be6-47dc-84f5-84c19a7eb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-0af2cfa9-f46b-4b5d-8cf4-14f67ca9675e,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-70f34ffc-a687-4c94-ab59-9526593ceec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-38777782-d71e-445b-9b48-7b2b1a74bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-8ca39fd2-7fe2-4866-9a46-cafed8d7c58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408875969-172.17.0.4-1598584242076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-8a024562-b54b-4706-a148-d21103145585,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-af79d9b2-bfe4-46cf-aec4-459f639af724,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-e48f27f8-4fda-4487-a58d-4616fe4c57d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-9ce00ebc-5be6-47dc-84f5-84c19a7eb3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-0af2cfa9-f46b-4b5d-8cf4-14f67ca9675e,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-70f34ffc-a687-4c94-ab59-9526593ceec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-38777782-d71e-445b-9b48-7b2b1a74bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-8ca39fd2-7fe2-4866-9a46-cafed8d7c58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445934330-172.17.0.4-1598584626862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-5123e0a4-a895-4b57-913b-11e15035e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-38de0042-dcfb-4670-8710-06f8681ca23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-8136963b-9f63-4550-80a6-de9512fa9e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80210550-ef75-4f79-b304-e37b0f84aa89,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-2fa2073d-5457-4a8d-920b-64af1d18142f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-a727cb81-78d2-47eb-a8b9-125325f1e474,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-03c8f736-3013-48b5-9268-3aa6ddd3adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-18eb5a84-ca27-4371-91ae-ab497c7cc295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445934330-172.17.0.4-1598584626862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44989,DS-5123e0a4-a895-4b57-913b-11e15035e80b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-38de0042-dcfb-4670-8710-06f8681ca23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-8136963b-9f63-4550-80a6-de9512fa9e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-80210550-ef75-4f79-b304-e37b0f84aa89,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-2fa2073d-5457-4a8d-920b-64af1d18142f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-a727cb81-78d2-47eb-a8b9-125325f1e474,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-03c8f736-3013-48b5-9268-3aa6ddd3adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-18eb5a84-ca27-4371-91ae-ab497c7cc295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777107284-172.17.0.4-1598584690171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-256a5e98-3f97-4d8f-bb07-3d662ad8a565,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3c6e8ff1-893d-49f5-a300-7288b8cbf5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-f5bffcd3-787a-46bf-bb98-b1e7a06bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-12954f68-2245-4f24-a6df-79ef30736a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-47bf11c8-4095-4f22-8b1f-738d82bebf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-28a62755-1dcc-448f-9443-42f8fda2e248,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-47934a6a-7791-4395-bcc9-213fa757b466,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-126d8211-dd7d-4b29-b7c6-3b90e9550e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777107284-172.17.0.4-1598584690171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-256a5e98-3f97-4d8f-bb07-3d662ad8a565,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3c6e8ff1-893d-49f5-a300-7288b8cbf5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-f5bffcd3-787a-46bf-bb98-b1e7a06bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-12954f68-2245-4f24-a6df-79ef30736a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-47bf11c8-4095-4f22-8b1f-738d82bebf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-28a62755-1dcc-448f-9443-42f8fda2e248,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-47934a6a-7791-4395-bcc9-213fa757b466,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-126d8211-dd7d-4b29-b7c6-3b90e9550e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916852013-172.17.0.4-1598585216557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45035,DS-755373df-ef90-48b4-8729-cc24a0c6a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-383eecb5-8603-42d9-96b7-95d33e9b22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-9b857337-4796-4cb3-85ea-b2b4a68b0eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-ce81be59-6342-4cc6-92be-9a15f3720b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f24c8eeb-ead5-4c69-80d4-8ec54177d948,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-609159e9-eb19-4a94-b7f7-319e8933b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-77c368f4-e96d-4569-83d9-af836b32f39f,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-403ccfc4-26dd-4ee9-979b-d8e88292e30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916852013-172.17.0.4-1598585216557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45035,DS-755373df-ef90-48b4-8729-cc24a0c6a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-383eecb5-8603-42d9-96b7-95d33e9b22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-9b857337-4796-4cb3-85ea-b2b4a68b0eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-ce81be59-6342-4cc6-92be-9a15f3720b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-f24c8eeb-ead5-4c69-80d4-8ec54177d948,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-609159e9-eb19-4a94-b7f7-319e8933b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-77c368f4-e96d-4569-83d9-af836b32f39f,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-403ccfc4-26dd-4ee9-979b-d8e88292e30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689379663-172.17.0.4-1598585292496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-50217523-7b24-4a9f-9233-2b0058ca607d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-8bf03d34-69b4-4e78-b183-4a78a1888f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3f3b252f-479d-476b-8e97-c0a63b48f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0871771b-7e42-46c2-9df2-f4bbb724d443,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-fa738a60-1ace-4788-8f71-4963a191bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-470f95c1-a3fb-463e-bd2c-8a5cbfe9b19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-6cd6924d-ce6c-4dd3-bedf-f7ef20f91347,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-209a093d-933e-4a85-90f2-8e6f48c510bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689379663-172.17.0.4-1598585292496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-50217523-7b24-4a9f-9233-2b0058ca607d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-8bf03d34-69b4-4e78-b183-4a78a1888f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3f3b252f-479d-476b-8e97-c0a63b48f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0871771b-7e42-46c2-9df2-f4bbb724d443,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-fa738a60-1ace-4788-8f71-4963a191bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-470f95c1-a3fb-463e-bd2c-8a5cbfe9b19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-6cd6924d-ce6c-4dd3-bedf-f7ef20f91347,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-209a093d-933e-4a85-90f2-8e6f48c510bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822988530-172.17.0.4-1598585394284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-85b3651f-5afb-4851-833f-d71c335fde8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-20faff0b-6ed9-4298-8f0d-f680a58e533b,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-748c9519-598a-41db-a441-c27f2fce3782,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-d4cf545f-5e3d-4c7f-b338-f020bc4ee06d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-4d02198a-1d5b-415b-a57a-e971bd21a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-97f1e5c6-7ba5-4a93-8bcd-e2db1fb88c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-f779df3a-b8f0-49da-96ed-fd6611c4f3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-359707c6-d4e1-44e8-9e6d-50be75fc9df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822988530-172.17.0.4-1598585394284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-85b3651f-5afb-4851-833f-d71c335fde8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-20faff0b-6ed9-4298-8f0d-f680a58e533b,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-748c9519-598a-41db-a441-c27f2fce3782,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-d4cf545f-5e3d-4c7f-b338-f020bc4ee06d,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-4d02198a-1d5b-415b-a57a-e971bd21a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-97f1e5c6-7ba5-4a93-8bcd-e2db1fb88c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-f779df3a-b8f0-49da-96ed-fd6611c4f3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-359707c6-d4e1-44e8-9e6d-50be75fc9df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364022737-172.17.0.4-1598585517107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32975,DS-08ee717e-9fad-4dd2-a197-614a79d0beff,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-05de1584-4469-4817-8a9d-c0b63cecd515,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-92f33b7a-58ee-446f-aae0-f0e3c7efe306,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-524df8ca-d798-44c0-b80f-51f7f1172fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-12a55dd7-2ac3-4525-b538-2b5bcdeffa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-087c4e5d-720b-4058-a3cb-2403006dce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-3e4e70ae-f9da-439d-93ca-607115a99e99,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-60f1163a-86fe-4e58-aaca-930f19acd725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364022737-172.17.0.4-1598585517107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32975,DS-08ee717e-9fad-4dd2-a197-614a79d0beff,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-05de1584-4469-4817-8a9d-c0b63cecd515,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-92f33b7a-58ee-446f-aae0-f0e3c7efe306,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-524df8ca-d798-44c0-b80f-51f7f1172fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-12a55dd7-2ac3-4525-b538-2b5bcdeffa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-087c4e5d-720b-4058-a3cb-2403006dce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-3e4e70ae-f9da-439d-93ca-607115a99e99,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-60f1163a-86fe-4e58-aaca-930f19acd725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119019917-172.17.0.4-1598585650709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-18f9477c-f349-4f55-a86f-964907d2bdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-dd8c5cd4-3da5-43fa-b141-631d956fb5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-cb795b49-4bc4-4947-804c-7aaab1def5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-9a6d5285-cb5a-40c8-ab38-aadd5a703ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b2a589b2-f8c3-4118-96fd-3562a529219c,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-cc6e8d0f-7c24-4918-8873-223e8d6bd646,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-8cfdc1c6-89c9-4a43-a813-1efb755c3408,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-2e6ab147-b5c3-491b-810e-d7ed47d0865c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119019917-172.17.0.4-1598585650709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44995,DS-18f9477c-f349-4f55-a86f-964907d2bdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-dd8c5cd4-3da5-43fa-b141-631d956fb5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-cb795b49-4bc4-4947-804c-7aaab1def5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-9a6d5285-cb5a-40c8-ab38-aadd5a703ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b2a589b2-f8c3-4118-96fd-3562a529219c,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-cc6e8d0f-7c24-4918-8873-223e8d6bd646,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-8cfdc1c6-89c9-4a43-a813-1efb755c3408,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-2e6ab147-b5c3-491b-810e-d7ed47d0865c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434979166-172.17.0.4-1598585760228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-b1c54eb3-afd7-44eb-919d-7deab2a0275f,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-d4b1ffc0-95c6-4e08-be10-55759de0cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-b349336a-9c94-4fea-80c8-9cf36d514721,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-62172892-64bc-4872-a88c-49450ecc9fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-d633c9d7-19b6-4899-86e7-3449f88f1e64,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-0f69e7ea-99c8-4751-bce7-aa7402c30083,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d7c1d74d-d9ce-4191-a028-40efe4e89719,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-55f90d72-43fe-49b8-a887-c035e833120b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434979166-172.17.0.4-1598585760228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44708,DS-b1c54eb3-afd7-44eb-919d-7deab2a0275f,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-d4b1ffc0-95c6-4e08-be10-55759de0cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-b349336a-9c94-4fea-80c8-9cf36d514721,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-62172892-64bc-4872-a88c-49450ecc9fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-d633c9d7-19b6-4899-86e7-3449f88f1e64,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-0f69e7ea-99c8-4751-bce7-aa7402c30083,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d7c1d74d-d9ce-4191-a028-40efe4e89719,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-55f90d72-43fe-49b8-a887-c035e833120b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679284522-172.17.0.4-1598585796447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44595,DS-9238f17a-17e5-4517-b68f-a5ebf27eb790,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-01c9de11-209a-4139-89e5-93b8cc04b075,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-76a0a340-02ae-42b4-bb24-9c98630a782b,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-f664b05c-f54d-4b7e-b757-242f1effec76,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1967439f-b3f5-402a-93ee-1b9c33c7ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-03cf4261-5707-473b-8e2a-c4ca3a8c5057,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-213113b0-8595-44fb-8b0a-973ad2c45a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-d452c83b-9c0b-4c71-a4ef-a9861a5663b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679284522-172.17.0.4-1598585796447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44595,DS-9238f17a-17e5-4517-b68f-a5ebf27eb790,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-01c9de11-209a-4139-89e5-93b8cc04b075,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-76a0a340-02ae-42b4-bb24-9c98630a782b,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-f664b05c-f54d-4b7e-b757-242f1effec76,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1967439f-b3f5-402a-93ee-1b9c33c7ce83,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-03cf4261-5707-473b-8e2a-c4ca3a8c5057,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-213113b0-8595-44fb-8b0a-973ad2c45a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-d452c83b-9c0b-4c71-a4ef-a9861a5663b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588804934-172.17.0.4-1598585866366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-87a06209-0e20-4abc-bb2f-e52a7a77c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a3653be3-31dc-4ae9-a2f9-f7fbed04afaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-91f0f010-5d3e-446b-a9b3-d88044f6bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-75c695d2-0655-4637-a77e-51f73490d100,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9fc25ccf-2ac0-421f-9ec4-51db41cb5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-d273c637-12b1-4bb8-9f64-17838883947d,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0a8abdaf-ab0f-4f61-b574-181774a6a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8a9760d7-ef84-4776-94d1-a611f9e287f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588804934-172.17.0.4-1598585866366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38370,DS-87a06209-0e20-4abc-bb2f-e52a7a77c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a3653be3-31dc-4ae9-a2f9-f7fbed04afaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-91f0f010-5d3e-446b-a9b3-d88044f6bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-75c695d2-0655-4637-a77e-51f73490d100,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-9fc25ccf-2ac0-421f-9ec4-51db41cb5e23,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-d273c637-12b1-4bb8-9f64-17838883947d,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-0a8abdaf-ab0f-4f61-b574-181774a6a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8a9760d7-ef84-4776-94d1-a611f9e287f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567117990-172.17.0.4-1598585897414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-1c3f583a-0252-47a8-a795-857145b789c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-5e8ee7f9-6e11-4252-9616-13cfb06682c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-2fc1b918-25ed-4fc7-a2f9-bfbb4b22e009,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-954fcacb-12ac-4f62-9828-91de79117237,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-327edc83-f8cd-41e8-bf39-43afd4e63678,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-ba7f0216-5dcf-4511-98f3-fab60120ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0849cb6a-e091-45d6-a413-44321d78b7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-e1e89044-8387-4bfb-a651-9cba401b5cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567117990-172.17.0.4-1598585897414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41365,DS-1c3f583a-0252-47a8-a795-857145b789c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-5e8ee7f9-6e11-4252-9616-13cfb06682c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-2fc1b918-25ed-4fc7-a2f9-bfbb4b22e009,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-954fcacb-12ac-4f62-9828-91de79117237,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-327edc83-f8cd-41e8-bf39-43afd4e63678,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-ba7f0216-5dcf-4511-98f3-fab60120ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0849cb6a-e091-45d6-a413-44321d78b7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-e1e89044-8387-4bfb-a651-9cba401b5cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949376893-172.17.0.4-1598585935703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-4d09d678-74f8-412b-b141-c30ece5b0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-045c5337-a888-433c-a59d-7191f8f4cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-fbc27d5f-3ec1-44b9-a25c-6d5cc22290a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c9052513-85a8-48ce-b6e0-cff9f9bbd4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-40fa3d9d-e271-456c-80a1-efbab6850ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-7ecc276e-d871-4263-aae6-a0c6b87848b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-317dffa3-c320-4b6b-9760-4f651379ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-f67c792b-2593-4ac8-8d9e-9e2e08895519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949376893-172.17.0.4-1598585935703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-4d09d678-74f8-412b-b141-c30ece5b0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-045c5337-a888-433c-a59d-7191f8f4cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-fbc27d5f-3ec1-44b9-a25c-6d5cc22290a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-c9052513-85a8-48ce-b6e0-cff9f9bbd4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-40fa3d9d-e271-456c-80a1-efbab6850ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-7ecc276e-d871-4263-aae6-a0c6b87848b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-317dffa3-c320-4b6b-9760-4f651379ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-f67c792b-2593-4ac8-8d9e-9e2e08895519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460498457-172.17.0.4-1598585970319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-87ae822b-2122-4c9f-b176-06130f9d28fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-4a27639d-3bc6-487d-ab45-8a7fdf83990b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-1682dfde-51a9-4405-b8b2-fc25a7eb79ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b903d4ed-5ba6-4de0-a228-a60d85052232,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-096bf3ad-7e08-40db-8940-6304ff0b7b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ecc1a223-7ae3-4c2a-80ce-41d053a4a978,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-db9264c5-934c-4728-b0fc-0570dd87075c,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-ebf27b53-9e42-469c-87db-fa7ae95a25a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460498457-172.17.0.4-1598585970319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-87ae822b-2122-4c9f-b176-06130f9d28fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-4a27639d-3bc6-487d-ab45-8a7fdf83990b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-1682dfde-51a9-4405-b8b2-fc25a7eb79ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-b903d4ed-5ba6-4de0-a228-a60d85052232,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-096bf3ad-7e08-40db-8940-6304ff0b7b51,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ecc1a223-7ae3-4c2a-80ce-41d053a4a978,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-db9264c5-934c-4728-b0fc-0570dd87075c,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-ebf27b53-9e42-469c-87db-fa7ae95a25a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469831975-172.17.0.4-1598586003118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-025d9359-9b13-4a06-b964-55b8ae5e181f,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-89be72d3-654d-4722-a438-6942eb9703c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-1adc8dbe-0243-4667-8e8c-c8f74a0b8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7ef717d6-dd40-4b18-ae34-a485225d07d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-d9457a7f-b51a-4481-a78e-af2f3a5e8647,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-d808a36f-e8a5-4120-8c84-b92a01e34792,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-2d393a6c-4df6-4c2c-87bf-b9905358746b,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-6862bea3-ac38-4669-b213-bc6d1b0cfe74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469831975-172.17.0.4-1598586003118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-025d9359-9b13-4a06-b964-55b8ae5e181f,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-89be72d3-654d-4722-a438-6942eb9703c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-1adc8dbe-0243-4667-8e8c-c8f74a0b8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7ef717d6-dd40-4b18-ae34-a485225d07d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-d9457a7f-b51a-4481-a78e-af2f3a5e8647,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-d808a36f-e8a5-4120-8c84-b92a01e34792,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-2d393a6c-4df6-4c2c-87bf-b9905358746b,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-6862bea3-ac38-4669-b213-bc6d1b0cfe74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608184965-172.17.0.4-1598586265084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-b9ebada2-3060-4c9c-b647-d5c83177adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-87160521-e63d-4472-ada5-3240f49246ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-a4b78b32-30df-4f6b-87f5-b405aa9ae21e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-3b891868-94e8-4cca-875e-aa92d4f7ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-1475a2b1-86cb-4077-a254-50821ac2a666,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4694d36e-f4db-4bd9-b294-1f184b149063,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-02ebef32-268a-4d19-b696-fbc262626f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-a5ddf8fa-5a3b-44fa-bc0e-050fc25894bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608184965-172.17.0.4-1598586265084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42283,DS-b9ebada2-3060-4c9c-b647-d5c83177adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-87160521-e63d-4472-ada5-3240f49246ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-a4b78b32-30df-4f6b-87f5-b405aa9ae21e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-3b891868-94e8-4cca-875e-aa92d4f7ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-1475a2b1-86cb-4077-a254-50821ac2a666,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4694d36e-f4db-4bd9-b294-1f184b149063,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-02ebef32-268a-4d19-b696-fbc262626f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-a5ddf8fa-5a3b-44fa-bc0e-050fc25894bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150442196-172.17.0.4-1598586338156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-f7a31000-386b-48f9-9cce-b5b24f1f5d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-a1759a1d-1eae-45e1-870d-21eefe078004,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-7d868b60-b963-4978-827e-320b25f6c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-6972a088-7dbb-4b4b-9e12-1312daeb29e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6faba103-70ef-4e95-b51c-770e43ddb26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0dfbcc2d-978f-4594-85f9-f77953776852,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-30196577-a39c-41a3-a880-6aa32b4c40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-710c471a-4e13-4fe6-80f6-367ae7e0611e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150442196-172.17.0.4-1598586338156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-f7a31000-386b-48f9-9cce-b5b24f1f5d58,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-a1759a1d-1eae-45e1-870d-21eefe078004,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-7d868b60-b963-4978-827e-320b25f6c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-6972a088-7dbb-4b4b-9e12-1312daeb29e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6faba103-70ef-4e95-b51c-770e43ddb26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0dfbcc2d-978f-4594-85f9-f77953776852,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-30196577-a39c-41a3-a880-6aa32b4c40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-710c471a-4e13-4fe6-80f6-367ae7e0611e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344441304-172.17.0.4-1598586506839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-cd85258a-e0f4-412c-b3cb-86fa8bdbe7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-cd86e837-2e3c-44bc-a712-95a590762227,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-41da9ecc-c454-4860-b204-6af95a82f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7a6236da-41eb-4443-90a6-7a10662a735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-b36622d2-881d-43ed-ac35-7977cade5be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-a0a47221-440d-40fe-b7c0-ec7ea64b170f,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-af7620bd-b9e1-42fa-90e6-126f658f9689,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-7296dc2c-c7cc-4ecd-937c-16d2f253175e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344441304-172.17.0.4-1598586506839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-cd85258a-e0f4-412c-b3cb-86fa8bdbe7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-cd86e837-2e3c-44bc-a712-95a590762227,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-41da9ecc-c454-4860-b204-6af95a82f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-7a6236da-41eb-4443-90a6-7a10662a735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-b36622d2-881d-43ed-ac35-7977cade5be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-a0a47221-440d-40fe-b7c0-ec7ea64b170f,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-af7620bd-b9e1-42fa-90e6-126f658f9689,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-7296dc2c-c7cc-4ecd-937c-16d2f253175e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297290275-172.17.0.4-1598586611937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-318f4b06-27be-4811-a3bb-74ba07fbfa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d4aecb5b-687b-4b1d-b2bf-92f63b7deb92,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-2e4c03ed-0b05-4c7a-ae0e-6e91a96be45a,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-5e0efa4a-9597-4c4c-ac8f-1ecee929fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b4f076f3-c25c-4ddc-968a-67d739e27f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-da4ba3aa-5120-45e5-849b-863c96161800,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-7bffa72e-6c32-4682-90d8-18b70738aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-6dfd1ee9-e558-4d38-8d9e-bc6cad7287b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297290275-172.17.0.4-1598586611937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-318f4b06-27be-4811-a3bb-74ba07fbfa66,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d4aecb5b-687b-4b1d-b2bf-92f63b7deb92,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-2e4c03ed-0b05-4c7a-ae0e-6e91a96be45a,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-5e0efa4a-9597-4c4c-ac8f-1ecee929fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-b4f076f3-c25c-4ddc-968a-67d739e27f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-da4ba3aa-5120-45e5-849b-863c96161800,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-7bffa72e-6c32-4682-90d8-18b70738aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-6dfd1ee9-e558-4d38-8d9e-bc6cad7287b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447002261-172.17.0.4-1598586960039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-55caf99d-c540-4054-841e-9e7e67566d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-d9894bae-0eae-4e8b-85ba-2596f52caa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-270ea041-2338-4de7-b32c-1c6623271fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-72f482b9-c486-4d37-8dbb-0729d6a50903,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-1be0da5e-9ac5-49db-821d-c1cdc9ed5d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-f1dc424b-8606-4bae-bc7a-8682dd3aaf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-31510160-06e3-4f66-a905-f58a71065786,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5f3e22c4-6fd7-47ef-a43e-ff4bf70a535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447002261-172.17.0.4-1598586960039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-55caf99d-c540-4054-841e-9e7e67566d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-d9894bae-0eae-4e8b-85ba-2596f52caa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-270ea041-2338-4de7-b32c-1c6623271fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-72f482b9-c486-4d37-8dbb-0729d6a50903,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-1be0da5e-9ac5-49db-821d-c1cdc9ed5d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-f1dc424b-8606-4bae-bc7a-8682dd3aaf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-31510160-06e3-4f66-a905-f58a71065786,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5f3e22c4-6fd7-47ef-a43e-ff4bf70a535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776376431-172.17.0.4-1598587285637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-bfd0be6c-c70a-4756-b112-52169d5f3240,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1be66ba5-d18a-4632-95d3-477612e5a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-3321b719-0a7e-4896-b504-3464c227c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2520bc69-4653-4244-b543-9a6cd223412c,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-508649a2-5993-401b-8da1-3afbe9276ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-60fe8b4b-e716-40c9-b21e-4cd1380cf748,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-49c01ee9-ae64-4aaf-9595-fcc2e1af73b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-36164176-e24e-45ee-bc7e-d8aaeba03718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776376431-172.17.0.4-1598587285637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-bfd0be6c-c70a-4756-b112-52169d5f3240,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-1be66ba5-d18a-4632-95d3-477612e5a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-3321b719-0a7e-4896-b504-3464c227c4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-2520bc69-4653-4244-b543-9a6cd223412c,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-508649a2-5993-401b-8da1-3afbe9276ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-60fe8b4b-e716-40c9-b21e-4cd1380cf748,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-49c01ee9-ae64-4aaf-9595-fcc2e1af73b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-36164176-e24e-45ee-bc7e-d8aaeba03718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429212316-172.17.0.4-1598587379755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-58fa073e-cbbf-4b3b-b80b-38a405a39f64,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-b78b4ac6-f782-4d61-b48f-df36a4314cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-20203de0-a0f8-44ef-b3c7-abf80ba3c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-0f9354f6-bba9-447b-b4b1-14d5c3f6b168,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-0b90cc20-c267-476d-afb3-aac363207fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-7a524b6e-d21a-43fc-8ab0-52d200aac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-b20e78aa-8907-4760-b09c-5ff861ef049f,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-76e7f3de-4953-467c-a18b-1768cee81b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429212316-172.17.0.4-1598587379755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-58fa073e-cbbf-4b3b-b80b-38a405a39f64,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-b78b4ac6-f782-4d61-b48f-df36a4314cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-20203de0-a0f8-44ef-b3c7-abf80ba3c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-0f9354f6-bba9-447b-b4b1-14d5c3f6b168,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-0b90cc20-c267-476d-afb3-aac363207fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-7a524b6e-d21a-43fc-8ab0-52d200aac5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-b20e78aa-8907-4760-b09c-5ff861ef049f,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-76e7f3de-4953-467c-a18b-1768cee81b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231716211-172.17.0.4-1598587845694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-3c22305b-5aba-43c2-836d-4ed0248510cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-d54d243c-472e-4a24-b0b7-78eea22c0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-9218caa0-c6c6-4afa-bdd2-830ae9292c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-f9318b8f-a3b5-4635-9487-838332d400ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-8c7f448b-a166-4c9d-9d00-3fb1d65d8816,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-d9c81bf4-4169-49e5-9900-420a1c9f97d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f98bb3c8-9b79-4e0e-8444-9532491943ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-6e364a5b-eafd-4f53-8cc7-be9716025242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231716211-172.17.0.4-1598587845694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-3c22305b-5aba-43c2-836d-4ed0248510cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-d54d243c-472e-4a24-b0b7-78eea22c0a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-9218caa0-c6c6-4afa-bdd2-830ae9292c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-f9318b8f-a3b5-4635-9487-838332d400ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-8c7f448b-a166-4c9d-9d00-3fb1d65d8816,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-d9c81bf4-4169-49e5-9900-420a1c9f97d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f98bb3c8-9b79-4e0e-8444-9532491943ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-6e364a5b-eafd-4f53-8cc7-be9716025242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494457746-172.17.0.4-1598588842355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-f72d0a32-de4d-426b-845d-2feadf5af228,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-5c19a1f7-2ae0-4156-a931-1b9c7c06b450,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-dae7ae18-3844-44a3-9e48-693b4bf4f478,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-943a186e-7e3a-4b51-8be8-bf5df9579180,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-abb8999c-3c9d-46fe-89a4-51ce3bc893ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-145fd2ae-f30c-41c0-9e09-0b7f09c95c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-e80aca79-d813-49c0-8428-f9042b01af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-91f94265-8b3b-4330-8c6b-1c167e2b4ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494457746-172.17.0.4-1598588842355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35987,DS-f72d0a32-de4d-426b-845d-2feadf5af228,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-5c19a1f7-2ae0-4156-a931-1b9c7c06b450,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-dae7ae18-3844-44a3-9e48-693b4bf4f478,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-943a186e-7e3a-4b51-8be8-bf5df9579180,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-abb8999c-3c9d-46fe-89a4-51ce3bc893ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-145fd2ae-f30c-41c0-9e09-0b7f09c95c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-e80aca79-d813-49c0-8428-f9042b01af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-91f94265-8b3b-4330-8c6b-1c167e2b4ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 4988
