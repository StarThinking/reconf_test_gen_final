reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834633988-172.17.0.19-1598486810769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-754276bf-d1f0-4c83-b698-2f3fadbb1661,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-04742afc-8fff-4f63-8c0f-68f6b8959890,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-26020b63-4ccc-4509-a30e-ee4050ec375c,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-e404b57f-2937-4d35-b076-ff545a3eb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-8fe397ca-d7dc-4d22-8ec5-bd2b3e6503bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-f2e39353-c308-4f54-8d99-644b0994f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-986a0edc-5b7f-4358-ad2d-09d4cfdfc16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-982b6bd6-de2f-4c9b-bba3-df5ced7a680b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834633988-172.17.0.19-1598486810769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-754276bf-d1f0-4c83-b698-2f3fadbb1661,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-04742afc-8fff-4f63-8c0f-68f6b8959890,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-26020b63-4ccc-4509-a30e-ee4050ec375c,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-e404b57f-2937-4d35-b076-ff545a3eb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-8fe397ca-d7dc-4d22-8ec5-bd2b3e6503bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-f2e39353-c308-4f54-8d99-644b0994f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-986a0edc-5b7f-4358-ad2d-09d4cfdfc16b,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-982b6bd6-de2f-4c9b-bba3-df5ced7a680b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774372844-172.17.0.19-1598486881316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39051,DS-8130b252-6457-4c9c-b728-396f489cfa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-70a890d1-a823-4cd5-9c19-b97a401372e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-9592d97a-ff95-4014-9150-7181babef6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-d5cd55d0-5adb-488f-8565-b413b276dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5156a269-ce1c-4a44-b5fe-db407fc86d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c9f6d950-09be-4417-8c4e-e5a483bf9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-58adc662-2aa8-4df0-88df-c784871eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-1370a536-cba6-47a4-ba25-e79df73460e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774372844-172.17.0.19-1598486881316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39051,DS-8130b252-6457-4c9c-b728-396f489cfa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-70a890d1-a823-4cd5-9c19-b97a401372e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-9592d97a-ff95-4014-9150-7181babef6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-d5cd55d0-5adb-488f-8565-b413b276dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5156a269-ce1c-4a44-b5fe-db407fc86d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c9f6d950-09be-4417-8c4e-e5a483bf9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-58adc662-2aa8-4df0-88df-c784871eeaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-1370a536-cba6-47a4-ba25-e79df73460e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595792014-172.17.0.19-1598487114352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-55828cd8-5575-4998-a6e5-f1b45f42069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-276cf1a1-006c-4e7e-96d0-cf64b0f61784,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-59c7ca95-6537-47d2-8901-2b108c656a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-da821f43-8854-481a-bd33-487241115d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-987dab03-6ca0-4e4e-9f37-f7d3bb5a0ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-2e2fd4d4-b88c-47c6-844b-16b19cdd1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d14146ca-62b5-4021-8b8c-0448e7440f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-fa6dba65-6072-4de4-a0dd-ea86053b4ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595792014-172.17.0.19-1598487114352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-55828cd8-5575-4998-a6e5-f1b45f42069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-276cf1a1-006c-4e7e-96d0-cf64b0f61784,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-59c7ca95-6537-47d2-8901-2b108c656a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-da821f43-8854-481a-bd33-487241115d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-987dab03-6ca0-4e4e-9f37-f7d3bb5a0ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-2e2fd4d4-b88c-47c6-844b-16b19cdd1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d14146ca-62b5-4021-8b8c-0448e7440f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-fa6dba65-6072-4de4-a0dd-ea86053b4ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166357091-172.17.0.19-1598487208678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32977,DS-12338720-322b-43a9-8b75-86e8e03087e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-46fa0c37-6c86-4c5e-a8ef-43ca798087d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-f7d75ea4-6dd1-4382-8321-964f3bd46b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-73d6a759-787f-4325-8933-461a45bfd5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-4a9f952a-3568-4276-b93f-74e2857c104e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9601c7aa-10f5-41ec-8caf-74952843e321,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-4ef21dbb-b98d-4130-8a08-c488ef25bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-7f3ea1e9-cffa-4f13-9832-3b31c3768289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166357091-172.17.0.19-1598487208678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32977,DS-12338720-322b-43a9-8b75-86e8e03087e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-46fa0c37-6c86-4c5e-a8ef-43ca798087d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-f7d75ea4-6dd1-4382-8321-964f3bd46b82,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-73d6a759-787f-4325-8933-461a45bfd5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-4a9f952a-3568-4276-b93f-74e2857c104e,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9601c7aa-10f5-41ec-8caf-74952843e321,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-4ef21dbb-b98d-4130-8a08-c488ef25bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-7f3ea1e9-cffa-4f13-9832-3b31c3768289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224069333-172.17.0.19-1598487442440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-f9c3da7c-4cdd-4d87-add3-de57f85a7d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-026aa3da-7899-45ca-8d75-259a38e97f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-b400ef2a-e17d-408f-ad5c-e0408000ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-ad66924e-465c-4f91-8eb0-59df582bb26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-501c8afd-d6a1-4eaa-aa09-47dd5e524088,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-17a06553-8065-4b19-ae66-a6f0960a462a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-532a20ec-9296-45e1-8bd8-6bdc94a32fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-17c7b30b-5ebb-4435-9e33-9fce6ee13782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224069333-172.17.0.19-1598487442440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-f9c3da7c-4cdd-4d87-add3-de57f85a7d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-026aa3da-7899-45ca-8d75-259a38e97f46,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-b400ef2a-e17d-408f-ad5c-e0408000ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-ad66924e-465c-4f91-8eb0-59df582bb26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-501c8afd-d6a1-4eaa-aa09-47dd5e524088,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-17a06553-8065-4b19-ae66-a6f0960a462a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-532a20ec-9296-45e1-8bd8-6bdc94a32fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-17c7b30b-5ebb-4435-9e33-9fce6ee13782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685096886-172.17.0.19-1598487641838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-2b9a64ca-c521-4588-883c-a0b023fe2c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-79ae72ac-ce5f-47ca-ac64-d99512f268b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-74556ff3-953a-4f9b-9c4d-08ca1f9ba79c,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-544e3a1a-e1a1-4ac5-9ff6-5aac6f570bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-d1a7ed4b-3ae1-4792-91d3-7757c2a9b813,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-b669dc92-3fc2-4129-9b08-3c372a91f59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-cf896a3d-a6aa-4c4d-8f1f-313771c82b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-af40a945-93d8-4e74-b852-6fbeaec59080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685096886-172.17.0.19-1598487641838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-2b9a64ca-c521-4588-883c-a0b023fe2c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-79ae72ac-ce5f-47ca-ac64-d99512f268b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-74556ff3-953a-4f9b-9c4d-08ca1f9ba79c,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-544e3a1a-e1a1-4ac5-9ff6-5aac6f570bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-d1a7ed4b-3ae1-4792-91d3-7757c2a9b813,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-b669dc92-3fc2-4129-9b08-3c372a91f59f,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-cf896a3d-a6aa-4c4d-8f1f-313771c82b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-af40a945-93d8-4e74-b852-6fbeaec59080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126723664-172.17.0.19-1598487677132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-0cd327bc-b7bd-4ce0-9bda-9596204fed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-755b4c26-869e-4ac7-aadb-3a8b8a7784b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-517723e5-113b-40aa-9ba2-8a6b816a9bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-785b6daa-ef4e-44d1-9869-a6d7b5d9a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-48db8798-b539-4aa2-97aa-455449821223,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-701ba510-26e4-4e9b-b0ab-ec74a9e4f221,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-359bbb6c-1d6b-4989-be5f-b2c2e5b7b90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-e28b9cb8-9ac9-461d-a104-efc589890f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126723664-172.17.0.19-1598487677132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-0cd327bc-b7bd-4ce0-9bda-9596204fed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-755b4c26-869e-4ac7-aadb-3a8b8a7784b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-517723e5-113b-40aa-9ba2-8a6b816a9bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-785b6daa-ef4e-44d1-9869-a6d7b5d9a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-48db8798-b539-4aa2-97aa-455449821223,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-701ba510-26e4-4e9b-b0ab-ec74a9e4f221,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-359bbb6c-1d6b-4989-be5f-b2c2e5b7b90a,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-e28b9cb8-9ac9-461d-a104-efc589890f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141560869-172.17.0.19-1598487977405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-184f2d2d-28c7-41cb-9dc6-4abbf8761d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-1378ad9d-cd7c-4926-9d37-fd04825e75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-0ea00193-70e2-4393-9848-a59464f6defb,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-d0b9a962-faa2-4570-9594-85020740cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-9740a3b9-e903-4333-bf60-9864b31d9c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-e7979d75-c1d3-416d-a7c8-f1d9b67d3bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ed6aae35-6a13-48f7-a54b-dd8e3e100582,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6ce94b85-b304-489c-a609-20b7f55222b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141560869-172.17.0.19-1598487977405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-184f2d2d-28c7-41cb-9dc6-4abbf8761d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-1378ad9d-cd7c-4926-9d37-fd04825e75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-0ea00193-70e2-4393-9848-a59464f6defb,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-d0b9a962-faa2-4570-9594-85020740cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-9740a3b9-e903-4333-bf60-9864b31d9c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-e7979d75-c1d3-416d-a7c8-f1d9b67d3bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ed6aae35-6a13-48f7-a54b-dd8e3e100582,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6ce94b85-b304-489c-a609-20b7f55222b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488633780-172.17.0.19-1598488674894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-6fdbdac5-b3b4-4770-b25b-3d0b74f16387,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-2af0b1fa-1725-4555-ade5-f23ded24563d,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-8fc4e9f5-7ca4-4753-b3c8-8a00b779030b,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-69453f11-78b6-4648-8cd4-1449b3e4e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-babeedbc-1918-4954-88f0-f85b4af0363e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c60c401b-60f5-44f2-bcc4-c2c0e1e06ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-2f67db87-8d14-455d-80fe-3dc0f7cf27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-83bc8ca9-e099-47ba-9708-c465c60c2b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488633780-172.17.0.19-1598488674894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-6fdbdac5-b3b4-4770-b25b-3d0b74f16387,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-2af0b1fa-1725-4555-ade5-f23ded24563d,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-8fc4e9f5-7ca4-4753-b3c8-8a00b779030b,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-69453f11-78b6-4648-8cd4-1449b3e4e6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-babeedbc-1918-4954-88f0-f85b4af0363e,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c60c401b-60f5-44f2-bcc4-c2c0e1e06ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-2f67db87-8d14-455d-80fe-3dc0f7cf27fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-83bc8ca9-e099-47ba-9708-c465c60c2b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853563040-172.17.0.19-1598489132835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-c3eb3103-5e40-4362-8f61-143ab3e48c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-0d6c9c02-e0c2-48ca-a446-08e78dc57d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-02d42356-dc3e-45f3-8feb-b80e4b7ba250,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-54b143b1-4d15-48a0-aeda-b75e0842d59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-3caf669c-491a-4ade-ab0f-65c6bafa9481,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-fac7d2e6-d2ed-461a-9ee8-a730d2446aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-e0acffd7-c85a-4c96-9372-85a3a590b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-5e1b6b67-c938-465a-b3f9-b06399ac56b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853563040-172.17.0.19-1598489132835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-c3eb3103-5e40-4362-8f61-143ab3e48c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-0d6c9c02-e0c2-48ca-a446-08e78dc57d86,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-02d42356-dc3e-45f3-8feb-b80e4b7ba250,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-54b143b1-4d15-48a0-aeda-b75e0842d59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-3caf669c-491a-4ade-ab0f-65c6bafa9481,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-fac7d2e6-d2ed-461a-9ee8-a730d2446aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-e0acffd7-c85a-4c96-9372-85a3a590b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-5e1b6b67-c938-465a-b3f9-b06399ac56b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267090007-172.17.0.19-1598489357241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-ac19be53-f4c0-488a-8d73-05775530d7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-29ad556e-65d7-4a77-af18-0e992cd60ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-200650aa-73a5-4e09-9250-fc60abe56bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-a330df96-4283-43c7-939f-45ea28f1e208,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-7ef49ee0-301a-45f1-b25f-1c8beff36bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-893db106-196e-4e1c-9211-527f9a098151,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-3016a599-dc53-4192-9845-0c428133b293,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2a0f5645-e196-430a-871b-266e4a2456d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267090007-172.17.0.19-1598489357241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-ac19be53-f4c0-488a-8d73-05775530d7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-29ad556e-65d7-4a77-af18-0e992cd60ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-200650aa-73a5-4e09-9250-fc60abe56bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-a330df96-4283-43c7-939f-45ea28f1e208,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-7ef49ee0-301a-45f1-b25f-1c8beff36bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-893db106-196e-4e1c-9211-527f9a098151,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-3016a599-dc53-4192-9845-0c428133b293,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-2a0f5645-e196-430a-871b-266e4a2456d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931358380-172.17.0.19-1598489390025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-d1d9c427-6f96-4aeb-b1bf-0cdc411d58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-29567f4e-57aa-4a10-8c2f-cd878666523a,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-d2a32373-a1eb-47db-a3b7-68fb2d9239ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-333d9872-1617-4ed8-b900-1dc527ed8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a0c7ec58-226d-43cd-92ef-cea9ffb20c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-363be8e6-e4f9-4b92-99bf-28de99773460,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-ef51aaeb-4891-4beb-83f8-4f177d5fe41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-bd6ecc09-ec7b-4cbf-b58f-cda193d529c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931358380-172.17.0.19-1598489390025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-d1d9c427-6f96-4aeb-b1bf-0cdc411d58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-29567f4e-57aa-4a10-8c2f-cd878666523a,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-d2a32373-a1eb-47db-a3b7-68fb2d9239ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-333d9872-1617-4ed8-b900-1dc527ed8c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a0c7ec58-226d-43cd-92ef-cea9ffb20c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-363be8e6-e4f9-4b92-99bf-28de99773460,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-ef51aaeb-4891-4beb-83f8-4f177d5fe41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-bd6ecc09-ec7b-4cbf-b58f-cda193d529c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055332547-172.17.0.19-1598489664265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-940d7932-5a64-4531-99cc-1a57b15c73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-90cf84e8-642f-46af-a13b-923e32dc0757,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-9ee02af2-588f-4d4b-bd61-38a87ef5dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-470cf5cf-c0bc-4ea9-b2d7-bf45b6275e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-c86f9c72-a047-489d-9331-a6b01f8f0e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4fd859fa-bd46-472f-bdd8-28155c274d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-98f72906-62cc-41a3-aa36-f703eb5dc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-ab5635e8-f6b9-49e6-8c76-a372ebb499ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055332547-172.17.0.19-1598489664265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-940d7932-5a64-4531-99cc-1a57b15c73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-90cf84e8-642f-46af-a13b-923e32dc0757,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-9ee02af2-588f-4d4b-bd61-38a87ef5dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-470cf5cf-c0bc-4ea9-b2d7-bf45b6275e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-c86f9c72-a047-489d-9331-a6b01f8f0e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4fd859fa-bd46-472f-bdd8-28155c274d07,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-98f72906-62cc-41a3-aa36-f703eb5dc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-ab5635e8-f6b9-49e6-8c76-a372ebb499ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543086813-172.17.0.19-1598489943343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-d347afd8-009f-4112-9d53-09f8b2e63bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-35eadc7d-145c-44cc-a469-dcf42f1f5977,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-92d65877-ef7d-4190-870d-61b5f80bb005,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-73d3d247-6068-4e2b-92cf-8e79f2785ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-25e2b801-e067-4239-b75a-7398aff86c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-586a94bb-ad17-44d0-84c7-f01fd79d0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-35b0c5cd-660f-4136-ad49-a8605ed390aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-b1138572-96fe-4f75-99cd-358406804070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543086813-172.17.0.19-1598489943343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-d347afd8-009f-4112-9d53-09f8b2e63bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-35eadc7d-145c-44cc-a469-dcf42f1f5977,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-92d65877-ef7d-4190-870d-61b5f80bb005,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-73d3d247-6068-4e2b-92cf-8e79f2785ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-25e2b801-e067-4239-b75a-7398aff86c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-586a94bb-ad17-44d0-84c7-f01fd79d0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-35b0c5cd-660f-4136-ad49-a8605ed390aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-b1138572-96fe-4f75-99cd-358406804070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692395016-172.17.0.19-1598489992067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37079,DS-eef7d85d-7ed9-4cfa-9a7b-8aa23ba9760d,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-32232b11-471c-46f3-b45c-4024998a065e,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-cd02fcd7-0e04-45dd-bb67-8700a4cc8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-3175d4cd-5a30-49db-a6f3-bef8f6d330a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-bbfd12f4-8443-441a-8d10-c6e4d0f4db16,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-b48ca5b6-df0a-4fe5-af09-d5b4339c3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b5ac57f7-ccfe-45cd-84ce-6471817890a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-2497a682-a7d6-48a4-94fd-33a1e2f9eace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692395016-172.17.0.19-1598489992067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37079,DS-eef7d85d-7ed9-4cfa-9a7b-8aa23ba9760d,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-32232b11-471c-46f3-b45c-4024998a065e,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-cd02fcd7-0e04-45dd-bb67-8700a4cc8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-3175d4cd-5a30-49db-a6f3-bef8f6d330a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-bbfd12f4-8443-441a-8d10-c6e4d0f4db16,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-b48ca5b6-df0a-4fe5-af09-d5b4339c3a74,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-b5ac57f7-ccfe-45cd-84ce-6471817890a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-2497a682-a7d6-48a4-94fd-33a1e2f9eace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562256029-172.17.0.19-1598490034462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-29a52470-f92f-4b68-a28e-9333ffa642ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-c5734f6f-9db3-483b-9c03-2d0942d16f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9ea4858e-1c20-40df-a133-424f6faf5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-4b299de3-1a2c-413d-8dc0-0f069543592c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-6163293a-97a2-4fa6-8c75-870a0f3da9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-36c99aab-b653-46de-b5ae-f317c180cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-6fc0acd9-1428-461f-a6bd-5a6f5d7701d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-bdf4551c-d839-4b8f-a829-a0f323ba4106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562256029-172.17.0.19-1598490034462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-29a52470-f92f-4b68-a28e-9333ffa642ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-c5734f6f-9db3-483b-9c03-2d0942d16f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9ea4858e-1c20-40df-a133-424f6faf5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-4b299de3-1a2c-413d-8dc0-0f069543592c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-6163293a-97a2-4fa6-8c75-870a0f3da9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-36c99aab-b653-46de-b5ae-f317c180cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-6fc0acd9-1428-461f-a6bd-5a6f5d7701d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-bdf4551c-d839-4b8f-a829-a0f323ba4106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305051073-172.17.0.19-1598490402486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-17663ad0-ac36-48df-9cd3-cdf7c1e5a566,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-c8783e13-c56c-474c-8453-f2d2103d76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-349e85d2-3d99-40ea-813b-205493888083,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-af09202d-94e0-4faf-82b4-aa08eda841bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3a9e6624-c762-4945-b676-464f5dd7b0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-7fd9f0b9-dd87-463c-ae82-00ca6cf2ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-9d300765-d26e-4f61-b85a-6c5a9848ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-cab2e43c-9099-4ddb-a303-aa72a35959cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305051073-172.17.0.19-1598490402486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39819,DS-17663ad0-ac36-48df-9cd3-cdf7c1e5a566,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-c8783e13-c56c-474c-8453-f2d2103d76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-349e85d2-3d99-40ea-813b-205493888083,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-af09202d-94e0-4faf-82b4-aa08eda841bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-3a9e6624-c762-4945-b676-464f5dd7b0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-7fd9f0b9-dd87-463c-ae82-00ca6cf2ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-9d300765-d26e-4f61-b85a-6c5a9848ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-cab2e43c-9099-4ddb-a303-aa72a35959cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238681181-172.17.0.19-1598490717294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-af7b5a65-f1b3-43e4-b1ae-1f7b8c9a6ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-fd5b3964-31ea-445b-bc66-8a1387332062,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c14a36e0-6cf8-4599-8b8e-86c1d6d65e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-b5de9da8-2c95-4ce3-901c-ce213ea9c516,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-0b8d884c-2cc6-48d3-ab76-e8b1a0b21a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-724d4ae4-b3f3-4c45-aca2-b5a0ba762b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-797cdd39-7645-493b-a4db-6a67019f7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-d234bcac-58ad-40f1-8ba1-ecd3c16e0831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238681181-172.17.0.19-1598490717294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-af7b5a65-f1b3-43e4-b1ae-1f7b8c9a6ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-fd5b3964-31ea-445b-bc66-8a1387332062,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c14a36e0-6cf8-4599-8b8e-86c1d6d65e64,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-b5de9da8-2c95-4ce3-901c-ce213ea9c516,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-0b8d884c-2cc6-48d3-ab76-e8b1a0b21a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-724d4ae4-b3f3-4c45-aca2-b5a0ba762b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-797cdd39-7645-493b-a4db-6a67019f7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-d234bcac-58ad-40f1-8ba1-ecd3c16e0831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 1000
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750655645-172.17.0.19-1598491662905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-ed2a7d54-5a84-4708-9324-5d3148e06f26,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-58bd8143-c430-41cf-b42f-f27f0dfbb95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-f7895bcf-b5cf-4b74-9178-212f17ee7e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-26417b29-08df-41b2-8ea3-12b35e7c7ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-9fe68798-b1f7-48e7-99c8-2b1f5d415876,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-4c86387a-abb2-4f78-aa91-6441848384ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-ff06704f-629e-48cc-9bcd-6274d12f0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-df1b5f3b-760a-441a-a7fc-19eff2f96cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750655645-172.17.0.19-1598491662905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-ed2a7d54-5a84-4708-9324-5d3148e06f26,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-58bd8143-c430-41cf-b42f-f27f0dfbb95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-f7895bcf-b5cf-4b74-9178-212f17ee7e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-26417b29-08df-41b2-8ea3-12b35e7c7ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-9fe68798-b1f7-48e7-99c8-2b1f5d415876,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-4c86387a-abb2-4f78-aa91-6441848384ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-ff06704f-629e-48cc-9bcd-6274d12f0c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-df1b5f3b-760a-441a-a7fc-19eff2f96cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5528
