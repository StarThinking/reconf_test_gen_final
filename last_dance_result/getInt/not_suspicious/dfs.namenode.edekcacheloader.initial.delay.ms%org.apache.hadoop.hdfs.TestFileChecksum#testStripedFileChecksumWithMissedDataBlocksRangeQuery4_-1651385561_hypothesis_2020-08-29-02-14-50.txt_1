reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642761646-172.17.0.3-1598667645009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-c53b2f7b-6a04-4fdf-8e80-50c435167bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-06db4f9b-8632-4e5a-a0f9-0dc06d75223f,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-c7624a68-30cd-4a78-aebb-4a45bfe3bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-a52944cc-3775-46a9-b890-e67d8abb768d,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-e446073c-4b52-4afe-af91-9e765368c422,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-737fe6d7-dea9-4054-a01d-eac8236c6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f39615a1-0b7c-46c4-836c-272953068685,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-beb3e967-abcc-4436-ad9c-545fca7ef64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642761646-172.17.0.3-1598667645009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-c53b2f7b-6a04-4fdf-8e80-50c435167bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-06db4f9b-8632-4e5a-a0f9-0dc06d75223f,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-c7624a68-30cd-4a78-aebb-4a45bfe3bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-a52944cc-3775-46a9-b890-e67d8abb768d,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-e446073c-4b52-4afe-af91-9e765368c422,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-737fe6d7-dea9-4054-a01d-eac8236c6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f39615a1-0b7c-46c4-836c-272953068685,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-beb3e967-abcc-4436-ad9c-545fca7ef64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755270337-172.17.0.3-1598667901958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-031e33f1-b18c-43d9-ba58-1fb6d2b554be,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-f84a773c-30f8-42b7-961d-751626d818fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-54717654-654c-4810-9d8c-3fa0b6d3e674,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-c9d13d3b-e0bd-4b80-9d54-c929be202d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-faa9f6ee-1daf-4496-8055-3ddd13f4e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-569ed043-6aff-459c-8abe-8ca8e2caff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-71e30d4c-33e9-48bc-9039-df93a459a665,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-2349d595-4f15-432b-a2bc-3e1768f532d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755270337-172.17.0.3-1598667901958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-031e33f1-b18c-43d9-ba58-1fb6d2b554be,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-f84a773c-30f8-42b7-961d-751626d818fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-54717654-654c-4810-9d8c-3fa0b6d3e674,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-c9d13d3b-e0bd-4b80-9d54-c929be202d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-faa9f6ee-1daf-4496-8055-3ddd13f4e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-569ed043-6aff-459c-8abe-8ca8e2caff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-71e30d4c-33e9-48bc-9039-df93a459a665,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-2349d595-4f15-432b-a2bc-3e1768f532d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296358651-172.17.0.3-1598668155523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-069a0538-4c24-4746-9d11-a72458abc904,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-7aecbe4e-7562-4fbf-9ab8-7148dc7c5116,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-8f592707-7dde-4b85-8ad7-279720692225,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-bd2d7d84-4a1a-41ff-9e49-98b1fdb78d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-ad1c389a-4123-4f8d-8612-fd6603c60f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-96817a95-d2f6-41bc-b77a-782d7dd857fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-dc246e2f-8a18-4c6f-8a45-d0f6c302a547,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-92298802-c148-4444-9453-8571162bdb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296358651-172.17.0.3-1598668155523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-069a0538-4c24-4746-9d11-a72458abc904,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-7aecbe4e-7562-4fbf-9ab8-7148dc7c5116,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-8f592707-7dde-4b85-8ad7-279720692225,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-bd2d7d84-4a1a-41ff-9e49-98b1fdb78d41,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-ad1c389a-4123-4f8d-8612-fd6603c60f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-96817a95-d2f6-41bc-b77a-782d7dd857fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-dc246e2f-8a18-4c6f-8a45-d0f6c302a547,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-92298802-c148-4444-9453-8571162bdb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395599168-172.17.0.3-1598668458940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-76c1150e-9132-4b57-8f3d-01217e122e61,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-e10efe51-b32c-4d65-907e-d3b3f04673d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d53dd352-bc92-4ef1-bf8b-00e262b753db,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-35b4599a-fd08-4528-8fc1-68b5377d7363,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-9621b2ef-e9b6-4fad-9c38-acf4bb460faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-10d6c47c-ec6d-4e5c-9ff4-234b19e26f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d926a00c-dcbe-4bd1-a866-17a263095a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-5802298e-d6f1-4241-a69d-100633880d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395599168-172.17.0.3-1598668458940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32918,DS-76c1150e-9132-4b57-8f3d-01217e122e61,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-e10efe51-b32c-4d65-907e-d3b3f04673d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-d53dd352-bc92-4ef1-bf8b-00e262b753db,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-35b4599a-fd08-4528-8fc1-68b5377d7363,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-9621b2ef-e9b6-4fad-9c38-acf4bb460faf,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-10d6c47c-ec6d-4e5c-9ff4-234b19e26f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d926a00c-dcbe-4bd1-a866-17a263095a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-5802298e-d6f1-4241-a69d-100633880d51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573547266-172.17.0.3-1598668874375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-8928297f-2bc6-4d7e-92b8-8cd6f21c8436,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-3c6cc86e-c485-40cc-ab7f-915a810b6c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-e8905c9d-636e-46ec-a0c9-bbde881d29b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-70e728e7-fc41-4756-8b1c-3101972159fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0e0682b7-f049-4e66-8527-7240434e8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-4b5916c3-05be-4b87-8a6d-9d39c01ca2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-6ef012a1-b7cd-4664-9f63-7e68bc7f00be,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-cf87165b-50b7-480e-88e4-a91367f6db93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573547266-172.17.0.3-1598668874375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-8928297f-2bc6-4d7e-92b8-8cd6f21c8436,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-3c6cc86e-c485-40cc-ab7f-915a810b6c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-e8905c9d-636e-46ec-a0c9-bbde881d29b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-70e728e7-fc41-4756-8b1c-3101972159fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0e0682b7-f049-4e66-8527-7240434e8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-4b5916c3-05be-4b87-8a6d-9d39c01ca2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-6ef012a1-b7cd-4664-9f63-7e68bc7f00be,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-cf87165b-50b7-480e-88e4-a91367f6db93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448832433-172.17.0.3-1598668911545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-de7fa126-43eb-492c-a6f5-29758189b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-64d10c04-2caf-4dff-9c57-4b2f2e818ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d796b874-f8e0-4d61-999c-96693106532c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-12518ce9-a934-4686-add5-a95654e9998a,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-a4eb92e6-8b45-4762-a1a0-304125a7ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-32a4f66f-5513-4053-b462-31dad7395fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9887ad64-4069-43a0-889b-fc69d7d8e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d026ecbf-55de-43fa-9a44-61e319513dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448832433-172.17.0.3-1598668911545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45067,DS-de7fa126-43eb-492c-a6f5-29758189b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-64d10c04-2caf-4dff-9c57-4b2f2e818ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d796b874-f8e0-4d61-999c-96693106532c,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-12518ce9-a934-4686-add5-a95654e9998a,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-a4eb92e6-8b45-4762-a1a0-304125a7ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-32a4f66f-5513-4053-b462-31dad7395fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9887ad64-4069-43a0-889b-fc69d7d8e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d026ecbf-55de-43fa-9a44-61e319513dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526739406-172.17.0.3-1598669160226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-11a1b348-74f6-42da-9ac3-fe15cb682b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-4b564fb4-c6b6-4c81-a045-829c93d478ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-1fcf27a8-bef2-4c34-bf33-d7b7ae925bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-0d7ea97a-7692-4413-80ac-13ed06c37999,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-bebd49b7-5f0a-4b31-8cc9-4b728941f552,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-37f47eaf-0b04-44e3-96de-d08314f024ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-c2b86834-dfe6-4be1-bc09-2e905b537f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-ce3cd017-b5e5-4e99-89c8-f8ac38bc3521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526739406-172.17.0.3-1598669160226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-11a1b348-74f6-42da-9ac3-fe15cb682b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-4b564fb4-c6b6-4c81-a045-829c93d478ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-1fcf27a8-bef2-4c34-bf33-d7b7ae925bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-0d7ea97a-7692-4413-80ac-13ed06c37999,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-bebd49b7-5f0a-4b31-8cc9-4b728941f552,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-37f47eaf-0b04-44e3-96de-d08314f024ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-c2b86834-dfe6-4be1-bc09-2e905b537f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-ce3cd017-b5e5-4e99-89c8-f8ac38bc3521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220003545-172.17.0.3-1598669282227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-b66e60a4-3f33-43d6-bb44-b9a40e4183a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-928872e7-71d4-44e9-b8a0-5e7f2669c7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-f54655ea-7f39-487e-b38a-433e714fa76e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-aa299dbb-7a68-4515-8f3d-cb76e0781a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-1768762b-58ab-4237-840e-40a68205a331,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-c9ae3d4d-80ff-41d5-85f7-e95f5ea96361,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-8fd9c709-1bdc-4217-b3a0-a5f8fcee61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-8f37fedb-2fa3-4f2b-ace2-f2aa35812ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220003545-172.17.0.3-1598669282227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-b66e60a4-3f33-43d6-bb44-b9a40e4183a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-928872e7-71d4-44e9-b8a0-5e7f2669c7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-f54655ea-7f39-487e-b38a-433e714fa76e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-aa299dbb-7a68-4515-8f3d-cb76e0781a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-1768762b-58ab-4237-840e-40a68205a331,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-c9ae3d4d-80ff-41d5-85f7-e95f5ea96361,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-8fd9c709-1bdc-4217-b3a0-a5f8fcee61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-8f37fedb-2fa3-4f2b-ace2-f2aa35812ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346316593-172.17.0.3-1598669671827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-56a87885-4d51-4934-855f-17981b35b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-847c5f1a-651e-4ea6-9e5c-2440ebbe62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-f80dd81b-645a-4f69-8b86-f80ac4fd3ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-42bec7dd-60b4-47d5-82a7-c0ff70a758db,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-7db5a184-4d96-42ef-b0eb-ce21182bac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-4ffa6b66-f156-4339-9d1e-8d1db2f56574,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-6215ae12-956e-4ddd-9e2b-5a0a357c596f,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-a8b9885c-fa76-491f-9e1c-365e68256aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346316593-172.17.0.3-1598669671827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-56a87885-4d51-4934-855f-17981b35b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-847c5f1a-651e-4ea6-9e5c-2440ebbe62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-f80dd81b-645a-4f69-8b86-f80ac4fd3ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-42bec7dd-60b4-47d5-82a7-c0ff70a758db,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-7db5a184-4d96-42ef-b0eb-ce21182bac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-4ffa6b66-f156-4339-9d1e-8d1db2f56574,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-6215ae12-956e-4ddd-9e2b-5a0a357c596f,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-a8b9885c-fa76-491f-9e1c-365e68256aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260795065-172.17.0.3-1598670305112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43976,DS-da00b839-7a10-45ff-b83b-522e7a0ba3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-b1d53962-5b6b-4368-a005-7572b152b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-11c1446d-0c58-4e46-ac4c-62906ab3d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-fe64990d-c76c-4e3f-9d70-a8dcabc2a144,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-7870c877-ea42-4281-b5b1-a5e225554996,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-1f30c4ec-f87a-4ad1-821f-69de0fdeb8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-ef44ed04-df17-4599-95c3-7eddb4f95168,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-f84b7f5f-ee4e-4509-ac9b-5cda54d75f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260795065-172.17.0.3-1598670305112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43976,DS-da00b839-7a10-45ff-b83b-522e7a0ba3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-b1d53962-5b6b-4368-a005-7572b152b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-11c1446d-0c58-4e46-ac4c-62906ab3d25a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-fe64990d-c76c-4e3f-9d70-a8dcabc2a144,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-7870c877-ea42-4281-b5b1-a5e225554996,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-1f30c4ec-f87a-4ad1-821f-69de0fdeb8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-ef44ed04-df17-4599-95c3-7eddb4f95168,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-f84b7f5f-ee4e-4509-ac9b-5cda54d75f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104763357-172.17.0.3-1598670612596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-5509fd9b-3d46-4f73-ad3c-6c81731fdf25,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-2f3beaf1-80a8-4bbf-bd29-29b3890e5999,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f2386036-5c5b-4dc1-9fc5-b7fa9bf1a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-4121eeba-5ddd-4a58-ae13-78df21e0effd,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c1bb54f4-6ea1-4aa0-a5f0-3429d03ccf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-da3ab940-3bce-480b-8a75-6f593e8c326d,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-18a2aea2-f52b-4961-a9c3-710d2fcb7b93,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-88bbda8a-377f-4222-8ef4-c00d677c59a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104763357-172.17.0.3-1598670612596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-5509fd9b-3d46-4f73-ad3c-6c81731fdf25,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-2f3beaf1-80a8-4bbf-bd29-29b3890e5999,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f2386036-5c5b-4dc1-9fc5-b7fa9bf1a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-4121eeba-5ddd-4a58-ae13-78df21e0effd,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c1bb54f4-6ea1-4aa0-a5f0-3429d03ccf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-da3ab940-3bce-480b-8a75-6f593e8c326d,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-18a2aea2-f52b-4961-a9c3-710d2fcb7b93,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-88bbda8a-377f-4222-8ef4-c00d677c59a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877404756-172.17.0.3-1598671686620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-4bee9e09-e184-4dfa-acb7-4a8acccb5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-b2dba0ca-dbcd-4c2e-8854-5041b3cd8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-e12ed237-e04f-45aa-94a4-dd014a5f0e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-c0ac2657-a552-410e-b04b-3a56c61ad05f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-5c656803-286c-4b71-b437-83bbfac3ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a508afe3-efc5-4e78-a7f3-942802cf5863,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-ee35816f-eec2-431d-8a45-0f41a11e98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-f57e9471-412f-4409-a2de-cd2e998976c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877404756-172.17.0.3-1598671686620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-4bee9e09-e184-4dfa-acb7-4a8acccb5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-b2dba0ca-dbcd-4c2e-8854-5041b3cd8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-e12ed237-e04f-45aa-94a4-dd014a5f0e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-c0ac2657-a552-410e-b04b-3a56c61ad05f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-5c656803-286c-4b71-b437-83bbfac3ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a508afe3-efc5-4e78-a7f3-942802cf5863,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-ee35816f-eec2-431d-8a45-0f41a11e98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-f57e9471-412f-4409-a2de-cd2e998976c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384766827-172.17.0.3-1598671874776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-e34e9f79-d16e-49c5-89f8-d6ed88b4284b,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-b087493e-432a-455a-84e6-8fada6aab45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-fa427e8f-ffb8-4b39-9912-bc5ed5156312,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-94743e33-3f5b-4644-b87e-a1fedbda0f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-5da4413e-4a44-460f-8d71-5796ffbce241,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-fc81e549-c713-4441-ac82-b46b86b043a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3a7ee615-921d-4df5-8dab-9d3abd89046d,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-6ea2f6c9-8cf3-4651-8504-270544e1e05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384766827-172.17.0.3-1598671874776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-e34e9f79-d16e-49c5-89f8-d6ed88b4284b,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-b087493e-432a-455a-84e6-8fada6aab45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-fa427e8f-ffb8-4b39-9912-bc5ed5156312,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-94743e33-3f5b-4644-b87e-a1fedbda0f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-5da4413e-4a44-460f-8d71-5796ffbce241,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-fc81e549-c713-4441-ac82-b46b86b043a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-3a7ee615-921d-4df5-8dab-9d3abd89046d,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-6ea2f6c9-8cf3-4651-8504-270544e1e05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922045241-172.17.0.3-1598671945840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-fcb5f6f6-0e4a-43ba-a754-bb78a5976b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-91effcc5-22ee-4d3e-8223-3e364b902971,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-0848dc40-416e-4607-aa76-c717304e7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-4cdb069e-eb93-4a01-8752-08c00b66b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-6a736f58-fc58-425f-ac80-525911b47169,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-fde4e844-1897-4a3d-b552-51f54f0e17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-7d29aee6-1dc9-40b1-b92a-2b49e73c0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-57b582be-4f97-4032-93e8-8e9c6ff43b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922045241-172.17.0.3-1598671945840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33580,DS-fcb5f6f6-0e4a-43ba-a754-bb78a5976b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-91effcc5-22ee-4d3e-8223-3e364b902971,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-0848dc40-416e-4607-aa76-c717304e7d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-4cdb069e-eb93-4a01-8752-08c00b66b1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-6a736f58-fc58-425f-ac80-525911b47169,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-fde4e844-1897-4a3d-b552-51f54f0e17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-7d29aee6-1dc9-40b1-b92a-2b49e73c0f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-57b582be-4f97-4032-93e8-8e9c6ff43b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665721119-172.17.0.3-1598672100120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-7b998b82-06ff-4ce1-9e60-79cff727000a,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-1c27fb74-f48a-42ea-8be2-978c7b384577,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-65ee07aa-9cfa-4aac-9316-dbbfe5f2ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-d42be631-753b-445c-8676-3cffb81cc9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-0d25a69b-fe58-4886-926e-a3c5c1611136,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-a073d6cc-9c64-47b5-b1a5-6c2b11faa4da,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-052f84c0-2944-47d7-ba4d-bf232788de37,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-34b50408-fcb6-4b6d-8a87-bc13e86980e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665721119-172.17.0.3-1598672100120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-7b998b82-06ff-4ce1-9e60-79cff727000a,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-1c27fb74-f48a-42ea-8be2-978c7b384577,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-65ee07aa-9cfa-4aac-9316-dbbfe5f2ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-d42be631-753b-445c-8676-3cffb81cc9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-0d25a69b-fe58-4886-926e-a3c5c1611136,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-a073d6cc-9c64-47b5-b1a5-6c2b11faa4da,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-052f84c0-2944-47d7-ba4d-bf232788de37,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-34b50408-fcb6-4b6d-8a87-bc13e86980e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106020638-172.17.0.3-1598672379179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-addb0088-0735-45fc-b454-7c6bb8b469ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-03f1ef65-3e08-4237-b565-f037ecd248a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-8c70b7eb-4064-4722-9a94-4a878bd67f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-cf1e4682-1684-4e43-87c5-17dc420d2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-f108964b-9ca6-412f-9c33-9d84435f2775,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-e99ea7f4-6d84-47c1-8604-7e37d7680224,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-e1822e74-6220-47e5-bfe2-4936a8ac10ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-d0197fa2-804b-46ef-bcd8-742b26d1c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106020638-172.17.0.3-1598672379179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35121,DS-addb0088-0735-45fc-b454-7c6bb8b469ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-03f1ef65-3e08-4237-b565-f037ecd248a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-8c70b7eb-4064-4722-9a94-4a878bd67f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-cf1e4682-1684-4e43-87c5-17dc420d2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-f108964b-9ca6-412f-9c33-9d84435f2775,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-e99ea7f4-6d84-47c1-8604-7e37d7680224,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-e1822e74-6220-47e5-bfe2-4936a8ac10ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-d0197fa2-804b-46ef-bcd8-742b26d1c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959541340-172.17.0.3-1598672458142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-5b1449a8-78b6-43bd-aef2-c2caeb06a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-2554a407-6048-424d-afb2-7bd9c93304af,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-765f518b-4815-4fa1-9c5b-e8feb344ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5f9995a1-43bf-4dce-88da-61490eff0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-0089274a-6e3b-4562-80e0-7d094978c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-951bb42d-ea59-447c-8295-0c97fa464dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-e62cd0d0-1902-479c-b48d-e1e7f965c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6007eb5c-9c81-4a58-a022-44236c8287cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959541340-172.17.0.3-1598672458142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-5b1449a8-78b6-43bd-aef2-c2caeb06a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-2554a407-6048-424d-afb2-7bd9c93304af,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-765f518b-4815-4fa1-9c5b-e8feb344ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5f9995a1-43bf-4dce-88da-61490eff0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-0089274a-6e3b-4562-80e0-7d094978c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-951bb42d-ea59-447c-8295-0c97fa464dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-e62cd0d0-1902-479c-b48d-e1e7f965c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6007eb5c-9c81-4a58-a022-44236c8287cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340093652-172.17.0.3-1598672781722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-160f8284-b2bc-4268-857c-620b1ba036eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-3475813b-e740-47d5-b693-380bc97bba20,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-5bc858d1-41f2-4940-921b-bd0b44797e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-ccb3e9c2-c7da-455a-b749-01d9cadf4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-dfd2f389-c9f7-4e70-950b-fe9b3bf14843,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-154ba108-0de3-4f1f-97e0-62012f9abd30,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-5e2a30e3-7b6f-457b-9484-07eb8959f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-24d52dab-0640-47bf-b0e1-f164a44514f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340093652-172.17.0.3-1598672781722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-160f8284-b2bc-4268-857c-620b1ba036eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-3475813b-e740-47d5-b693-380bc97bba20,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-5bc858d1-41f2-4940-921b-bd0b44797e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-ccb3e9c2-c7da-455a-b749-01d9cadf4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-dfd2f389-c9f7-4e70-950b-fe9b3bf14843,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-154ba108-0de3-4f1f-97e0-62012f9abd30,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-5e2a30e3-7b6f-457b-9484-07eb8959f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-24d52dab-0640-47bf-b0e1-f164a44514f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5671
