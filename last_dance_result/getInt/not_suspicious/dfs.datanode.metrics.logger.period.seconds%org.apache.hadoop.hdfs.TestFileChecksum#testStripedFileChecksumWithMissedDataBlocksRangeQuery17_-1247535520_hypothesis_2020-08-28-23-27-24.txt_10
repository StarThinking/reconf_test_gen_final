reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581143441-172.17.0.14-1598657438328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-47f9c926-60e8-4459-b4e1-4b281a649127,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-6745e3af-c62a-4289-9fba-38d1f80e3b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-516c900a-f319-4c41-9241-7ba7d8375c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-a9207273-5a8c-4412-a0e8-5768dacec98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-4c603256-0038-4b51-bfc1-40b6f67d33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-a19c6986-6e75-4db1-aa84-d3cac166175d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-6d79bd49-4895-48da-8264-d13c8fb96522,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-6e1bcfc4-8839-4165-94e5-9738ba07764e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581143441-172.17.0.14-1598657438328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-47f9c926-60e8-4459-b4e1-4b281a649127,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-6745e3af-c62a-4289-9fba-38d1f80e3b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-516c900a-f319-4c41-9241-7ba7d8375c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-a9207273-5a8c-4412-a0e8-5768dacec98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-4c603256-0038-4b51-bfc1-40b6f67d33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-a19c6986-6e75-4db1-aa84-d3cac166175d,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-6d79bd49-4895-48da-8264-d13c8fb96522,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-6e1bcfc4-8839-4165-94e5-9738ba07764e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673168052-172.17.0.14-1598657875627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34186,DS-21ae21f7-5677-4903-bc2f-92e6dc536f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-104fe2a3-6713-4882-9e44-c04a344ac691,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5d50bffd-9dcf-4712-bfb1-47d9494dcf01,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-5635638f-cb9c-4878-9bb6-ec00c0199765,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e0d85981-e787-4efb-9fd6-173176de2522,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-b8ae3592-1194-41ca-bb6f-88a155b86b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-53c0d86b-fa36-4c6b-b8fd-38b66a19d092,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e52de1f9-edf8-4aa7-9297-71a0722fec54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673168052-172.17.0.14-1598657875627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34186,DS-21ae21f7-5677-4903-bc2f-92e6dc536f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-104fe2a3-6713-4882-9e44-c04a344ac691,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-5d50bffd-9dcf-4712-bfb1-47d9494dcf01,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-5635638f-cb9c-4878-9bb6-ec00c0199765,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-e0d85981-e787-4efb-9fd6-173176de2522,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-b8ae3592-1194-41ca-bb6f-88a155b86b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-53c0d86b-fa36-4c6b-b8fd-38b66a19d092,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e52de1f9-edf8-4aa7-9297-71a0722fec54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146614841-172.17.0.14-1598658210415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34497,DS-e13cd00e-4fa8-4563-81e4-52ab31e84409,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-000b6b6f-81df-4893-b682-59abe87f9ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-13869bdb-89a2-4d05-ba12-1d305ed47035,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-6950a152-f4e1-4adc-a465-2a85418f59bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-1f8bdcd8-4118-43aa-a45d-da23b2589867,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-e69b9f33-ea28-4820-bd74-2597038b6cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-7248460a-bf61-4ee3-a092-2e7bbb85f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-350a062e-eea3-45ed-909e-f360c4ad21d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146614841-172.17.0.14-1598658210415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34497,DS-e13cd00e-4fa8-4563-81e4-52ab31e84409,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-000b6b6f-81df-4893-b682-59abe87f9ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-13869bdb-89a2-4d05-ba12-1d305ed47035,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-6950a152-f4e1-4adc-a465-2a85418f59bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-1f8bdcd8-4118-43aa-a45d-da23b2589867,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-e69b9f33-ea28-4820-bd74-2597038b6cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-7248460a-bf61-4ee3-a092-2e7bbb85f4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-350a062e-eea3-45ed-909e-f360c4ad21d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8704329-172.17.0.14-1598658244500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-16eb2c74-a494-4305-90cc-3ced54a8f666,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1b127c46-410e-43c2-b1b9-d6b98e4e4789,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-361c7f75-0b73-48c1-a2e3-9b563265b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-3d9b3a8e-3ee4-48ea-b0ca-7f6f0a679eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-0edad237-ab73-4a5c-af2b-42886c6a8562,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-12d181e3-1b2d-423d-a347-997d4829a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-a9a9bf2e-2b91-414f-9371-66c504e3d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-f26c42a1-f9a5-46ed-b05a-9410afa92d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8704329-172.17.0.14-1598658244500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-16eb2c74-a494-4305-90cc-3ced54a8f666,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-1b127c46-410e-43c2-b1b9-d6b98e4e4789,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-361c7f75-0b73-48c1-a2e3-9b563265b8af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-3d9b3a8e-3ee4-48ea-b0ca-7f6f0a679eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-0edad237-ab73-4a5c-af2b-42886c6a8562,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-12d181e3-1b2d-423d-a347-997d4829a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-a9a9bf2e-2b91-414f-9371-66c504e3d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-f26c42a1-f9a5-46ed-b05a-9410afa92d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119939815-172.17.0.14-1598658820905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-bf38ea13-a917-4bc2-acad-d200fdec4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-14f89aba-2ee1-4b40-a8dd-66872146190a,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-3ce63c32-b4b5-4265-a75e-1a71218b330c,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-54900bd8-050f-4d91-bfdc-7abd8e61799d,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-f440e3d9-0a4c-4f9f-ab26-991bcc2fa446,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-154decd1-4811-412b-bebd-a49e5fa1cccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5f7c0699-5fea-47ac-9457-551522683217,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-76d33df3-5b21-4f54-b474-eb43368f558f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119939815-172.17.0.14-1598658820905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-bf38ea13-a917-4bc2-acad-d200fdec4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-14f89aba-2ee1-4b40-a8dd-66872146190a,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-3ce63c32-b4b5-4265-a75e-1a71218b330c,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-54900bd8-050f-4d91-bfdc-7abd8e61799d,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-f440e3d9-0a4c-4f9f-ab26-991bcc2fa446,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-154decd1-4811-412b-bebd-a49e5fa1cccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5f7c0699-5fea-47ac-9457-551522683217,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-76d33df3-5b21-4f54-b474-eb43368f558f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475284194-172.17.0.14-1598659322578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-196c886a-65ca-44a0-b86a-9dfdc89cf582,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-24ddf3f1-3fe2-4aa7-aa3c-abd5a993ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-9e04d541-a64f-42a0-837f-f0600ad5f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-8dd29703-6749-4693-a2cf-14a355b9c950,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-635f6252-946c-4199-810f-a8d156a288b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-d8f60cd0-fbde-461c-8bdb-71df1a77120f,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-317e6218-7c7e-4fec-8c2a-3b2d845ac817,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bdf5c177-74bd-42b6-9f3a-5361788ad955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475284194-172.17.0.14-1598659322578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-196c886a-65ca-44a0-b86a-9dfdc89cf582,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-24ddf3f1-3fe2-4aa7-aa3c-abd5a993ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-9e04d541-a64f-42a0-837f-f0600ad5f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-8dd29703-6749-4693-a2cf-14a355b9c950,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-635f6252-946c-4199-810f-a8d156a288b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-d8f60cd0-fbde-461c-8bdb-71df1a77120f,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-317e6218-7c7e-4fec-8c2a-3b2d845ac817,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bdf5c177-74bd-42b6-9f3a-5361788ad955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334371042-172.17.0.14-1598660091875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-04255d7c-a02a-4718-842e-b95811cede2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-e472ea3f-aeb5-4282-9ef4-fd69e236e825,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-2e8d2667-3abb-42a3-be01-cd31f99a775f,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-48a1b600-676d-4dce-aa85-3a62f5391991,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-9cde4880-fcb6-46d9-9b06-b39ca4f2fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-c200bd12-eecb-4304-bca1-d6f1b349a267,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-7d37f6f8-c9d7-452d-a1c0-7fba3639da27,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-204d1afc-c5de-43d9-9fe8-0b36ea9f3b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334371042-172.17.0.14-1598660091875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-04255d7c-a02a-4718-842e-b95811cede2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-e472ea3f-aeb5-4282-9ef4-fd69e236e825,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-2e8d2667-3abb-42a3-be01-cd31f99a775f,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-48a1b600-676d-4dce-aa85-3a62f5391991,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-9cde4880-fcb6-46d9-9b06-b39ca4f2fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-c200bd12-eecb-4304-bca1-d6f1b349a267,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-7d37f6f8-c9d7-452d-a1c0-7fba3639da27,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-204d1afc-c5de-43d9-9fe8-0b36ea9f3b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262511988-172.17.0.14-1598660328000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-903b9b21-6b2c-48ad-aada-3af4084db976,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-41fa25ee-dfa0-4ab3-b93c-ce74ebe0cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-60d94ef3-0486-4c12-8f93-3571a4885ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-5e2655f7-57c9-4e58-8e42-26d234c1021b,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-37454500-c5d5-43f2-acf1-9ece610e4359,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-bc85a7db-b7ff-4dfb-8b72-068d856142fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-97c0df6a-d275-4e19-a7c7-69b00753b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-953b68b4-e3ea-4859-a362-6aade30aa603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262511988-172.17.0.14-1598660328000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-903b9b21-6b2c-48ad-aada-3af4084db976,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-41fa25ee-dfa0-4ab3-b93c-ce74ebe0cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-60d94ef3-0486-4c12-8f93-3571a4885ace,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-5e2655f7-57c9-4e58-8e42-26d234c1021b,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-37454500-c5d5-43f2-acf1-9ece610e4359,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-bc85a7db-b7ff-4dfb-8b72-068d856142fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-97c0df6a-d275-4e19-a7c7-69b00753b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-953b68b4-e3ea-4859-a362-6aade30aa603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777587170-172.17.0.14-1598660369181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-fec7d0d5-8915-42e4-82dc-4426523dea57,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-3f43c77d-a5c5-4b2b-be97-3b4227b23ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-5b4f1f90-4e32-4efb-ac64-ea00c6239d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-0bf21d20-0da4-442e-b2a9-5e6fb3abc846,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-a82a8bac-5194-43ca-97af-ba436bc446de,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-957ae0db-7c6b-4131-a48f-32e24fd279a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-7a57159d-8d54-4c04-bad3-04167908c417,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-1bfe52c8-5c66-49f3-8b9a-887ae3d6f48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777587170-172.17.0.14-1598660369181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-fec7d0d5-8915-42e4-82dc-4426523dea57,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-3f43c77d-a5c5-4b2b-be97-3b4227b23ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-5b4f1f90-4e32-4efb-ac64-ea00c6239d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-0bf21d20-0da4-442e-b2a9-5e6fb3abc846,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-a82a8bac-5194-43ca-97af-ba436bc446de,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-957ae0db-7c6b-4131-a48f-32e24fd279a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-7a57159d-8d54-4c04-bad3-04167908c417,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-1bfe52c8-5c66-49f3-8b9a-887ae3d6f48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727663973-172.17.0.14-1598660706974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42688,DS-e3c83dcb-9e81-468d-a6e5-02b270e09886,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-94c8d5af-7879-462d-b0ea-31360ab55666,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-5a4c72ad-a120-48ff-9751-e5d3977e2b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-2bf4402c-aca1-4d98-8889-50f451c16f49,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-498b980b-f320-4fce-bb0b-e67638329aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-20cccdf2-ad44-4090-a43f-584aa21ea8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-a2c44fcf-91f9-477e-9cff-f108a3f3f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c309ff03-f4f5-428d-a97b-559e3b8e4db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727663973-172.17.0.14-1598660706974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42688,DS-e3c83dcb-9e81-468d-a6e5-02b270e09886,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-94c8d5af-7879-462d-b0ea-31360ab55666,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-5a4c72ad-a120-48ff-9751-e5d3977e2b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-2bf4402c-aca1-4d98-8889-50f451c16f49,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-498b980b-f320-4fce-bb0b-e67638329aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-20cccdf2-ad44-4090-a43f-584aa21ea8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-a2c44fcf-91f9-477e-9cff-f108a3f3f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c309ff03-f4f5-428d-a97b-559e3b8e4db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311462795-172.17.0.14-1598660931090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-71a51c4e-2690-450d-bcb1-5f60525d8100,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-04936305-499c-46c0-9b2e-0be93836dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-c947c260-d551-4ee2-bbbb-95d2ee5acdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-70b80575-20bc-424d-aa3f-05ae8a16d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-734c0f97-ed60-45b4-911a-46b94811556f,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-9cc86293-a9cb-4732-a6ce-37164fab8198,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-164099ec-0d72-4926-910f-1bd308337dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-052c0329-87a8-4b17-8d63-83ed26d041ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311462795-172.17.0.14-1598660931090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-71a51c4e-2690-450d-bcb1-5f60525d8100,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-04936305-499c-46c0-9b2e-0be93836dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-c947c260-d551-4ee2-bbbb-95d2ee5acdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-70b80575-20bc-424d-aa3f-05ae8a16d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-734c0f97-ed60-45b4-911a-46b94811556f,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-9cc86293-a9cb-4732-a6ce-37164fab8198,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-164099ec-0d72-4926-910f-1bd308337dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-052c0329-87a8-4b17-8d63-83ed26d041ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908638391-172.17.0.14-1598661083150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-5f453d99-4f02-438e-ad97-c22f0668bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-4e087842-3876-4470-a47b-48a5b67e82cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-8761d21e-e3f2-4078-ab21-84160ce6a104,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-423ec7d3-68bb-4ae1-bf09-1cbce314297d,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-14e5e597-c39c-4e74-947a-71725d72b939,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-f1f3c774-ed6f-4e4a-b703-2d0ebb5abbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-e5929a73-ca7d-4f6d-88d1-129dd8b2c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-9af016d9-9aa1-4a36-9d98-00f880a4ffc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908638391-172.17.0.14-1598661083150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44943,DS-5f453d99-4f02-438e-ad97-c22f0668bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-4e087842-3876-4470-a47b-48a5b67e82cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-8761d21e-e3f2-4078-ab21-84160ce6a104,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-423ec7d3-68bb-4ae1-bf09-1cbce314297d,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-14e5e597-c39c-4e74-947a-71725d72b939,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-f1f3c774-ed6f-4e4a-b703-2d0ebb5abbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-e5929a73-ca7d-4f6d-88d1-129dd8b2c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-9af016d9-9aa1-4a36-9d98-00f880a4ffc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121359192-172.17.0.14-1598661264625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-5f48bcbd-3e93-4447-bac7-5cf432b8540d,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-3fa1f2aa-128e-43f9-b45d-a890feaae857,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-5e4bc634-2d2b-47af-ac80-56768d1bdee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-7a50b847-2055-49d5-8ab5-37b3f52b71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-480a71dd-fa6e-4163-ba40-cf6f9c17eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7cb39b41-bf5d-4650-8bdc-fd0cbead8564,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9f74cfd0-2186-4c34-b636-b7fd7a16267e,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-4b700e51-69e0-44bf-bbb1-274c7aea3450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121359192-172.17.0.14-1598661264625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-5f48bcbd-3e93-4447-bac7-5cf432b8540d,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-3fa1f2aa-128e-43f9-b45d-a890feaae857,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-5e4bc634-2d2b-47af-ac80-56768d1bdee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-7a50b847-2055-49d5-8ab5-37b3f52b71f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-480a71dd-fa6e-4163-ba40-cf6f9c17eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-7cb39b41-bf5d-4650-8bdc-fd0cbead8564,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9f74cfd0-2186-4c34-b636-b7fd7a16267e,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-4b700e51-69e0-44bf-bbb1-274c7aea3450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963447756-172.17.0.14-1598661609618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-39591897-2907-4dd4-8395-715452a68cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-ce7236e2-8de6-40d0-bb55-51fc37b9234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-4b8324a5-d60b-4561-972f-e235edfee158,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7f8d1ff8-1940-47f3-8eaa-7f8ee7b4565b,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-7746b1f5-1f83-4125-b7b6-11e4fed8f507,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-937bf389-452e-4ae0-9dfe-b0932e928f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-0e2e6ef1-24bc-4eda-88f3-a68d425250d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-1bf22b07-9273-4c32-84f5-8e932963e1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963447756-172.17.0.14-1598661609618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-39591897-2907-4dd4-8395-715452a68cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-ce7236e2-8de6-40d0-bb55-51fc37b9234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-4b8324a5-d60b-4561-972f-e235edfee158,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7f8d1ff8-1940-47f3-8eaa-7f8ee7b4565b,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-7746b1f5-1f83-4125-b7b6-11e4fed8f507,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-937bf389-452e-4ae0-9dfe-b0932e928f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-0e2e6ef1-24bc-4eda-88f3-a68d425250d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-1bf22b07-9273-4c32-84f5-8e932963e1c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167258238-172.17.0.14-1598662110557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-9e7ad90b-0242-4c21-a43f-30eea9b58579,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-a56f8b42-3c83-4837-88be-9d4bd0f276de,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-28296c3a-232e-4de0-968f-a3d5087ae3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-43f427d4-90d5-4cce-a6b4-c1aa8e2ce48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f1d406bf-7620-445b-99df-245d41e17a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-02cccec2-4a17-4533-84ad-b592ef7f3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-55771ebf-5742-4de4-a7ee-667309c5903f,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-48c0c672-a28e-4726-98a9-f0e1a127beb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167258238-172.17.0.14-1598662110557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-9e7ad90b-0242-4c21-a43f-30eea9b58579,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-a56f8b42-3c83-4837-88be-9d4bd0f276de,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-28296c3a-232e-4de0-968f-a3d5087ae3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-43f427d4-90d5-4cce-a6b4-c1aa8e2ce48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-f1d406bf-7620-445b-99df-245d41e17a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-02cccec2-4a17-4533-84ad-b592ef7f3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-55771ebf-5742-4de4-a7ee-667309c5903f,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-48c0c672-a28e-4726-98a9-f0e1a127beb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5336
