reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003210416-172.17.0.14-1598637029211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-9a7c8f4d-a17a-426e-a753-17d398dc6078,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-6fe5be92-2458-4106-b64a-fede2e28f0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-e9269276-b26f-494c-a410-f694546e1d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-fa372689-c355-4018-bd14-dba4c7eb502b,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-725d13f8-789f-45db-bfcb-8f7a5e99d9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-48355c8e-0abe-404a-a8da-6dfb002bc434,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-0a8a6ef0-f0c2-4cd0-813f-6c519fc15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9a8ff062-c2bc-4ca2-8ca4-259a3c248d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003210416-172.17.0.14-1598637029211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-9a7c8f4d-a17a-426e-a753-17d398dc6078,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-6fe5be92-2458-4106-b64a-fede2e28f0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-e9269276-b26f-494c-a410-f694546e1d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-fa372689-c355-4018-bd14-dba4c7eb502b,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-725d13f8-789f-45db-bfcb-8f7a5e99d9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-48355c8e-0abe-404a-a8da-6dfb002bc434,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-0a8a6ef0-f0c2-4cd0-813f-6c519fc15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9a8ff062-c2bc-4ca2-8ca4-259a3c248d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051095073-172.17.0.14-1598637197082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-19392676-3828-4c04-ac97-bf400f58a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-52036ac0-d020-46d9-a49e-cefa123c048a,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-9a4d95c8-a2fc-46c4-92a2-541c61dada30,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-6bb31a67-25d7-4d8f-952f-9f74a1ef38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-ed57df53-b730-468b-9992-eef5ff54666e,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-12d9affa-7fe9-4a19-9b94-347e4d0d897c,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cdaca34f-6555-46da-b5dd-2d2770547f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-abe6203d-1522-4e96-91bc-57b35b1688d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051095073-172.17.0.14-1598637197082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-19392676-3828-4c04-ac97-bf400f58a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-52036ac0-d020-46d9-a49e-cefa123c048a,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-9a4d95c8-a2fc-46c4-92a2-541c61dada30,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-6bb31a67-25d7-4d8f-952f-9f74a1ef38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-ed57df53-b730-468b-9992-eef5ff54666e,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-12d9affa-7fe9-4a19-9b94-347e4d0d897c,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cdaca34f-6555-46da-b5dd-2d2770547f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-abe6203d-1522-4e96-91bc-57b35b1688d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657211971-172.17.0.14-1598637305530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-01055e1b-2bb2-4311-8753-fbbf74994afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-734faf47-5316-419e-88bf-471f4b589962,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-e83f1570-ea53-4197-9386-4b73663567d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-c733ae32-5a1b-4bd9-873d-b2e9896b5a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-3c8cced0-3b02-4bfd-8d01-7daf69fccf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ed3d5685-3a36-4229-9b97-fd73433c71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-7c466fa8-3546-4d3b-931e-4f691b55145a,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-dbe372bb-481e-4eb5-9099-4eecbe5bf4c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657211971-172.17.0.14-1598637305530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-01055e1b-2bb2-4311-8753-fbbf74994afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-734faf47-5316-419e-88bf-471f4b589962,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-e83f1570-ea53-4197-9386-4b73663567d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-c733ae32-5a1b-4bd9-873d-b2e9896b5a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-3c8cced0-3b02-4bfd-8d01-7daf69fccf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ed3d5685-3a36-4229-9b97-fd73433c71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-7c466fa8-3546-4d3b-931e-4f691b55145a,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-dbe372bb-481e-4eb5-9099-4eecbe5bf4c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070238144-172.17.0.14-1598637402869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-dcbe3f85-3843-491a-9ee3-48f5f4919dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-03b09971-df98-4fba-a14c-9ca7b934ad9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-068cdcf4-5a5d-4966-ac5b-60286986a058,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-486395b0-b7a1-4cf3-b244-ad4402243118,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-1ae47b68-3000-4164-95fb-90a96ce86b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-94da0596-1918-475f-abaf-0fa04d7ed876,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-370fc61b-b86c-4bf6-81a5-8be2f53ae901,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-2d8b2b21-b19c-4da8-8074-31cfbd45eeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070238144-172.17.0.14-1598637402869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-dcbe3f85-3843-491a-9ee3-48f5f4919dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-03b09971-df98-4fba-a14c-9ca7b934ad9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-068cdcf4-5a5d-4966-ac5b-60286986a058,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-486395b0-b7a1-4cf3-b244-ad4402243118,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-1ae47b68-3000-4164-95fb-90a96ce86b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-94da0596-1918-475f-abaf-0fa04d7ed876,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-370fc61b-b86c-4bf6-81a5-8be2f53ae901,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-2d8b2b21-b19c-4da8-8074-31cfbd45eeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269473228-172.17.0.14-1598638135057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-db7c4fc6-d32c-46a5-bc6e-8351a197e27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-4640995c-d5fe-45a9-a41e-b81b63242446,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-97e5abd7-2a65-4473-bb21-4196b43dc425,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0fd6cbcd-72a0-4ad3-8821-fe7eeab213be,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-cfad605c-5b0b-4b1a-a880-19d051632e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-ce5d5f93-fd62-4b6f-ba88-9a4af399863a,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-8bfc5112-be0b-47cb-887a-a6c1e5ad6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9a796226-7ddc-4b4f-bf54-20e220cafd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269473228-172.17.0.14-1598638135057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33188,DS-db7c4fc6-d32c-46a5-bc6e-8351a197e27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-4640995c-d5fe-45a9-a41e-b81b63242446,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-97e5abd7-2a65-4473-bb21-4196b43dc425,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0fd6cbcd-72a0-4ad3-8821-fe7eeab213be,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-cfad605c-5b0b-4b1a-a880-19d051632e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-ce5d5f93-fd62-4b6f-ba88-9a4af399863a,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-8bfc5112-be0b-47cb-887a-a6c1e5ad6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9a796226-7ddc-4b4f-bf54-20e220cafd16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82206626-172.17.0.14-1598638442558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-a4a6b52c-6a8a-484b-bc3f-5824417ebb79,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-ad1c1f27-1e20-44ca-9405-b8303a4ce15a,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-27738026-3dd8-4335-89f6-2c1948153813,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-347da84d-3493-4b97-8555-41e7585c36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-33cf651c-ad5d-46c9-8b7f-67f1a90ec62d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-99034dbb-199d-41d4-9740-fa830de0e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-79e0d2ff-ba83-4dca-97ad-a61165cc237d,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-8e4ea546-08e2-4a27-8bb6-8081d8da8fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82206626-172.17.0.14-1598638442558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-a4a6b52c-6a8a-484b-bc3f-5824417ebb79,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-ad1c1f27-1e20-44ca-9405-b8303a4ce15a,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-27738026-3dd8-4335-89f6-2c1948153813,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-347da84d-3493-4b97-8555-41e7585c36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-33cf651c-ad5d-46c9-8b7f-67f1a90ec62d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-99034dbb-199d-41d4-9740-fa830de0e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-79e0d2ff-ba83-4dca-97ad-a61165cc237d,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-8e4ea546-08e2-4a27-8bb6-8081d8da8fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428574549-172.17.0.14-1598638592978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-8afcdf1a-6976-4a9e-856e-fc5504dc1130,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-6bea0782-caf1-4f43-b20b-07088015176b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-0b4387ce-b142-4e53-b9bd-bf115d561b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-938565fa-c1ae-4d27-95a2-9314e798b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-5ae8395c-84e5-4a29-bdb4-083025c0ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-7da9d641-093b-4a93-aebb-1b87599db760,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-7ea6c5bb-0d41-4d72-865c-b7edd882db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-56f01214-357d-4df7-9562-8930947ea635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428574549-172.17.0.14-1598638592978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-8afcdf1a-6976-4a9e-856e-fc5504dc1130,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-6bea0782-caf1-4f43-b20b-07088015176b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-0b4387ce-b142-4e53-b9bd-bf115d561b05,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-938565fa-c1ae-4d27-95a2-9314e798b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-5ae8395c-84e5-4a29-bdb4-083025c0ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-7da9d641-093b-4a93-aebb-1b87599db760,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-7ea6c5bb-0d41-4d72-865c-b7edd882db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-56f01214-357d-4df7-9562-8930947ea635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178526853-172.17.0.14-1598639122973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-35dda475-42d5-4e38-bf95-46bb96c6ea39,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-98c2e21e-26a9-4622-941c-0bf871417cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-2eadff96-90e2-4daf-9bbf-b7da814b0f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-9ec5865d-0f1b-4667-b324-9d163015e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-409ed423-e4dd-41fa-888d-dbe541d7fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-741accfa-2ea1-48af-8db0-9519e3d02b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-45507bfd-f050-4c09-8225-382557b9248e,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-2ae8e79e-8422-48f7-9061-bbebe1ac4e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178526853-172.17.0.14-1598639122973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-35dda475-42d5-4e38-bf95-46bb96c6ea39,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-98c2e21e-26a9-4622-941c-0bf871417cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-2eadff96-90e2-4daf-9bbf-b7da814b0f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-9ec5865d-0f1b-4667-b324-9d163015e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-409ed423-e4dd-41fa-888d-dbe541d7fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-741accfa-2ea1-48af-8db0-9519e3d02b58,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-45507bfd-f050-4c09-8225-382557b9248e,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-2ae8e79e-8422-48f7-9061-bbebe1ac4e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321695946-172.17.0.14-1598639390386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-ad20a229-08b6-4657-9f1f-56632972beeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f2b80adf-b44a-43df-b38d-3fa2e5720707,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0ccbe0c6-6abf-46bd-937f-d1362c48e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-b4955642-eb71-4657-a5f3-90f4a6857ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-124cba26-5975-4bbb-a9dd-2dbe7ce22a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-456f0c45-7259-4317-9472-5fb6e8d9b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-529a7f02-6b3d-46fe-b966-4e5b665bd603,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-63aa4424-4b38-4549-8da2-b91561602539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321695946-172.17.0.14-1598639390386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-ad20a229-08b6-4657-9f1f-56632972beeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f2b80adf-b44a-43df-b38d-3fa2e5720707,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0ccbe0c6-6abf-46bd-937f-d1362c48e09a,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-b4955642-eb71-4657-a5f3-90f4a6857ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-124cba26-5975-4bbb-a9dd-2dbe7ce22a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-456f0c45-7259-4317-9472-5fb6e8d9b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-529a7f02-6b3d-46fe-b966-4e5b665bd603,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-63aa4424-4b38-4549-8da2-b91561602539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101421990-172.17.0.14-1598640131323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-0ef9a2a8-c564-4f88-ae58-8d6908df34dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-43b9d939-29bf-4e5f-9406-3cb8a2f41e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-0abfa05f-07fa-4cbc-9160-24792a2383ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-2ac70cdb-e1d7-4659-bc29-5a5e693f3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-128e0631-bf4d-4b23-8338-76ab69e87e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-273397fc-8bb9-4a2b-a90e-e2ca34020c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-7ad3613b-da1a-4819-9ab9-e6fb3a1f2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-5c7abfe0-1548-49bd-83be-5ecfa0d08d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101421990-172.17.0.14-1598640131323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-0ef9a2a8-c564-4f88-ae58-8d6908df34dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-43b9d939-29bf-4e5f-9406-3cb8a2f41e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-0abfa05f-07fa-4cbc-9160-24792a2383ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-2ac70cdb-e1d7-4659-bc29-5a5e693f3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-128e0631-bf4d-4b23-8338-76ab69e87e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-273397fc-8bb9-4a2b-a90e-e2ca34020c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-7ad3613b-da1a-4819-9ab9-e6fb3a1f2ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-5c7abfe0-1548-49bd-83be-5ecfa0d08d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666347533-172.17.0.14-1598640172991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-391445a8-c6b2-4abd-ad55-378ae0aeef45,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-65b00bae-7549-4de9-962b-de9f667b3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-e1e8e3cb-6e66-47e9-a368-94bf4d5f3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-897f92f5-152f-4ca2-b6b1-a40084576301,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-0b1895cb-01a7-4c8e-bb17-afa576c2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-3cb4ea5d-e413-45f2-b050-ce5d2534a020,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-13b84c07-8e9e-4b61-96e6-49747a9b9406,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-36b48949-f065-4ed3-90a0-1d977ddab37d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666347533-172.17.0.14-1598640172991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-391445a8-c6b2-4abd-ad55-378ae0aeef45,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-65b00bae-7549-4de9-962b-de9f667b3aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-e1e8e3cb-6e66-47e9-a368-94bf4d5f3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-897f92f5-152f-4ca2-b6b1-a40084576301,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-0b1895cb-01a7-4c8e-bb17-afa576c2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-3cb4ea5d-e413-45f2-b050-ce5d2534a020,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-13b84c07-8e9e-4b61-96e6-49747a9b9406,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-36b48949-f065-4ed3-90a0-1d977ddab37d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11915026-172.17.0.14-1598640543655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-678f6212-0f60-4ad4-a8b1-5da0468a8881,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-c4bdbf19-efb6-4253-bb17-b9a92e95eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-05c39b90-6b5d-4bb2-80fd-cf97fe91c016,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-3b357ae2-e23e-4c0f-8f65-869b35351a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-a3fbc480-825d-405a-bf70-63165d4294bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-86b5a471-775a-45c2-9763-2359e29b4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-7211ed3f-9e93-46ef-b8f6-5602cf3ea2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-0caa9cd3-4fc7-4b69-81ee-9fcb8d69d3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11915026-172.17.0.14-1598640543655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-678f6212-0f60-4ad4-a8b1-5da0468a8881,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-c4bdbf19-efb6-4253-bb17-b9a92e95eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-05c39b90-6b5d-4bb2-80fd-cf97fe91c016,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-3b357ae2-e23e-4c0f-8f65-869b35351a70,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-a3fbc480-825d-405a-bf70-63165d4294bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-86b5a471-775a-45c2-9763-2359e29b4dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-7211ed3f-9e93-46ef-b8f6-5602cf3ea2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-0caa9cd3-4fc7-4b69-81ee-9fcb8d69d3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491605029-172.17.0.14-1598640653312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-a65ceb81-2c5b-458e-adc8-34bc964d6049,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-1b1a70bc-d3fc-4245-a5ba-76d199f8d3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-20a90cf2-3543-4627-bc55-50ec179268a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-465e8bc9-943e-4b7f-ba60-1d492600d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-45c22640-0292-41f9-a51b-373708e68a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-afc2253e-f764-4ed6-8ef5-8bbd1d5f031f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9d1b145a-f2b2-41a8-a525-7aabeb89f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-3aa2eb69-c2e6-42f5-9e3d-584d863f2063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491605029-172.17.0.14-1598640653312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-a65ceb81-2c5b-458e-adc8-34bc964d6049,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-1b1a70bc-d3fc-4245-a5ba-76d199f8d3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-20a90cf2-3543-4627-bc55-50ec179268a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-465e8bc9-943e-4b7f-ba60-1d492600d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-45c22640-0292-41f9-a51b-373708e68a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-afc2253e-f764-4ed6-8ef5-8bbd1d5f031f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9d1b145a-f2b2-41a8-a525-7aabeb89f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-3aa2eb69-c2e6-42f5-9e3d-584d863f2063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354272634-172.17.0.14-1598640695409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-2171e2e2-e9b7-4165-874a-ec36a9641d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-14b4c460-b1c1-4193-aa4a-cdda42ecf451,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-f03ecfd8-1b1c-486f-b4da-3eeb5f7824dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-cc9c2d59-36f0-4f26-9ecf-f70ca428f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8c720655-9178-441a-8960-b6ad1a02a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-56268eac-19b8-49ab-b025-b9dd30f9ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-f2f3774c-d6f1-4d05-b817-d68b01ebc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-aa1593aa-991e-4b85-bcca-d0481456214c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354272634-172.17.0.14-1598640695409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44017,DS-2171e2e2-e9b7-4165-874a-ec36a9641d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-14b4c460-b1c1-4193-aa4a-cdda42ecf451,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-f03ecfd8-1b1c-486f-b4da-3eeb5f7824dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-cc9c2d59-36f0-4f26-9ecf-f70ca428f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8c720655-9178-441a-8960-b6ad1a02a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-56268eac-19b8-49ab-b025-b9dd30f9ac09,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-f2f3774c-d6f1-4d05-b817-d68b01ebc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-aa1593aa-991e-4b85-bcca-d0481456214c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632623843-172.17.0.14-1598641020681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-45e8dca8-d6a8-47a6-af64-ec73d25711d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-08a5100f-d563-4c76-8779-7a5bfa888143,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-a6638e3e-2fbb-40d9-a932-290d97fde4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-53d23e6d-5a26-419e-958e-f5d71dfbd885,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-f0a560ea-4c4e-404d-b5da-12ce76ba4731,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-1455cb9c-f41c-4ce8-b949-e2a5467e6a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f7e43388-4e8d-49c4-ba6a-00f5e26668d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f27b96b9-924d-47af-bfda-1d4af4298c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632623843-172.17.0.14-1598641020681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-45e8dca8-d6a8-47a6-af64-ec73d25711d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-08a5100f-d563-4c76-8779-7a5bfa888143,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-a6638e3e-2fbb-40d9-a932-290d97fde4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-53d23e6d-5a26-419e-958e-f5d71dfbd885,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-f0a560ea-4c4e-404d-b5da-12ce76ba4731,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-1455cb9c-f41c-4ce8-b949-e2a5467e6a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-f7e43388-4e8d-49c4-ba6a-00f5e26668d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f27b96b9-924d-47af-bfda-1d4af4298c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327348475-172.17.0.14-1598641294708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-6409e30e-9c69-4ad6-8c3e-0196298754da,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-43af9ee6-1d92-46cc-8580-14fad4eb23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-314a139c-b9ae-4f29-bd61-6c43d9dbf4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-669d1f54-554d-4f45-b286-bdddd847a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-19c3bd9a-6484-466b-9504-40d72c8e1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-7582e4f5-bbb8-407f-b348-0b38d59ac80c,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-28a56811-e52b-4b28-8fe7-eb60a334a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-46136612-462f-4af4-8ebb-78965f51eb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327348475-172.17.0.14-1598641294708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-6409e30e-9c69-4ad6-8c3e-0196298754da,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-43af9ee6-1d92-46cc-8580-14fad4eb23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-314a139c-b9ae-4f29-bd61-6c43d9dbf4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-669d1f54-554d-4f45-b286-bdddd847a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-19c3bd9a-6484-466b-9504-40d72c8e1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-7582e4f5-bbb8-407f-b348-0b38d59ac80c,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-28a56811-e52b-4b28-8fe7-eb60a334a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-46136612-462f-4af4-8ebb-78965f51eb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848943583-172.17.0.14-1598641439857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-6f905d7d-5490-47a3-aa35-8a2f35bbac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-f6a61f54-53b8-44ce-852e-c531e9a9f716,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-8992210a-be47-4975-b45b-6ed692d0af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-2a103056-5405-4cd6-8302-6358afc91c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-9e1d32c5-a334-4efe-9ae6-fbb380f971c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-50d40f4b-4692-44fb-aa63-b8ec8873923c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-4304f871-69c2-4c72-84ba-e3c67f784a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-429dbdc0-535a-4028-82af-51318dbeb759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848943583-172.17.0.14-1598641439857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-6f905d7d-5490-47a3-aa35-8a2f35bbac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-f6a61f54-53b8-44ce-852e-c531e9a9f716,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-8992210a-be47-4975-b45b-6ed692d0af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-2a103056-5405-4cd6-8302-6358afc91c77,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-9e1d32c5-a334-4efe-9ae6-fbb380f971c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-50d40f4b-4692-44fb-aa63-b8ec8873923c,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-4304f871-69c2-4c72-84ba-e3c67f784a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-429dbdc0-535a-4028-82af-51318dbeb759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957197319-172.17.0.14-1598641708438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42977,DS-0ff831e0-b5e8-4aa2-adb5-cb865eff3526,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-5bab4c6d-e900-4784-bd55-dd5109f6eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-7b759797-bf41-4133-86ad-83c82da81902,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-73b6710f-6461-4d0c-874c-35d8d7a3bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-fd39a004-4b36-487d-9212-5729f63da8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-e23eefd6-27cc-416e-87c0-b1d4544244dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-2931081d-0da3-436d-b2e1-efa4b282d6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-9c77c9a2-70d6-42f7-8fad-e96441e9a6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957197319-172.17.0.14-1598641708438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42977,DS-0ff831e0-b5e8-4aa2-adb5-cb865eff3526,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-5bab4c6d-e900-4784-bd55-dd5109f6eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-7b759797-bf41-4133-86ad-83c82da81902,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-73b6710f-6461-4d0c-874c-35d8d7a3bf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-fd39a004-4b36-487d-9212-5729f63da8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-e23eefd6-27cc-416e-87c0-b1d4544244dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-2931081d-0da3-436d-b2e1-efa4b282d6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-9c77c9a2-70d6-42f7-8fad-e96441e9a6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910630830-172.17.0.14-1598641745857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41689,DS-99993910-b299-47b4-acc5-8db06598ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-0bb9131e-bf70-4075-8afc-ab4d6086660b,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-22027d09-4c35-48da-badc-fccea3016e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-d535df1a-bd81-4379-9e3b-b1e2afa91fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-2d133e2a-e233-4f3e-ba3e-2153a7a21492,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-c9e3ec52-4663-40f9-bd39-5829ca476fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-2e4b7f1e-5d02-4ddf-bc33-7cec43656f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-cd48afe5-234f-4ab5-938f-08f8718c4ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910630830-172.17.0.14-1598641745857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41689,DS-99993910-b299-47b4-acc5-8db06598ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-0bb9131e-bf70-4075-8afc-ab4d6086660b,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-22027d09-4c35-48da-badc-fccea3016e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-d535df1a-bd81-4379-9e3b-b1e2afa91fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-2d133e2a-e233-4f3e-ba3e-2153a7a21492,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-c9e3ec52-4663-40f9-bd39-5829ca476fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-2e4b7f1e-5d02-4ddf-bc33-7cec43656f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-cd48afe5-234f-4ab5-938f-08f8718c4ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325213126-172.17.0.14-1598641821473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-68139843-1fda-4f24-9244-93dc2c1ae7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-d301b134-1955-48fe-b284-5e2c9cb688c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-12d73b48-6026-40c2-9dfb-ad52f6838185,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-669f9c06-ec50-45c3-a543-2b1a1ff2133e,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-8d56d330-4e49-42f1-a576-42815257229f,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-241de1d7-f5d7-42e1-81f6-c96342aaf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d8506750-f7b5-4dc9-b199-52e1340dfa38,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-1bf2d14e-c9e8-4296-9936-ae6cac5b4e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325213126-172.17.0.14-1598641821473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-68139843-1fda-4f24-9244-93dc2c1ae7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-d301b134-1955-48fe-b284-5e2c9cb688c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-12d73b48-6026-40c2-9dfb-ad52f6838185,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-669f9c06-ec50-45c3-a543-2b1a1ff2133e,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-8d56d330-4e49-42f1-a576-42815257229f,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-241de1d7-f5d7-42e1-81f6-c96342aaf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d8506750-f7b5-4dc9-b199-52e1340dfa38,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-1bf2d14e-c9e8-4296-9936-ae6cac5b4e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5426
