reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771699705-172.17.0.20-1598699356567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-56234d66-97f7-4092-b535-9811ce1054da,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-a3fb0c5c-5853-45ed-93c0-4fb92d44ce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a664ff99-0fe0-4031-b73e-9879121b830f,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-db81dc13-06f8-497e-acf6-7f2348b3c55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-4f7c614b-c03f-406c-83c0-ca240a277e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-caa2fe72-496c-46f1-84dd-bbb1a5fb50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-030f3c99-ce0f-4b80-9944-8d8622fd3245,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-fb5f8d09-202f-4634-b267-33c0d3193e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771699705-172.17.0.20-1598699356567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-56234d66-97f7-4092-b535-9811ce1054da,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-a3fb0c5c-5853-45ed-93c0-4fb92d44ce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a664ff99-0fe0-4031-b73e-9879121b830f,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-db81dc13-06f8-497e-acf6-7f2348b3c55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-4f7c614b-c03f-406c-83c0-ca240a277e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-caa2fe72-496c-46f1-84dd-bbb1a5fb50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-030f3c99-ce0f-4b80-9944-8d8622fd3245,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-fb5f8d09-202f-4634-b267-33c0d3193e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116577633-172.17.0.20-1598699509611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-2880e1f1-f2cc-4edc-9290-5baebf45b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-261bdedc-eefc-4792-8f9a-cdc794cf6284,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-c2a0e0ce-e25a-47bf-99c8-dae40f972582,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-4d3a2bba-3cd3-408b-aee6-58168aec3049,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-8641a9ef-904d-44a6-ab53-ebe83b70781a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-5bf4aca9-d10c-4c37-9874-ef723e1574c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-80a82b8d-bde9-4513-972f-69cb8082ee9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-2eb38087-908f-4beb-9ba8-35e6a4e54575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116577633-172.17.0.20-1598699509611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-2880e1f1-f2cc-4edc-9290-5baebf45b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-261bdedc-eefc-4792-8f9a-cdc794cf6284,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-c2a0e0ce-e25a-47bf-99c8-dae40f972582,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-4d3a2bba-3cd3-408b-aee6-58168aec3049,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-8641a9ef-904d-44a6-ab53-ebe83b70781a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-5bf4aca9-d10c-4c37-9874-ef723e1574c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-80a82b8d-bde9-4513-972f-69cb8082ee9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-2eb38087-908f-4beb-9ba8-35e6a4e54575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087707073-172.17.0.20-1598699720260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-27fa9f4d-8b6f-4dac-bb10-29a2e47b4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-68da411f-3f7a-4b6d-9b04-c5e299d9608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-35e2a67f-56c5-453d-9be1-0648c36e5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-61b19239-7eb6-469a-b7f8-f3e20235cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-553f9663-a8c5-4beb-a78a-24d785884d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-9bb569fa-a4b6-4fcd-93fc-786f628b48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-9d497dd5-7810-49a0-9eac-d72d3afb69eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-b60a4a0d-85dc-4769-9547-26c8d3bfab09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087707073-172.17.0.20-1598699720260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-27fa9f4d-8b6f-4dac-bb10-29a2e47b4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-68da411f-3f7a-4b6d-9b04-c5e299d9608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-35e2a67f-56c5-453d-9be1-0648c36e5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-61b19239-7eb6-469a-b7f8-f3e20235cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-553f9663-a8c5-4beb-a78a-24d785884d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-9bb569fa-a4b6-4fcd-93fc-786f628b48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-9d497dd5-7810-49a0-9eac-d72d3afb69eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-b60a4a0d-85dc-4769-9547-26c8d3bfab09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529790443-172.17.0.20-1598699751889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-2d1f4802-b6b5-4d14-835d-d5c9ffe7712c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d535108e-274a-4428-baf5-7aca7c56da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-c4b9eecb-bb21-4aee-98dd-e4c0bcd65a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-2107b172-2b3f-492a-806f-4c2ed296a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-71d22d50-78c8-4485-afab-dea1b255dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-df88a1af-004f-440d-a90a-76224b916e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5b19cce4-5849-4168-a5a1-78fbc7455123,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-fb076892-2eab-4b03-b419-8da5b2b35cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529790443-172.17.0.20-1598699751889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-2d1f4802-b6b5-4d14-835d-d5c9ffe7712c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d535108e-274a-4428-baf5-7aca7c56da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-c4b9eecb-bb21-4aee-98dd-e4c0bcd65a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-2107b172-2b3f-492a-806f-4c2ed296a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-71d22d50-78c8-4485-afab-dea1b255dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-df88a1af-004f-440d-a90a-76224b916e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5b19cce4-5849-4168-a5a1-78fbc7455123,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-fb076892-2eab-4b03-b419-8da5b2b35cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289375253-172.17.0.20-1598700251672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-a41601b2-1877-44a8-a54b-fd4b22887d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-6c159fa1-e7dd-4829-88bc-9fe08e3feac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-f171269b-ea9f-436c-89e2-67d0d41dcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-c12a0baf-364d-4e23-81b5-d5c815718e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-124ae766-42cb-49fa-b185-c26a20061386,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-0e0f20fc-636a-40d3-be9d-8200b1059ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-56adcb0c-02c7-446b-96e2-644495706df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-8849e141-bd47-4489-ab2d-cdcdf73dee31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289375253-172.17.0.20-1598700251672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-a41601b2-1877-44a8-a54b-fd4b22887d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-6c159fa1-e7dd-4829-88bc-9fe08e3feac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-f171269b-ea9f-436c-89e2-67d0d41dcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-c12a0baf-364d-4e23-81b5-d5c815718e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-124ae766-42cb-49fa-b185-c26a20061386,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-0e0f20fc-636a-40d3-be9d-8200b1059ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-56adcb0c-02c7-446b-96e2-644495706df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-8849e141-bd47-4489-ab2d-cdcdf73dee31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682529548-172.17.0.20-1598700830608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-7e803835-b475-4797-b6f3-8929aed30158,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-0faa2d13-d4b9-42fb-b1ad-4c007bc76a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-049462ed-9ddb-43ec-b183-946629efb903,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d89c5141-db28-4b19-84b4-b22f547b9607,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-5914f501-5fb8-44d4-b079-4f9bf2c3c423,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-4f98b923-1c16-4814-8623-f028467b27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-6884f56a-d137-41f3-a153-a6e648549e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-41f4a20c-011b-451a-8c94-3fcf4224fc94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682529548-172.17.0.20-1598700830608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-7e803835-b475-4797-b6f3-8929aed30158,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-0faa2d13-d4b9-42fb-b1ad-4c007bc76a41,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-049462ed-9ddb-43ec-b183-946629efb903,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d89c5141-db28-4b19-84b4-b22f547b9607,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-5914f501-5fb8-44d4-b079-4f9bf2c3c423,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-4f98b923-1c16-4814-8623-f028467b27e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-6884f56a-d137-41f3-a153-a6e648549e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-41f4a20c-011b-451a-8c94-3fcf4224fc94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545604272-172.17.0.20-1598701382786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-4f35ba5a-78ee-4b28-8791-0be4a8aa7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-d2a2c301-2e12-4fab-b7d8-dd2e327351b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-74c77ec7-241f-44b0-8fe7-fcce5391919d,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-cb8730a9-ba62-4501-8b59-ea582eccce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-396c338f-d005-47b6-88af-4af6ec755f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-79786fea-3de4-4e25-993f-c576a2d2a699,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a4c196db-2ef6-4284-89d0-0e57d4f1b0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-d57165bc-da7c-440b-9c6d-6fe12c0b7238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545604272-172.17.0.20-1598701382786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43411,DS-4f35ba5a-78ee-4b28-8791-0be4a8aa7d85,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-d2a2c301-2e12-4fab-b7d8-dd2e327351b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-74c77ec7-241f-44b0-8fe7-fcce5391919d,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-cb8730a9-ba62-4501-8b59-ea582eccce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-396c338f-d005-47b6-88af-4af6ec755f78,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-79786fea-3de4-4e25-993f-c576a2d2a699,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-a4c196db-2ef6-4284-89d0-0e57d4f1b0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-d57165bc-da7c-440b-9c6d-6fe12c0b7238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365865614-172.17.0.20-1598701498627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-8176d750-3452-4908-8fcb-cd0e4302cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-6d305094-26c3-483c-bad1-9a6bb9c52a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-1272a8f5-4375-48f4-b0ea-dab107390507,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-99e45b1f-e732-4b93-84b4-e43c734ef82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-bcee1e4e-d501-41d5-87e9-7d2bd06ba966,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-0938f47e-9207-41bc-95e0-4682a90fee26,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-cb31efcb-d628-45a1-9781-015b7b6d76b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-dcc80a8d-1c29-4c21-9a5c-1b0ce97ec669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365865614-172.17.0.20-1598701498627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-8176d750-3452-4908-8fcb-cd0e4302cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-6d305094-26c3-483c-bad1-9a6bb9c52a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-1272a8f5-4375-48f4-b0ea-dab107390507,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-99e45b1f-e732-4b93-84b4-e43c734ef82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-bcee1e4e-d501-41d5-87e9-7d2bd06ba966,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-0938f47e-9207-41bc-95e0-4682a90fee26,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-cb31efcb-d628-45a1-9781-015b7b6d76b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-dcc80a8d-1c29-4c21-9a5c-1b0ce97ec669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012723921-172.17.0.20-1598701844608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-af596b91-a39f-4006-b129-b73b30bda3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-9f4bc878-0b5c-40a3-b754-b55006605cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-abd40cf1-3009-4762-918f-4b019db29390,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3d67e5bf-f8aa-48d0-95a0-b94470b8bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-38b25a0e-c621-49af-b329-a39db684e448,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-1d51630e-6adb-4483-9611-667f55bf5d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-e39e3c33-2452-418e-b32e-83dfdc1266ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-15609c5f-306a-4ec3-896f-6d62c6536576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012723921-172.17.0.20-1598701844608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36060,DS-af596b91-a39f-4006-b129-b73b30bda3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-9f4bc878-0b5c-40a3-b754-b55006605cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-abd40cf1-3009-4762-918f-4b019db29390,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3d67e5bf-f8aa-48d0-95a0-b94470b8bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-38b25a0e-c621-49af-b329-a39db684e448,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-1d51630e-6adb-4483-9611-667f55bf5d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-e39e3c33-2452-418e-b32e-83dfdc1266ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-15609c5f-306a-4ec3-896f-6d62c6536576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969702610-172.17.0.20-1598702056855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42023,DS-ab412f17-08b5-4fcc-88aa-ddd0574b9d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-870f74bc-4681-4291-89c8-52be2f536adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-492bbd1b-b124-4b2c-b2d5-3338a487ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9e17a90c-daa3-469e-b1d3-5ce6e8612f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-7c40b7fa-3a94-43b5-83ff-ed18fe03bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-4d0a0067-0696-450a-8738-b986b9542b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-20e90e9f-a403-49dc-9aa3-8a5126ea0d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ab6ff905-f9e5-4c52-ae4f-8fd5b4a31f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969702610-172.17.0.20-1598702056855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42023,DS-ab412f17-08b5-4fcc-88aa-ddd0574b9d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-870f74bc-4681-4291-89c8-52be2f536adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-492bbd1b-b124-4b2c-b2d5-3338a487ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9e17a90c-daa3-469e-b1d3-5ce6e8612f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-7c40b7fa-3a94-43b5-83ff-ed18fe03bccf,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-4d0a0067-0696-450a-8738-b986b9542b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-20e90e9f-a403-49dc-9aa3-8a5126ea0d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ab6ff905-f9e5-4c52-ae4f-8fd5b4a31f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822508194-172.17.0.20-1598702434030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-aab2a3a1-0d3a-4248-b563-82d1b390923d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-de7a6ec0-10f0-4854-a5b1-de1e957c1635,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-07627144-78ec-4e21-b88d-16b2ee8f90f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5d3f126d-c400-4cf0-92c9-1f00228b2779,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-9b69aa75-a9a5-48ff-830e-46a8ec880526,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-1baaf505-9d99-4612-8ed4-1b0547c72039,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-237937b3-567a-4ba7-bb37-19a3714aec00,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-3ab9416a-eda2-402f-9188-ca4b3813d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822508194-172.17.0.20-1598702434030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32795,DS-aab2a3a1-0d3a-4248-b563-82d1b390923d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-de7a6ec0-10f0-4854-a5b1-de1e957c1635,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-07627144-78ec-4e21-b88d-16b2ee8f90f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5d3f126d-c400-4cf0-92c9-1f00228b2779,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-9b69aa75-a9a5-48ff-830e-46a8ec880526,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-1baaf505-9d99-4612-8ed4-1b0547c72039,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-237937b3-567a-4ba7-bb37-19a3714aec00,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-3ab9416a-eda2-402f-9188-ca4b3813d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83802062-172.17.0.20-1598702533378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38274,DS-22c42a16-dbc2-4d1f-a7a8-9a24a34e88cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-07cb4798-1c8e-4c6f-a3e2-669c0850f257,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-2ea2211a-aced-4a2b-b111-ee05c06bf6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-986043fb-b45a-4110-a51e-802bbd849247,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-42d2b862-a5d7-479c-9384-77ecf5991bde,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-82b287d9-f533-4af1-8d58-9e6eb4e3b824,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-32451956-3e8a-419d-8cc3-e7ea53419322,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-44bf8590-fbc3-4f99-8fbd-1a99d4c5ade6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83802062-172.17.0.20-1598702533378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38274,DS-22c42a16-dbc2-4d1f-a7a8-9a24a34e88cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-07cb4798-1c8e-4c6f-a3e2-669c0850f257,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-2ea2211a-aced-4a2b-b111-ee05c06bf6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-986043fb-b45a-4110-a51e-802bbd849247,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-42d2b862-a5d7-479c-9384-77ecf5991bde,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-82b287d9-f533-4af1-8d58-9e6eb4e3b824,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-32451956-3e8a-419d-8cc3-e7ea53419322,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-44bf8590-fbc3-4f99-8fbd-1a99d4c5ade6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485087832-172.17.0.20-1598702648157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-7f82e83d-5de0-42e3-a0af-d7d34f9f2067,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e7fb9dfa-c81e-4eae-9992-7dd305db25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-73f75caf-3c32-4662-8ee0-f8194a8da1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-dbcb3e09-5fc8-435b-91e9-fa69c7f32aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-ad486b4f-80cd-45cf-a8a8-a4bd26342dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-57923ac2-712b-4986-bc75-080e81c4f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-19be1d5c-9900-47f8-9b48-48fe345ebabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-8f62b6c1-b8f8-4367-8376-b32aac113d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485087832-172.17.0.20-1598702648157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-7f82e83d-5de0-42e3-a0af-d7d34f9f2067,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e7fb9dfa-c81e-4eae-9992-7dd305db25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-73f75caf-3c32-4662-8ee0-f8194a8da1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-dbcb3e09-5fc8-435b-91e9-fa69c7f32aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-ad486b4f-80cd-45cf-a8a8-a4bd26342dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-57923ac2-712b-4986-bc75-080e81c4f4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-19be1d5c-9900-47f8-9b48-48fe345ebabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-8f62b6c1-b8f8-4367-8376-b32aac113d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 3782
