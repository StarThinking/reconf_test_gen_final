reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842136550-172.17.0.5-1598572033711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-8cb0871d-223b-4843-b131-91f1b2021651,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-174ac377-804d-4b3d-907a-e1443d9607a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-fe1e19b2-90f4-48ad-b07e-a75ec69a2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-4b890a13-7739-41f0-8926-64d7baf92a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-e159555c-470c-4651-96c6-16486653dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-6be44276-a227-4b81-b7d6-b81e8f025732,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-82ea174f-f408-4526-bb1e-9e4bbf0b6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-c70c9302-9ffc-4dfc-bb62-f96e2f2288cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842136550-172.17.0.5-1598572033711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-8cb0871d-223b-4843-b131-91f1b2021651,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-174ac377-804d-4b3d-907a-e1443d9607a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-fe1e19b2-90f4-48ad-b07e-a75ec69a2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-4b890a13-7739-41f0-8926-64d7baf92a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-e159555c-470c-4651-96c6-16486653dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-6be44276-a227-4b81-b7d6-b81e8f025732,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-82ea174f-f408-4526-bb1e-9e4bbf0b6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-c70c9302-9ffc-4dfc-bb62-f96e2f2288cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908581960-172.17.0.5-1598572143431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-e3f809cb-ef55-40e5-adbc-ab330b66b9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-bf3017b9-9e54-428a-bcea-79c2f6dff739,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-e04503a3-a5e4-4c99-a763-394db9a77f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-ad1817f1-3ac3-473c-bf73-c9ca55e9d141,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-0a2cc539-4e3f-4eb3-8307-a20168e874df,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-96165b3f-430b-433c-abc0-c01551639594,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-b69d7030-4918-4061-abe1-872ca2aae0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-c0e736db-afb8-4984-a5a3-a4162361cb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908581960-172.17.0.5-1598572143431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43229,DS-e3f809cb-ef55-40e5-adbc-ab330b66b9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-bf3017b9-9e54-428a-bcea-79c2f6dff739,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-e04503a3-a5e4-4c99-a763-394db9a77f55,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-ad1817f1-3ac3-473c-bf73-c9ca55e9d141,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-0a2cc539-4e3f-4eb3-8307-a20168e874df,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-96165b3f-430b-433c-abc0-c01551639594,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-b69d7030-4918-4061-abe1-872ca2aae0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-c0e736db-afb8-4984-a5a3-a4162361cb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196551480-172.17.0.5-1598572687310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-f0cb77e5-4dd7-4799-abc7-d2abf2d3aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bf067ab6-e3e8-4409-84fc-445275191fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-96fec4a1-9fa3-4d38-8037-ddfcb93582cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-49354b03-07f4-4b92-b956-70636e9600d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-2654763d-744a-40fd-8809-1e7e79121135,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-797044f9-d491-4866-916a-f3b41c3eee11,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-a68b1a69-1d2a-4757-94fb-1ff407ffc089,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-91078043-e5a8-4ef5-a129-f45082b58615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196551480-172.17.0.5-1598572687310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-f0cb77e5-4dd7-4799-abc7-d2abf2d3aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-bf067ab6-e3e8-4409-84fc-445275191fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-96fec4a1-9fa3-4d38-8037-ddfcb93582cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-49354b03-07f4-4b92-b956-70636e9600d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-2654763d-744a-40fd-8809-1e7e79121135,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-797044f9-d491-4866-916a-f3b41c3eee11,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-a68b1a69-1d2a-4757-94fb-1ff407ffc089,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-91078043-e5a8-4ef5-a129-f45082b58615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628700827-172.17.0.5-1598573166961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-863b6d88-cfdb-45e1-8f59-f143610cff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-eaee1c3a-67ee-4f7a-8a76-8160d08aecbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-86775caf-6ffb-4476-82d3-379c8cc8e041,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-dcc35f64-e183-4add-b5bd-e4662b06c671,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-525c4c63-44fa-4c73-ac8e-f8dfa63ce6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-2e9bed94-69dc-416f-b87e-c4048b2b6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-a313db84-e1a7-4791-885e-c28b68e2dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-97446e47-f97c-4fb2-aab0-ddc70ca3783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628700827-172.17.0.5-1598573166961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-863b6d88-cfdb-45e1-8f59-f143610cff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-eaee1c3a-67ee-4f7a-8a76-8160d08aecbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-86775caf-6ffb-4476-82d3-379c8cc8e041,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-dcc35f64-e183-4add-b5bd-e4662b06c671,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-525c4c63-44fa-4c73-ac8e-f8dfa63ce6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-2e9bed94-69dc-416f-b87e-c4048b2b6c33,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-a313db84-e1a7-4791-885e-c28b68e2dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-97446e47-f97c-4fb2-aab0-ddc70ca3783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093887008-172.17.0.5-1598573238901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39925,DS-3d86456e-d384-4abe-8147-82d8e93e0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-62c8048b-2e73-4c18-9f93-32374cb72c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-e0438fc4-907f-4806-8005-7c30098ecd68,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-aeb37b69-44b9-4d09-a432-a6275257f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7ac1f698-ea9d-4605-ad61-3c1eb8cd604b,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-5d8cfd30-c15b-4733-a1af-50d1f1b3ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-b5bd0e6d-b754-4cf4-b7ea-7a82477495c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-9fd8865b-c035-48a8-a332-1b33b04ef288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093887008-172.17.0.5-1598573238901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39925,DS-3d86456e-d384-4abe-8147-82d8e93e0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-62c8048b-2e73-4c18-9f93-32374cb72c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-e0438fc4-907f-4806-8005-7c30098ecd68,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-aeb37b69-44b9-4d09-a432-a6275257f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7ac1f698-ea9d-4605-ad61-3c1eb8cd604b,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-5d8cfd30-c15b-4733-a1af-50d1f1b3ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-b5bd0e6d-b754-4cf4-b7ea-7a82477495c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-9fd8865b-c035-48a8-a332-1b33b04ef288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326999894-172.17.0.5-1598573268381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-1a2a0f41-cc08-45f1-b3aa-732fb96f8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-3602cb30-ff34-4bd2-850d-bc5e803bf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-e2d2a36c-7bc1-4df9-aad5-44326f573b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-42d9c998-435f-49d5-bb54-aaeac5aa419f,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-55b97e22-2d8f-4c96-a0fb-ca729e556401,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-59022cac-0067-4b13-bb71-09cfbb11ced0,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-03a7f6c0-750d-4d51-a10e-fe70fecc9cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-13ddd264-3fc5-486d-aba4-ffb6939c0add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326999894-172.17.0.5-1598573268381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-1a2a0f41-cc08-45f1-b3aa-732fb96f8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-3602cb30-ff34-4bd2-850d-bc5e803bf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-e2d2a36c-7bc1-4df9-aad5-44326f573b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-42d9c998-435f-49d5-bb54-aaeac5aa419f,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-55b97e22-2d8f-4c96-a0fb-ca729e556401,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-59022cac-0067-4b13-bb71-09cfbb11ced0,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-03a7f6c0-750d-4d51-a10e-fe70fecc9cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-13ddd264-3fc5-486d-aba4-ffb6939c0add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638390120-172.17.0.5-1598573566303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-3239b9f2-ed36-4fe5-b3e7-59cb29258e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-8bb92be8-e8dd-4768-9d36-a66a710cc4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-b881baa9-e4b5-4c0b-b76a-c0854715ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-84dacbcc-7d72-4478-b5e1-d058375c20d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-8b648120-d194-4cf5-aec4-7bd485238c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-c23e18e0-b503-4583-a09f-fc7b96abcebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-238c9f38-e16f-4a8c-a306-b35876ac679e,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e016b210-5f0a-4230-ad8d-ab407934ef92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638390120-172.17.0.5-1598573566303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-3239b9f2-ed36-4fe5-b3e7-59cb29258e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-8bb92be8-e8dd-4768-9d36-a66a710cc4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-b881baa9-e4b5-4c0b-b76a-c0854715ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-84dacbcc-7d72-4478-b5e1-d058375c20d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-8b648120-d194-4cf5-aec4-7bd485238c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-c23e18e0-b503-4583-a09f-fc7b96abcebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-238c9f38-e16f-4a8c-a306-b35876ac679e,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e016b210-5f0a-4230-ad8d-ab407934ef92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665937474-172.17.0.5-1598573993673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-ab3a84d1-6c32-41bb-b0b0-b9f2679725b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-3d86e4ea-3675-4c6b-bb64-9d2e04f497c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-16f03de4-652a-4147-bdde-af8da49a1fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-dec09c73-25e2-40c1-b204-42205bab7615,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-b8dc36d0-e76f-439d-9a70-5ecd01b4b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-41ce3e6f-3c65-4829-8519-128dc9b071ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-392e4c94-fdd2-4129-9862-8b8c039ddbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-31fa36bd-f081-4efa-96ed-00d81ceebf18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665937474-172.17.0.5-1598573993673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45901,DS-ab3a84d1-6c32-41bb-b0b0-b9f2679725b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-3d86e4ea-3675-4c6b-bb64-9d2e04f497c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-16f03de4-652a-4147-bdde-af8da49a1fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-dec09c73-25e2-40c1-b204-42205bab7615,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-b8dc36d0-e76f-439d-9a70-5ecd01b4b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-41ce3e6f-3c65-4829-8519-128dc9b071ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-392e4c94-fdd2-4129-9862-8b8c039ddbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-31fa36bd-f081-4efa-96ed-00d81ceebf18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308786819-172.17.0.5-1598574239868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-a9f10ac2-b4b3-4e9d-b992-6b97b26f1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-aef7e833-a7a9-4fdb-8434-05398a264ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-efb42ec8-9eb7-412d-a64d-add84a7a78ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-794e1b00-3a40-4948-bdb9-89fcf6056ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-2df4e119-4303-44ae-8201-f4a2b0ce6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-e36fe6e3-798a-4885-94a5-fafc7b8746c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-a1e6040f-018e-4d48-9f3e-2832c8ff5021,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ef140eeb-df98-4528-b2ac-86a0216d748b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308786819-172.17.0.5-1598574239868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-a9f10ac2-b4b3-4e9d-b992-6b97b26f1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-aef7e833-a7a9-4fdb-8434-05398a264ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-efb42ec8-9eb7-412d-a64d-add84a7a78ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-794e1b00-3a40-4948-bdb9-89fcf6056ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-2df4e119-4303-44ae-8201-f4a2b0ce6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-e36fe6e3-798a-4885-94a5-fafc7b8746c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-a1e6040f-018e-4d48-9f3e-2832c8ff5021,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ef140eeb-df98-4528-b2ac-86a0216d748b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 100
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649635401-172.17.0.5-1598574408311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-0a41de5b-c4a8-41fd-b76c-e5f3dda24ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-9d381bd4-5a59-4151-bd53-44505a2b7264,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-2d65ae2a-7e6f-4e88-b691-8657ebcfb06c,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-ccb6447a-3913-4854-bb8f-8fe9200ea760,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-ea6bbeec-80ee-4d2f-9f6f-3537e4caa197,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-f758efca-970b-496f-8d09-b4fc506b9231,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-ba8f630b-d070-4f75-a196-e8f6a0851c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-59cb1244-3311-45c6-9d84-93203fcd39d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649635401-172.17.0.5-1598574408311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-0a41de5b-c4a8-41fd-b76c-e5f3dda24ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-9d381bd4-5a59-4151-bd53-44505a2b7264,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-2d65ae2a-7e6f-4e88-b691-8657ebcfb06c,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-ccb6447a-3913-4854-bb8f-8fe9200ea760,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-ea6bbeec-80ee-4d2f-9f6f-3537e4caa197,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-f758efca-970b-496f-8d09-b4fc506b9231,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-ba8f630b-d070-4f75-a196-e8f6a0851c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-59cb1244-3311-45c6-9d84-93203fcd39d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5259
