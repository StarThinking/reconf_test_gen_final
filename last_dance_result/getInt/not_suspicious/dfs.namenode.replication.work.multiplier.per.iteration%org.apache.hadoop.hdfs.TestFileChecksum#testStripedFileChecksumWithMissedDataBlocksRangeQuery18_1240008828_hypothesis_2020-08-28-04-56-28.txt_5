reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771247126-172.17.0.3-1598590750948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-ffb6ea6c-1c3c-4ef0-9d64-a6addd6061b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-e948d1d4-7bcd-4a65-992b-c99ddab1dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-38b7afae-f581-46e8-8280-68ea4d77d9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-7c2be8a3-a369-455f-9a96-90676b00793c,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-7d99ea46-16ae-4ed9-994d-4979aa00cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-6c86f19b-65a9-438a-b907-603a76c0d265,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-01d9c6bc-e261-4a70-94a6-09e030f17e36,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3f080005-3b6e-4361-a373-95be2659e6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771247126-172.17.0.3-1598590750948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-ffb6ea6c-1c3c-4ef0-9d64-a6addd6061b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-e948d1d4-7bcd-4a65-992b-c99ddab1dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-38b7afae-f581-46e8-8280-68ea4d77d9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-7c2be8a3-a369-455f-9a96-90676b00793c,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-7d99ea46-16ae-4ed9-994d-4979aa00cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-6c86f19b-65a9-438a-b907-603a76c0d265,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-01d9c6bc-e261-4a70-94a6-09e030f17e36,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3f080005-3b6e-4361-a373-95be2659e6eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762685559-172.17.0.3-1598590880970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-146190d7-6b1c-410c-8e1f-edb4316a83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-dd1bfbeb-bf7f-45b1-9fcc-87f53b58f046,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-a836b606-df67-4ded-b146-b57e6c0f214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2e1e2b3c-dd7b-41af-9230-96e8e35507fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-aeef87aa-a201-4d3d-8a1e-c16e37dd6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-682eb33d-a38d-4ef5-9688-5f8ea7283940,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7352aac9-334e-476c-a4d9-4579b9f104fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-97b027db-3947-4d18-bdcb-84c5a091e032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762685559-172.17.0.3-1598590880970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-146190d7-6b1c-410c-8e1f-edb4316a83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-dd1bfbeb-bf7f-45b1-9fcc-87f53b58f046,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-a836b606-df67-4ded-b146-b57e6c0f214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2e1e2b3c-dd7b-41af-9230-96e8e35507fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-aeef87aa-a201-4d3d-8a1e-c16e37dd6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-682eb33d-a38d-4ef5-9688-5f8ea7283940,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-7352aac9-334e-476c-a4d9-4579b9f104fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-97b027db-3947-4d18-bdcb-84c5a091e032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879014954-172.17.0.3-1598590953150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-8f1b8cb3-b8a2-4bdf-bca2-4b56d2d753c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-06ecb2b7-7167-4e04-b62c-c408f376b5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-39167694-bb5e-42db-b3db-0e44125d55d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-4d0f3979-e768-4185-9561-ce3d968ce64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-98c1b4df-aacb-4240-8ade-d28ce18c5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-905f4dc7-8d5b-4014-bc0d-e86892c0aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-3299748c-2330-4a65-aa23-c49bac864061,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-62a8a2c0-d6c5-4bb8-ae76-3fc95e4b38ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879014954-172.17.0.3-1598590953150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-8f1b8cb3-b8a2-4bdf-bca2-4b56d2d753c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-06ecb2b7-7167-4e04-b62c-c408f376b5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-39167694-bb5e-42db-b3db-0e44125d55d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-4d0f3979-e768-4185-9561-ce3d968ce64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-98c1b4df-aacb-4240-8ade-d28ce18c5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-905f4dc7-8d5b-4014-bc0d-e86892c0aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-3299748c-2330-4a65-aa23-c49bac864061,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-62a8a2c0-d6c5-4bb8-ae76-3fc95e4b38ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63502745-172.17.0.3-1598591148965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-d46ffc4d-70c7-4698-9d9c-256bec29a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-41e851c9-5094-44d2-b2ba-ff645af064ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-1df131c7-d94a-47ee-8969-1fedc79aa811,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-bd11973b-0a71-431d-b7df-9e7727d494e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-21d59bfa-3427-40f0-bbd5-30c25bd44d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-c35e8b66-aa75-404b-8203-7655ce3a45a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-4d9d9fd1-65a1-4aa8-bf25-5c951b4fa6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-e3369168-27f8-4720-9658-cc0da8939098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63502745-172.17.0.3-1598591148965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-d46ffc4d-70c7-4698-9d9c-256bec29a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-41e851c9-5094-44d2-b2ba-ff645af064ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-1df131c7-d94a-47ee-8969-1fedc79aa811,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-bd11973b-0a71-431d-b7df-9e7727d494e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-21d59bfa-3427-40f0-bbd5-30c25bd44d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-c35e8b66-aa75-404b-8203-7655ce3a45a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-4d9d9fd1-65a1-4aa8-bf25-5c951b4fa6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-e3369168-27f8-4720-9658-cc0da8939098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464193380-172.17.0.3-1598591730448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-9cd82215-9b4c-4feb-9251-1f5e2ed17066,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-a9f2f2de-1b13-4a1c-b658-e72cf13d6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-67405f10-ea7e-4fa5-82af-c3b78b44bf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-00239828-a437-4273-81c2-4e8245a4b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-cb04b42c-a649-4c05-978d-dd7645c13cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-a57d6b0e-2131-4670-bdeb-5f602d94c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-e3dc1be7-3e8a-4e2d-b279-1c76855834b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-bd82fc19-5dfb-44b0-b7fd-739ba2b64f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464193380-172.17.0.3-1598591730448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-9cd82215-9b4c-4feb-9251-1f5e2ed17066,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-a9f2f2de-1b13-4a1c-b658-e72cf13d6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-67405f10-ea7e-4fa5-82af-c3b78b44bf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-00239828-a437-4273-81c2-4e8245a4b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-cb04b42c-a649-4c05-978d-dd7645c13cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-a57d6b0e-2131-4670-bdeb-5f602d94c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-e3dc1be7-3e8a-4e2d-b279-1c76855834b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-bd82fc19-5dfb-44b0-b7fd-739ba2b64f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908781157-172.17.0.3-1598591845726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-6d0db874-6304-415c-ac67-b102d2067834,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-f1b38cdf-e191-4d33-a231-f247f467c80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-73d84398-e9aa-4de5-ab0f-67912658df79,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8a3c3f9c-4ee6-4dcf-b12e-f83684091456,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-ebee95ad-8df6-4e6a-9102-89e61c51d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-534721b0-7741-44a6-a060-039ad6882271,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ec8a6af6-8594-4774-92d7-21af26fa13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-81513ede-e6c6-4543-83ac-1313893e5ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908781157-172.17.0.3-1598591845726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33054,DS-6d0db874-6304-415c-ac67-b102d2067834,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-f1b38cdf-e191-4d33-a231-f247f467c80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-73d84398-e9aa-4de5-ab0f-67912658df79,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8a3c3f9c-4ee6-4dcf-b12e-f83684091456,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-ebee95ad-8df6-4e6a-9102-89e61c51d6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-534721b0-7741-44a6-a060-039ad6882271,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-ec8a6af6-8594-4774-92d7-21af26fa13e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-81513ede-e6c6-4543-83ac-1313893e5ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460366429-172.17.0.3-1598591881050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-59a08eda-6348-4d15-b946-0f6b154103af,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c634297f-9823-4c27-89fa-1f0a2e06dacd,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-758ffa41-59ab-4605-a8ab-09e20409af91,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-fcf8cd3f-9220-495f-a8f2-217a0f127cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-b5cf2c8d-a545-435a-b672-e457ce0701f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-eda06b01-6751-4899-92d6-4d1e069b2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-c2d854f8-74b1-41f0-9353-f8188508bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-680ee24c-aa13-4d3c-af31-1ae7728347fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460366429-172.17.0.3-1598591881050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-59a08eda-6348-4d15-b946-0f6b154103af,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-c634297f-9823-4c27-89fa-1f0a2e06dacd,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-758ffa41-59ab-4605-a8ab-09e20409af91,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-fcf8cd3f-9220-495f-a8f2-217a0f127cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-b5cf2c8d-a545-435a-b672-e457ce0701f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-eda06b01-6751-4899-92d6-4d1e069b2d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-c2d854f8-74b1-41f0-9353-f8188508bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-680ee24c-aa13-4d3c-af31-1ae7728347fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567359073-172.17.0.3-1598591993453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-d8ff6c02-40b7-4788-9470-1909b804c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-46e0ba90-a4a8-48b8-858a-c8c0d4885e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-f9a7daca-4bfa-4e7b-a63e-a8287231063a,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-a6d9b851-181b-4ef0-bfc9-eba80c65e522,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-8361e6eb-6d8f-4602-bffc-b73ceec0ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-94231711-33ed-4c34-90df-791b87c003f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3071f51a-6ae1-498a-beb6-a5df5290e034,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-68bbd761-0642-485a-8e6b-69e1eb566703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567359073-172.17.0.3-1598591993453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-d8ff6c02-40b7-4788-9470-1909b804c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-46e0ba90-a4a8-48b8-858a-c8c0d4885e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-f9a7daca-4bfa-4e7b-a63e-a8287231063a,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-a6d9b851-181b-4ef0-bfc9-eba80c65e522,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-8361e6eb-6d8f-4602-bffc-b73ceec0ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-94231711-33ed-4c34-90df-791b87c003f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3071f51a-6ae1-498a-beb6-a5df5290e034,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-68bbd761-0642-485a-8e6b-69e1eb566703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304706015-172.17.0.3-1598592131516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-a12ddaab-8641-4bf0-a800-b35995e561ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-38cc774d-ac6b-4e26-bd75-5cfe76a725da,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-ae30ec44-8d91-4c25-9c4d-88823591fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-fe330aef-9434-4c55-93b3-fa0bf8760763,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-87bfa340-bb9b-49c9-9e33-8666da135725,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-be1d68e9-030a-4b8a-9d96-fed1a0bf2553,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c5a6e7d1-ce53-4e43-b5b2-773d4e231caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b5e0612e-8d1c-4894-82d5-14abdbd129d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304706015-172.17.0.3-1598592131516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-a12ddaab-8641-4bf0-a800-b35995e561ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-38cc774d-ac6b-4e26-bd75-5cfe76a725da,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-ae30ec44-8d91-4c25-9c4d-88823591fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-fe330aef-9434-4c55-93b3-fa0bf8760763,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-87bfa340-bb9b-49c9-9e33-8666da135725,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-be1d68e9-030a-4b8a-9d96-fed1a0bf2553,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-c5a6e7d1-ce53-4e43-b5b2-773d4e231caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b5e0612e-8d1c-4894-82d5-14abdbd129d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880316272-172.17.0.3-1598593235341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-d425088d-02e0-43e3-ab75-66d05aa795cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-19b5e54d-88ab-45db-a49e-962c7d704220,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d2d099f3-5e61-4d7c-957f-4500605ccd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-884657fa-a2a8-4c87-bdd6-ea36ae1f22bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-d36395b0-9e22-42d0-9512-a2458bf8978d,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-1dbb00f1-0170-4cc2-9250-0d444d1fe6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-1bdac335-b50e-4d26-bc91-a314d418c605,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-c1c929e6-0bf9-4874-8c5c-fdf3f971667b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880316272-172.17.0.3-1598593235341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-d425088d-02e0-43e3-ab75-66d05aa795cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-19b5e54d-88ab-45db-a49e-962c7d704220,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-d2d099f3-5e61-4d7c-957f-4500605ccd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-884657fa-a2a8-4c87-bdd6-ea36ae1f22bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-d36395b0-9e22-42d0-9512-a2458bf8978d,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-1dbb00f1-0170-4cc2-9250-0d444d1fe6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-1bdac335-b50e-4d26-bc91-a314d418c605,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-c1c929e6-0bf9-4874-8c5c-fdf3f971667b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392365883-172.17.0.3-1598593358429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-de7c8333-830e-433a-aae9-faa64ed71af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-fcd28619-c973-442e-bae6-21e7854eeb35,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-41b5779f-e2cb-49bc-9b6e-0664edb5d710,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-c525d271-fab2-45ea-9bfe-5f47dca7926e,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-015c6c3d-ad93-4197-af9f-a1cf8cdf4a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-1e0e7428-972b-4480-bca1-6ddf981c04ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1cd0f055-fa14-4c96-9f09-78441b6ae4da,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c29ca66c-2917-401a-b6d4-c4739eb285b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392365883-172.17.0.3-1598593358429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-de7c8333-830e-433a-aae9-faa64ed71af7,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-fcd28619-c973-442e-bae6-21e7854eeb35,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-41b5779f-e2cb-49bc-9b6e-0664edb5d710,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-c525d271-fab2-45ea-9bfe-5f47dca7926e,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-015c6c3d-ad93-4197-af9f-a1cf8cdf4a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-1e0e7428-972b-4480-bca1-6ddf981c04ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1cd0f055-fa14-4c96-9f09-78441b6ae4da,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c29ca66c-2917-401a-b6d4-c4739eb285b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940786092-172.17.0.3-1598593776768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-3d3700cd-d0e5-4bb4-a9cd-4d6e3d3727b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-12148a83-1375-4de7-bb9c-71a20d57834e,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-00cb92a8-7099-4811-af03-f2ccb7102d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-51d29d3c-f3ff-4068-b897-69240feee0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5a866d03-f2c1-463f-8e2c-5bd7d994f234,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-bb1b604e-58d1-466d-8baf-8e8f79b40916,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-88ca2bd8-5283-4e2e-bfcf-4b79ec3eecfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-35260f32-a76d-4cc5-9de4-a2c2178d5a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940786092-172.17.0.3-1598593776768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-3d3700cd-d0e5-4bb4-a9cd-4d6e3d3727b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-12148a83-1375-4de7-bb9c-71a20d57834e,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-00cb92a8-7099-4811-af03-f2ccb7102d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-51d29d3c-f3ff-4068-b897-69240feee0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5a866d03-f2c1-463f-8e2c-5bd7d994f234,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-bb1b604e-58d1-466d-8baf-8e8f79b40916,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-88ca2bd8-5283-4e2e-bfcf-4b79ec3eecfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-35260f32-a76d-4cc5-9de4-a2c2178d5a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6194461-172.17.0.3-1598593979908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45346,DS-68f75a45-675b-44ab-ae79-0cd6da6259ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-bc1deb3b-668c-4c02-973e-5cfbc20d431b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-cbfeed57-057b-463a-ba3a-2f1975d63380,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-8c6f5f99-1460-47fa-b3c2-85a350716add,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-3186be18-9307-45db-a639-97846a5da8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-06d6dca5-c4ce-4354-8fda-3b1a3bc47dae,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-dbfd474d-da53-429f-83ee-25fbef10044d,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-01242bba-2982-4d5f-b486-d9cdf28367de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6194461-172.17.0.3-1598593979908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45346,DS-68f75a45-675b-44ab-ae79-0cd6da6259ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-bc1deb3b-668c-4c02-973e-5cfbc20d431b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-cbfeed57-057b-463a-ba3a-2f1975d63380,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-8c6f5f99-1460-47fa-b3c2-85a350716add,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-3186be18-9307-45db-a639-97846a5da8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-06d6dca5-c4ce-4354-8fda-3b1a3bc47dae,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-dbfd474d-da53-429f-83ee-25fbef10044d,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-01242bba-2982-4d5f-b486-d9cdf28367de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711618223-172.17.0.3-1598594452027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-c3d68e12-573c-405e-8575-ea9c32becc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d6017d5c-7b96-4736-9485-c02a08d08bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-9683c6d1-edda-469e-b203-b5342a85dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-d043803d-d84b-43e0-b10b-e557ffe1b508,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-d6f5c044-db0d-471c-ba76-a57754dcf539,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-cbc21f9d-68c7-4386-a47a-ccb858d49f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-a9e11f3b-6046-44ff-b3f9-2da8521f9cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-635d30af-7434-4811-a9e7-265ca49be3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711618223-172.17.0.3-1598594452027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-c3d68e12-573c-405e-8575-ea9c32becc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d6017d5c-7b96-4736-9485-c02a08d08bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-9683c6d1-edda-469e-b203-b5342a85dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-d043803d-d84b-43e0-b10b-e557ffe1b508,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-d6f5c044-db0d-471c-ba76-a57754dcf539,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-cbc21f9d-68c7-4386-a47a-ccb858d49f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-a9e11f3b-6046-44ff-b3f9-2da8521f9cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-635d30af-7434-4811-a9e7-265ca49be3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889248366-172.17.0.3-1598594712129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-15439f68-8803-440c-a7ea-6f3fa7e07ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-dc440852-e73b-4d64-add1-16ebc1fbf620,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-6e6c9c38-4797-44bf-911b-421044a8878b,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d48b3b7f-e9c8-4de7-bbef-6fbe9fb60e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-aaa67f00-62e4-4a27-b838-7087c28ab500,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6dd045f5-31ff-4cbf-9c3b-86fcc528e128,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-cf6bb345-939e-4d97-b2a1-c2e39b0b162c,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-ca403baa-54a0-42c6-962b-da316fdcb637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889248366-172.17.0.3-1598594712129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-15439f68-8803-440c-a7ea-6f3fa7e07ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-dc440852-e73b-4d64-add1-16ebc1fbf620,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-6e6c9c38-4797-44bf-911b-421044a8878b,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-d48b3b7f-e9c8-4de7-bbef-6fbe9fb60e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-aaa67f00-62e4-4a27-b838-7087c28ab500,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-6dd045f5-31ff-4cbf-9c3b-86fcc528e128,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-cf6bb345-939e-4d97-b2a1-c2e39b0b162c,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-ca403baa-54a0-42c6-962b-da316fdcb637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357678652-172.17.0.3-1598594853357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36471,DS-f60ac88b-043e-42e3-8f4c-e5c8f8e7ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-045a3ee0-a68b-4028-8562-ffce0aa5fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-0700ce9b-1d63-421d-bbe0-9375a6e69726,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-ca2b3f34-97a1-4719-a5ab-164882ca5334,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b63c7bd7-c0af-4809-a064-651502a2534c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b6fa0f94-fd28-4397-87af-597fe6006ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-d06bebb4-a9e7-400f-9b50-7c352c3b406b,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1d25dbfa-be15-4a5c-84a2-2f620b871f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357678652-172.17.0.3-1598594853357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36471,DS-f60ac88b-043e-42e3-8f4c-e5c8f8e7ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-045a3ee0-a68b-4028-8562-ffce0aa5fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-0700ce9b-1d63-421d-bbe0-9375a6e69726,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-ca2b3f34-97a1-4719-a5ab-164882ca5334,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-b63c7bd7-c0af-4809-a064-651502a2534c,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-b6fa0f94-fd28-4397-87af-597fe6006ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-d06bebb4-a9e7-400f-9b50-7c352c3b406b,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1d25dbfa-be15-4a5c-84a2-2f620b871f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-147996405-172.17.0.3-1598595325593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-bc89bfd9-c949-48f0-acf0-209c0d265cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-fc7f0bb4-1cd7-4842-87eb-e5616fab802d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-d2378b70-2f3e-4487-954b-5a0a881d18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-30b986a1-d6d4-4e6d-b022-8dab02b17d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-c51a3a81-9310-4275-9d5c-19cf0f71a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-381ec697-c0f3-47f5-b4c8-02e8e6ead150,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-fa680a16-04f8-46cb-b5c6-4f703514dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-12e67bfc-018a-4431-8f31-d54e6891c154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-147996405-172.17.0.3-1598595325593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-bc89bfd9-c949-48f0-acf0-209c0d265cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-fc7f0bb4-1cd7-4842-87eb-e5616fab802d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-d2378b70-2f3e-4487-954b-5a0a881d18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-30b986a1-d6d4-4e6d-b022-8dab02b17d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-c51a3a81-9310-4275-9d5c-19cf0f71a1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-381ec697-c0f3-47f5-b4c8-02e8e6ead150,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-fa680a16-04f8-46cb-b5c6-4f703514dc70,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-12e67bfc-018a-4431-8f31-d54e6891c154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105580603-172.17.0.3-1598595660708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-bc0ab03b-8ef9-406f-b900-57f45f42f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-8e2797ec-554e-4d73-b855-32e7b451a755,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-50950dd6-855d-4892-91d0-b7e748390cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1d346a33-c1f4-4061-a39b-66df5fb91a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-ff90f4bf-215b-467e-99f7-d1924dd1567f,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-d384984d-e825-4aea-8850-46c58483067e,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-0f308d54-29da-4d02-913e-a11237c8a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-0dd318a4-1461-459c-bce0-81f145671007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105580603-172.17.0.3-1598595660708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-bc0ab03b-8ef9-406f-b900-57f45f42f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-8e2797ec-554e-4d73-b855-32e7b451a755,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-50950dd6-855d-4892-91d0-b7e748390cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1d346a33-c1f4-4061-a39b-66df5fb91a22,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-ff90f4bf-215b-467e-99f7-d1924dd1567f,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-d384984d-e825-4aea-8850-46c58483067e,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-0f308d54-29da-4d02-913e-a11237c8a8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-0dd318a4-1461-459c-bce0-81f145671007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618684998-172.17.0.3-1598595794084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-f3d10113-2837-452a-8069-035f47d0ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-074ea83a-0909-4fc1-9b72-0cbfce912368,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-76fc55e5-ba0a-4610-8004-09911b8d11a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-23763484-ecb2-42e4-8aa6-5ce1873a235f,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-e3495afd-4a19-420d-a083-827de95a9131,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-74712ca0-e67d-40d5-b337-147e57d01b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-9d530d56-24af-4586-ab26-35c0e4cb49de,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-7cf382ff-b4dd-4b58-9f1b-faf370d68c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618684998-172.17.0.3-1598595794084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44380,DS-f3d10113-2837-452a-8069-035f47d0ce79,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-074ea83a-0909-4fc1-9b72-0cbfce912368,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-76fc55e5-ba0a-4610-8004-09911b8d11a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-23763484-ecb2-42e4-8aa6-5ce1873a235f,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-e3495afd-4a19-420d-a083-827de95a9131,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-74712ca0-e67d-40d5-b337-147e57d01b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-9d530d56-24af-4586-ab26-35c0e4cb49de,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-7cf382ff-b4dd-4b58-9f1b-faf370d68c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5297
