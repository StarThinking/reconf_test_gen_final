reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96557431-172.17.0.13-1598591091337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-d0e85602-dea4-4271-a890-a57fbd0a8371,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-919071dd-b1cc-4b89-b2de-0a07c0171c33,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f89cd17b-e2a0-4b33-afd6-aabd137ceca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-194e4a1f-8f3d-467d-9b40-4a4b13d6f5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-420831e1-0ed5-4b54-81e9-20e71b40b187,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-118a6d60-7bea-4311-92f6-017023565cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-d4d00447-5f41-411f-9eaf-b368492fc223,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-8cca062b-f418-433e-9d3f-f25a37da7be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96557431-172.17.0.13-1598591091337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-d0e85602-dea4-4271-a890-a57fbd0a8371,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-919071dd-b1cc-4b89-b2de-0a07c0171c33,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-f89cd17b-e2a0-4b33-afd6-aabd137ceca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-194e4a1f-8f3d-467d-9b40-4a4b13d6f5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-420831e1-0ed5-4b54-81e9-20e71b40b187,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-118a6d60-7bea-4311-92f6-017023565cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-d4d00447-5f41-411f-9eaf-b368492fc223,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-8cca062b-f418-433e-9d3f-f25a37da7be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964930316-172.17.0.13-1598591132011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-4c917b58-cfb1-4e18-8133-74514c115265,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-135fea93-de5e-4cd4-a179-c11878846a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-859fcd52-9649-4ef2-8f74-6129e834822c,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-21bfd875-2b32-4355-8f1e-67aa8f7992f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-c788aae7-97ca-4a8c-b9e2-0ee69103dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f108f117-aa53-4e9a-a451-1cdaac5e2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-735f0a7b-a552-492b-bf88-5cda81b6d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-1119cf60-d8c2-4fd7-a2df-0d3a55c582fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964930316-172.17.0.13-1598591132011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-4c917b58-cfb1-4e18-8133-74514c115265,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-135fea93-de5e-4cd4-a179-c11878846a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-859fcd52-9649-4ef2-8f74-6129e834822c,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-21bfd875-2b32-4355-8f1e-67aa8f7992f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-c788aae7-97ca-4a8c-b9e2-0ee69103dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f108f117-aa53-4e9a-a451-1cdaac5e2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-735f0a7b-a552-492b-bf88-5cda81b6d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-1119cf60-d8c2-4fd7-a2df-0d3a55c582fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704425572-172.17.0.13-1598591207389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-3f169344-8d5b-4659-a693-8bfc23f2c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-3096b10a-048f-4c48-be26-d0383e63b79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-3285d01f-fac5-4cca-ba2d-0e20ca2a6c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-c422d55a-03be-4e2f-8a5a-41b378d269bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-441f3866-0147-4fe0-8ca2-0bd84ba3fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-f47a8018-c273-4982-9dc6-32d1ce3dc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-566d219a-0ff4-4416-87c1-c81be4fccd94,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-429bec3c-ded9-4731-9604-3e3944b086e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704425572-172.17.0.13-1598591207389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-3f169344-8d5b-4659-a693-8bfc23f2c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-3096b10a-048f-4c48-be26-d0383e63b79b,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-3285d01f-fac5-4cca-ba2d-0e20ca2a6c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-c422d55a-03be-4e2f-8a5a-41b378d269bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-441f3866-0147-4fe0-8ca2-0bd84ba3fd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-f47a8018-c273-4982-9dc6-32d1ce3dc6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-566d219a-0ff4-4416-87c1-c81be4fccd94,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-429bec3c-ded9-4731-9604-3e3944b086e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205995714-172.17.0.13-1598591365401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-cbb35977-f283-446e-89bf-4a17c123ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-11e73e85-060b-4721-953a-9010fed40cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-92ce2778-a693-4027-8017-d17115782fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-8520ec46-3a6a-48da-93ff-b260c30d2171,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-c7a1c428-406a-4223-859c-1aebb8af6595,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-87c22970-a591-4bd8-a217-5789cec656e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-654e1e38-0438-414a-9fca-a1b2969b67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-6c23b2db-7eb2-464c-bf12-cf76699c8951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205995714-172.17.0.13-1598591365401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44616,DS-cbb35977-f283-446e-89bf-4a17c123ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-11e73e85-060b-4721-953a-9010fed40cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-92ce2778-a693-4027-8017-d17115782fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-8520ec46-3a6a-48da-93ff-b260c30d2171,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-c7a1c428-406a-4223-859c-1aebb8af6595,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-87c22970-a591-4bd8-a217-5789cec656e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-654e1e38-0438-414a-9fca-a1b2969b67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-6c23b2db-7eb2-464c-bf12-cf76699c8951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272693435-172.17.0.13-1598591410542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-f3852a99-562b-4c7d-ba4b-0449cfbfd021,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-33b8a385-eae0-4002-82ed-23ec64888489,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b2a5ca47-8ddf-4bf9-9fb1-2574b8556c15,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-60775991-ee44-471f-b7f0-cccccd690a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-63aa4303-e283-4c42-bb38-7cb6b98ed9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-3dd824c4-5741-4db8-84fa-986fac5315e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-cd6e3745-3536-4fa1-81aa-7ad1a45650b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-328744b9-f45f-49a7-8c56-4bc0190cd766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272693435-172.17.0.13-1598591410542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-f3852a99-562b-4c7d-ba4b-0449cfbfd021,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-33b8a385-eae0-4002-82ed-23ec64888489,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b2a5ca47-8ddf-4bf9-9fb1-2574b8556c15,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-60775991-ee44-471f-b7f0-cccccd690a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-63aa4303-e283-4c42-bb38-7cb6b98ed9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-3dd824c4-5741-4db8-84fa-986fac5315e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-cd6e3745-3536-4fa1-81aa-7ad1a45650b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-328744b9-f45f-49a7-8c56-4bc0190cd766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246406433-172.17.0.13-1598591525067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-771a11a6-ec4e-41ce-8ce6-5ae726834853,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-839ec45c-c88f-45f6-8956-5f0a24c16f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-912d9aef-6bae-4830-8751-1664fdaac9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-678b8603-1290-44ff-9556-35af2f73ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-2097ffca-937b-44b3-860f-d913ead34572,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-acc335a5-5696-42af-94d5-24bee81a0d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-b07841a7-88c3-4da8-b8f8-176e2029e342,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-a1bb39a9-cc4d-4dea-a1c7-e3b9f5e55fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246406433-172.17.0.13-1598591525067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-771a11a6-ec4e-41ce-8ce6-5ae726834853,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-839ec45c-c88f-45f6-8956-5f0a24c16f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-912d9aef-6bae-4830-8751-1664fdaac9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-678b8603-1290-44ff-9556-35af2f73ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-2097ffca-937b-44b3-860f-d913ead34572,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-acc335a5-5696-42af-94d5-24bee81a0d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-b07841a7-88c3-4da8-b8f8-176e2029e342,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-a1bb39a9-cc4d-4dea-a1c7-e3b9f5e55fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022593833-172.17.0.13-1598591988671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-40ecd242-5485-480b-9f29-6ffe2c518883,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-23fbe360-41cd-486f-b9b0-d4ea40200bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-380707b5-6528-4a7a-b649-8398703b032c,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-10ec086e-ee29-4d70-828c-abba99fba689,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-a970edc2-4f90-4eec-972b-3d477546f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-7f8f2406-657c-4c1f-9e9b-3ccf48ce36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-d3f35040-9d35-40dd-8796-404c10f12804,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-07d0320a-5d08-44d5-9b82-42cd3eaa5a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022593833-172.17.0.13-1598591988671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-40ecd242-5485-480b-9f29-6ffe2c518883,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-23fbe360-41cd-486f-b9b0-d4ea40200bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-380707b5-6528-4a7a-b649-8398703b032c,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-10ec086e-ee29-4d70-828c-abba99fba689,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-a970edc2-4f90-4eec-972b-3d477546f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-7f8f2406-657c-4c1f-9e9b-3ccf48ce36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-d3f35040-9d35-40dd-8796-404c10f12804,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-07d0320a-5d08-44d5-9b82-42cd3eaa5a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669601776-172.17.0.13-1598592377898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-a3306669-bb6a-43bd-b7fb-57cac8a25005,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-94d45179-d910-4732-a17e-3cca43e3571d,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-630f3ba7-eab0-4141-a398-5937780bef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6913c014-47e7-4ce4-b203-e450e01d6253,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-07c9fecb-021b-4471-81e2-26a129f657ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-3dd886d3-25f9-4cb7-8d5d-25dcd7f61d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-35dbbb36-ce16-4205-8c08-ac3dcc1c251b,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-87d40951-2d64-47a1-9027-678e94108551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669601776-172.17.0.13-1598592377898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-a3306669-bb6a-43bd-b7fb-57cac8a25005,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-94d45179-d910-4732-a17e-3cca43e3571d,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-630f3ba7-eab0-4141-a398-5937780bef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-6913c014-47e7-4ce4-b203-e450e01d6253,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-07c9fecb-021b-4471-81e2-26a129f657ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-3dd886d3-25f9-4cb7-8d5d-25dcd7f61d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-35dbbb36-ce16-4205-8c08-ac3dcc1c251b,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-87d40951-2d64-47a1-9027-678e94108551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588499228-172.17.0.13-1598592453397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-e941f9f1-db18-447b-bddf-04cad607c222,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-b2306ef5-6871-4ce5-afaa-585043ca22b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-f475c468-e1e3-40f6-95f9-5891f43cea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-b839a102-3ce9-40b8-9d8d-70dd6771668a,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-09478dbb-a279-4e08-a69c-64c21e6f8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-fe96010e-f0b6-4456-82a7-aef372c015d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-da2e2d2b-3a48-4f00-81a9-c37076c31bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-b3954db8-e9a3-479d-8d03-841263e24516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588499228-172.17.0.13-1598592453397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37785,DS-e941f9f1-db18-447b-bddf-04cad607c222,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-b2306ef5-6871-4ce5-afaa-585043ca22b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-f475c468-e1e3-40f6-95f9-5891f43cea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-b839a102-3ce9-40b8-9d8d-70dd6771668a,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-09478dbb-a279-4e08-a69c-64c21e6f8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-fe96010e-f0b6-4456-82a7-aef372c015d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-da2e2d2b-3a48-4f00-81a9-c37076c31bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-b3954db8-e9a3-479d-8d03-841263e24516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214451251-172.17.0.13-1598593083862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-301f0864-423d-4969-9afb-8a453e6b8592,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-034987b1-76ac-45ef-9562-86535f056926,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-81a4883e-23c4-457e-9d4f-e3346f33f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-ff82fdd4-0079-4dae-8d75-407b43526afd,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-4596b9d2-5b07-4e12-9bcf-1c5b7ac80044,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-edfbbb73-5cbf-4d60-9c95-926f5f4cc358,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-8b83e784-8fea-4f4a-adf7-38f4bf763972,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-9325d61c-1813-4092-9d1b-060664160901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214451251-172.17.0.13-1598593083862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-301f0864-423d-4969-9afb-8a453e6b8592,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-034987b1-76ac-45ef-9562-86535f056926,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-81a4883e-23c4-457e-9d4f-e3346f33f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-ff82fdd4-0079-4dae-8d75-407b43526afd,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-4596b9d2-5b07-4e12-9bcf-1c5b7ac80044,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-edfbbb73-5cbf-4d60-9c95-926f5f4cc358,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-8b83e784-8fea-4f4a-adf7-38f4bf763972,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-9325d61c-1813-4092-9d1b-060664160901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002265476-172.17.0.13-1598594150436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-eaef3230-a3f4-4c3f-99aa-95aeeed68c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-5751e88a-abf3-4243-9ffa-3cd498b9c3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-3acbefd1-cbda-4d67-9d3e-917d8e59e186,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-160122f7-d2e4-4866-bb51-82096517818c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-c4c30ee4-04d8-49f0-a406-d4b4462e36e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-55933dc3-e04f-4f81-a011-03aebfcd3f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-353efc7f-42b8-4ea4-bf23-c13fbaba08cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-5c9a8667-77e9-4155-abf3-67fae72f82ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002265476-172.17.0.13-1598594150436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-eaef3230-a3f4-4c3f-99aa-95aeeed68c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-5751e88a-abf3-4243-9ffa-3cd498b9c3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-3acbefd1-cbda-4d67-9d3e-917d8e59e186,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-160122f7-d2e4-4866-bb51-82096517818c,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-c4c30ee4-04d8-49f0-a406-d4b4462e36e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-55933dc3-e04f-4f81-a011-03aebfcd3f79,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-353efc7f-42b8-4ea4-bf23-c13fbaba08cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-5c9a8667-77e9-4155-abf3-67fae72f82ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896003200-172.17.0.13-1598594674098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43268,DS-60f79bcb-a2a0-40ae-989a-db207d2167ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-0a93023e-ed44-46b6-9b9f-8f3dd157f45c,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-1a24adb3-2691-49dc-b80a-a7d7461ddf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-c55922f5-d033-4314-9e49-832a8c199ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-2e64a9e3-3b03-4a14-b952-cecb18f6e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-03f917d3-1518-4455-94f9-b28667925991,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-645bd099-239c-4aba-a7e6-09798eb7ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-7ead70b8-7733-42ae-bb44-69c7209616b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896003200-172.17.0.13-1598594674098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43268,DS-60f79bcb-a2a0-40ae-989a-db207d2167ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-0a93023e-ed44-46b6-9b9f-8f3dd157f45c,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-1a24adb3-2691-49dc-b80a-a7d7461ddf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-c55922f5-d033-4314-9e49-832a8c199ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-2e64a9e3-3b03-4a14-b952-cecb18f6e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-03f917d3-1518-4455-94f9-b28667925991,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-645bd099-239c-4aba-a7e6-09798eb7ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-7ead70b8-7733-42ae-bb44-69c7209616b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370034668-172.17.0.13-1598595249107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-1676215b-f8fd-4811-b58f-d639e72cb669,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-3dc90c8a-cb53-455f-8782-3d01edb7a048,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-7679e2ac-0ebb-49d8-969a-f4c0d8126005,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-89e87302-372a-424b-87fa-0037e321012a,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-b4bc916e-cb94-4adc-aae9-e2906232b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-d59f69e5-3183-46bb-a5e4-80060e582c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-c7ef7f41-67b3-4190-a33d-dc1c4c04b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-1336458a-ef20-4a75-bf42-3e104e630c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370034668-172.17.0.13-1598595249107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-1676215b-f8fd-4811-b58f-d639e72cb669,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-3dc90c8a-cb53-455f-8782-3d01edb7a048,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-7679e2ac-0ebb-49d8-969a-f4c0d8126005,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-89e87302-372a-424b-87fa-0037e321012a,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-b4bc916e-cb94-4adc-aae9-e2906232b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-d59f69e5-3183-46bb-a5e4-80060e582c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-c7ef7f41-67b3-4190-a33d-dc1c4c04b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-1336458a-ef20-4a75-bf42-3e104e630c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236957989-172.17.0.13-1598595375828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-0ae4a9ee-6182-43da-b96d-750ec875f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-e69323fc-48e3-44e0-a8be-87abe115b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-e499adfd-a107-4061-bf93-d0aff1aadf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-aa0cb255-090f-4936-8efc-e8faf45cdbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-29552d06-608a-4931-9deb-e08036d1991c,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-d15c66d2-441e-4da9-8fee-e47a7793af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-1f2dcd35-5000-4e93-a531-2b8859be80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-cc0876a8-bab0-4dc1-a45e-7e3782389a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236957989-172.17.0.13-1598595375828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-0ae4a9ee-6182-43da-b96d-750ec875f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-e69323fc-48e3-44e0-a8be-87abe115b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-e499adfd-a107-4061-bf93-d0aff1aadf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-aa0cb255-090f-4936-8efc-e8faf45cdbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-29552d06-608a-4931-9deb-e08036d1991c,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-d15c66d2-441e-4da9-8fee-e47a7793af2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-1f2dcd35-5000-4e93-a531-2b8859be80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-cc0876a8-bab0-4dc1-a45e-7e3782389a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344779404-172.17.0.13-1598595602440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-c5aa0c2a-b792-4860-973f-ddfb08c04be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-60989bfd-51d7-48bd-bbe5-0011777396b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f288ee0d-66c1-4dfb-9137-009c6f9981b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-49b6eda2-8485-48c1-970a-b2b031c12744,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-bc4e3b09-2136-4e83-8733-8abee07967d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-aa98ba27-ece5-4e01-8c3b-c6bd53f46715,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-741f8782-f860-4807-8e28-7001a370ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-66ca4e3b-1a7d-4265-baca-ac5cea7a4e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344779404-172.17.0.13-1598595602440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-c5aa0c2a-b792-4860-973f-ddfb08c04be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-60989bfd-51d7-48bd-bbe5-0011777396b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f288ee0d-66c1-4dfb-9137-009c6f9981b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-49b6eda2-8485-48c1-970a-b2b031c12744,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-bc4e3b09-2136-4e83-8733-8abee07967d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-aa98ba27-ece5-4e01-8c3b-c6bd53f46715,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-741f8782-f860-4807-8e28-7001a370ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-66ca4e3b-1a7d-4265-baca-ac5cea7a4e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5390
