reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463641476-172.17.0.7-1598539731683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-5e4b1374-83cf-4527-9114-2bd4dada33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-b87adebc-77b6-482a-9f38-2e5fdb1a3841,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-c83011e9-b6a3-4872-a64e-8963868cb4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-afedc126-1747-41d3-8bcf-951400b0f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-42d78a5c-de93-4b07-bd3b-efaf20cb91e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-460f7b02-063d-48c7-b415-84c200ef7557,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-3fa0410d-f55d-4649-ad57-98d7f65e5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-31332963-d311-4e5a-abe2-26bf9af4a2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463641476-172.17.0.7-1598539731683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-5e4b1374-83cf-4527-9114-2bd4dada33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-b87adebc-77b6-482a-9f38-2e5fdb1a3841,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-c83011e9-b6a3-4872-a64e-8963868cb4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-afedc126-1747-41d3-8bcf-951400b0f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-42d78a5c-de93-4b07-bd3b-efaf20cb91e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-460f7b02-063d-48c7-b415-84c200ef7557,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-3fa0410d-f55d-4649-ad57-98d7f65e5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-31332963-d311-4e5a-abe2-26bf9af4a2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172667088-172.17.0.7-1598540142508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-77af57df-e40f-482c-af23-08c03f6930c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-7968f2a0-7c9f-4184-a0b5-bd05e9071bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-c650825f-8fda-43f4-aab5-b7bb499d44b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-899a0d90-c73e-47db-9bd8-e9e0644f5728,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-2ca21f1c-e1de-4036-bdd6-190b0bd06d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-2d7a65b4-0cb7-4e47-9392-852660b04437,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-00798d8b-85db-482f-a6b6-cf85d6f396a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-f36e27ca-1497-4f06-bfff-fdce08d84585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172667088-172.17.0.7-1598540142508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34088,DS-77af57df-e40f-482c-af23-08c03f6930c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-7968f2a0-7c9f-4184-a0b5-bd05e9071bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-c650825f-8fda-43f4-aab5-b7bb499d44b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-899a0d90-c73e-47db-9bd8-e9e0644f5728,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-2ca21f1c-e1de-4036-bdd6-190b0bd06d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-2d7a65b4-0cb7-4e47-9392-852660b04437,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-00798d8b-85db-482f-a6b6-cf85d6f396a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-f36e27ca-1497-4f06-bfff-fdce08d84585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556165301-172.17.0.7-1598540807170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-d8140bfd-94c3-47e2-ab5e-a426f8ee5de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-16115489-188e-4bfc-8ffe-181543af5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-4832234a-d7b4-46dd-b046-54ee86ec57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7ade568a-b4df-403f-89a9-3f8eb5f65d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-da670e8b-e062-4ded-9ddd-0e5f94e5b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-e829a138-d3c6-4494-85e1-8fe86cac0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-59707e6d-885d-4f01-bf95-9fdebba75c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e4641d8e-aa62-48d3-b136-6f79d7b7afb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556165301-172.17.0.7-1598540807170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-d8140bfd-94c3-47e2-ab5e-a426f8ee5de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-16115489-188e-4bfc-8ffe-181543af5b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-4832234a-d7b4-46dd-b046-54ee86ec57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7ade568a-b4df-403f-89a9-3f8eb5f65d13,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-da670e8b-e062-4ded-9ddd-0e5f94e5b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-e829a138-d3c6-4494-85e1-8fe86cac0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-59707e6d-885d-4f01-bf95-9fdebba75c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-e4641d8e-aa62-48d3-b136-6f79d7b7afb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483149164-172.17.0.7-1598540868761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34606,DS-804fdccc-2610-4557-abb1-64484c07eed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-78367ab4-6deb-4ede-a873-4dcc875bb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-c4dea0c8-a0b1-4341-bdf1-a53159679737,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-48eee8a9-76cc-4070-8a05-063152d848af,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-c7a31cc4-63cb-486c-8f33-2884a11ee2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-31422517-e9f8-4441-8e8b-4f7dffdc0b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-d8588b47-c799-4091-8fde-6292b0d13792,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-ef0dd648-cfad-4ca8-b270-9440f631dbd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483149164-172.17.0.7-1598540868761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34606,DS-804fdccc-2610-4557-abb1-64484c07eed4,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-78367ab4-6deb-4ede-a873-4dcc875bb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-c4dea0c8-a0b1-4341-bdf1-a53159679737,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-48eee8a9-76cc-4070-8a05-063152d848af,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-c7a31cc4-63cb-486c-8f33-2884a11ee2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-31422517-e9f8-4441-8e8b-4f7dffdc0b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-d8588b47-c799-4091-8fde-6292b0d13792,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-ef0dd648-cfad-4ca8-b270-9440f631dbd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922323182-172.17.0.7-1598541009859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44242,DS-137e5199-82cd-4dd3-b784-5d197d88f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-8660f35e-f158-44e3-a8bd-764ded5357a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-dae61325-a4d0-4822-835d-3d7913871d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-cc0d158a-3849-42fd-9044-922b1335def2,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-000dcae2-068b-4c9e-9fcc-e59696bdbb85,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-8cb7c024-475f-4a22-87f4-280964adf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-e7767757-77d8-4f4e-afa8-609171a80654,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-ce662625-193d-4074-8186-c4bea0d506da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922323182-172.17.0.7-1598541009859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44242,DS-137e5199-82cd-4dd3-b784-5d197d88f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-8660f35e-f158-44e3-a8bd-764ded5357a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-dae61325-a4d0-4822-835d-3d7913871d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-cc0d158a-3849-42fd-9044-922b1335def2,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-000dcae2-068b-4c9e-9fcc-e59696bdbb85,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-8cb7c024-475f-4a22-87f4-280964adf31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-e7767757-77d8-4f4e-afa8-609171a80654,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-ce662625-193d-4074-8186-c4bea0d506da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708672223-172.17.0.7-1598541173870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42577,DS-b5cbe435-ef04-4a3e-8fb7-5d52652ac0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-53a2713d-0ab7-44ae-922f-89aa082e2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-960cf974-c16b-4f82-8127-a1f5d5a538a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-b7f8b6b4-6214-47eb-9a3d-0c036a388e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-fc712474-c19c-40f4-a9da-628b390d6300,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-9666b523-9e1c-4c0b-bc2a-29429f7b84dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-45bd150f-2b78-409a-8f4a-a9adabc9dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-7d999b20-c453-4fe6-a508-e880f895d497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708672223-172.17.0.7-1598541173870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42577,DS-b5cbe435-ef04-4a3e-8fb7-5d52652ac0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-53a2713d-0ab7-44ae-922f-89aa082e2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-960cf974-c16b-4f82-8127-a1f5d5a538a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-b7f8b6b4-6214-47eb-9a3d-0c036a388e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-fc712474-c19c-40f4-a9da-628b390d6300,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-9666b523-9e1c-4c0b-bc2a-29429f7b84dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-45bd150f-2b78-409a-8f4a-a9adabc9dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-7d999b20-c453-4fe6-a508-e880f895d497,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631240047-172.17.0.7-1598541566266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-4c4a6205-1746-4477-86ad-688ec190c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-a4ed10b9-f961-4727-95d6-4488d7e68d80,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-76412585-16d5-49b6-8772-06e82dfabfec,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-8b9c76f7-32ee-44d0-ac64-6b6270d13bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-36ca1c9e-ffe1-41b8-81a8-106fc637c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f79cedb3-e511-4ff8-a148-1ea4238414a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f28ba353-7879-4927-b155-d2e105739da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-26bcac2a-6eaf-4264-964c-b744bce111f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631240047-172.17.0.7-1598541566266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-4c4a6205-1746-4477-86ad-688ec190c1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-a4ed10b9-f961-4727-95d6-4488d7e68d80,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-76412585-16d5-49b6-8772-06e82dfabfec,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-8b9c76f7-32ee-44d0-ac64-6b6270d13bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-36ca1c9e-ffe1-41b8-81a8-106fc637c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f79cedb3-e511-4ff8-a148-1ea4238414a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-f28ba353-7879-4927-b155-d2e105739da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-26bcac2a-6eaf-4264-964c-b744bce111f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844942529-172.17.0.7-1598541671975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-6a39ff30-b843-483b-8486-f98f045be602,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-97bd0b03-cab0-4320-9d67-2889ea2c37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-3a4ab8e1-6f5b-42ce-8f74-046f2f1e8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-7a6c851a-1527-4cd0-8963-cb8b1f3961c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3a985811-6a89-4467-9b41-e5f9fcde7610,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c333058f-db17-43ba-bedf-c5b0b4c54eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-7c716dee-b08d-4c41-ab6c-8fcc561e2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-5a92a22d-eb02-4c55-a41e-65678b9cff33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844942529-172.17.0.7-1598541671975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-6a39ff30-b843-483b-8486-f98f045be602,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-97bd0b03-cab0-4320-9d67-2889ea2c37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-3a4ab8e1-6f5b-42ce-8f74-046f2f1e8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-7a6c851a-1527-4cd0-8963-cb8b1f3961c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-3a985811-6a89-4467-9b41-e5f9fcde7610,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c333058f-db17-43ba-bedf-c5b0b4c54eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-7c716dee-b08d-4c41-ab6c-8fcc561e2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-5a92a22d-eb02-4c55-a41e-65678b9cff33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2147046387-172.17.0.7-1598541777117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-622f65a7-54c3-4a41-9c78-0dfaad77807f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-388a594c-57ed-4e5c-979b-f9d12b7e7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-67f121b0-4ae9-4644-a6e7-80d860427015,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-0d686f97-1883-47a7-b376-a9cbd09a66d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-6b00e2c7-93d5-4f1f-b4a6-59cbaeb7b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d0ebd576-840f-42f6-81f2-7ffbb8b17715,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-b5052ae7-5987-460f-b9ed-e0c069fdaabe,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-b8231099-0916-46e8-b8e4-b5ff7cc0e758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2147046387-172.17.0.7-1598541777117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-622f65a7-54c3-4a41-9c78-0dfaad77807f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-388a594c-57ed-4e5c-979b-f9d12b7e7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-67f121b0-4ae9-4644-a6e7-80d860427015,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-0d686f97-1883-47a7-b376-a9cbd09a66d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-6b00e2c7-93d5-4f1f-b4a6-59cbaeb7b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d0ebd576-840f-42f6-81f2-7ffbb8b17715,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-b5052ae7-5987-460f-b9ed-e0c069fdaabe,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-b8231099-0916-46e8-b8e4-b5ff7cc0e758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77451564-172.17.0.7-1598541995585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36492,DS-80d1697b-692f-4bbd-b9c4-5a7d22df7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-95e573a9-5291-4c3e-8965-8cb23c01f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-5c20642f-8061-4717-85d4-d9996b2eaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-5d3775fb-aeef-4f9d-a4cf-2f42e74f6512,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-4d8e15f6-15b8-4fef-a21c-8b40c64983f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-0a2f892a-cd69-487c-a1f1-8d238f5ad7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-21441d37-d231-4795-ba6b-aee8d611fc34,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-afdd71bd-6e60-4c6b-9998-7c3b231ea75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77451564-172.17.0.7-1598541995585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36492,DS-80d1697b-692f-4bbd-b9c4-5a7d22df7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-95e573a9-5291-4c3e-8965-8cb23c01f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-5c20642f-8061-4717-85d4-d9996b2eaf94,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-5d3775fb-aeef-4f9d-a4cf-2f42e74f6512,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-4d8e15f6-15b8-4fef-a21c-8b40c64983f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-0a2f892a-cd69-487c-a1f1-8d238f5ad7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-21441d37-d231-4795-ba6b-aee8d611fc34,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-afdd71bd-6e60-4c6b-9998-7c3b231ea75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271617798-172.17.0.7-1598542591710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-67169f4a-a10f-4f4a-aab3-b6650cf4fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-bd8965c8-5796-4ea8-9247-139d675824cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-85458460-c149-40c8-95f3-bb66682b0437,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9aeb2b78-db1a-4b79-b461-02acc6b14e64,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e42329d9-c3cf-4584-b510-93a3e0d472b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-623ae2fc-6fdf-46b2-9c14-fd9f8a8373ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-6e77a5dd-2ccf-4af7-a078-1003a1cbbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-d08cca98-ee8a-407e-aa64-6e10abf7e187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271617798-172.17.0.7-1598542591710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-67169f4a-a10f-4f4a-aab3-b6650cf4fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-bd8965c8-5796-4ea8-9247-139d675824cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-85458460-c149-40c8-95f3-bb66682b0437,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9aeb2b78-db1a-4b79-b461-02acc6b14e64,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-e42329d9-c3cf-4584-b510-93a3e0d472b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-623ae2fc-6fdf-46b2-9c14-fd9f8a8373ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-6e77a5dd-2ccf-4af7-a078-1003a1cbbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-d08cca98-ee8a-407e-aa64-6e10abf7e187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504856733-172.17.0.7-1598543337408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-bbacdb96-2d4c-406f-8876-286e4574996b,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-03afdf69-b31c-4592-b4a9-4cced9971d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-084c68ba-744e-48a8-9665-d573682c4858,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-25baafd6-c453-4060-8ee8-3136f8a1b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-4243e047-ea6b-4e09-931d-e156311e4eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-5b3b2e28-26f6-41fd-9616-757538dc3501,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-73b2e087-8b67-4600-8b81-3e894edfc54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-9c1d99f9-b9d3-4f39-894b-b8b5dee18052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504856733-172.17.0.7-1598543337408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-bbacdb96-2d4c-406f-8876-286e4574996b,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-03afdf69-b31c-4592-b4a9-4cced9971d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-084c68ba-744e-48a8-9665-d573682c4858,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-25baafd6-c453-4060-8ee8-3136f8a1b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-4243e047-ea6b-4e09-931d-e156311e4eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-5b3b2e28-26f6-41fd-9616-757538dc3501,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-73b2e087-8b67-4600-8b81-3e894edfc54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-9c1d99f9-b9d3-4f39-894b-b8b5dee18052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746353504-172.17.0.7-1598543367412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-f5356485-b791-4751-9555-b511c921f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-a37a676d-08a3-4e94-93a1-edda2af997fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-be983f4f-085d-4364-ad5f-49bd3f1d8026,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-866b73d3-035c-4e65-89ce-9ed9e4809691,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-153daa19-27b9-4d9b-a23c-d8d99f371870,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-d35c7937-db7d-4ee9-8a4e-8ab5b99dd6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-ed677d67-b8a8-40d6-aa74-0f0534b4151f,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-db11653e-329d-468d-9564-7d6c20089b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746353504-172.17.0.7-1598543367412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-f5356485-b791-4751-9555-b511c921f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-a37a676d-08a3-4e94-93a1-edda2af997fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-be983f4f-085d-4364-ad5f-49bd3f1d8026,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-866b73d3-035c-4e65-89ce-9ed9e4809691,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-153daa19-27b9-4d9b-a23c-d8d99f371870,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-d35c7937-db7d-4ee9-8a4e-8ab5b99dd6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-ed677d67-b8a8-40d6-aa74-0f0534b4151f,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-db11653e-329d-468d-9564-7d6c20089b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578237005-172.17.0.7-1598543787753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-b09b8a9b-768a-40f6-8418-7530e6a67f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-947cff70-0089-4b86-bd47-ba0edb06ab29,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-8af7aab2-162f-4280-a2ca-5727de64e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-3771e30c-d4b3-40a2-ae3a-2fbd213b66cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-d0c10f94-6c1d-414c-9898-afe9108183ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-d667b187-6f73-447b-b08f-5a0ddb544d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ba5a8ccd-7b38-4807-b5fc-814d5a511a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-5517f657-ffea-4bdc-8ac8-48e20323b45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578237005-172.17.0.7-1598543787753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-b09b8a9b-768a-40f6-8418-7530e6a67f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-947cff70-0089-4b86-bd47-ba0edb06ab29,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-8af7aab2-162f-4280-a2ca-5727de64e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-3771e30c-d4b3-40a2-ae3a-2fbd213b66cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-d0c10f94-6c1d-414c-9898-afe9108183ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-d667b187-6f73-447b-b08f-5a0ddb544d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ba5a8ccd-7b38-4807-b5fc-814d5a511a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-5517f657-ffea-4bdc-8ac8-48e20323b45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5038
