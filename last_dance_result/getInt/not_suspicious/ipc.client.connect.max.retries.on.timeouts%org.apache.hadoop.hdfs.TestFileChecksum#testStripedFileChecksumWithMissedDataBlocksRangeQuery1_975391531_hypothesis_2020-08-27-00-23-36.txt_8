reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273822939-172.17.0.13-1598488172282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45410,DS-53b5bfb4-2bdc-491e-9420-bffa8d20bac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-67298485-f03c-472c-8b41-4bbbdb48303a,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-854e2774-1d82-43d4-82ae-f31105ceb70d,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-95f881fe-29e2-48dd-9969-54d3dd3a7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-9d92a7ff-7ad8-494c-acac-2f4516d04936,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-198b5e51-dd85-40a9-a2ea-5847e558246e,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-4a0cc3d4-c065-4265-87f7-60d146e50aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-9b0e5e65-26af-4014-9b34-19aa23ffab27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273822939-172.17.0.13-1598488172282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45410,DS-53b5bfb4-2bdc-491e-9420-bffa8d20bac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-67298485-f03c-472c-8b41-4bbbdb48303a,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-854e2774-1d82-43d4-82ae-f31105ceb70d,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-95f881fe-29e2-48dd-9969-54d3dd3a7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-9d92a7ff-7ad8-494c-acac-2f4516d04936,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-198b5e51-dd85-40a9-a2ea-5847e558246e,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-4a0cc3d4-c065-4265-87f7-60d146e50aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-9b0e5e65-26af-4014-9b34-19aa23ffab27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634611499-172.17.0.13-1598488383909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-c1534f72-3bcd-4a13-bd57-704295f388d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-b4909a3c-84f8-40e2-9160-ce5b22feabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-e35bd1d0-1fa6-471e-b21b-e29dafdc53fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-5c1a4ba6-83b4-4633-a397-12035b351b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-718e9cc4-3fd8-479f-b377-7683559667f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-6bd70867-1cc3-4a13-8041-49e696d0beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-55378d9f-5784-4fb6-9de1-ad77fc0ef915,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-524b9e02-b294-49f2-9bc9-582b8f776361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634611499-172.17.0.13-1598488383909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-c1534f72-3bcd-4a13-bd57-704295f388d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-b4909a3c-84f8-40e2-9160-ce5b22feabbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-e35bd1d0-1fa6-471e-b21b-e29dafdc53fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-5c1a4ba6-83b4-4633-a397-12035b351b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-718e9cc4-3fd8-479f-b377-7683559667f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-6bd70867-1cc3-4a13-8041-49e696d0beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-55378d9f-5784-4fb6-9de1-ad77fc0ef915,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-524b9e02-b294-49f2-9bc9-582b8f776361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877429428-172.17.0.13-1598488603958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-00675dcc-d4e4-4974-8296-e652a0fab503,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-38dc4212-f2a1-48b0-9c8c-8007ea4c8293,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-08f47c4c-9a41-47cf-9f92-ce1c0b9f2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-ba501884-f3eb-41ed-8c10-81611e3ef3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-2b98efc5-3b0a-4e66-a632-df93564c9add,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b4108d45-a935-4cea-a473-2f99691266bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-f67b30d3-b605-479b-8161-ad954ad2014d,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-371110be-587a-4bd1-8f0c-d520cf702d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877429428-172.17.0.13-1598488603958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-00675dcc-d4e4-4974-8296-e652a0fab503,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-38dc4212-f2a1-48b0-9c8c-8007ea4c8293,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-08f47c4c-9a41-47cf-9f92-ce1c0b9f2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-ba501884-f3eb-41ed-8c10-81611e3ef3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-2b98efc5-3b0a-4e66-a632-df93564c9add,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b4108d45-a935-4cea-a473-2f99691266bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-f67b30d3-b605-479b-8161-ad954ad2014d,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-371110be-587a-4bd1-8f0c-d520cf702d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714663773-172.17.0.13-1598488943160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-9c6db621-3648-4fae-a803-82b27874b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-597e5a66-9cf6-416f-96d0-24b09d38e557,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-28f9a8d4-31be-432a-8f99-2b0102c570b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-9659ac4e-80f3-4a49-a900-e55199964136,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d19f9d05-eda4-40b9-be3a-9543be3aa23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-3632da46-f052-4c31-86ff-70a19e46d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-d2cb4c20-c416-4e19-8af7-e8797be0ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-21a081a9-2d54-4f6d-a68c-8e8d2ff7c025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714663773-172.17.0.13-1598488943160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-9c6db621-3648-4fae-a803-82b27874b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-597e5a66-9cf6-416f-96d0-24b09d38e557,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-28f9a8d4-31be-432a-8f99-2b0102c570b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-9659ac4e-80f3-4a49-a900-e55199964136,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d19f9d05-eda4-40b9-be3a-9543be3aa23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-3632da46-f052-4c31-86ff-70a19e46d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-d2cb4c20-c416-4e19-8af7-e8797be0ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-21a081a9-2d54-4f6d-a68c-8e8d2ff7c025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612271990-172.17.0.13-1598488984527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-fb9ef8b0-2874-4a70-80c2-88d747480cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-1eb731c7-c08a-4fca-9f33-6e5d78a1faea,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-88f9c73c-79de-4a0e-b94e-57ef565445ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-e5446b76-2dc2-442e-9df6-105bd7b7a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-17de1804-45e5-439b-b858-1baf0452120c,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5513dc6d-5420-4510-bb4b-168358826b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-42733153-eef0-46e0-9a95-5806929df635,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-c7cfd147-24bf-4018-9fbe-1e2e04ae7af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612271990-172.17.0.13-1598488984527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-fb9ef8b0-2874-4a70-80c2-88d747480cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-1eb731c7-c08a-4fca-9f33-6e5d78a1faea,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-88f9c73c-79de-4a0e-b94e-57ef565445ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-e5446b76-2dc2-442e-9df6-105bd7b7a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-17de1804-45e5-439b-b858-1baf0452120c,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5513dc6d-5420-4510-bb4b-168358826b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-42733153-eef0-46e0-9a95-5806929df635,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-c7cfd147-24bf-4018-9fbe-1e2e04ae7af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906048260-172.17.0.13-1598489400502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-c6fc5003-9d5e-4d38-a51a-1e963000a59b,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-c2f2bf7f-b17d-4d02-936d-909d49ead9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-a51e1943-3889-4243-b436-75b15f252baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-e02ec766-6cc5-467b-9a4a-513fec17cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-1eb3d2e5-6f32-4440-9122-e617b29b7773,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-6217372e-333f-4aef-8ac7-04882567ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-bc129f23-ca70-4ad7-af6e-764e47fbe48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-7d9bfccd-7814-48af-966a-1f4b5d0e4de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906048260-172.17.0.13-1598489400502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-c6fc5003-9d5e-4d38-a51a-1e963000a59b,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-c2f2bf7f-b17d-4d02-936d-909d49ead9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-a51e1943-3889-4243-b436-75b15f252baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-e02ec766-6cc5-467b-9a4a-513fec17cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-1eb3d2e5-6f32-4440-9122-e617b29b7773,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-6217372e-333f-4aef-8ac7-04882567ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-bc129f23-ca70-4ad7-af6e-764e47fbe48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-7d9bfccd-7814-48af-966a-1f4b5d0e4de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124280344-172.17.0.13-1598490198459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-6a88685b-3f9e-4f89-a762-51b883e251e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d5cd03da-9e08-458b-990c-6e9e0b6887ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-584796fe-9513-4702-b66f-0c8f5671128f,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7dae6706-4ebd-4b81-ba5b-731e4b58261b,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f2e3f309-1a02-4f03-b747-ad065003d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-d449c2e4-77da-4bf8-8dfe-440f82f27ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-b4330d88-4476-4854-b055-4415306184df,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-465e7fa2-2989-45b4-b4cc-3d41b92a92b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124280344-172.17.0.13-1598490198459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-6a88685b-3f9e-4f89-a762-51b883e251e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d5cd03da-9e08-458b-990c-6e9e0b6887ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-584796fe-9513-4702-b66f-0c8f5671128f,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-7dae6706-4ebd-4b81-ba5b-731e4b58261b,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-f2e3f309-1a02-4f03-b747-ad065003d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-d449c2e4-77da-4bf8-8dfe-440f82f27ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-b4330d88-4476-4854-b055-4415306184df,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-465e7fa2-2989-45b4-b4cc-3d41b92a92b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266946387-172.17.0.13-1598491319833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-19582202-5057-4d5c-be88-bff484848596,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a1f3194-c8ac-458f-b543-b489db288771,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-57f97188-c788-44b9-941a-86ce5b28204d,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-efa68313-5617-4279-8e80-54461fd80ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-8b259a82-2190-44f7-a119-9fb1cb644ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-ffe74c27-278e-4cfb-9978-10d6089a2399,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-25fc8aca-578f-4f81-b7ea-34af6a64669c,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-8a2764c6-2058-4ac4-95c2-f4a04ab1af45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266946387-172.17.0.13-1598491319833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-19582202-5057-4d5c-be88-bff484848596,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-1a1f3194-c8ac-458f-b543-b489db288771,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-57f97188-c788-44b9-941a-86ce5b28204d,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-efa68313-5617-4279-8e80-54461fd80ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-8b259a82-2190-44f7-a119-9fb1cb644ace,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-ffe74c27-278e-4cfb-9978-10d6089a2399,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-25fc8aca-578f-4f81-b7ea-34af6a64669c,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-8a2764c6-2058-4ac4-95c2-f4a04ab1af45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253040272-172.17.0.13-1598491463150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-aba1c46b-4845-4aef-9f87-c488d44aebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-18af8fde-9b13-434e-8261-b94f76f57072,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f7040264-3b77-4578-bd31-1b2d2f184d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-8913b326-eabe-4cd4-8132-f464afa0777b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-4260a611-f2b7-4055-8bd6-0612b4433561,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-21c02f3c-71da-4cc6-9313-e31bee312d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-58332318-e486-4659-8f89-0cd50e5dcdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-c9dcbcd1-385f-4d8a-bddf-f3e3cf24dc66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253040272-172.17.0.13-1598491463150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-aba1c46b-4845-4aef-9f87-c488d44aebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-18af8fde-9b13-434e-8261-b94f76f57072,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f7040264-3b77-4578-bd31-1b2d2f184d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-8913b326-eabe-4cd4-8132-f464afa0777b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-4260a611-f2b7-4055-8bd6-0612b4433561,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-21c02f3c-71da-4cc6-9313-e31bee312d71,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-58332318-e486-4659-8f89-0cd50e5dcdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-c9dcbcd1-385f-4d8a-bddf-f3e3cf24dc66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966322749-172.17.0.13-1598493084612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-50b7e3a9-fc96-4beb-9c79-9f4cebde6969,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-ed550a84-b1ee-4d77-8d55-47a7ccca730d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-457accd7-afff-489b-a3fc-7e18bb6a0578,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9e3bc69f-ac1b-4e36-a88c-fcd0449e7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-69338d3b-fbce-4073-8614-ce4d5c7e8610,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-01e24906-d33a-40d4-86b7-3beb60f0cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-e204092b-cd9a-4a05-b831-b6fb5d37e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-cf755888-0903-42c0-ac55-6e435f4ea527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966322749-172.17.0.13-1598493084612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-50b7e3a9-fc96-4beb-9c79-9f4cebde6969,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-ed550a84-b1ee-4d77-8d55-47a7ccca730d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-457accd7-afff-489b-a3fc-7e18bb6a0578,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9e3bc69f-ac1b-4e36-a88c-fcd0449e7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-69338d3b-fbce-4073-8614-ce4d5c7e8610,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-01e24906-d33a-40d4-86b7-3beb60f0cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-e204092b-cd9a-4a05-b831-b6fb5d37e0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-cf755888-0903-42c0-ac55-6e435f4ea527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5327
