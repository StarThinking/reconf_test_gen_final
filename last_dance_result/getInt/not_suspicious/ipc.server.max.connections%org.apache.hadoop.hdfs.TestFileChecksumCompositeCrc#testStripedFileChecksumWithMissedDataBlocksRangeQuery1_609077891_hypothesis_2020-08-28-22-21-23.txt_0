reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21126324-172.17.0.18-1598653557548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-61b7f466-c2f4-4079-a527-5d9629117d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-1d2622df-1e2f-41cb-92c2-056c22da8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-e0b437e4-a452-4bd5-ae52-b0625be60285,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-b24319c6-8b78-40b0-ae86-622f735460c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-34893a46-0b66-417e-80c7-4938a5105fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bf93b018-fac2-4ac4-8a6e-03bc0b3a0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-3b873e7b-71f6-4945-a1c2-8e571437f42e,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-461bb66c-53aa-4b57-8101-ef766cb1f53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21126324-172.17.0.18-1598653557548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-61b7f466-c2f4-4079-a527-5d9629117d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-1d2622df-1e2f-41cb-92c2-056c22da8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-e0b437e4-a452-4bd5-ae52-b0625be60285,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-b24319c6-8b78-40b0-ae86-622f735460c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-34893a46-0b66-417e-80c7-4938a5105fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-bf93b018-fac2-4ac4-8a6e-03bc0b3a0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-3b873e7b-71f6-4945-a1c2-8e571437f42e,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-461bb66c-53aa-4b57-8101-ef766cb1f53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628143938-172.17.0.18-1598653600304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-9e566a5d-d730-4159-a9fb-fa9b9284bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-1078cb54-b9fa-4940-9794-f9378c3f9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-0baef581-8528-4af8-8615-26b7115592fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-a191ed79-290f-48de-bc2b-9cb14454fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-904b5a96-02c3-443a-9322-e921d48c6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-4c6ad07d-3b55-426d-b20c-882407beae08,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-e4ca95dd-1477-4c52-84dd-450f537c16d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c3c2fab3-7cda-4ca5-8750-53abbbfffb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628143938-172.17.0.18-1598653600304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33021,DS-9e566a5d-d730-4159-a9fb-fa9b9284bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-1078cb54-b9fa-4940-9794-f9378c3f9d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-0baef581-8528-4af8-8615-26b7115592fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-a191ed79-290f-48de-bc2b-9cb14454fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-904b5a96-02c3-443a-9322-e921d48c6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-4c6ad07d-3b55-426d-b20c-882407beae08,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-e4ca95dd-1477-4c52-84dd-450f537c16d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c3c2fab3-7cda-4ca5-8750-53abbbfffb74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938513871-172.17.0.18-1598653634903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-73fa3c4f-e839-4a31-9743-0e439d5380ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6cedcf8f-fb78-488f-bcf7-4fbd42bcec80,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-2b8346dc-74d9-43a3-9193-1b74bbe948a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2d254c5b-42e4-4c09-8a61-c8ee5d8545de,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-7d33ce83-b63e-4805-85e2-979be1491f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-c5e701e1-f554-4cde-9be2-7888398a5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-9aebe777-51f7-4598-afc8-070b3fa41ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-726f5a84-4731-4231-9503-a831c011806b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938513871-172.17.0.18-1598653634903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-73fa3c4f-e839-4a31-9743-0e439d5380ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-6cedcf8f-fb78-488f-bcf7-4fbd42bcec80,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-2b8346dc-74d9-43a3-9193-1b74bbe948a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2d254c5b-42e4-4c09-8a61-c8ee5d8545de,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-7d33ce83-b63e-4805-85e2-979be1491f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-c5e701e1-f554-4cde-9be2-7888398a5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-9aebe777-51f7-4598-afc8-070b3fa41ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-726f5a84-4731-4231-9503-a831c011806b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549920895-172.17.0.18-1598653711236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-39c6b271-595b-4aeb-882a-bd5f3b4d7f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-e8589167-a299-4af2-b72c-08a5cdd8581d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-ec3fa1ef-2217-43f8-8437-168828b42317,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-2b3de133-ad29-440f-b672-bf72ae363534,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-760938df-4d4f-4999-bf87-83a5e8ffa05c,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-fa98cf62-97f5-4a1f-bc8b-7f89312741d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-c1ea0dc0-4cf2-4a8e-a6aa-71d8559a2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-78ce8853-1a3c-4b49-a1f0-71a4b73b35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549920895-172.17.0.18-1598653711236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-39c6b271-595b-4aeb-882a-bd5f3b4d7f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-e8589167-a299-4af2-b72c-08a5cdd8581d,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-ec3fa1ef-2217-43f8-8437-168828b42317,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-2b3de133-ad29-440f-b672-bf72ae363534,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-760938df-4d4f-4999-bf87-83a5e8ffa05c,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-fa98cf62-97f5-4a1f-bc8b-7f89312741d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-c1ea0dc0-4cf2-4a8e-a6aa-71d8559a2b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-78ce8853-1a3c-4b49-a1f0-71a4b73b35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972229869-172.17.0.18-1598653744162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-cf52cf1e-6cbb-4b86-a2b5-421fe76ae085,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-eda72146-e60d-4334-9672-bfa69018d864,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-a8f41944-3e12-45a6-bb34-78b964aa5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-0456893c-c07a-41d0-b4f1-7334d836c942,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ceb3cf70-4d19-4f54-804a-18be5fc38fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-564432c5-5387-4e82-b7df-2ec4d6172e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-92163966-e505-45a7-a96f-ab9742bff6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-66d119a0-9371-4754-9d72-3b54600ca79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972229869-172.17.0.18-1598653744162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-cf52cf1e-6cbb-4b86-a2b5-421fe76ae085,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-eda72146-e60d-4334-9672-bfa69018d864,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-a8f41944-3e12-45a6-bb34-78b964aa5f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-0456893c-c07a-41d0-b4f1-7334d836c942,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ceb3cf70-4d19-4f54-804a-18be5fc38fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-564432c5-5387-4e82-b7df-2ec4d6172e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-92163966-e505-45a7-a96f-ab9742bff6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-66d119a0-9371-4754-9d72-3b54600ca79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869729099-172.17.0.18-1598653784380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46416,DS-7015ccaf-a71a-4955-9ba1-df9610f86d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-3810b5d4-f496-44c0-98ff-d0f4cca4c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-f195dff1-a75b-4104-8e4b-aaffbdff112e,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-778b5cfc-6c4f-4272-a373-26efaee6f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f5117c74-f046-4377-992a-eb1ef0f84d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-bbc42b4a-1627-4786-9858-69d3c3747963,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9a8a2882-789c-44da-a756-9033bf732d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-72f92843-6533-43e4-8f48-1f0d2433576e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869729099-172.17.0.18-1598653784380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46416,DS-7015ccaf-a71a-4955-9ba1-df9610f86d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-3810b5d4-f496-44c0-98ff-d0f4cca4c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-f195dff1-a75b-4104-8e4b-aaffbdff112e,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-778b5cfc-6c4f-4272-a373-26efaee6f05d,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f5117c74-f046-4377-992a-eb1ef0f84d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-bbc42b4a-1627-4786-9858-69d3c3747963,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-9a8a2882-789c-44da-a756-9033bf732d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-72f92843-6533-43e4-8f48-1f0d2433576e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95315622-172.17.0.18-1598653962780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-881ddd4a-64cd-458c-b5c7-05cabf984996,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-e8d42b97-2534-46fd-9be4-854eca743267,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-c60c4dc6-88c6-402d-b914-514ba0788d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-fefc3b01-4512-4a3a-a508-17df46876905,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-68482414-df86-4435-9daa-6e9cc74dee81,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-5eec6b5c-df43-4b90-a69a-15ddefa39983,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-2fdfaeeb-142b-4f80-b22e-e1e59d3456f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b7120358-7382-4458-81fd-87571ccabe4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95315622-172.17.0.18-1598653962780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-881ddd4a-64cd-458c-b5c7-05cabf984996,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-e8d42b97-2534-46fd-9be4-854eca743267,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-c60c4dc6-88c6-402d-b914-514ba0788d55,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-fefc3b01-4512-4a3a-a508-17df46876905,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-68482414-df86-4435-9daa-6e9cc74dee81,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-5eec6b5c-df43-4b90-a69a-15ddefa39983,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-2fdfaeeb-142b-4f80-b22e-e1e59d3456f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b7120358-7382-4458-81fd-87571ccabe4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616835684-172.17.0.18-1598654315915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-e2047417-644f-4c41-83b6-64fd1a252436,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-331f2e8e-cf9d-4f02-9726-6c53932d84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-1b0d7d67-06cc-44ed-b362-3f31dbd03dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-221ef966-37aa-4d3f-8abb-64d443125b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-2ce8353b-dfdf-4675-8846-53e2c4161ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-d00c602a-ff1d-4bd4-b802-7b62876d139b,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-2c68533e-39f0-49e3-b066-ef9e288f9004,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c6342fec-2f68-40a2-a68f-fc606dc358a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616835684-172.17.0.18-1598654315915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-e2047417-644f-4c41-83b6-64fd1a252436,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-331f2e8e-cf9d-4f02-9726-6c53932d84a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-1b0d7d67-06cc-44ed-b362-3f31dbd03dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-221ef966-37aa-4d3f-8abb-64d443125b27,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-2ce8353b-dfdf-4675-8846-53e2c4161ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-d00c602a-ff1d-4bd4-b802-7b62876d139b,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-2c68533e-39f0-49e3-b066-ef9e288f9004,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-c6342fec-2f68-40a2-a68f-fc606dc358a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704997232-172.17.0.18-1598654659921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-79135fc6-8953-42f4-b7d8-557cf56f3404,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-88711625-f8b1-4c6e-8440-1d63d8e8831f,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-026d8b1c-6759-4f11-a9f8-4f840c8aa0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-5352cc6e-8626-4d17-9929-a216505bd224,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-c4e33f03-0d50-4e3d-b755-275ab691fe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-5861c95f-6d86-4624-9fd0-487b3e15f164,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-21f77a2d-326f-49db-9868-64f0bf5a3887,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-7f8b4e88-bfcc-4756-b600-e7b6010996bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704997232-172.17.0.18-1598654659921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-79135fc6-8953-42f4-b7d8-557cf56f3404,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-88711625-f8b1-4c6e-8440-1d63d8e8831f,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-026d8b1c-6759-4f11-a9f8-4f840c8aa0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-5352cc6e-8626-4d17-9929-a216505bd224,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-c4e33f03-0d50-4e3d-b755-275ab691fe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-5861c95f-6d86-4624-9fd0-487b3e15f164,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-21f77a2d-326f-49db-9868-64f0bf5a3887,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-7f8b4e88-bfcc-4756-b600-e7b6010996bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370278641-172.17.0.18-1598655074171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-fb0971eb-a8bc-4691-8248-e97748cc5d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-8f2488da-f9ee-4b37-90f8-f5729e48cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-28dda8c3-b5d1-4f84-bca8-7f9ed178eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-8abc8288-6ac2-48c0-b74b-7bed5e28e36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-310e4c03-1956-4580-a90d-b2f7da736de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-bfc54291-2722-47e0-8085-2439f14dc204,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-441b4dd0-656c-4c2f-b1cc-c00f8e1df18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-0292f729-ab20-4225-86e6-e71b8e801dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370278641-172.17.0.18-1598655074171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-fb0971eb-a8bc-4691-8248-e97748cc5d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-8f2488da-f9ee-4b37-90f8-f5729e48cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-28dda8c3-b5d1-4f84-bca8-7f9ed178eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-8abc8288-6ac2-48c0-b74b-7bed5e28e36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-310e4c03-1956-4580-a90d-b2f7da736de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-bfc54291-2722-47e0-8085-2439f14dc204,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-441b4dd0-656c-4c2f-b1cc-c00f8e1df18f,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-0292f729-ab20-4225-86e6-e71b8e801dd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119130491-172.17.0.18-1598655193237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-0d6627ad-4cdf-48cf-b660-8a6c96a9b2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-e9769175-71c2-4ea7-98d7-45771b4c5d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-75dbd099-30a6-4bbb-8904-34b78d6b7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-8cf80782-b9e1-459e-8382-56dc7d4e8938,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-49b7b70a-efd4-40d7-b653-9b5c91705309,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-359a0332-f4ad-4e52-b914-1432dcaf0bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f2b98584-2b6f-4f44-b3e0-5411f8a316c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-90a7c99d-1fce-40cf-81ed-5de8b333ea4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119130491-172.17.0.18-1598655193237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-0d6627ad-4cdf-48cf-b660-8a6c96a9b2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-e9769175-71c2-4ea7-98d7-45771b4c5d50,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-75dbd099-30a6-4bbb-8904-34b78d6b7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-8cf80782-b9e1-459e-8382-56dc7d4e8938,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-49b7b70a-efd4-40d7-b653-9b5c91705309,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-359a0332-f4ad-4e52-b914-1432dcaf0bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-f2b98584-2b6f-4f44-b3e0-5411f8a316c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-90a7c99d-1fce-40cf-81ed-5de8b333ea4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089199749-172.17.0.18-1598655297279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-db0783ac-e6c5-4480-9de7-85c83c89c088,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3a3df597-d890-41e0-bfbf-cddbddb519e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-55f806af-d802-4dc7-b451-cbd1f5ef7903,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-7cd65b31-5340-434a-b0b0-f7fab63069da,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-8af99532-1a7f-4fd7-ae96-379f66978228,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-f0b6ce82-ae1f-4eb8-a6c5-f88c8ee3495f,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-e189d7ac-8d4f-4d40-89d8-80c3e50a9044,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-e755e57a-33c1-44a3-99df-34b4ab6786b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089199749-172.17.0.18-1598655297279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-db0783ac-e6c5-4480-9de7-85c83c89c088,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3a3df597-d890-41e0-bfbf-cddbddb519e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-55f806af-d802-4dc7-b451-cbd1f5ef7903,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-7cd65b31-5340-434a-b0b0-f7fab63069da,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-8af99532-1a7f-4fd7-ae96-379f66978228,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-f0b6ce82-ae1f-4eb8-a6c5-f88c8ee3495f,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-e189d7ac-8d4f-4d40-89d8-80c3e50a9044,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-e755e57a-33c1-44a3-99df-34b4ab6786b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436976553-172.17.0.18-1598655561947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-25ddb744-8a2e-4a57-a63d-428f55ca3a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-3e5bc474-313e-4a9b-ae00-15d533da7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-4f6c18ed-a3fb-483b-be84-0f133aabeda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-e17210b9-6e51-48cc-83fd-050481668fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-0d60536b-6f7c-4ca6-b7c6-432eb2390e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-56486a1d-0e63-43d9-b27b-31f21e343c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-692aca82-b7a9-453b-8509-4556295f52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-491aeb82-96ce-4e84-bf6e-a89e7ea56ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436976553-172.17.0.18-1598655561947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-25ddb744-8a2e-4a57-a63d-428f55ca3a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-3e5bc474-313e-4a9b-ae00-15d533da7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-4f6c18ed-a3fb-483b-be84-0f133aabeda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-e17210b9-6e51-48cc-83fd-050481668fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-0d60536b-6f7c-4ca6-b7c6-432eb2390e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-56486a1d-0e63-43d9-b27b-31f21e343c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-692aca82-b7a9-453b-8509-4556295f52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-491aeb82-96ce-4e84-bf6e-a89e7ea56ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444745423-172.17.0.18-1598655697260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-e3d4a608-4e0b-4ab9-9e90-acdaf3f3ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-0c6ebe9e-e757-4cf3-897b-4a0702c85b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-a6ae26bc-d1b3-4507-a391-395d40c5805d,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-32b98c2c-8b0e-45e5-98cd-56f656b1f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-192f767d-e166-48ef-9b4a-0d4800ff030a,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-7cefaa2a-ec9b-4a20-a2b9-fb0a45ded264,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-e3e24e51-e660-4e8c-bd38-e805441cfac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d25751d5-067c-4945-af13-6b7f1eae4a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444745423-172.17.0.18-1598655697260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-e3d4a608-4e0b-4ab9-9e90-acdaf3f3ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-0c6ebe9e-e757-4cf3-897b-4a0702c85b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-a6ae26bc-d1b3-4507-a391-395d40c5805d,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-32b98c2c-8b0e-45e5-98cd-56f656b1f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-192f767d-e166-48ef-9b4a-0d4800ff030a,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-7cefaa2a-ec9b-4a20-a2b9-fb0a45ded264,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-e3e24e51-e660-4e8c-bd38-e805441cfac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d25751d5-067c-4945-af13-6b7f1eae4a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065942061-172.17.0.18-1598656316696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-f770930e-6133-46ec-8a25-13301f5f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-102ac2d5-ee23-450a-b2d9-08fec35cc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-034f126d-0786-4aec-930d-d2d3b63a62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-1782aec7-be98-4b7d-9ef4-c8887009a641,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-3a4802f4-e3ed-4678-9653-8acfbd0b56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-67a24435-cfd4-4688-9fda-aef8f47ea05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-a1f19d85-d88c-4fc8-9eec-6e8467b8c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-2a9c9158-c355-4646-8e61-27236aeb9460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065942061-172.17.0.18-1598656316696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-f770930e-6133-46ec-8a25-13301f5f997c,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-102ac2d5-ee23-450a-b2d9-08fec35cc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-034f126d-0786-4aec-930d-d2d3b63a62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-1782aec7-be98-4b7d-9ef4-c8887009a641,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-3a4802f4-e3ed-4678-9653-8acfbd0b56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-67a24435-cfd4-4688-9fda-aef8f47ea05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-a1f19d85-d88c-4fc8-9eec-6e8467b8c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-2a9c9158-c355-4646-8e61-27236aeb9460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809026794-172.17.0.18-1598656594105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-ea5649dc-fc6c-4d89-8f8c-6d7f76ab2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-192e4c89-d545-4b71-b82c-686b84d7d723,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-7b0a3c60-f1e0-443d-8ccc-dd957034b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-8d8f1f18-1f18-4c9d-8778-ee435be67860,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-0d0e189d-3abd-4ed0-ba43-7d0323c1dd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-58b10db1-f896-4078-b9df-220a04266c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-e09860ba-d6b3-4a20-83eb-d3936065c334,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-018a1b9d-24be-49a5-98fb-a2f0359e7752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809026794-172.17.0.18-1598656594105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-ea5649dc-fc6c-4d89-8f8c-6d7f76ab2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-192e4c89-d545-4b71-b82c-686b84d7d723,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-7b0a3c60-f1e0-443d-8ccc-dd957034b5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-8d8f1f18-1f18-4c9d-8778-ee435be67860,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-0d0e189d-3abd-4ed0-ba43-7d0323c1dd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-58b10db1-f896-4078-b9df-220a04266c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-e09860ba-d6b3-4a20-83eb-d3936065c334,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-018a1b9d-24be-49a5-98fb-a2f0359e7752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827394564-172.17.0.18-1598656808975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-7520a513-f439-49a8-bf28-69860ec93ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-50a24e73-99b3-43cd-b3c1-5f4f9d66d722,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-3b0aaa60-39d5-4fd5-80e8-4ec3a30b045a,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-35177ca4-21e8-4650-b4d7-b32379684a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-7855414b-949d-4dd1-ac1e-0b1bbb40e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-5749895f-3ad6-489d-8645-4173a412110b,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-04f4a8cb-40e8-4ec9-99c1-b6d6ca4d8a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-dc1fa638-18d8-4745-8359-e9fd83ba2ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827394564-172.17.0.18-1598656808975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-7520a513-f439-49a8-bf28-69860ec93ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-50a24e73-99b3-43cd-b3c1-5f4f9d66d722,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-3b0aaa60-39d5-4fd5-80e8-4ec3a30b045a,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-35177ca4-21e8-4650-b4d7-b32379684a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-7855414b-949d-4dd1-ac1e-0b1bbb40e0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-5749895f-3ad6-489d-8645-4173a412110b,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-04f4a8cb-40e8-4ec9-99c1-b6d6ca4d8a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-dc1fa638-18d8-4745-8359-e9fd83ba2ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287705862-172.17.0.18-1598656845670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-59d76955-dfdd-4509-afb1-3ff9646e1897,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-ff15f887-1814-4864-a77f-f0d0ff2f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-98a25e42-ca98-427a-aafd-b470622b82fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-1c24313a-8f03-40c1-a9e6-11a4f39cd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-182a4cfc-7c77-4343-a99c-c9b25edc08a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-5aaebf50-c28e-417b-a01c-28f681fccabc,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-ed955262-84a1-4a18-a9d6-0c6deab1882e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-907e6c26-d667-431a-8152-7e9013d5482a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287705862-172.17.0.18-1598656845670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-59d76955-dfdd-4509-afb1-3ff9646e1897,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-ff15f887-1814-4864-a77f-f0d0ff2f260a,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-98a25e42-ca98-427a-aafd-b470622b82fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-1c24313a-8f03-40c1-a9e6-11a4f39cd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-182a4cfc-7c77-4343-a99c-c9b25edc08a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-5aaebf50-c28e-417b-a01c-28f681fccabc,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-ed955262-84a1-4a18-a9d6-0c6deab1882e,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-907e6c26-d667-431a-8152-7e9013d5482a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657335500-172.17.0.18-1598656920459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-72234c81-a445-4b8b-be9f-bed448b5495a,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-6b1ee570-8b77-4e9f-95d0-3412f308e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-c67555ce-0e75-41ff-98ec-c87a2b063a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-e6d8a460-4b29-4067-82c3-b2bd0d84cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9579d85f-4daf-43ad-8c9a-a57fee5eb17c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e3bbcc8c-c5ea-4ca8-83f8-dc50775d3b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-0b5ef33c-eb72-48f9-8bfb-bcf6ab879f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-68faac38-f78c-4bcf-963d-478ef36f0655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657335500-172.17.0.18-1598656920459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-72234c81-a445-4b8b-be9f-bed448b5495a,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-6b1ee570-8b77-4e9f-95d0-3412f308e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-c67555ce-0e75-41ff-98ec-c87a2b063a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-e6d8a460-4b29-4067-82c3-b2bd0d84cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9579d85f-4daf-43ad-8c9a-a57fee5eb17c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e3bbcc8c-c5ea-4ca8-83f8-dc50775d3b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-0b5ef33c-eb72-48f9-8bfb-bcf6ab879f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-68faac38-f78c-4bcf-963d-478ef36f0655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218528372-172.17.0.18-1598657443395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-87c7ebdf-7e29-49b1-801b-6ffb8545f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-1239c347-6440-4318-a89e-c7e394292129,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-333e6bfe-02e2-4bf6-9b68-1f0c77f21af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-608d3ecd-efd5-43b1-9a38-e1ef7e4aa6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-95208fce-75f0-4b59-a942-d4501613c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-78d923cd-a91f-45d7-98f7-0c8cf165e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-8a725ce6-1c57-4fe3-8f32-f5a9a4a91970,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-83d1a55b-fbbb-4f02-89a7-7236b544b13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218528372-172.17.0.18-1598657443395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-87c7ebdf-7e29-49b1-801b-6ffb8545f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-1239c347-6440-4318-a89e-c7e394292129,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-333e6bfe-02e2-4bf6-9b68-1f0c77f21af7,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-608d3ecd-efd5-43b1-9a38-e1ef7e4aa6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-95208fce-75f0-4b59-a942-d4501613c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-78d923cd-a91f-45d7-98f7-0c8cf165e4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-8a725ce6-1c57-4fe3-8f32-f5a9a4a91970,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-83d1a55b-fbbb-4f02-89a7-7236b544b13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297500844-172.17.0.18-1598657666962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-c4e898ce-b0f4-4d2b-a8af-91de9e0d5ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-76618eb3-476d-400e-b93c-6f59f258b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-af1516d3-9c88-4ff2-bc11-be6a9a06ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d622607e-87d4-4aef-aebc-788515ff7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-15851588-4ffc-4bb2-8609-33688646fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-cca82767-2bd3-44e4-89a5-b09848293cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-714933cc-ffaa-40e6-96df-dc9b1d709e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9b4b0809-5efb-412b-89e7-070305e308ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297500844-172.17.0.18-1598657666962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-c4e898ce-b0f4-4d2b-a8af-91de9e0d5ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-76618eb3-476d-400e-b93c-6f59f258b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-af1516d3-9c88-4ff2-bc11-be6a9a06ddc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-d622607e-87d4-4aef-aebc-788515ff7c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-15851588-4ffc-4bb2-8609-33688646fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-cca82767-2bd3-44e4-89a5-b09848293cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-714933cc-ffaa-40e6-96df-dc9b1d709e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-9b4b0809-5efb-412b-89e7-070305e308ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124441424-172.17.0.18-1598658203194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-87d413f5-9258-494c-ae14-03f782ca8a72,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-0706c45d-bb77-4851-9fcf-f46e0654059c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-e616e492-9182-442d-a3e5-80f5b608912b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-6bd7424d-00f4-4483-b695-5d81751a2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-d9a25989-2da1-4352-9c70-4af5e5013285,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-7c401f81-c650-4fef-8d26-44f1f33e8605,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d6d13dd2-ca4c-40b2-b0b0-6f8c3b372a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-17eb33eb-e7a5-43b9-9d05-d665eb10a823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124441424-172.17.0.18-1598658203194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35751,DS-87d413f5-9258-494c-ae14-03f782ca8a72,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-0706c45d-bb77-4851-9fcf-f46e0654059c,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-e616e492-9182-442d-a3e5-80f5b608912b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-6bd7424d-00f4-4483-b695-5d81751a2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-d9a25989-2da1-4352-9c70-4af5e5013285,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-7c401f81-c650-4fef-8d26-44f1f33e8605,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d6d13dd2-ca4c-40b2-b0b0-6f8c3b372a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-17eb33eb-e7a5-43b9-9d05-d665eb10a823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27986470-172.17.0.18-1598658476981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-c959c40f-62a1-47c6-be14-7a30c3f1bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-c39c70ad-0139-4ca8-bee8-3a81a04291aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-0ad7a5ac-f9b2-4ff8-8637-3f838ce857e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-452781ff-9b3b-429d-9b5e-71a11237b537,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-cd0e8df9-a837-420b-b1ba-c76da706ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-b1cc914e-2b95-4e93-8305-6dfe31b3134d,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-4091bcd6-fbeb-43c8-9a99-40ec7b733680,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-e601dc54-0eb8-4813-953e-5f5cb031a8ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27986470-172.17.0.18-1598658476981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-c959c40f-62a1-47c6-be14-7a30c3f1bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-c39c70ad-0139-4ca8-bee8-3a81a04291aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-0ad7a5ac-f9b2-4ff8-8637-3f838ce857e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-452781ff-9b3b-429d-9b5e-71a11237b537,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-cd0e8df9-a837-420b-b1ba-c76da706ab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-b1cc914e-2b95-4e93-8305-6dfe31b3134d,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-4091bcd6-fbeb-43c8-9a99-40ec7b733680,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-e601dc54-0eb8-4813-953e-5f5cb031a8ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613461954-172.17.0.18-1598658509684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-8210f7a7-2006-4a31-bfb2-a4d9624c8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-63cc4be5-baca-4b96-9467-e5a8fd6e0175,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-6346a916-ac08-4456-b409-ea50229c0398,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-245cc7fd-4af3-4754-b590-f95f35eb4c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c8abbec5-e36a-49b7-8e44-a6785fc0311c,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-3c46ed5b-85e5-4541-85f6-beb658606aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-ab2fe9eb-20ec-4889-83f9-33b8fcf46af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-2a2e241b-4bee-45ca-85bf-00c8d769e0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613461954-172.17.0.18-1598658509684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-8210f7a7-2006-4a31-bfb2-a4d9624c8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-63cc4be5-baca-4b96-9467-e5a8fd6e0175,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-6346a916-ac08-4456-b409-ea50229c0398,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-245cc7fd-4af3-4754-b590-f95f35eb4c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-c8abbec5-e36a-49b7-8e44-a6785fc0311c,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-3c46ed5b-85e5-4541-85f6-beb658606aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-ab2fe9eb-20ec-4889-83f9-33b8fcf46af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-2a2e241b-4bee-45ca-85bf-00c8d769e0e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790701508-172.17.0.18-1598658656197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-444a2efa-eaaf-4a9a-afc0-a935b6a8f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-cdee626e-27f3-4c66-9241-957842d9988f,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e776f2f1-fb84-4d95-a6bd-a42153bfc4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-7b4f4d15-4b04-4571-bbde-de728b4cb013,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-b478be3d-fc63-4cbc-9e5a-20ca6222bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-bd596d27-763a-4c68-b292-6ce048fb7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-76617332-ade5-4b6e-881b-52e3e3012e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-6198ac01-c33b-4763-ab84-836aa5f1bce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790701508-172.17.0.18-1598658656197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-444a2efa-eaaf-4a9a-afc0-a935b6a8f2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-cdee626e-27f3-4c66-9241-957842d9988f,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e776f2f1-fb84-4d95-a6bd-a42153bfc4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-7b4f4d15-4b04-4571-bbde-de728b4cb013,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-b478be3d-fc63-4cbc-9e5a-20ca6222bebd,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-bd596d27-763a-4c68-b292-6ce048fb7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-76617332-ade5-4b6e-881b-52e3e3012e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-6198ac01-c33b-4763-ab84-836aa5f1bce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5572
