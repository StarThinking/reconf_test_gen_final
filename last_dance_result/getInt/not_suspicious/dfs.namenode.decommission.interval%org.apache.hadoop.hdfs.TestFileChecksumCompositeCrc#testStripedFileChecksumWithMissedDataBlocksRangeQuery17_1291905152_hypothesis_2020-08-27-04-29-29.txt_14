reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823780026-172.17.0.19-1598503552048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-bd6acd5f-1c88-4a90-8df5-50cff29ed258,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-411f6ef0-7ae2-4b3d-a7e1-fc8a17fd856e,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2bfeb6a5-9fdb-4a15-b6f7-ccc90d6b3eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-351ab919-493b-4633-823a-215c7ed1da24,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-59cd67d7-11db-4f77-a513-29798fb7449a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-57c70a89-c90f-4cd6-8e81-f4f5cc5235fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-c5b7b5e6-bcdc-4274-af6b-e375fc9a896c,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-b0b7bd00-f3fc-4107-b1e2-21773b7ff793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823780026-172.17.0.19-1598503552048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-bd6acd5f-1c88-4a90-8df5-50cff29ed258,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-411f6ef0-7ae2-4b3d-a7e1-fc8a17fd856e,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2bfeb6a5-9fdb-4a15-b6f7-ccc90d6b3eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-351ab919-493b-4633-823a-215c7ed1da24,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-59cd67d7-11db-4f77-a513-29798fb7449a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-57c70a89-c90f-4cd6-8e81-f4f5cc5235fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-c5b7b5e6-bcdc-4274-af6b-e375fc9a896c,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-b0b7bd00-f3fc-4107-b1e2-21773b7ff793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104648677-172.17.0.19-1598504118536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39272,DS-a8df8af9-9700-4e28-992b-6f1d0325748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-99d8dd5f-e5e3-4fe0-8f67-7ebfb068fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-5487971b-d4e5-4e71-acb2-26ff6fc90b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-059afe64-1f34-4c94-b920-bd0568c8173b,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-496a2a5f-718f-4d2e-a7c2-01661224cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-bf4bdcef-8f01-4101-9d3c-721e33438391,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-71ae944e-e374-4331-bee2-25f45c071666,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-bd78c899-98e4-41f2-b5d7-0d1cd40868c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104648677-172.17.0.19-1598504118536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39272,DS-a8df8af9-9700-4e28-992b-6f1d0325748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-99d8dd5f-e5e3-4fe0-8f67-7ebfb068fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-5487971b-d4e5-4e71-acb2-26ff6fc90b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-059afe64-1f34-4c94-b920-bd0568c8173b,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-496a2a5f-718f-4d2e-a7c2-01661224cab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-bf4bdcef-8f01-4101-9d3c-721e33438391,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-71ae944e-e374-4331-bee2-25f45c071666,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-bd78c899-98e4-41f2-b5d7-0d1cd40868c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823288150-172.17.0.19-1598504191096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-cb048f79-33f2-40f1-8fc2-7efd6735e952,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-fe6393e9-5ed1-40b3-8401-0b870dcc7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-730ee888-f0c6-43ce-aba4-738a62cc6bac,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-62a98595-3452-4891-a480-28c3f1c2524a,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-4993327a-41a4-4b8f-b533-45d3155e3105,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-e2d60859-b21f-46f2-b5b8-becad34bb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-889030b8-71d8-45b9-97cd-9f0c31ae1ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-45edfbb9-3519-4b1c-91bf-102cc18643ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823288150-172.17.0.19-1598504191096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-cb048f79-33f2-40f1-8fc2-7efd6735e952,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-fe6393e9-5ed1-40b3-8401-0b870dcc7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-730ee888-f0c6-43ce-aba4-738a62cc6bac,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-62a98595-3452-4891-a480-28c3f1c2524a,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-4993327a-41a4-4b8f-b533-45d3155e3105,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-e2d60859-b21f-46f2-b5b8-becad34bb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-889030b8-71d8-45b9-97cd-9f0c31ae1ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-45edfbb9-3519-4b1c-91bf-102cc18643ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602040629-172.17.0.19-1598504568100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-44d66b34-0e33-4f1c-849d-5679f99c0f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b008ade3-b3da-416a-b4db-ad656be4441a,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e5259d26-8cbc-4209-a69b-4e9bf90879d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-9d8fea4c-275f-4ac6-8083-d175001847ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d3c0cf17-3f17-4db7-989e-7c8719cabd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-aa92f906-3b74-46d7-8b93-e3b2a9e826db,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-57f05692-b0ad-46cf-be77-9e33d55bf532,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f9a183a3-71c2-4b36-a8ff-2ad7f0460aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602040629-172.17.0.19-1598504568100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-44d66b34-0e33-4f1c-849d-5679f99c0f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-b008ade3-b3da-416a-b4db-ad656be4441a,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e5259d26-8cbc-4209-a69b-4e9bf90879d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-9d8fea4c-275f-4ac6-8083-d175001847ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d3c0cf17-3f17-4db7-989e-7c8719cabd92,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-aa92f906-3b74-46d7-8b93-e3b2a9e826db,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-57f05692-b0ad-46cf-be77-9e33d55bf532,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f9a183a3-71c2-4b36-a8ff-2ad7f0460aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391482914-172.17.0.19-1598505518667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-7c7ccd2c-7f17-4244-8a53-bfbe8142dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-2791d76b-7bcc-49fe-8334-b935752edb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2831afab-6242-4d55-88ba-2cbc7f98b079,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-f9f975e6-116a-4268-95c0-1b980ddaf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8302b634-cede-419d-99f4-e40b891a00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-767a2352-252a-4421-b713-054e07d12062,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-56f844fa-50f0-4756-ba12-bfecaff95144,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-55b62637-b7e5-4fac-8d39-f5242b2c5c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391482914-172.17.0.19-1598505518667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-7c7ccd2c-7f17-4244-8a53-bfbe8142dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-2791d76b-7bcc-49fe-8334-b935752edb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2831afab-6242-4d55-88ba-2cbc7f98b079,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-f9f975e6-116a-4268-95c0-1b980ddaf1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8302b634-cede-419d-99f4-e40b891a00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-767a2352-252a-4421-b713-054e07d12062,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-56f844fa-50f0-4756-ba12-bfecaff95144,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-55b62637-b7e5-4fac-8d39-f5242b2c5c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646728560-172.17.0.19-1598505558559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-d5a04512-265e-4d25-96d5-645d531da52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-7d94a8b4-5253-4544-b84e-3e20c8261712,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-bdc61f68-e9c3-42ea-8ca5-3198e2db31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-7d0b8d6e-1bca-427e-97cc-da226006f9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-b474782e-2afe-43fd-bc78-4c3eb15b82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-b674706a-82bc-4f98-b074-dfa53d67af04,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-6406b8e4-ec8e-413f-9ef8-39482b13a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-15494a3f-c3e5-4c97-bc4d-c663d77f21dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646728560-172.17.0.19-1598505558559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-d5a04512-265e-4d25-96d5-645d531da52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-7d94a8b4-5253-4544-b84e-3e20c8261712,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-bdc61f68-e9c3-42ea-8ca5-3198e2db31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-7d0b8d6e-1bca-427e-97cc-da226006f9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-b474782e-2afe-43fd-bc78-4c3eb15b82b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-b674706a-82bc-4f98-b074-dfa53d67af04,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-6406b8e4-ec8e-413f-9ef8-39482b13a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-15494a3f-c3e5-4c97-bc4d-c663d77f21dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356103425-172.17.0.19-1598505666744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-053e8292-c433-4d20-a152-01898636fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-aa58a285-6ac5-4ed0-b651-41eeed51081d,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7c209afd-8e30-4995-8a2d-196eb19194f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-c5576ac6-ce59-4165-bbe1-fa7185c26e04,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-705ea33d-0096-4da9-a880-348fb5c1a148,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-869c646e-1757-49a5-9dab-bf6f45c109ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-d65ae797-28d6-4945-9932-24bc5033bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-2ef7bae8-2823-400c-bf77-be1341e0032f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356103425-172.17.0.19-1598505666744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-053e8292-c433-4d20-a152-01898636fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-aa58a285-6ac5-4ed0-b651-41eeed51081d,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7c209afd-8e30-4995-8a2d-196eb19194f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-c5576ac6-ce59-4165-bbe1-fa7185c26e04,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-705ea33d-0096-4da9-a880-348fb5c1a148,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-869c646e-1757-49a5-9dab-bf6f45c109ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-d65ae797-28d6-4945-9932-24bc5033bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-2ef7bae8-2823-400c-bf77-be1341e0032f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808826010-172.17.0.19-1598506028479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-2a1b8071-f435-48b6-b81e-0e5f7bbbfabc,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b8d3de32-4259-412a-bae4-ce9b3194553f,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-424d10dc-d669-462a-8433-86e23b8fd136,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-92e41540-ec6a-41e9-91a2-a114c8ebb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-a0a05229-c50a-4792-87bd-7219b8c2aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-130b6f42-fd6a-4bd9-bc1b-b0bfe46e2724,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d10e5672-7480-4d19-81f5-c7a379585f58,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-f289a50c-653d-4f8a-9656-0c3ee1d16450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808826010-172.17.0.19-1598506028479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-2a1b8071-f435-48b6-b81e-0e5f7bbbfabc,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-b8d3de32-4259-412a-bae4-ce9b3194553f,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-424d10dc-d669-462a-8433-86e23b8fd136,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-92e41540-ec6a-41e9-91a2-a114c8ebb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-a0a05229-c50a-4792-87bd-7219b8c2aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-130b6f42-fd6a-4bd9-bc1b-b0bfe46e2724,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d10e5672-7480-4d19-81f5-c7a379585f58,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-f289a50c-653d-4f8a-9656-0c3ee1d16450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168995133-172.17.0.19-1598506681309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-98e7053a-a7d5-4754-8997-1027a9fdc460,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-9a9d2faf-b46e-4bc8-8360-df8ab2d866a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-b2c7afa4-50aa-4937-ac96-72fe1d00b115,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-e8994a15-08b8-4234-8bda-1317b5f2d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1e9ca44b-1433-4df1-95a6-8e9b94cc5b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-00ada385-5a59-4c64-8a8b-f0a65dac88db,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-df5c6738-7282-4301-9b8b-e415ee9ae9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-54b20c32-37e3-42fa-9aee-e2974dd24ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168995133-172.17.0.19-1598506681309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-98e7053a-a7d5-4754-8997-1027a9fdc460,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-9a9d2faf-b46e-4bc8-8360-df8ab2d866a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-b2c7afa4-50aa-4937-ac96-72fe1d00b115,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-e8994a15-08b8-4234-8bda-1317b5f2d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-1e9ca44b-1433-4df1-95a6-8e9b94cc5b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-00ada385-5a59-4c64-8a8b-f0a65dac88db,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-df5c6738-7282-4301-9b8b-e415ee9ae9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-54b20c32-37e3-42fa-9aee-e2974dd24ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083825942-172.17.0.19-1598506791388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-d6fb2cde-0bd5-4dcc-9276-c8b3bf967514,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-03f18851-9939-4f5d-a8c9-4b6f8664c074,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-8c9f46e8-8d61-4b77-8169-2a9be46aad02,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-6db29f5b-051b-478d-8ebe-38302211b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-13bb43e6-033e-409d-b515-4769590030ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c2c93804-7332-4177-88bc-027d80a4a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-7929a5a6-1d10-42c6-9427-8cfb3e0481e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d717c749-595f-48f3-88f5-bd75c1e6b043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083825942-172.17.0.19-1598506791388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-d6fb2cde-0bd5-4dcc-9276-c8b3bf967514,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-03f18851-9939-4f5d-a8c9-4b6f8664c074,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-8c9f46e8-8d61-4b77-8169-2a9be46aad02,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-6db29f5b-051b-478d-8ebe-38302211b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-13bb43e6-033e-409d-b515-4769590030ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-c2c93804-7332-4177-88bc-027d80a4a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-7929a5a6-1d10-42c6-9427-8cfb3e0481e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d717c749-595f-48f3-88f5-bd75c1e6b043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933872104-172.17.0.19-1598506858876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-4c21d020-628c-4c40-bb50-bbf2d9e4b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-fbf000af-ed76-4d03-b76e-26cc08e0003b,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-98028909-bb0b-482d-9922-58c26e7cd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-52feb28f-4d3d-4f11-af61-4fa223d66e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-932688d9-70d9-42a7-94bd-5f2bfe92865a,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-c2c13770-a93b-4276-a56f-b6d10706da31,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-8a9e994b-d4ed-476f-a460-1fa89c176707,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-43193363-c7f7-417a-afdd-2accd9d9198d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-933872104-172.17.0.19-1598506858876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38290,DS-4c21d020-628c-4c40-bb50-bbf2d9e4b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-fbf000af-ed76-4d03-b76e-26cc08e0003b,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-98028909-bb0b-482d-9922-58c26e7cd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-52feb28f-4d3d-4f11-af61-4fa223d66e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-932688d9-70d9-42a7-94bd-5f2bfe92865a,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-c2c13770-a93b-4276-a56f-b6d10706da31,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-8a9e994b-d4ed-476f-a460-1fa89c176707,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-43193363-c7f7-417a-afdd-2accd9d9198d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997607966-172.17.0.19-1598506989908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-03cf9641-7dd1-4b06-b103-92639f17fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3489ce21-ddf2-444a-a37b-cd271196e9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-5c327400-c6b9-48a0-825b-0e6b7f8f7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-3700f408-a87f-43cc-9509-b58fec0c7831,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-6fa1c787-9cfd-4887-8e23-fbee0bbad292,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-4833f1d8-705c-4953-b4e7-c33ad863bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-5a806616-686d-4470-873f-95ac2d3f23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-5855e7ce-2c01-4189-898a-4ed482348dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997607966-172.17.0.19-1598506989908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-03cf9641-7dd1-4b06-b103-92639f17fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-3489ce21-ddf2-444a-a37b-cd271196e9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-5c327400-c6b9-48a0-825b-0e6b7f8f7b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-3700f408-a87f-43cc-9509-b58fec0c7831,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-6fa1c787-9cfd-4887-8e23-fbee0bbad292,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-4833f1d8-705c-4953-b4e7-c33ad863bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-5a806616-686d-4470-873f-95ac2d3f23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-5855e7ce-2c01-4189-898a-4ed482348dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455304009-172.17.0.19-1598507411914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-ae7e5c52-2184-4f78-a901-90bd84cde719,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-d64e5387-1772-4dfd-ae83-2f0ae91fa948,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c813e1d3-1db8-453f-8fbd-79282b940334,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-1d34955c-5bf4-4eb4-b89b-a42936044295,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-4500abb1-9eab-49f8-aeef-a8a285679741,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-9c5d5c6c-ec25-4090-ac95-07cfe537a711,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-dfcb861e-470c-4865-9644-e3313eb47727,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-d1d061e4-6139-4326-82e2-5bd599739d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455304009-172.17.0.19-1598507411914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-ae7e5c52-2184-4f78-a901-90bd84cde719,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-d64e5387-1772-4dfd-ae83-2f0ae91fa948,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c813e1d3-1db8-453f-8fbd-79282b940334,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-1d34955c-5bf4-4eb4-b89b-a42936044295,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-4500abb1-9eab-49f8-aeef-a8a285679741,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-9c5d5c6c-ec25-4090-ac95-07cfe537a711,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-dfcb861e-470c-4865-9644-e3313eb47727,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-d1d061e4-6139-4326-82e2-5bd599739d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169306439-172.17.0.19-1598507489095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-5681e9db-0a4f-4e47-aaea-065e1f482392,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-3305c671-b6ba-4aca-a532-2953f9164ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-dff22d70-3b86-4a22-a46e-3ca8e80dba18,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-401e1a8b-32a1-4a6b-af8d-44201874e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-79c0ffe8-ce58-4083-9e28-da9f4e57d2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-42c8e58e-20fc-4ed1-8cd3-d410283b0414,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-4bb25cba-e05a-4c70-a021-f9b4090a06b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-76e9f2a7-d184-480b-8641-1087b7accdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169306439-172.17.0.19-1598507489095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-5681e9db-0a4f-4e47-aaea-065e1f482392,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-3305c671-b6ba-4aca-a532-2953f9164ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-dff22d70-3b86-4a22-a46e-3ca8e80dba18,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-401e1a8b-32a1-4a6b-af8d-44201874e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-79c0ffe8-ce58-4083-9e28-da9f4e57d2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-42c8e58e-20fc-4ed1-8cd3-d410283b0414,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-4bb25cba-e05a-4c70-a021-f9b4090a06b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-76e9f2a7-d184-480b-8641-1087b7accdf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.interval
component: hdfs:NameNode
v1: 3
v2: 60s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529792001-172.17.0.19-1598507609004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-a81f6a98-33fe-4250-a74a-917f527af2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-00dd32e6-d6c9-4b3b-8bf7-a2abf16c42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-fe63f11f-6960-4d3b-bc30-c2413cc63c03,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-3d1094da-6bbe-4c6c-a686-09c994440382,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-a46e8b87-a542-446c-8fe1-b2f9daa708a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-7122ac15-d783-47a9-987a-957c61233f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-223521da-17c5-4102-82ff-9fa273b0c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-29e04c20-d5a0-4e52-a321-ec14b206270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529792001-172.17.0.19-1598507609004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-a81f6a98-33fe-4250-a74a-917f527af2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-00dd32e6-d6c9-4b3b-8bf7-a2abf16c42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-fe63f11f-6960-4d3b-bc30-c2413cc63c03,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-3d1094da-6bbe-4c6c-a686-09c994440382,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-a46e8b87-a542-446c-8fe1-b2f9daa708a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-7122ac15-d783-47a9-987a-957c61233f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-223521da-17c5-4102-82ff-9fa273b0c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-29e04c20-d5a0-4e52-a321-ec14b206270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5436
