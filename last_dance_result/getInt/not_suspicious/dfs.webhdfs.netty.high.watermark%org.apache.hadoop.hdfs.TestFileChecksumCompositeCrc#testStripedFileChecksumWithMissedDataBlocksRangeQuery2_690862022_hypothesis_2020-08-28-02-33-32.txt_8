reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092677464-172.17.0.3-1598582184023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-ea4f857b-b29b-4ae0-9474-9e164bd24f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-09fc9a6d-1418-47f7-9071-b9bbe7a7c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b29d357f-73e1-4a62-8887-8edd517b74a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-9805c7c1-8db4-4523-8cf4-109aef15b714,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-d38e8e3e-cff1-4d99-b0f4-782998a2abde,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-7996530f-c466-4838-8244-3bf07ae99de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-f6b4e8c1-1af2-4334-8af9-97420ba3df02,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-b706ce88-90a4-44cc-9f47-a80be6290761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092677464-172.17.0.3-1598582184023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-ea4f857b-b29b-4ae0-9474-9e164bd24f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-09fc9a6d-1418-47f7-9071-b9bbe7a7c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b29d357f-73e1-4a62-8887-8edd517b74a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-9805c7c1-8db4-4523-8cf4-109aef15b714,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-d38e8e3e-cff1-4d99-b0f4-782998a2abde,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-7996530f-c466-4838-8244-3bf07ae99de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-f6b4e8c1-1af2-4334-8af9-97420ba3df02,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-b706ce88-90a4-44cc-9f47-a80be6290761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533037123-172.17.0.3-1598582253225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-371d47b4-24eb-4be8-9c2a-60eaf362e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-324ead16-30d6-4c69-839c-f826a47ed5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-5ebebb55-c378-4c40-af76-708664a14b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-8892949d-2b55-432c-93b1-ebf870667070,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-bd2646ba-71cb-4a40-a1b6-724473447ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-fa47a1ce-2534-451f-98c8-c4eac406d85c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-5f5ca408-7423-4b02-8400-52d9092f1bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-b06fd2e5-81dc-41b7-8d24-d153df1b00df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533037123-172.17.0.3-1598582253225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-371d47b4-24eb-4be8-9c2a-60eaf362e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-324ead16-30d6-4c69-839c-f826a47ed5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-5ebebb55-c378-4c40-af76-708664a14b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-8892949d-2b55-432c-93b1-ebf870667070,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-bd2646ba-71cb-4a40-a1b6-724473447ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-fa47a1ce-2534-451f-98c8-c4eac406d85c,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-5f5ca408-7423-4b02-8400-52d9092f1bab,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-b06fd2e5-81dc-41b7-8d24-d153df1b00df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405955908-172.17.0.3-1598582949729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-5c174c52-c6e9-4fbf-a247-a7e2a2f9863e,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-f74c4701-4f30-41b9-b6ae-340aa3af2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-2c262b37-f24c-473f-b484-a25e83e8e07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-5acc6603-e7aa-45a0-aef7-1ffc1cee5164,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-fc062d0b-f75d-471a-8246-1e1f0bfaca84,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c92495a2-96d2-4e11-8812-17d9526f16ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-99325c85-039b-4541-adb3-a1b8e3b0be1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-21b2a6f0-4a4a-4793-b892-94effe740663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405955908-172.17.0.3-1598582949729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-5c174c52-c6e9-4fbf-a247-a7e2a2f9863e,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-f74c4701-4f30-41b9-b6ae-340aa3af2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-2c262b37-f24c-473f-b484-a25e83e8e07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-5acc6603-e7aa-45a0-aef7-1ffc1cee5164,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-fc062d0b-f75d-471a-8246-1e1f0bfaca84,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c92495a2-96d2-4e11-8812-17d9526f16ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-99325c85-039b-4541-adb3-a1b8e3b0be1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-21b2a6f0-4a4a-4793-b892-94effe740663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454607922-172.17.0.3-1598582979222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-398c26d4-73f5-4a9a-93dc-dc79bc29e012,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-44f0d7bd-6d3c-4b18-841c-7b6cfba1c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-2a041f26-2420-4fc9-b294-6e48d155ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-ef4366c5-2505-4354-b731-2182617af0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-44621c40-6464-4274-9ba0-15c5c5275d45,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-001e473b-0abd-4722-a2f4-450d920fd5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-cd090dd9-4af0-4c0f-a74a-0b23a4dd9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-c469c3c9-ef47-42db-aed7-eeaebd99fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454607922-172.17.0.3-1598582979222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-398c26d4-73f5-4a9a-93dc-dc79bc29e012,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-44f0d7bd-6d3c-4b18-841c-7b6cfba1c7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-2a041f26-2420-4fc9-b294-6e48d155ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-ef4366c5-2505-4354-b731-2182617af0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-44621c40-6464-4274-9ba0-15c5c5275d45,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-001e473b-0abd-4722-a2f4-450d920fd5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-cd090dd9-4af0-4c0f-a74a-0b23a4dd9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-c469c3c9-ef47-42db-aed7-eeaebd99fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574976745-172.17.0.3-1598583977943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36251,DS-6f1c454f-aefb-4edf-b6fc-01da4aa4478d,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-ad97eb70-fc18-4019-aae3-34db09b4f980,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-381cec92-3563-46ab-b4df-520c82620185,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-d7493e46-9274-48a6-b455-f917375c2628,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-516a021d-0216-4f24-8c9a-e3b84c040347,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-b659fa65-721b-43c2-aa08-5ae8c0539ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-196d1455-ffdd-43e8-a592-7a49dd710544,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e8836872-7bee-450c-bf96-e6899789ada7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574976745-172.17.0.3-1598583977943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36251,DS-6f1c454f-aefb-4edf-b6fc-01da4aa4478d,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-ad97eb70-fc18-4019-aae3-34db09b4f980,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-381cec92-3563-46ab-b4df-520c82620185,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-d7493e46-9274-48a6-b455-f917375c2628,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-516a021d-0216-4f24-8c9a-e3b84c040347,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-b659fa65-721b-43c2-aa08-5ae8c0539ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-196d1455-ffdd-43e8-a592-7a49dd710544,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-e8836872-7bee-450c-bf96-e6899789ada7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154352661-172.17.0.3-1598584181832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-79b478f7-ceaf-477d-9b6c-e0f9189ad8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-aeb9df7b-ba59-4c54-a8bc-fe5c42d749f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-1a5c6707-a09b-49c7-bbbf-8ceb23896000,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-009f0e1c-329a-46f9-8016-d9232e1298df,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-826de1a7-e895-444a-b059-d06d631886df,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-d2d77b30-90ee-4ba9-8335-e36653147419,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b20edcc4-4865-4be5-88cf-3c48e31b5b81,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-f6d6891d-96db-4d8d-897c-2c5bcffdebc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154352661-172.17.0.3-1598584181832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-79b478f7-ceaf-477d-9b6c-e0f9189ad8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-aeb9df7b-ba59-4c54-a8bc-fe5c42d749f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-1a5c6707-a09b-49c7-bbbf-8ceb23896000,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-009f0e1c-329a-46f9-8016-d9232e1298df,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-826de1a7-e895-444a-b059-d06d631886df,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-d2d77b30-90ee-4ba9-8335-e36653147419,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-b20edcc4-4865-4be5-88cf-3c48e31b5b81,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-f6d6891d-96db-4d8d-897c-2c5bcffdebc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086572862-172.17.0.3-1598584214258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-084d76c3-8042-4155-b72d-d9f58fb81440,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-0fd90e6b-fb4a-49ff-8849-d1f5905326b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-63125b4c-3668-4234-8e73-44a80606b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-f4dd2c32-84ca-4dad-8cf6-26e38887863a,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4e128fd7-955e-4549-af54-d33e1a0466d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-22daada6-174c-4b3e-9a14-5ce1c7220847,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-cceb9adc-75fa-4964-8a05-3b00112f1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-6b3199c6-f67d-4c53-9871-5618ae792dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086572862-172.17.0.3-1598584214258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38905,DS-084d76c3-8042-4155-b72d-d9f58fb81440,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-0fd90e6b-fb4a-49ff-8849-d1f5905326b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-63125b4c-3668-4234-8e73-44a80606b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-f4dd2c32-84ca-4dad-8cf6-26e38887863a,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4e128fd7-955e-4549-af54-d33e1a0466d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-22daada6-174c-4b3e-9a14-5ce1c7220847,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-cceb9adc-75fa-4964-8a05-3b00112f1b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-6b3199c6-f67d-4c53-9871-5618ae792dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914605656-172.17.0.3-1598584729764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-67385c4d-1294-4002-b0ca-1a27c84a420d,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-bc8cd176-78fc-4a99-9bbc-0d12870729d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e7d8dc37-2cb8-4b10-82a8-b12f320d66f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-3aaaa928-7a08-4beb-850f-4e6f390f7517,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-f82a0cc6-e525-4e57-b0de-efae5ca2425a,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-78893561-55a5-4fee-900e-3f4e838bd0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-02573079-f2b4-4197-823c-1a4f942cc137,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-f6b097a8-7ff7-4a2d-814b-57534377c8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914605656-172.17.0.3-1598584729764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-67385c4d-1294-4002-b0ca-1a27c84a420d,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-bc8cd176-78fc-4a99-9bbc-0d12870729d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-e7d8dc37-2cb8-4b10-82a8-b12f320d66f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-3aaaa928-7a08-4beb-850f-4e6f390f7517,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-f82a0cc6-e525-4e57-b0de-efae5ca2425a,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-78893561-55a5-4fee-900e-3f4e838bd0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-02573079-f2b4-4197-823c-1a4f942cc137,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-f6b097a8-7ff7-4a2d-814b-57534377c8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144417839-172.17.0.3-1598585006673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-5f988874-2f45-41c0-87e2-b12f3e008358,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-75809a01-4e3a-4da6-8d55-37bba9539142,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-7472a541-a8c8-4023-9f11-39ca597e74ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-c851bfc1-e9ed-4848-93d1-bb3995382c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-9b3ed64b-bdb2-442c-8bcb-18ea359c1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-aa03850b-9064-4b58-acd8-ba748b1afbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-92811b57-3121-46cb-93d4-fc4efc0e5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-ca7ccbd5-4923-455e-9a6f-7d12c49e92c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144417839-172.17.0.3-1598585006673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-5f988874-2f45-41c0-87e2-b12f3e008358,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-75809a01-4e3a-4da6-8d55-37bba9539142,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-7472a541-a8c8-4023-9f11-39ca597e74ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-c851bfc1-e9ed-4848-93d1-bb3995382c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-9b3ed64b-bdb2-442c-8bcb-18ea359c1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-aa03850b-9064-4b58-acd8-ba748b1afbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-92811b57-3121-46cb-93d4-fc4efc0e5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-ca7ccbd5-4923-455e-9a6f-7d12c49e92c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242499177-172.17.0.3-1598585253819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39315,DS-8a48589b-d1fd-439d-932d-ddeb3a6277b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7dcd35b3-4fbe-4830-a068-ed4cb24b40db,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-3ecdcbf4-c46a-467e-88b4-f4414c5d5f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-9b5467b5-03a9-4a19-983b-56263bca164d,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-096f1e02-9753-400c-baad-033dac1dbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-51654ec8-014e-4754-8695-83774d9bf8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-11a6df43-7b84-4a94-9c63-6bbf3605fb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-3d1195b3-70a0-42df-ac80-2e6d846ce486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242499177-172.17.0.3-1598585253819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39315,DS-8a48589b-d1fd-439d-932d-ddeb3a6277b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-7dcd35b3-4fbe-4830-a068-ed4cb24b40db,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-3ecdcbf4-c46a-467e-88b4-f4414c5d5f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-9b5467b5-03a9-4a19-983b-56263bca164d,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-096f1e02-9753-400c-baad-033dac1dbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-51654ec8-014e-4754-8695-83774d9bf8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-11a6df43-7b84-4a94-9c63-6bbf3605fb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-3d1195b3-70a0-42df-ac80-2e6d846ce486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617938457-172.17.0.3-1598585289058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-3ffdbd63-0c0c-42e1-ad88-05f4de28f346,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-7b2216b0-4ecb-4f48-8d1f-d562e02ec990,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a0b7389f-d8a1-4545-bbfa-ccde2a56f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-2270ad2b-2f21-4bb2-898b-4ec9b6a1037b,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-b42d66dc-79e9-4cf6-b8aa-4d14f7fbb720,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-46917d7c-003b-488c-9541-4b8ae48c5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-926e27ea-886e-46e7-b4a1-11e505962816,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-eaa2b8e1-a8de-4963-8d51-a788bbf96a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617938457-172.17.0.3-1598585289058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36706,DS-3ffdbd63-0c0c-42e1-ad88-05f4de28f346,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-7b2216b0-4ecb-4f48-8d1f-d562e02ec990,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-a0b7389f-d8a1-4545-bbfa-ccde2a56f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-2270ad2b-2f21-4bb2-898b-4ec9b6a1037b,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-b42d66dc-79e9-4cf6-b8aa-4d14f7fbb720,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-46917d7c-003b-488c-9541-4b8ae48c5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-926e27ea-886e-46e7-b4a1-11e505962816,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-eaa2b8e1-a8de-4963-8d51-a788bbf96a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685439240-172.17.0.3-1598585318525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-c1823df7-572a-4255-a9da-a689fdfc8198,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-30dd2f30-a39e-4962-bdfa-040674cad94a,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-fb4ea1b1-1584-4125-8c8c-1400f13e8b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d024b7b1-8215-4c65-b23d-f286f8337e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-6d530d7b-0c0b-4c29-aa6f-958da217eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-230b9afd-e06a-434f-8407-8f3a403807d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-64804493-0ec3-4156-8086-1aa1e0492aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-fddadcad-c349-4d50-811e-6e5aa5a6633a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685439240-172.17.0.3-1598585318525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-c1823df7-572a-4255-a9da-a689fdfc8198,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-30dd2f30-a39e-4962-bdfa-040674cad94a,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-fb4ea1b1-1584-4125-8c8c-1400f13e8b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-d024b7b1-8215-4c65-b23d-f286f8337e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-6d530d7b-0c0b-4c29-aa6f-958da217eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-230b9afd-e06a-434f-8407-8f3a403807d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-64804493-0ec3-4156-8086-1aa1e0492aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-fddadcad-c349-4d50-811e-6e5aa5a6633a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212418142-172.17.0.3-1598585382958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-651faa53-a0c0-4674-8fca-1beb3061b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-0662a510-22e3-4d2a-aff4-57366caf577e,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-bd0675e7-6f0d-4c0a-aae8-e7d361cd3e68,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-affe8dd9-0c75-467e-8751-4873bd166505,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-75419b7e-1151-44a2-9470-c8dcab0f1172,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-c2d6d4b3-5eb2-415e-87e6-61fd21fbe369,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-037b07ac-6846-44c9-a661-d7b425b4b857,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-a96f545e-fef6-42b2-ad71-dc83fae8bee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212418142-172.17.0.3-1598585382958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-651faa53-a0c0-4674-8fca-1beb3061b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-0662a510-22e3-4d2a-aff4-57366caf577e,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-bd0675e7-6f0d-4c0a-aae8-e7d361cd3e68,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-affe8dd9-0c75-467e-8751-4873bd166505,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-75419b7e-1151-44a2-9470-c8dcab0f1172,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-c2d6d4b3-5eb2-415e-87e6-61fd21fbe369,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-037b07ac-6846-44c9-a661-d7b425b4b857,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-a96f545e-fef6-42b2-ad71-dc83fae8bee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249645741-172.17.0.3-1598585486642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-021671b4-7666-46da-b4f4-fa356318307f,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ea9d3a24-5a26-415c-a50f-66b24733778c,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-61db18cf-9f8f-40aa-84d7-0a9b2dc08856,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-f5ab05cb-9b30-4c52-9c63-6bf382b2ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-8a9d05c8-3b41-4db2-aa7f-16d9a37e7a32,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-4ec0c670-2116-400d-86f2-f66b816a9139,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-e57637c4-e898-4c37-a287-a500787dc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-9ec70369-0488-496c-90b4-77e6cec09165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249645741-172.17.0.3-1598585486642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-021671b4-7666-46da-b4f4-fa356318307f,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ea9d3a24-5a26-415c-a50f-66b24733778c,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-61db18cf-9f8f-40aa-84d7-0a9b2dc08856,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-f5ab05cb-9b30-4c52-9c63-6bf382b2ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-8a9d05c8-3b41-4db2-aa7f-16d9a37e7a32,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-4ec0c670-2116-400d-86f2-f66b816a9139,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-e57637c4-e898-4c37-a287-a500787dc10b,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-9ec70369-0488-496c-90b4-77e6cec09165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910320425-172.17.0.3-1598585593562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-c05511c5-60e0-4eb5-804b-1acbb1bd9bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-5a34103a-393b-45df-9685-f44a92d17873,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-315bb22a-8fe6-47d9-9992-28702a6bcf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ab1e5595-f3bf-4b8a-a7d7-e77c96f4896a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-82566c6a-0a57-4772-bd91-5d9620779e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-3b9a037c-a4c0-4a13-a04b-f79f5b9a29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-6ea5d53e-eef5-4690-94e5-263bcae8b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dc1b9c74-f00c-41e9-aafa-75215d21b14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910320425-172.17.0.3-1598585593562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38783,DS-c05511c5-60e0-4eb5-804b-1acbb1bd9bff,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-5a34103a-393b-45df-9685-f44a92d17873,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-315bb22a-8fe6-47d9-9992-28702a6bcf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-ab1e5595-f3bf-4b8a-a7d7-e77c96f4896a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-82566c6a-0a57-4772-bd91-5d9620779e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-3b9a037c-a4c0-4a13-a04b-f79f5b9a29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-6ea5d53e-eef5-4690-94e5-263bcae8b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dc1b9c74-f00c-41e9-aafa-75215d21b14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112445166-172.17.0.3-1598586537996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-d33e9bb7-0746-4509-8ef9-f96f63eaa05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-60694d39-212e-4aac-aba3-cb95f997346c,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-f38a02f0-cdc9-4636-b10c-c32012d8e223,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-7cedd00e-c965-4827-9f6e-0020ec744b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-4a8d09c9-abd6-4d95-b7ac-a02b01c0046a,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-433519b8-be55-4ce3-86a5-96f34733656c,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-6b883d19-2704-4d43-8487-61c6fa63fc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-cc8e6ce3-0bf3-4f32-a485-7f3275cdf696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112445166-172.17.0.3-1598586537996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-d33e9bb7-0746-4509-8ef9-f96f63eaa05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-60694d39-212e-4aac-aba3-cb95f997346c,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-f38a02f0-cdc9-4636-b10c-c32012d8e223,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-7cedd00e-c965-4827-9f6e-0020ec744b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-4a8d09c9-abd6-4d95-b7ac-a02b01c0046a,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-433519b8-be55-4ce3-86a5-96f34733656c,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-6b883d19-2704-4d43-8487-61c6fa63fc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-cc8e6ce3-0bf3-4f32-a485-7f3275cdf696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063840958-172.17.0.3-1598586717776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36617,DS-8e4f6db3-7840-484e-893b-752e4f0dbd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-d0404a7c-14d2-4a94-8e7f-5ae9971cd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b00e7bc9-9987-4c1b-95dc-8bb05a7ebc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-ae71049c-f502-426d-839b-5f05cb7cdd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-3b929fa0-9f5a-48a2-bdeb-13381711b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-7afdcf65-9f58-4797-abfd-43d3dfb3723a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-945d8582-a5f0-4070-8948-f664781cd505,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-65d89da6-c4cd-469f-b6b9-919bb7a1e253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063840958-172.17.0.3-1598586717776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36617,DS-8e4f6db3-7840-484e-893b-752e4f0dbd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-d0404a7c-14d2-4a94-8e7f-5ae9971cd8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-b00e7bc9-9987-4c1b-95dc-8bb05a7ebc33,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-ae71049c-f502-426d-839b-5f05cb7cdd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-3b929fa0-9f5a-48a2-bdeb-13381711b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-7afdcf65-9f58-4797-abfd-43d3dfb3723a,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-945d8582-a5f0-4070-8948-f664781cd505,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-65d89da6-c4cd-469f-b6b9-919bb7a1e253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502499686-172.17.0.3-1598586790886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-e9b7d538-5809-4ba4-91e2-2ee4582c3883,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-27f66abb-ad3e-4052-b661-de5a667b358b,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-cecdb963-6234-419f-8855-78615bfce407,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-d4c48afb-260c-49d3-86c3-8aceb3f6d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-8092540c-f951-40dd-bb08-fd99149653ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-3668a1e6-de4d-44f6-9338-2a3992ae4201,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-d9b78756-05ad-471e-8e58-dfa797dbe061,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-aa400146-a31e-420e-a541-e182a251c3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502499686-172.17.0.3-1598586790886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-e9b7d538-5809-4ba4-91e2-2ee4582c3883,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-27f66abb-ad3e-4052-b661-de5a667b358b,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-cecdb963-6234-419f-8855-78615bfce407,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-d4c48afb-260c-49d3-86c3-8aceb3f6d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-8092540c-f951-40dd-bb08-fd99149653ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-3668a1e6-de4d-44f6-9338-2a3992ae4201,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-d9b78756-05ad-471e-8e58-dfa797dbe061,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-aa400146-a31e-420e-a541-e182a251c3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273395709-172.17.0.3-1598587031109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-57df8089-1128-4449-984c-cc7d19564db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e9726835-2df8-48d7-ad51-5425e32dc122,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-42b90d1e-e590-42e8-befd-ef8ce24bc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a266c945-0c61-4948-b898-e426fc182b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-02de001e-e947-4375-9fa0-b06e7ec47467,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-9f0c3424-582c-4e2a-8e19-82870f14274e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-bc5181f3-651e-4c93-9c83-76a7f935d009,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-ab702ff0-ce1b-47a1-812b-4f0cb6156144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273395709-172.17.0.3-1598587031109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-57df8089-1128-4449-984c-cc7d19564db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e9726835-2df8-48d7-ad51-5425e32dc122,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-42b90d1e-e590-42e8-befd-ef8ce24bc2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a266c945-0c61-4948-b898-e426fc182b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-02de001e-e947-4375-9fa0-b06e7ec47467,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-9f0c3424-582c-4e2a-8e19-82870f14274e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-bc5181f3-651e-4c93-9c83-76a7f935d009,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-ab702ff0-ce1b-47a1-812b-4f0cb6156144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5169
