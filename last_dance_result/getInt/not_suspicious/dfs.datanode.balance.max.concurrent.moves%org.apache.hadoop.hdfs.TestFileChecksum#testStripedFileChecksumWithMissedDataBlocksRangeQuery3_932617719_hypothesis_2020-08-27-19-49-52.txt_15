reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908205223-172.17.0.10-1598558098357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-6f125aee-1d7d-4016-8069-357caf9a2d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-8fa860b8-33e1-471b-9820-c1b8217031bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-142fa6ae-8a46-4d40-a5ba-c875b940448c,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-22648ef2-eca7-4cdb-878f-0552a64a7730,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-561e0605-af58-45df-bb36-0b354fb7dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-1ca0d4f4-4628-4507-8ff2-0be58d8b96db,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-4058141d-6f97-451f-8ac8-c687ad74ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-db6a16da-3447-4ad7-b9c2-e05987285be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908205223-172.17.0.10-1598558098357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-6f125aee-1d7d-4016-8069-357caf9a2d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-8fa860b8-33e1-471b-9820-c1b8217031bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-142fa6ae-8a46-4d40-a5ba-c875b940448c,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-22648ef2-eca7-4cdb-878f-0552a64a7730,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-561e0605-af58-45df-bb36-0b354fb7dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-1ca0d4f4-4628-4507-8ff2-0be58d8b96db,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-4058141d-6f97-451f-8ac8-c687ad74ce2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-db6a16da-3447-4ad7-b9c2-e05987285be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222350055-172.17.0.10-1598558289499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-614ec11e-2ae1-4fee-9692-93a137a27bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-e415bbe5-b70f-4102-9396-dd1a49063c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-1644fa86-0ef5-44c8-acdf-8a75c01d0819,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-436b7919-ccb4-4db1-842e-fd52e797582f,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-61e47f32-6e8d-4467-ae6d-64096fa76d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-225e72b4-a7d2-42b4-856c-6ce3589c9aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-81dfc0a9-e8e3-45cc-addf-5376ec4bcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-7c798771-9785-486d-834a-3c7cb0fcbeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222350055-172.17.0.10-1598558289499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-614ec11e-2ae1-4fee-9692-93a137a27bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-e415bbe5-b70f-4102-9396-dd1a49063c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-1644fa86-0ef5-44c8-acdf-8a75c01d0819,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-436b7919-ccb4-4db1-842e-fd52e797582f,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-61e47f32-6e8d-4467-ae6d-64096fa76d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-225e72b4-a7d2-42b4-856c-6ce3589c9aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-81dfc0a9-e8e3-45cc-addf-5376ec4bcadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-7c798771-9785-486d-834a-3c7cb0fcbeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107539137-172.17.0.10-1598558361411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-9a7137e5-b7a3-4a23-b2b4-173700a3eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-625b75c7-150d-48f8-823a-49cf75c4fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-dc40c171-e22f-4e8b-9255-68ca24a60447,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-94381c18-8dd8-4d94-b73f-1bf32fc0aaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-a583a6d0-05d5-4d82-a258-92db8c699c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-dd1c11e1-d54b-4eb7-9c8f-f7fa5bb9f535,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-3ff61351-4c52-47a2-b088-ee8686e1f184,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4aca4adc-5101-40eb-9cf0-4b8b34830549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107539137-172.17.0.10-1598558361411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-9a7137e5-b7a3-4a23-b2b4-173700a3eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-625b75c7-150d-48f8-823a-49cf75c4fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-dc40c171-e22f-4e8b-9255-68ca24a60447,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-94381c18-8dd8-4d94-b73f-1bf32fc0aaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-a583a6d0-05d5-4d82-a258-92db8c699c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-dd1c11e1-d54b-4eb7-9c8f-f7fa5bb9f535,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-3ff61351-4c52-47a2-b088-ee8686e1f184,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-4aca4adc-5101-40eb-9cf0-4b8b34830549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092099019-172.17.0.10-1598558421389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-82d431b7-5066-4c27-ae74-3ce5e828cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-2a0129c6-c3df-4839-9b47-c29d09e26e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-faa2b687-fc4f-4772-91d6-24383c993370,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-aa839cff-1d1c-4070-ad24-47c8b441dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-4f7d9e7a-bced-4e4a-942e-b51681033e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-1a996cb5-88c9-4bd8-833c-df9b45574f32,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-8d9caf24-d344-4bf1-ac61-a584d2198647,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-4685b8d5-886b-4b5a-8102-c2f63dbbed7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092099019-172.17.0.10-1598558421389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-82d431b7-5066-4c27-ae74-3ce5e828cc81,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-2a0129c6-c3df-4839-9b47-c29d09e26e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-faa2b687-fc4f-4772-91d6-24383c993370,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-aa839cff-1d1c-4070-ad24-47c8b441dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-4f7d9e7a-bced-4e4a-942e-b51681033e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-1a996cb5-88c9-4bd8-833c-df9b45574f32,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-8d9caf24-d344-4bf1-ac61-a584d2198647,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-4685b8d5-886b-4b5a-8102-c2f63dbbed7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274653091-172.17.0.10-1598559485281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-dbbf8bdc-9065-4ec9-9b0a-b91d707fee97,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-15cd6b0b-2f91-46b8-ae59-b8b08cb7d157,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8bd4a7c2-52be-4f85-988d-899d79253acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-3a1eca6f-4ff6-4609-9fc4-6382d96ae066,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-eebbdc33-6b77-4ec9-b062-51df86f8d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-dcbd3008-e3ac-410d-87b9-8bc22da9b829,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-830f44b7-9a21-444b-9de3-9d5985a24b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-5f5644f8-7e8a-49aa-a342-086e01daca32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274653091-172.17.0.10-1598559485281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35153,DS-dbbf8bdc-9065-4ec9-9b0a-b91d707fee97,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-15cd6b0b-2f91-46b8-ae59-b8b08cb7d157,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8bd4a7c2-52be-4f85-988d-899d79253acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-3a1eca6f-4ff6-4609-9fc4-6382d96ae066,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-eebbdc33-6b77-4ec9-b062-51df86f8d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-dcbd3008-e3ac-410d-87b9-8bc22da9b829,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-830f44b7-9a21-444b-9de3-9d5985a24b35,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-5f5644f8-7e8a-49aa-a342-086e01daca32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80024175-172.17.0.10-1598559629388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-aa2f2805-a47b-41d8-b1cb-0fa309a1bd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-b97c9bd0-1be1-43be-a7db-15b9acbdfb21,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-cca3b8cd-7829-4b89-80f2-97d676260c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-3e5e95bd-2bed-4786-a562-b08faf6dd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-70198f87-ccd8-439d-9177-44c924882c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-cd2750ea-e5e2-4b0f-bcfc-dc2b6ba334f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-a72afd7c-3f85-46eb-ae07-1cbfec8929de,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-9a9bfca3-0f11-4fcc-826b-3ffb818131a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80024175-172.17.0.10-1598559629388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-aa2f2805-a47b-41d8-b1cb-0fa309a1bd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-b97c9bd0-1be1-43be-a7db-15b9acbdfb21,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-cca3b8cd-7829-4b89-80f2-97d676260c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-3e5e95bd-2bed-4786-a562-b08faf6dd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-70198f87-ccd8-439d-9177-44c924882c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-cd2750ea-e5e2-4b0f-bcfc-dc2b6ba334f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-a72afd7c-3f85-46eb-ae07-1cbfec8929de,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-9a9bfca3-0f11-4fcc-826b-3ffb818131a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138186233-172.17.0.10-1598560311254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-4ce5f13d-81ec-4775-ae1e-c945debc6cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-24ffbcc8-b869-457c-a4a8-12b729bbf383,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-606f17c0-4c9b-49a1-83ce-2b32db46b79c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6413a369-aae0-4d1e-b53c-2e1557b55323,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-7460a08f-6684-4a30-a00c-fe112ee3f919,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-34b03642-9c54-4424-8d6a-4fb6667bdf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-c5df75ca-33d2-4d71-a5a5-1a1c2b8090cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-f7d3e023-53f7-47bc-a5d2-0508263f1bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138186233-172.17.0.10-1598560311254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-4ce5f13d-81ec-4775-ae1e-c945debc6cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-24ffbcc8-b869-457c-a4a8-12b729bbf383,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-606f17c0-4c9b-49a1-83ce-2b32db46b79c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6413a369-aae0-4d1e-b53c-2e1557b55323,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-7460a08f-6684-4a30-a00c-fe112ee3f919,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-34b03642-9c54-4424-8d6a-4fb6667bdf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-c5df75ca-33d2-4d71-a5a5-1a1c2b8090cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-f7d3e023-53f7-47bc-a5d2-0508263f1bfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730203163-172.17.0.10-1598560757532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42321,DS-46740acc-a8ec-419a-a996-39303a2ee7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-eee87ae5-7086-4c16-bea7-ea5c5ef6d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-6750b46b-662c-4ddc-933a-7eeb56958352,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-ed77e18c-1e09-4df3-99ff-7f5756597571,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-943f576f-528b-4a20-ba7f-71daa28a8922,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-a50d0683-0703-4536-ab23-1b9b191ba281,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-68e881c1-69c6-472c-9ff3-fb9f00e9ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-2cf14366-985c-4469-9a49-0af73370bdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730203163-172.17.0.10-1598560757532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42321,DS-46740acc-a8ec-419a-a996-39303a2ee7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-eee87ae5-7086-4c16-bea7-ea5c5ef6d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-6750b46b-662c-4ddc-933a-7eeb56958352,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-ed77e18c-1e09-4df3-99ff-7f5756597571,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-943f576f-528b-4a20-ba7f-71daa28a8922,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-a50d0683-0703-4536-ab23-1b9b191ba281,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-68e881c1-69c6-472c-9ff3-fb9f00e9ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-2cf14366-985c-4469-9a49-0af73370bdef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262301602-172.17.0.10-1598560796787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46308,DS-6156d8cc-1afd-4368-aca1-00979ae51656,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ff675c67-4d0c-4792-a4db-d804fab7e6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-8688007f-4e47-4a45-897a-745fcc73b767,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-977b7d37-0c66-487b-ab92-9a75fdd59d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-dc868510-915c-4119-84ee-61dc671e1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-474611de-b89f-4a67-a3ec-c3ff08c5f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-0fced80d-8fd1-440a-83fa-3b24d51f400c,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-956ef735-6a6f-496c-ab1d-7682aad4b3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262301602-172.17.0.10-1598560796787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46308,DS-6156d8cc-1afd-4368-aca1-00979ae51656,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ff675c67-4d0c-4792-a4db-d804fab7e6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-8688007f-4e47-4a45-897a-745fcc73b767,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-977b7d37-0c66-487b-ab92-9a75fdd59d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-dc868510-915c-4119-84ee-61dc671e1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-474611de-b89f-4a67-a3ec-c3ff08c5f26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-0fced80d-8fd1-440a-83fa-3b24d51f400c,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-956ef735-6a6f-496c-ab1d-7682aad4b3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716140154-172.17.0.10-1598561015903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-d9ccddf6-078f-404a-8924-40dd1d1f791e,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-8f99d9f7-0ec2-41fe-bcdc-46cb6c5e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-6f569702-3eee-4dde-a744-b18f97949f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-3610c48d-86c9-4fa7-8e84-54b0f836dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-21110b6f-4497-4c18-8589-f630858388f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-84bc763e-15e3-469c-85c1-01f3905bb767,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-40cfed52-9365-4d47-afe9-0bd465a1cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-f65ea70e-b1e3-4d90-a342-96a72953f7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716140154-172.17.0.10-1598561015903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-d9ccddf6-078f-404a-8924-40dd1d1f791e,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-8f99d9f7-0ec2-41fe-bcdc-46cb6c5e2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-6f569702-3eee-4dde-a744-b18f97949f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-3610c48d-86c9-4fa7-8e84-54b0f836dcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-21110b6f-4497-4c18-8589-f630858388f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-84bc763e-15e3-469c-85c1-01f3905bb767,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-40cfed52-9365-4d47-afe9-0bd465a1cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-f65ea70e-b1e3-4d90-a342-96a72953f7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54872431-172.17.0.10-1598561442529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-af5a63e6-8afe-423c-a9cb-9ab35537132e,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-bfcbc1e6-20b2-444e-a056-f5974879041f,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-b93dfc88-5774-4611-9fb0-ac36007c7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-fe637564-ae1b-4b96-84f4-5d284f05b8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-378681e2-c17a-42dc-b1ea-caa75760d220,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-738b0bfd-55af-45e6-8b62-242c7f335852,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-de38b1fd-2a5f-49bc-ac10-4ff0324d5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-b8273d39-e60a-4a77-98fc-f024bdf41d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54872431-172.17.0.10-1598561442529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-af5a63e6-8afe-423c-a9cb-9ab35537132e,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-bfcbc1e6-20b2-444e-a056-f5974879041f,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-b93dfc88-5774-4611-9fb0-ac36007c7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-fe637564-ae1b-4b96-84f4-5d284f05b8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-378681e2-c17a-42dc-b1ea-caa75760d220,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-738b0bfd-55af-45e6-8b62-242c7f335852,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-de38b1fd-2a5f-49bc-ac10-4ff0324d5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-b8273d39-e60a-4a77-98fc-f024bdf41d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600477437-172.17.0.10-1598561620956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-e94ef376-7dcc-4f6e-ba7b-8185fdd51f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-fe3c2066-e874-4e0f-8fa2-e6ef27417949,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-e459493e-c387-4e33-a862-17f9c8c14686,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-baa38c12-3619-4247-b03a-f736f14d1d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-3857d2da-4c05-458e-93a1-2876d40005fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ac50b6c7-c4ad-4696-b25e-e800468c7044,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-f5751a34-1ad4-48d1-a85e-5ecd8d7814f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-da5f4c15-28fb-4380-9c2a-41d607f75c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600477437-172.17.0.10-1598561620956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-e94ef376-7dcc-4f6e-ba7b-8185fdd51f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-fe3c2066-e874-4e0f-8fa2-e6ef27417949,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-e459493e-c387-4e33-a862-17f9c8c14686,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-baa38c12-3619-4247-b03a-f736f14d1d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-3857d2da-4c05-458e-93a1-2876d40005fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ac50b6c7-c4ad-4696-b25e-e800468c7044,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-f5751a34-1ad4-48d1-a85e-5ecd8d7814f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-da5f4c15-28fb-4380-9c2a-41d607f75c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959150854-172.17.0.10-1598561658702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-03a83455-5bc4-4ce1-8cc0-cda72157ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-754ad7e1-907d-48f2-8b8e-0f5a52eabf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8b3454d2-c600-40d7-8903-2989d58c8563,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-8383dbdf-06ad-444b-a28e-4e9372d72e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-9cbc8572-8b73-44d6-8aad-b8185f048a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-f18c43a5-6281-4af8-8145-6f2493d6f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-04c25bd3-793d-494f-bb3f-12058f28d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-c75f352c-1b65-41fc-970d-a21e27bde507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959150854-172.17.0.10-1598561658702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-03a83455-5bc4-4ce1-8cc0-cda72157ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-754ad7e1-907d-48f2-8b8e-0f5a52eabf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8b3454d2-c600-40d7-8903-2989d58c8563,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-8383dbdf-06ad-444b-a28e-4e9372d72e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-9cbc8572-8b73-44d6-8aad-b8185f048a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-f18c43a5-6281-4af8-8145-6f2493d6f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-04c25bd3-793d-494f-bb3f-12058f28d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-c75f352c-1b65-41fc-970d-a21e27bde507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307771875-172.17.0.10-1598562249904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-ce684d0b-d8be-402e-b9cb-e0e73abd8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-c650728e-e96d-453d-b1ad-84691dd5649e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-a307eb63-6fd7-455b-93b0-8f1034dfa808,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-2a4e707a-673f-4d50-8c83-63daa7362d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-5f63c5ad-db42-4a17-a00a-d69d84456274,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-81a1cf9d-ff08-4747-8d7a-1fae663e4584,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-57b8a206-31f6-413b-9c3d-4fc16f7e044a,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-9aec99e1-fb03-4c07-8782-9dfc3f504043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307771875-172.17.0.10-1598562249904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-ce684d0b-d8be-402e-b9cb-e0e73abd8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-c650728e-e96d-453d-b1ad-84691dd5649e,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-a307eb63-6fd7-455b-93b0-8f1034dfa808,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-2a4e707a-673f-4d50-8c83-63daa7362d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-5f63c5ad-db42-4a17-a00a-d69d84456274,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-81a1cf9d-ff08-4747-8d7a-1fae663e4584,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-57b8a206-31f6-413b-9c3d-4fc16f7e044a,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-9aec99e1-fb03-4c07-8782-9dfc3f504043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042036259-172.17.0.10-1598562574824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-0af4c250-785d-47b2-a852-57f6ed8301eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-2daceb58-336f-4406-b916-d5f3e8a604ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-1b338bf2-01be-4461-8d7c-c1e4c70d96b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-f791f612-f012-4f5e-8ec2-fe8f4e73fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-aa21ee84-05c7-461e-a0f2-8e3918ddb133,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-54cbacc2-36e0-4c83-a946-47e6596aafda,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-065efe81-eb30-4ecc-867e-410f124332db,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-494c6c86-214f-46e3-80f4-1bdb12cd89f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042036259-172.17.0.10-1598562574824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45857,DS-0af4c250-785d-47b2-a852-57f6ed8301eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-2daceb58-336f-4406-b916-d5f3e8a604ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-1b338bf2-01be-4461-8d7c-c1e4c70d96b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-f791f612-f012-4f5e-8ec2-fe8f4e73fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-aa21ee84-05c7-461e-a0f2-8e3918ddb133,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-54cbacc2-36e0-4c83-a946-47e6596aafda,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-065efe81-eb30-4ecc-867e-410f124332db,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-494c6c86-214f-46e3-80f4-1bdb12cd89f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5342
