reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992382404-172.17.0.15-1598639942120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-6d79d285-c32b-44ea-91e8-8c64038b32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-7e2b1124-29ad-4414-abef-d82542d42e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-8ddc528e-a2df-437c-a058-4de4252bb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-b5354fb2-294e-4cdf-88c9-7bbd8ea6f183,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-e4e08abd-9d0d-491c-9a6d-ea67e7c230c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-8371b40c-cbc2-4e0b-aad2-79d1873ad85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-47eb7e67-743e-480f-a8dc-bbfb81ded17e,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-00018b9f-a56a-421c-a28c-217dbb5d32a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992382404-172.17.0.15-1598639942120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-6d79d285-c32b-44ea-91e8-8c64038b32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-7e2b1124-29ad-4414-abef-d82542d42e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-8ddc528e-a2df-437c-a058-4de4252bb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-b5354fb2-294e-4cdf-88c9-7bbd8ea6f183,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-e4e08abd-9d0d-491c-9a6d-ea67e7c230c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-8371b40c-cbc2-4e0b-aad2-79d1873ad85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-47eb7e67-743e-480f-a8dc-bbfb81ded17e,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-00018b9f-a56a-421c-a28c-217dbb5d32a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674253381-172.17.0.15-1598640302177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-e75f96cc-2c44-4231-9e52-e2c6590144fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-72953121-0d22-443a-b873-ccba6e79aaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-e1b2f383-f6ac-425a-92fb-ea73fa3a046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-b4c96abc-0059-4561-9359-5c0594146f49,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-fbc543bf-b8d4-4aa9-8d3d-c80dc3a5833b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-544904d5-5519-44bc-adac-07756e82f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-f90e5e79-7d07-44f9-96ec-a164588d91eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-045ad85b-72b5-4432-83fc-ce397240a8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674253381-172.17.0.15-1598640302177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-e75f96cc-2c44-4231-9e52-e2c6590144fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-72953121-0d22-443a-b873-ccba6e79aaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-e1b2f383-f6ac-425a-92fb-ea73fa3a046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-b4c96abc-0059-4561-9359-5c0594146f49,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-fbc543bf-b8d4-4aa9-8d3d-c80dc3a5833b,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-544904d5-5519-44bc-adac-07756e82f19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-f90e5e79-7d07-44f9-96ec-a164588d91eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-045ad85b-72b5-4432-83fc-ce397240a8e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918846044-172.17.0.15-1598640362529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-da5a39b0-0af2-4fec-a9d1-e4da781bd193,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b34de4b0-ae0f-4fd9-ba84-75f0aa3c9b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-ec737706-8652-4018-8d5f-a3354bfe7a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-668f95c2-e8f0-45e6-a546-a8d85adcc3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-3bb296b7-68b1-4d83-94c3-243349e39f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8446380e-4534-4ef8-8f9c-2f88f07008c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-100fea4e-da2c-47b4-8b59-0a71ed56bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-42aae44b-28f3-43fb-a606-d65deeda7506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918846044-172.17.0.15-1598640362529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-da5a39b0-0af2-4fec-a9d1-e4da781bd193,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b34de4b0-ae0f-4fd9-ba84-75f0aa3c9b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-ec737706-8652-4018-8d5f-a3354bfe7a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-668f95c2-e8f0-45e6-a546-a8d85adcc3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-3bb296b7-68b1-4d83-94c3-243349e39f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-8446380e-4534-4ef8-8f9c-2f88f07008c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-100fea4e-da2c-47b4-8b59-0a71ed56bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-42aae44b-28f3-43fb-a606-d65deeda7506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957371430-172.17.0.15-1598640527571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-69a15a62-3b00-48d5-abf7-3462c76b28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-102ef6d5-dccf-4703-92e2-fc9204f7ab65,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-511f27de-257d-4e8f-b9a8-ff0fe4029e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7f45bbcf-d92f-4744-9311-11efe64dccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-4f6f84a9-9a6d-454e-9274-d314132cd38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-4a073466-0e16-41ef-b9a4-fa66c137080e,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-be597137-7037-4ccd-af8b-8ebb14f65193,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-1f356a82-0304-423d-9d38-a177178778eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957371430-172.17.0.15-1598640527571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-69a15a62-3b00-48d5-abf7-3462c76b28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-102ef6d5-dccf-4703-92e2-fc9204f7ab65,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-511f27de-257d-4e8f-b9a8-ff0fe4029e66,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7f45bbcf-d92f-4744-9311-11efe64dccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-4f6f84a9-9a6d-454e-9274-d314132cd38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-4a073466-0e16-41ef-b9a4-fa66c137080e,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-be597137-7037-4ccd-af8b-8ebb14f65193,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-1f356a82-0304-423d-9d38-a177178778eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72119100-172.17.0.15-1598640561181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-b5505d97-cd30-48e5-b6a1-760691e3fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-a7ddbddb-e072-4a14-8346-8aa16e8f1336,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-65117f0f-4ee8-40fe-b672-6838d4648c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-d320857b-f43a-4b82-827b-82813bb87438,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-09541feb-b963-4592-8227-7e6855c1f45e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-0c3a1c0e-523a-44cd-a5e9-06f6a5079bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-6054c408-b720-4003-a81f-7966c861b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-809d97ed-b43b-4de1-932f-d31dfcf37d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72119100-172.17.0.15-1598640561181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-b5505d97-cd30-48e5-b6a1-760691e3fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-a7ddbddb-e072-4a14-8346-8aa16e8f1336,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-65117f0f-4ee8-40fe-b672-6838d4648c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-d320857b-f43a-4b82-827b-82813bb87438,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-09541feb-b963-4592-8227-7e6855c1f45e,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-0c3a1c0e-523a-44cd-a5e9-06f6a5079bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-6054c408-b720-4003-a81f-7966c861b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-809d97ed-b43b-4de1-932f-d31dfcf37d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023565419-172.17.0.15-1598640903441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44465,DS-bf9f0677-04d3-4f8a-a649-47d66afc9185,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-87d119d5-9b10-4b26-a467-17556eb0b291,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-3c23b89b-f3c3-467b-92ed-710a0e65893b,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-fc85aad2-1afe-44a3-8cd7-99c7aae9c988,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-5632d787-eb12-47f5-993a-f6c835225554,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-40bf3e5b-05ca-45d6-933e-15e9feb010da,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-086a0e40-4d04-4dd7-b923-42d325c1f405,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-773fa973-7b8a-42ae-b12d-62456ba85c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023565419-172.17.0.15-1598640903441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44465,DS-bf9f0677-04d3-4f8a-a649-47d66afc9185,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-87d119d5-9b10-4b26-a467-17556eb0b291,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-3c23b89b-f3c3-467b-92ed-710a0e65893b,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-fc85aad2-1afe-44a3-8cd7-99c7aae9c988,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-5632d787-eb12-47f5-993a-f6c835225554,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-40bf3e5b-05ca-45d6-933e-15e9feb010da,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-086a0e40-4d04-4dd7-b923-42d325c1f405,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-773fa973-7b8a-42ae-b12d-62456ba85c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439618968-172.17.0.15-1598641033419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-d9de5bea-9983-43a0-a0fe-b28fdeffa552,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-997246de-6f25-404f-a999-9a679357a784,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-b6aad2c8-fafc-464f-830d-e3e3aea31cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-76d66d43-cdc3-4914-80a9-84f4dae6aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-ce5709c3-3e51-4b77-98eb-e716a6999414,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-f0b50265-1c4a-4e63-98bd-2aae68a5a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-3871aa41-355a-4e71-a38e-a85a1dbfe245,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-403e5d05-a464-449b-9b6d-8f3aff10290f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439618968-172.17.0.15-1598641033419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-d9de5bea-9983-43a0-a0fe-b28fdeffa552,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-997246de-6f25-404f-a999-9a679357a784,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-b6aad2c8-fafc-464f-830d-e3e3aea31cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-76d66d43-cdc3-4914-80a9-84f4dae6aab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-ce5709c3-3e51-4b77-98eb-e716a6999414,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-f0b50265-1c4a-4e63-98bd-2aae68a5a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-3871aa41-355a-4e71-a38e-a85a1dbfe245,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-403e5d05-a464-449b-9b6d-8f3aff10290f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815984599-172.17.0.15-1598641075149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-16456dc6-555b-4a29-b22b-037dc519732a,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-0d39c688-6c2d-42d3-b084-34f0b0f4fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-86b69158-cae2-4ad6-919c-4135cb7d562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-4d523744-ecf3-4a45-842d-aa4178d483f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-1d41b70b-d467-4484-8642-28deae13dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6ab624b3-8092-4a90-b60d-85fb1ad2bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-7b330d69-a641-460f-8ef2-8a25d3862f19,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-1a3c08db-6255-495f-87f6-08f8b9309dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815984599-172.17.0.15-1598641075149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-16456dc6-555b-4a29-b22b-037dc519732a,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-0d39c688-6c2d-42d3-b084-34f0b0f4fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-86b69158-cae2-4ad6-919c-4135cb7d562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-4d523744-ecf3-4a45-842d-aa4178d483f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-1d41b70b-d467-4484-8642-28deae13dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-6ab624b3-8092-4a90-b60d-85fb1ad2bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-7b330d69-a641-460f-8ef2-8a25d3862f19,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-1a3c08db-6255-495f-87f6-08f8b9309dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919241634-172.17.0.15-1598641548325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-46affde0-b5d7-46a1-9b00-ff83d0fad11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-a1bd6ad3-8805-44a1-800d-ee6d4af90023,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-30388bba-22a6-424f-b228-bee41d919b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-5e8f74d4-9a3b-41ba-9a2a-97821fe0ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-54d1cba7-0ed2-4d95-af15-6c9fb4807a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-adb29acb-fc15-4112-b7c3-01de93b187b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-d183a0bd-a98b-4f90-a364-e7f16196379d,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-84f9be9f-045b-4701-b8f9-556e95a864db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919241634-172.17.0.15-1598641548325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-46affde0-b5d7-46a1-9b00-ff83d0fad11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-a1bd6ad3-8805-44a1-800d-ee6d4af90023,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-30388bba-22a6-424f-b228-bee41d919b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-5e8f74d4-9a3b-41ba-9a2a-97821fe0ff6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-54d1cba7-0ed2-4d95-af15-6c9fb4807a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-adb29acb-fc15-4112-b7c3-01de93b187b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-d183a0bd-a98b-4f90-a364-e7f16196379d,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-84f9be9f-045b-4701-b8f9-556e95a864db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156108336-172.17.0.15-1598642332202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-1ca111e9-3ad2-4a99-8d55-8f72585041af,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-da3caefa-7827-439d-bcc2-52987f32e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-c2d2189d-c0aa-4192-95f7-2b792e6ebe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-1cb546d9-55d3-4ba7-b748-cf2de687571d,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-3c205a8a-429c-4296-ab8e-0ab795b5e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-00c69dc5-0c6b-4056-bafb-fd7024c393e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-fc63b097-fa5f-43e5-9c51-7605d0387d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-f4b554a4-879b-496e-9e89-ba1eb01992d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156108336-172.17.0.15-1598642332202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-1ca111e9-3ad2-4a99-8d55-8f72585041af,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-da3caefa-7827-439d-bcc2-52987f32e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-c2d2189d-c0aa-4192-95f7-2b792e6ebe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-1cb546d9-55d3-4ba7-b748-cf2de687571d,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-3c205a8a-429c-4296-ab8e-0ab795b5e2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-00c69dc5-0c6b-4056-bafb-fd7024c393e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-fc63b097-fa5f-43e5-9c51-7605d0387d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-f4b554a4-879b-496e-9e89-ba1eb01992d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071276465-172.17.0.15-1598642687436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-987a6f58-ef5e-4582-bbf8-cd22a4e6b181,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-e085994f-4a66-4e79-ae2b-900b07c161a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-baa777df-9b17-4cad-841d-78b75bb081b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f3ba2713-bdd2-4110-8673-0898a0511d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-8120693c-00b8-48e3-a510-1dd4de22c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ae5a3bde-47cd-496b-b04f-ee62e644fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fb5d3bf3-af9a-4cd8-af65-a0129b79b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-cf5f900f-0e94-416a-b95a-14a1ac6bad4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071276465-172.17.0.15-1598642687436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-987a6f58-ef5e-4582-bbf8-cd22a4e6b181,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-e085994f-4a66-4e79-ae2b-900b07c161a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-baa777df-9b17-4cad-841d-78b75bb081b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f3ba2713-bdd2-4110-8673-0898a0511d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-8120693c-00b8-48e3-a510-1dd4de22c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-ae5a3bde-47cd-496b-b04f-ee62e644fd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fb5d3bf3-af9a-4cd8-af65-a0129b79b97f,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-cf5f900f-0e94-416a-b95a-14a1ac6bad4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123313319-172.17.0.15-1598642816535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-0ebe02ed-1e4e-458d-a1a7-d4dd21be42e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-b8eec5ad-7bf3-4f58-84da-e92d58e00b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-b5555dd3-4159-4d5a-8479-b1e0032cbfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3b6d5cd5-5534-4b8d-880f-8e398654f360,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-7555cb75-096c-4d2d-ae6b-6ab7f164f433,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-a68ed435-fa15-4bc6-a0a1-40a21708dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-367638bf-73e7-4c99-86b1-5eeafb80b36c,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3a2af7a0-5797-4009-b54f-93882d467b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123313319-172.17.0.15-1598642816535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-0ebe02ed-1e4e-458d-a1a7-d4dd21be42e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-b8eec5ad-7bf3-4f58-84da-e92d58e00b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-b5555dd3-4159-4d5a-8479-b1e0032cbfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3b6d5cd5-5534-4b8d-880f-8e398654f360,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-7555cb75-096c-4d2d-ae6b-6ab7f164f433,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-a68ed435-fa15-4bc6-a0a1-40a21708dfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-367638bf-73e7-4c99-86b1-5eeafb80b36c,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3a2af7a0-5797-4009-b54f-93882d467b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597215692-172.17.0.15-1598643164444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-11c49966-6015-4dea-861b-838f1c55f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-4b98c5e2-c72e-44a3-be50-42ea8529ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f4e2ed4b-29d2-42ac-998f-2a2925a41ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-22289746-3aac-440e-85f3-8c3455cfc89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-4148a121-af60-4bfb-8550-5e158002902d,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-edf29302-4fa7-44e6-84e7-492eecc9a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-9fad0ff0-b337-4b66-884a-4652873461b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-0c3b8642-5025-4d3a-88e8-47ebe54ddc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-597215692-172.17.0.15-1598643164444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-11c49966-6015-4dea-861b-838f1c55f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-4b98c5e2-c72e-44a3-be50-42ea8529ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f4e2ed4b-29d2-42ac-998f-2a2925a41ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-22289746-3aac-440e-85f3-8c3455cfc89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-4148a121-af60-4bfb-8550-5e158002902d,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-edf29302-4fa7-44e6-84e7-492eecc9a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-9fad0ff0-b337-4b66-884a-4652873461b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-0c3b8642-5025-4d3a-88e8-47ebe54ddc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096121735-172.17.0.15-1598643196934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33334,DS-283fefb2-251b-4353-a3f4-0cd6b23ad715,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-b6b6dd5b-8a82-4d7b-bac0-30b804a9be82,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-3d1c9b37-8e9e-4493-95a9-fa465baabeed,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-d8fb9367-69df-4c14-a103-76a90e20efef,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e4a81321-9f6c-4589-bb05-48306941a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-d39eccf1-1603-43be-b0a5-ede40bd86518,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-8918d46d-42e0-464b-927d-f44feaa5e80a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-137b590a-beab-4175-aa4b-349f902dd218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096121735-172.17.0.15-1598643196934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33334,DS-283fefb2-251b-4353-a3f4-0cd6b23ad715,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-b6b6dd5b-8a82-4d7b-bac0-30b804a9be82,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-3d1c9b37-8e9e-4493-95a9-fa465baabeed,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-d8fb9367-69df-4c14-a103-76a90e20efef,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e4a81321-9f6c-4589-bb05-48306941a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-d39eccf1-1603-43be-b0a5-ede40bd86518,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-8918d46d-42e0-464b-927d-f44feaa5e80a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-137b590a-beab-4175-aa4b-349f902dd218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642188251-172.17.0.15-1598643530237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-18efdc15-8890-4565-849d-72887187192e,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-b5ba86d9-20ee-4dfd-aa85-c46579d1c813,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-35f009ef-2149-4c24-ba9a-40e39bd50ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ba9a34df-6d19-4fb1-adfd-30436d5e2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-76a4a019-9eb9-4df4-831c-806eff3a6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-87b2a4e9-0ca3-495f-9301-73eb34ed7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b9789d6b-b50e-4cdb-8d3a-86e104744521,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-85fb1ee8-a85e-4af8-99c9-6feae855b068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642188251-172.17.0.15-1598643530237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-18efdc15-8890-4565-849d-72887187192e,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-b5ba86d9-20ee-4dfd-aa85-c46579d1c813,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-35f009ef-2149-4c24-ba9a-40e39bd50ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-ba9a34df-6d19-4fb1-adfd-30436d5e2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-76a4a019-9eb9-4df4-831c-806eff3a6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-87b2a4e9-0ca3-495f-9301-73eb34ed7d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-b9789d6b-b50e-4cdb-8d3a-86e104744521,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-85fb1ee8-a85e-4af8-99c9-6feae855b068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262741095-172.17.0.15-1598643602694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-5062cda6-d24e-4fcc-8924-ddac668973bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-efdd59ec-add9-4655-9033-4494d87d1014,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-08b0cb7f-5187-4594-a921-f7944f7f0b00,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-6258391c-57f9-43e8-a0fb-83d1721580de,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-26919aa0-f858-450e-a98a-3be554aa8104,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-0f07a5df-3cbc-4936-bf6f-59218063e927,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-672563b9-4be6-489f-9f2a-74801f63fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-3b875ee8-7f4e-4455-bfa2-0b74fbafaa03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262741095-172.17.0.15-1598643602694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-5062cda6-d24e-4fcc-8924-ddac668973bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-efdd59ec-add9-4655-9033-4494d87d1014,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-08b0cb7f-5187-4594-a921-f7944f7f0b00,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-6258391c-57f9-43e8-a0fb-83d1721580de,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-26919aa0-f858-450e-a98a-3be554aa8104,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-0f07a5df-3cbc-4936-bf6f-59218063e927,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-672563b9-4be6-489f-9f2a-74801f63fc67,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-3b875ee8-7f4e-4455-bfa2-0b74fbafaa03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.file.close.num-committed-allowed
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106503024-172.17.0.15-1598643670808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-79dda28d-4272-4fdf-9459-32a568e78937,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-e8b6584f-4f45-411c-99e3-fce8c1b0c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-8295492f-584f-46ba-988c-a58465730143,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d3075576-dbb1-4acd-bc12-c0b6366796b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-f9f97426-9e63-45a0-8de1-f0c6925bfc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-5d69c650-291f-4d20-8ef8-d480f45704d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-caa4c476-a67e-45a4-812d-bc7966093206,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-41993c66-a5aa-4e0f-8cda-9507554290dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106503024-172.17.0.15-1598643670808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-79dda28d-4272-4fdf-9459-32a568e78937,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-e8b6584f-4f45-411c-99e3-fce8c1b0c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-8295492f-584f-46ba-988c-a58465730143,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d3075576-dbb1-4acd-bc12-c0b6366796b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-f9f97426-9e63-45a0-8de1-f0c6925bfc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-5d69c650-291f-4d20-8ef8-d480f45704d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-caa4c476-a67e-45a4-812d-bc7966093206,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-41993c66-a5aa-4e0f-8cda-9507554290dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4940
