reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503758095-172.17.0.9-1598548988965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33731,DS-f277114e-8d60-4788-9f40-2ba7d76c93d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-86e42ee9-cc22-4923-a52d-a2e7102202bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-7c76d0ed-5b64-4348-855b-5023abb30ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-afc0003b-e36e-4eea-9627-15a102a75b37,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-1a1ae48d-fff6-4081-b8c0-53b830875e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-a67c6205-d98f-41b5-b1d1-7f44c4a2874a,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-d39e801b-2d1a-4a0e-8e95-22a6eaab9f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-d71cb26b-6b51-47ec-9c35-8b20d6204920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503758095-172.17.0.9-1598548988965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33731,DS-f277114e-8d60-4788-9f40-2ba7d76c93d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-86e42ee9-cc22-4923-a52d-a2e7102202bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-7c76d0ed-5b64-4348-855b-5023abb30ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-afc0003b-e36e-4eea-9627-15a102a75b37,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-1a1ae48d-fff6-4081-b8c0-53b830875e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-a67c6205-d98f-41b5-b1d1-7f44c4a2874a,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-d39e801b-2d1a-4a0e-8e95-22a6eaab9f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-d71cb26b-6b51-47ec-9c35-8b20d6204920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361800397-172.17.0.9-1598549021414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43198,DS-fc34151d-958f-47c4-a250-a22333079b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-ddd85922-d76d-4b72-ac8e-359f313e9057,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-215694a1-a57d-4ba4-ac63-dbca96552f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ee565d72-6b16-4686-a7b5-d1f0f227089f,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-b0e35164-fab9-49b3-9226-917a182bd133,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-381816ae-4aea-4474-89aa-a3f5edf72f41,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-029831eb-fa21-4c10-a610-89aa61eb2706,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-1b054069-d7af-4dd1-97f3-f8d02667895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361800397-172.17.0.9-1598549021414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43198,DS-fc34151d-958f-47c4-a250-a22333079b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-ddd85922-d76d-4b72-ac8e-359f313e9057,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-215694a1-a57d-4ba4-ac63-dbca96552f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-ee565d72-6b16-4686-a7b5-d1f0f227089f,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-b0e35164-fab9-49b3-9226-917a182bd133,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-381816ae-4aea-4474-89aa-a3f5edf72f41,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-029831eb-fa21-4c10-a610-89aa61eb2706,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-1b054069-d7af-4dd1-97f3-f8d02667895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260557194-172.17.0.9-1598549373359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-4688381b-061a-40b3-aacc-eee7818a8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-bc0485ce-c97d-447d-88af-193d73abc2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-b7c98501-5148-4542-b33c-0f6873e36726,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-506dc4ca-c2d8-4f9a-bae4-0c65e968523d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-a1eb9f3c-0767-4f7c-acae-0d7005e9e685,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-120f8189-19a1-48f3-b374-5017088660af,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-39182b9a-6ab4-4346-9064-9f9e4874450f,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-2422a1fb-eb0c-4eb4-b6d9-9b1cbeb7c418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260557194-172.17.0.9-1598549373359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-4688381b-061a-40b3-aacc-eee7818a8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-bc0485ce-c97d-447d-88af-193d73abc2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-b7c98501-5148-4542-b33c-0f6873e36726,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-506dc4ca-c2d8-4f9a-bae4-0c65e968523d,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-a1eb9f3c-0767-4f7c-acae-0d7005e9e685,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-120f8189-19a1-48f3-b374-5017088660af,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-39182b9a-6ab4-4346-9064-9f9e4874450f,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-2422a1fb-eb0c-4eb4-b6d9-9b1cbeb7c418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320919079-172.17.0.9-1598549407273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-85ee387f-ac32-4cde-b9fb-dfb8507acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-37fa7622-3bad-47e7-b724-12c0759469a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-84826c9a-1f1b-4592-a08b-1c0107cf9b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-c4fd0e3e-8f70-44aa-a240-d362ddb80300,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-9f19760f-cc0f-456c-8b62-ab9cd4c51539,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-64cbee8a-844d-423e-9851-b1b9436505db,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-1cde8932-0a61-4aa3-8c73-dd0fa22b1c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-99cfe50b-6457-4a4f-a20a-d71870016389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320919079-172.17.0.9-1598549407273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-85ee387f-ac32-4cde-b9fb-dfb8507acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-37fa7622-3bad-47e7-b724-12c0759469a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-84826c9a-1f1b-4592-a08b-1c0107cf9b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-c4fd0e3e-8f70-44aa-a240-d362ddb80300,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-9f19760f-cc0f-456c-8b62-ab9cd4c51539,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-64cbee8a-844d-423e-9851-b1b9436505db,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-1cde8932-0a61-4aa3-8c73-dd0fa22b1c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-99cfe50b-6457-4a4f-a20a-d71870016389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879625829-172.17.0.9-1598550272035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-57426392-e7d0-43ba-95a8-dc410e614fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f655a247-66f4-44e3-84d0-596704e8cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-1e11a479-0709-431e-b6af-2b15a4258d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-f9cbba44-b9f0-496a-a371-76db48caad71,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-88ba3a56-9296-4eb1-b578-c481dee98857,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-6c068f4a-db55-4b6f-af61-0b9cafdfb68d,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-07145204-5347-48b9-ba94-e39fb64e824a,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4a20cc9c-670d-425d-9af8-905a6af219c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879625829-172.17.0.9-1598550272035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-57426392-e7d0-43ba-95a8-dc410e614fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f655a247-66f4-44e3-84d0-596704e8cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-1e11a479-0709-431e-b6af-2b15a4258d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-f9cbba44-b9f0-496a-a371-76db48caad71,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-88ba3a56-9296-4eb1-b578-c481dee98857,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-6c068f4a-db55-4b6f-af61-0b9cafdfb68d,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-07145204-5347-48b9-ba94-e39fb64e824a,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4a20cc9c-670d-425d-9af8-905a6af219c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474064706-172.17.0.9-1598550807354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-5c4c272b-316b-4417-8385-48c06a3f461c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e06a0c57-b9cb-45da-9379-2ab30139f185,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-8e930e10-2d23-4e92-a7dc-08d9f128f635,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-dcef69c7-d89e-4ce9-8fa7-f84277a25b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-e5fd2be8-57bb-432a-a063-7e4fe0c8721a,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-6e446932-ea76-42d7-9f70-c8f9a9c099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-cd3ff3bd-47f0-459d-8061-27fa5547bcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-48d09368-c2be-4db8-99f5-0fde29e503cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474064706-172.17.0.9-1598550807354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34157,DS-5c4c272b-316b-4417-8385-48c06a3f461c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e06a0c57-b9cb-45da-9379-2ab30139f185,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-8e930e10-2d23-4e92-a7dc-08d9f128f635,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-dcef69c7-d89e-4ce9-8fa7-f84277a25b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-e5fd2be8-57bb-432a-a063-7e4fe0c8721a,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-6e446932-ea76-42d7-9f70-c8f9a9c099b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-cd3ff3bd-47f0-459d-8061-27fa5547bcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-48d09368-c2be-4db8-99f5-0fde29e503cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417120330-172.17.0.9-1598551184573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37261,DS-5184c10f-b962-4125-9544-2ecafe91b530,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-2f25219d-0196-4c91-a377-60a9c5b01e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-ccd676c3-a65e-4517-b973-fbb3ecb86fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-0dba43ac-3a80-4f8a-a35e-11a5f92eb4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-1a57c9ff-1742-44ca-b758-387c0cbbba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-3f858779-c036-4d82-9bd2-bcda70f8e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-9d46e0e5-2006-4bfe-a344-ebd56a78ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-667aca2f-55bb-4c66-81d4-05975fd8bcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417120330-172.17.0.9-1598551184573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37261,DS-5184c10f-b962-4125-9544-2ecafe91b530,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-2f25219d-0196-4c91-a377-60a9c5b01e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-ccd676c3-a65e-4517-b973-fbb3ecb86fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-0dba43ac-3a80-4f8a-a35e-11a5f92eb4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-1a57c9ff-1742-44ca-b758-387c0cbbba8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-3f858779-c036-4d82-9bd2-bcda70f8e3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-9d46e0e5-2006-4bfe-a344-ebd56a78ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-667aca2f-55bb-4c66-81d4-05975fd8bcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664438736-172.17.0.9-1598551276041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-a6720ce4-bd6b-4090-8ca8-e3d510c200bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-deb6e621-c82b-4850-bd73-3000fc095172,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0d46a100-6185-481a-8d60-63c79d2fddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-0a16251e-efcf-4896-a42a-071266dac3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-30d5eca2-8100-4445-a8f7-a72f79e4524d,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5bf16785-0b85-418a-828d-f1abf1bb3930,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-5ec58a9d-9f7a-4e88-9d1f-e1320154ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-bc666727-f421-4b9b-8557-8c790e3bbc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664438736-172.17.0.9-1598551276041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37739,DS-a6720ce4-bd6b-4090-8ca8-e3d510c200bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-deb6e621-c82b-4850-bd73-3000fc095172,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-0d46a100-6185-481a-8d60-63c79d2fddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-0a16251e-efcf-4896-a42a-071266dac3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-30d5eca2-8100-4445-a8f7-a72f79e4524d,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5bf16785-0b85-418a-828d-f1abf1bb3930,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-5ec58a9d-9f7a-4e88-9d1f-e1320154ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-bc666727-f421-4b9b-8557-8c790e3bbc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244495875-172.17.0.9-1598551438012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-07f93d62-77d7-43f4-a1eb-4d47a516f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-80829088-270a-4057-924d-684758d3b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-0687510f-47e4-4221-8646-d0de37b62f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-60758e09-2096-4eb8-8827-b30c862b4707,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-1d9dcec1-bb31-415b-9ba8-542afd0c7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-9d6ba6e3-0f4f-4a42-929f-4df61fa429e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-72ef6747-93d2-46b9-a874-e9ca7bacf695,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-30e4b8c5-33c2-4efc-9e58-d6edd3f80402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244495875-172.17.0.9-1598551438012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33819,DS-07f93d62-77d7-43f4-a1eb-4d47a516f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-80829088-270a-4057-924d-684758d3b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-0687510f-47e4-4221-8646-d0de37b62f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-60758e09-2096-4eb8-8827-b30c862b4707,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-1d9dcec1-bb31-415b-9ba8-542afd0c7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-9d6ba6e3-0f4f-4a42-929f-4df61fa429e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-72ef6747-93d2-46b9-a874-e9ca7bacf695,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-30e4b8c5-33c2-4efc-9e58-d6edd3f80402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818837100-172.17.0.9-1598552054863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-e08127e8-d671-4d3e-acbf-56942c5799d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-9c9e5bad-0ded-4eac-b7a3-ad31346463ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-0a5dc374-9c6e-40fc-943d-692c6031312f,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-73542738-4235-4365-96b1-9a148d6a71a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-27a8e8ec-0a1e-4734-b7cd-296567122f92,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-8e8b1702-7c37-44f6-999a-2120e3248174,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-57bd6360-b552-4679-a48a-057515ba2fea,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-8cff3b3a-c6b6-4ec3-8259-2714de8c6fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818837100-172.17.0.9-1598552054863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-e08127e8-d671-4d3e-acbf-56942c5799d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-9c9e5bad-0ded-4eac-b7a3-ad31346463ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-0a5dc374-9c6e-40fc-943d-692c6031312f,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-73542738-4235-4365-96b1-9a148d6a71a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-27a8e8ec-0a1e-4734-b7cd-296567122f92,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-8e8b1702-7c37-44f6-999a-2120e3248174,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-57bd6360-b552-4679-a48a-057515ba2fea,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-8cff3b3a-c6b6-4ec3-8259-2714de8c6fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 50
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437126298-172.17.0.9-1598552199645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-9874f3b5-9f23-446e-a963-0aba2e7f32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-33dfc4d2-0f49-4e7c-9b2a-12564133d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-ff34fd53-5130-4e89-8f87-969f088d7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b91afba2-13e4-4f9e-9498-58e183f05e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-647d1914-8c49-44b6-9ea6-85612cd9c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-0fe3b78a-1f57-4588-bd56-a33be9461bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-530f88e0-1b56-4b90-8a99-4728242a36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-f196e152-0105-43d4-ba13-94ecbe0a7289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437126298-172.17.0.9-1598552199645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-9874f3b5-9f23-446e-a963-0aba2e7f32ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-33dfc4d2-0f49-4e7c-9b2a-12564133d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-ff34fd53-5130-4e89-8f87-969f088d7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b91afba2-13e4-4f9e-9498-58e183f05e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-647d1914-8c49-44b6-9ea6-85612cd9c2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-0fe3b78a-1f57-4588-bd56-a33be9461bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-530f88e0-1b56-4b90-8a99-4728242a36c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-f196e152-0105-43d4-ba13-94ecbe0a7289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5011
