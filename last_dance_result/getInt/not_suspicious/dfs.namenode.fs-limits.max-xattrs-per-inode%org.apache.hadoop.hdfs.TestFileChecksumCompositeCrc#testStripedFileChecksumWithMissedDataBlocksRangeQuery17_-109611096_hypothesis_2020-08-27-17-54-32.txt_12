reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685852170-172.17.0.19-1598551555301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-baf1a7dd-b954-4ef2-93c9-e780b4569fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-600a8ac1-aebd-4913-808f-05fac41b9e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-121d6e49-cec0-420e-9246-1087d74dcdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-8616aa0b-cf45-4c60-a2b5-9fdcabfd597f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-393a191e-ecae-4a0b-9ed2-330b9e3c51bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-f7434f21-4d85-437e-9626-6d19b29b46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-35dc0fb7-170d-4eb5-93a4-543a7b2a18f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-9bfd1c3f-c053-4d1c-ae00-c3043757475a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1685852170-172.17.0.19-1598551555301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46834,DS-baf1a7dd-b954-4ef2-93c9-e780b4569fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-600a8ac1-aebd-4913-808f-05fac41b9e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-121d6e49-cec0-420e-9246-1087d74dcdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-8616aa0b-cf45-4c60-a2b5-9fdcabfd597f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-393a191e-ecae-4a0b-9ed2-330b9e3c51bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-f7434f21-4d85-437e-9626-6d19b29b46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-35dc0fb7-170d-4eb5-93a4-543a7b2a18f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-9bfd1c3f-c053-4d1c-ae00-c3043757475a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688532197-172.17.0.19-1598551588100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-ef98a23b-d2fa-4ce2-8a5e-5f017e9ba62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-861da359-3281-4bfc-a174-598988f9f5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-1ddb56cc-3434-48c7-96b3-b4b0da6eb526,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-5ce63f08-b2c5-4c50-a35b-0a84d63fc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-f8b03ed5-870f-4a99-b5ba-4011ad0d0368,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-39549822-f2c0-4f2d-8772-450aea8710b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5467b1fe-e036-49c0-a917-9b864dd0d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-6ce0f8a7-b28b-41d2-9d08-f5db113f499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688532197-172.17.0.19-1598551588100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-ef98a23b-d2fa-4ce2-8a5e-5f017e9ba62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-861da359-3281-4bfc-a174-598988f9f5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-1ddb56cc-3434-48c7-96b3-b4b0da6eb526,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-5ce63f08-b2c5-4c50-a35b-0a84d63fc2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-f8b03ed5-870f-4a99-b5ba-4011ad0d0368,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-39549822-f2c0-4f2d-8772-450aea8710b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5467b1fe-e036-49c0-a917-9b864dd0d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-6ce0f8a7-b28b-41d2-9d08-f5db113f499b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169078707-172.17.0.19-1598551807140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-efd465e6-4fa7-42e0-b451-e39d48729423,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-f881bf9b-aa3b-42ef-93be-a579de171d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-43783784-21a5-41c5-a4f7-bf3ca9f7acc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-94117209-21e1-499e-919c-2b31d0d13de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-b7861af3-0618-4945-8d75-86556bb27bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4611406d-33b3-45ba-b701-7445821c3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-7686f99f-a6da-4928-a2af-7656002eeeea,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-ce25e822-0e28-4b44-ba44-5db6c4cdb23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169078707-172.17.0.19-1598551807140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-efd465e6-4fa7-42e0-b451-e39d48729423,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-f881bf9b-aa3b-42ef-93be-a579de171d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-43783784-21a5-41c5-a4f7-bf3ca9f7acc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-94117209-21e1-499e-919c-2b31d0d13de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-b7861af3-0618-4945-8d75-86556bb27bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4611406d-33b3-45ba-b701-7445821c3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-7686f99f-a6da-4928-a2af-7656002eeeea,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-ce25e822-0e28-4b44-ba44-5db6c4cdb23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770386529-172.17.0.19-1598552459395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46686,DS-79786cc1-3fa5-40fc-9f0e-1b64f411b710,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d5280d6e-bf0f-47b1-8780-694e0ad04699,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-14aa075e-8401-4874-8882-85850462ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-31f287fc-1218-4b4b-b2b6-fe05cf7766b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-f44f5d91-d23c-42a1-be28-f12cdd6836f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-e35a8e05-5ff5-413c-9cb6-72ab9c05ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-52afced5-6536-43ba-a5d0-7b3fca26f01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-c108b3f1-5651-4426-b9a0-7b8f9b969ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770386529-172.17.0.19-1598552459395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46686,DS-79786cc1-3fa5-40fc-9f0e-1b64f411b710,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d5280d6e-bf0f-47b1-8780-694e0ad04699,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-14aa075e-8401-4874-8882-85850462ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-31f287fc-1218-4b4b-b2b6-fe05cf7766b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-f44f5d91-d23c-42a1-be28-f12cdd6836f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-e35a8e05-5ff5-413c-9cb6-72ab9c05ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-52afced5-6536-43ba-a5d0-7b3fca26f01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-c108b3f1-5651-4426-b9a0-7b8f9b969ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893058644-172.17.0.19-1598552593798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-d87c0892-565e-4d35-81d5-1a4cf0bbb777,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-8e6efe10-e20b-4809-b860-bd9fda2d5931,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-9c85218a-d4e8-4883-b1ca-e6db2ce29245,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-145a2801-7713-439c-8661-99e1798c7e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-90a40dc2-baa8-4dd2-b833-7628c061f469,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-9c944100-73f6-483b-aab3-ebf04761af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-4b68b12a-7b7c-43d7-a37c-23b95de38893,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-b1b52c32-7922-4eff-9b80-dc8cb56d0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893058644-172.17.0.19-1598552593798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-d87c0892-565e-4d35-81d5-1a4cf0bbb777,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-8e6efe10-e20b-4809-b860-bd9fda2d5931,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-9c85218a-d4e8-4883-b1ca-e6db2ce29245,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-145a2801-7713-439c-8661-99e1798c7e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-90a40dc2-baa8-4dd2-b833-7628c061f469,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-9c944100-73f6-483b-aab3-ebf04761af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-4b68b12a-7b7c-43d7-a37c-23b95de38893,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-b1b52c32-7922-4eff-9b80-dc8cb56d0ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439366492-172.17.0.19-1598552666754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-ac0e6ac2-2743-41e6-aadc-5d90c433de51,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-bb2c3fe3-4626-4d32-acb6-734b73bdfa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-18d45dd5-77cc-4e69-a75c-e28e3e8b6b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-771e6d7e-284d-450a-ae07-6956ce2bf777,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-a234143c-7f66-4e77-8f10-b34754a157b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-a3b822a7-a94a-45d6-ab38-93ef8ecf8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0455dce3-bc76-4cb6-85ce-25b9f0d22a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-c2ce9dad-70a6-4cfe-ac46-d2509412409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439366492-172.17.0.19-1598552666754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42053,DS-ac0e6ac2-2743-41e6-aadc-5d90c433de51,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-bb2c3fe3-4626-4d32-acb6-734b73bdfa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-18d45dd5-77cc-4e69-a75c-e28e3e8b6b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-771e6d7e-284d-450a-ae07-6956ce2bf777,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-a234143c-7f66-4e77-8f10-b34754a157b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-a3b822a7-a94a-45d6-ab38-93ef8ecf8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0455dce3-bc76-4cb6-85ce-25b9f0d22a85,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-c2ce9dad-70a6-4cfe-ac46-d2509412409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549764765-172.17.0.19-1598553011155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34689,DS-cb8b69aa-22e2-4f19-896c-033fa7c1f27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-4912e2e9-3b29-4a5f-b6c5-515b90d7ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-0913ed1d-9b1d-4ec2-9f9c-82466175623d,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-1ae1cded-d19a-412c-9609-f912efc983a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-66530dd9-9a0d-4ab6-9ed5-ec570332e607,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3c5eee2-fc34-4d53-8851-162eff0bcf54,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-08a39038-ad0f-4f58-824f-73d5889ffdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-99a872e5-47aa-4ec5-afef-50069f117ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549764765-172.17.0.19-1598553011155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34689,DS-cb8b69aa-22e2-4f19-896c-033fa7c1f27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-4912e2e9-3b29-4a5f-b6c5-515b90d7ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-0913ed1d-9b1d-4ec2-9f9c-82466175623d,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-1ae1cded-d19a-412c-9609-f912efc983a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-66530dd9-9a0d-4ab6-9ed5-ec570332e607,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c3c5eee2-fc34-4d53-8851-162eff0bcf54,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-08a39038-ad0f-4f58-824f-73d5889ffdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-99a872e5-47aa-4ec5-afef-50069f117ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253414279-172.17.0.19-1598553077664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-29eb061b-d004-469f-8f18-b49fc688785b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-7dc3b551-1475-4c56-8a0d-38847c911876,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-4d171f6b-03f2-4e63-981a-30cdf24c858f,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-e9336ce6-d0ac-432f-bbe0-cbca8a86db66,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-1a7db687-4dc0-4c8f-b24a-c58d9961b67f,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-92e4aeef-caa5-4953-a5fc-3cd26fa38f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-4777a834-aa9c-419d-a1c7-dc4d6701a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-65820836-5741-41a3-b18f-28ceb6ab398f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253414279-172.17.0.19-1598553077664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-29eb061b-d004-469f-8f18-b49fc688785b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-7dc3b551-1475-4c56-8a0d-38847c911876,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-4d171f6b-03f2-4e63-981a-30cdf24c858f,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-e9336ce6-d0ac-432f-bbe0-cbca8a86db66,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-1a7db687-4dc0-4c8f-b24a-c58d9961b67f,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-92e4aeef-caa5-4953-a5fc-3cd26fa38f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-4777a834-aa9c-419d-a1c7-dc4d6701a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-65820836-5741-41a3-b18f-28ceb6ab398f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499121587-172.17.0.19-1598553432968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-8a2a02e2-d005-4240-ad1b-e62feb487c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-130b29e5-3dd3-4356-ab2b-5971f4397a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-095f7cff-312d-463f-b3a4-ff6cdb22b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-4cafda6d-36c0-4542-9b41-b76326d06a61,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-b79427b1-410f-4c15-9bc0-23fbeec96d72,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2c8ddd81-dcfc-48b6-b454-33ae0cd1ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-4617c6ed-5a5f-471d-add5-d87881bcce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-bcb7e366-374e-480a-8811-c0db8c2569da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499121587-172.17.0.19-1598553432968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-8a2a02e2-d005-4240-ad1b-e62feb487c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-130b29e5-3dd3-4356-ab2b-5971f4397a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-095f7cff-312d-463f-b3a4-ff6cdb22b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-4cafda6d-36c0-4542-9b41-b76326d06a61,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-b79427b1-410f-4c15-9bc0-23fbeec96d72,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2c8ddd81-dcfc-48b6-b454-33ae0cd1ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-4617c6ed-5a5f-471d-add5-d87881bcce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-bcb7e366-374e-480a-8811-c0db8c2569da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401395556-172.17.0.19-1598553614485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44968,DS-8c94a63f-656c-4fea-9f44-7b09db5f1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-ea6b855a-ab9d-4345-9d21-da08fdb40fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-bf1a5edd-3917-4236-ab55-d31d53cce175,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-fb6e7717-07d3-4ba3-907c-157315639af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-f6a9ad27-e2cc-44e8-8c23-8dd1ef94673b,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-c08730f4-0747-42e6-890f-768eadeeb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-8fc62c33-ff3b-4cf5-b2d5-f76acae4279d,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-d79a7546-d62a-4336-b6b7-a4b48923f148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401395556-172.17.0.19-1598553614485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44968,DS-8c94a63f-656c-4fea-9f44-7b09db5f1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-ea6b855a-ab9d-4345-9d21-da08fdb40fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-bf1a5edd-3917-4236-ab55-d31d53cce175,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-fb6e7717-07d3-4ba3-907c-157315639af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-f6a9ad27-e2cc-44e8-8c23-8dd1ef94673b,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-c08730f4-0747-42e6-890f-768eadeeb39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-8fc62c33-ff3b-4cf5-b2d5-f76acae4279d,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-d79a7546-d62a-4336-b6b7-a4b48923f148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443184704-172.17.0.19-1598553651410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-99799f26-e459-4662-b361-05601a628eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-641d0b0f-cb7a-4a15-a92d-e7aded4332b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-44b92065-d09b-4def-8545-fef60ef5af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-5f7a16ed-9988-4efb-b10c-f6dce8e6d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-e65bb8fb-0c1d-482d-961b-e011eaa40e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-a4a1849f-1f9b-4d1a-9300-07723bf87a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-0b99f0f8-b346-4b6c-b59a-82856b763161,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-0817b998-f122-48c7-9f11-b55f14164753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443184704-172.17.0.19-1598553651410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40670,DS-99799f26-e459-4662-b361-05601a628eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-641d0b0f-cb7a-4a15-a92d-e7aded4332b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-44b92065-d09b-4def-8545-fef60ef5af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-5f7a16ed-9988-4efb-b10c-f6dce8e6d25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-e65bb8fb-0c1d-482d-961b-e011eaa40e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-a4a1849f-1f9b-4d1a-9300-07723bf87a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-0b99f0f8-b346-4b6c-b59a-82856b763161,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-0817b998-f122-48c7-9f11-b55f14164753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649710291-172.17.0.19-1598555203519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-7fa26b0c-8c59-419a-bb0b-1401369e42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-d04d3a80-1192-4fd6-a1ea-da14e8a4a769,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-61a8e3c2-5832-4342-a45d-3083fe59cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-89abe9bb-41a8-42e5-b750-953abea69760,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-1928b132-8b6a-4d75-add7-de07f399e1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-ae1153f1-ac09-4b2d-8f29-e7a4e17b8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-1dcc2a08-61f4-4343-9fb1-efed45173609,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-46d86b5a-382a-46bd-bd47-72bee5f97fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649710291-172.17.0.19-1598555203519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41465,DS-7fa26b0c-8c59-419a-bb0b-1401369e42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-d04d3a80-1192-4fd6-a1ea-da14e8a4a769,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-61a8e3c2-5832-4342-a45d-3083fe59cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-89abe9bb-41a8-42e5-b750-953abea69760,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-1928b132-8b6a-4d75-add7-de07f399e1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-ae1153f1-ac09-4b2d-8f29-e7a4e17b8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-1dcc2a08-61f4-4343-9fb1-efed45173609,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-46d86b5a-382a-46bd-bd47-72bee5f97fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5332
