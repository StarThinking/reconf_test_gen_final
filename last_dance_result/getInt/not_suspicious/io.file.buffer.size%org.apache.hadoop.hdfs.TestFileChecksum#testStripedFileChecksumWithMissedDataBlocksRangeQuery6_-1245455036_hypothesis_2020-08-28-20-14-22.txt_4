reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100817386-172.17.0.6-1598645680383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-fc785e1c-8c1f-49ca-9a41-940226e9d292,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-0498fe67-5214-437a-bb79-0d7035a70cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-ad6af981-772c-4a2c-99c9-8d6feec76a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-5170e566-1f8b-46b4-b0b5-8ff114182cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-6da24dab-1466-4552-8f40-90e366b7ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d1cfac20-c667-4ed0-8c7f-e2eb82f15378,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-93a8888f-1a31-4cb8-964d-56bbf7d5567e,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-fa081283-1766-4f98-89bc-728b4f037081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100817386-172.17.0.6-1598645680383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-fc785e1c-8c1f-49ca-9a41-940226e9d292,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-0498fe67-5214-437a-bb79-0d7035a70cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-ad6af981-772c-4a2c-99c9-8d6feec76a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-5170e566-1f8b-46b4-b0b5-8ff114182cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-6da24dab-1466-4552-8f40-90e366b7ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d1cfac20-c667-4ed0-8c7f-e2eb82f15378,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-93a8888f-1a31-4cb8-964d-56bbf7d5567e,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-fa081283-1766-4f98-89bc-728b4f037081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086678269-172.17.0.6-1598646438825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-7946cbab-489a-40f8-9420-eb4f8f6690d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b61edbd0-ba17-4b0a-905f-2e962b6ea573,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-7c6fcb9e-133e-4a96-9f63-154a3aafc959,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-b1adfa24-0aa6-4306-b2f2-0b25048ab967,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-b9742490-f98b-4318-900b-084a9cdadc50,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-a082aec9-83de-40c0-8d8f-887a060cb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-c1ed2a95-1958-4620-b08d-2a227b429375,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fe0fdbc9-806f-470d-ae07-11cb81600f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086678269-172.17.0.6-1598646438825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-7946cbab-489a-40f8-9420-eb4f8f6690d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b61edbd0-ba17-4b0a-905f-2e962b6ea573,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-7c6fcb9e-133e-4a96-9f63-154a3aafc959,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-b1adfa24-0aa6-4306-b2f2-0b25048ab967,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-b9742490-f98b-4318-900b-084a9cdadc50,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-a082aec9-83de-40c0-8d8f-887a060cb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-c1ed2a95-1958-4620-b08d-2a227b429375,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fe0fdbc9-806f-470d-ae07-11cb81600f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371930153-172.17.0.6-1598646587742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-cb32dc70-d0a1-4a58-8443-ce5f96cb2588,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-685b3067-e048-44a6-b48f-57801ecd683e,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-423df9e9-d52c-4d0f-b66a-9ef6bfed0ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ab6dbb27-8c57-4dd6-9fc2-dfc374be550d,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-e5f81699-c241-4994-973e-2af218319677,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-b06f417f-8468-4ef1-82fa-a7e975d3ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-9c89ad9f-8452-4e3d-bb3e-7c493da1f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-48ecf8b3-e260-4921-8e83-3792cdde4d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371930153-172.17.0.6-1598646587742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-cb32dc70-d0a1-4a58-8443-ce5f96cb2588,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-685b3067-e048-44a6-b48f-57801ecd683e,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-423df9e9-d52c-4d0f-b66a-9ef6bfed0ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-ab6dbb27-8c57-4dd6-9fc2-dfc374be550d,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-e5f81699-c241-4994-973e-2af218319677,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-b06f417f-8468-4ef1-82fa-a7e975d3ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-9c89ad9f-8452-4e3d-bb3e-7c493da1f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-48ecf8b3-e260-4921-8e83-3792cdde4d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023807392-172.17.0.6-1598647026257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-ad5a667d-f5ab-46f8-ab55-d412dccf78df,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-4bf2569f-a130-4398-a1ec-692d1a9e804c,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-55bb51fd-7e38-43fe-813b-da11c58c9c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-e4a8d46d-b231-4ef6-aee8-8460507a9afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-3d55ec46-a352-4cf4-bb00-6e434646d80d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-8c2b66de-d7d1-48dc-b12e-e30b995bf616,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-381e2ab1-070e-4159-b660-17e535807770,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-e656fca3-42fd-412a-94d3-9aacadd00221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023807392-172.17.0.6-1598647026257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-ad5a667d-f5ab-46f8-ab55-d412dccf78df,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-4bf2569f-a130-4398-a1ec-692d1a9e804c,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-55bb51fd-7e38-43fe-813b-da11c58c9c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-e4a8d46d-b231-4ef6-aee8-8460507a9afc,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-3d55ec46-a352-4cf4-bb00-6e434646d80d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-8c2b66de-d7d1-48dc-b12e-e30b995bf616,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-381e2ab1-070e-4159-b660-17e535807770,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-e656fca3-42fd-412a-94d3-9aacadd00221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513259407-172.17.0.6-1598647305891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-5815d7c5-a4dd-4b1c-ba69-a21a68647d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-862bd1a9-f64c-4614-b496-0caa0e7894be,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-2318488e-b434-4232-ac54-dc8793ee25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-8cb34a4d-5add-4fb2-8e47-96b05d36d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ac0fdfcc-5a83-4392-abf8-7e7997046700,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-19cfdd6c-7090-47c9-a4e2-823e8cccd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-5051ff99-5de1-4641-8f22-1dc3af22f394,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-3b2438ac-16fe-4f0e-8142-2e614c767d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513259407-172.17.0.6-1598647305891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-5815d7c5-a4dd-4b1c-ba69-a21a68647d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-862bd1a9-f64c-4614-b496-0caa0e7894be,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-2318488e-b434-4232-ac54-dc8793ee25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-8cb34a4d-5add-4fb2-8e47-96b05d36d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ac0fdfcc-5a83-4392-abf8-7e7997046700,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-19cfdd6c-7090-47c9-a4e2-823e8cccd75f,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-5051ff99-5de1-4641-8f22-1dc3af22f394,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-3b2438ac-16fe-4f0e-8142-2e614c767d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761363636-172.17.0.6-1598647481028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-afceeffb-980b-4c9d-ab0c-fb1f5d010d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-7de7c133-4749-43cd-91e9-f7e5271a1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e060bf04-3ee4-435b-8529-cd1e513e9553,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fe9cef3b-5158-4246-a7cd-6ad65952cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-746f1e84-7159-489d-83cc-2da59fe33fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-68b689c8-d728-43c2-b56d-346d42ddf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-757e35a6-8c35-46cb-bff6-618e0cd46682,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-5da48283-3f0f-4276-8fbd-a58e491f4a66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761363636-172.17.0.6-1598647481028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-afceeffb-980b-4c9d-ab0c-fb1f5d010d15,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-7de7c133-4749-43cd-91e9-f7e5271a1c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e060bf04-3ee4-435b-8529-cd1e513e9553,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fe9cef3b-5158-4246-a7cd-6ad65952cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-746f1e84-7159-489d-83cc-2da59fe33fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-68b689c8-d728-43c2-b56d-346d42ddf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-757e35a6-8c35-46cb-bff6-618e0cd46682,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-5da48283-3f0f-4276-8fbd-a58e491f4a66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083803819-172.17.0.6-1598647684186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-e7f6faea-cfdd-4048-922f-114a1270bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-658925e8-cd68-4f86-a8cc-ffdf004f91bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-1f4c7ab5-452f-40c1-91d2-4ff4657d0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d9013461-b000-4a60-8213-23103ea1d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-f83fee82-c982-4670-bb71-5150af31d132,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-952ca6b9-c312-4a67-87f6-2da1127ab88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-fafe429e-54e5-4e72-b8f1-18b85018ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-eda3ead0-6e85-44f5-8184-24e49790e147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083803819-172.17.0.6-1598647684186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-e7f6faea-cfdd-4048-922f-114a1270bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-658925e8-cd68-4f86-a8cc-ffdf004f91bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-1f4c7ab5-452f-40c1-91d2-4ff4657d0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d9013461-b000-4a60-8213-23103ea1d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-f83fee82-c982-4670-bb71-5150af31d132,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-952ca6b9-c312-4a67-87f6-2da1127ab88a,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-fafe429e-54e5-4e72-b8f1-18b85018ac1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-eda3ead0-6e85-44f5-8184-24e49790e147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188542177-172.17.0.6-1598647840173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40226,DS-0435f9b1-a05d-401b-b04f-2d8c2a99d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-30ffe690-8b68-4a03-81af-087656e45499,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-f5abc4e8-5ff8-46d7-bfaa-25ee057e5538,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-bcadc0de-bba3-4992-9f5c-99d783eed3de,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-b37ad6c7-8749-477f-ba1a-a199465c10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-cf13e7c1-3138-4c17-8153-9e10b7d3a462,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-06174906-abd0-4c28-acd7-b0f3b02cc326,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-0fba706e-e788-4b11-811b-6f351543ed9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188542177-172.17.0.6-1598647840173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40226,DS-0435f9b1-a05d-401b-b04f-2d8c2a99d65b,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-30ffe690-8b68-4a03-81af-087656e45499,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-f5abc4e8-5ff8-46d7-bfaa-25ee057e5538,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-bcadc0de-bba3-4992-9f5c-99d783eed3de,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-b37ad6c7-8749-477f-ba1a-a199465c10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-cf13e7c1-3138-4c17-8153-9e10b7d3a462,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-06174906-abd0-4c28-acd7-b0f3b02cc326,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-0fba706e-e788-4b11-811b-6f351543ed9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236998172-172.17.0.6-1598648392213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-b35b1d3a-8f44-4517-92ff-ea6fa392bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-337a0e14-b3f8-4301-ab71-b2bfdcf0c345,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ddc6fffe-4c66-40b8-847d-81a41e364e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-5211df5e-7a7a-4789-a3a4-329c1eb25bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-c887724f-3a16-48a9-97f9-e9a96ec1bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-8a1d5f2e-64c0-442b-a894-08d7630daa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-8c1a28b0-d293-4dfe-a81a-6623d781a153,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e97d3cf2-a708-4b6f-b3a4-0c94da578c1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236998172-172.17.0.6-1598648392213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-b35b1d3a-8f44-4517-92ff-ea6fa392bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-337a0e14-b3f8-4301-ab71-b2bfdcf0c345,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-ddc6fffe-4c66-40b8-847d-81a41e364e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-5211df5e-7a7a-4789-a3a4-329c1eb25bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-c887724f-3a16-48a9-97f9-e9a96ec1bbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-8a1d5f2e-64c0-442b-a894-08d7630daa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-8c1a28b0-d293-4dfe-a81a-6623d781a153,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e97d3cf2-a708-4b6f-b3a4-0c94da578c1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166863379-172.17.0.6-1598648580065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-56601d65-4b40-4a55-8937-249489daa92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-9f26756b-1ef9-4f7e-ba6c-14b4c1cc17d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-f06d3095-7e92-4376-a8bb-d2930b2d7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c76388a4-2a9a-4b26-847c-4299eaede2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0ce96a5d-f9f6-4d11-9989-05ba64ecbb24,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-0547935b-cca9-47a5-a98e-2d7d4efeecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-17a0ceac-3ba5-4152-a872-e6ce0c14bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8ef4118a-1380-475d-881e-e13fe5059539,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166863379-172.17.0.6-1598648580065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-56601d65-4b40-4a55-8937-249489daa92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-9f26756b-1ef9-4f7e-ba6c-14b4c1cc17d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-f06d3095-7e92-4376-a8bb-d2930b2d7cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c76388a4-2a9a-4b26-847c-4299eaede2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-0ce96a5d-f9f6-4d11-9989-05ba64ecbb24,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-0547935b-cca9-47a5-a98e-2d7d4efeecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-17a0ceac-3ba5-4152-a872-e6ce0c14bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8ef4118a-1380-475d-881e-e13fe5059539,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840486718-172.17.0.6-1598648737374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-9d1063a5-6be2-4682-9b79-349c00c3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-cc84bdfb-3015-42ba-a37d-be5fbab117ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-bfc13c08-78c5-4423-9208-f4fcf01d21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-8f00ff66-c93a-48ab-b56f-28b08043d754,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-de83732d-1c2d-49ff-933f-a36185aed493,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-4226c96f-5c72-4e11-a9cc-75463f83c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-573b2975-32f4-45b2-b76c-c55f08b74309,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-edaa77c7-2617-4c28-adc8-1a68effb21b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840486718-172.17.0.6-1598648737374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-9d1063a5-6be2-4682-9b79-349c00c3d870,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-cc84bdfb-3015-42ba-a37d-be5fbab117ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-bfc13c08-78c5-4423-9208-f4fcf01d21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-8f00ff66-c93a-48ab-b56f-28b08043d754,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-de83732d-1c2d-49ff-933f-a36185aed493,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-4226c96f-5c72-4e11-a9cc-75463f83c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-573b2975-32f4-45b2-b76c-c55f08b74309,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-edaa77c7-2617-4c28-adc8-1a68effb21b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29325521-172.17.0.6-1598648810400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-9d5b7f2d-99fe-4520-9be0-cef5acb8846b,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-6aa4bdb7-ebcd-4c05-94fa-5f5fb33da9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-77011ba6-9f6d-4bfa-8bf5-b3ea6033f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-51dea322-2781-4575-9748-9840a1b9b441,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-66d266b7-f98e-44bf-9510-6fa41f7e5094,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-24de156a-8ad8-4f5e-9e5f-53f6a1102e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-e3abe9b6-b352-49fa-907e-a40ac45cd364,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-6b9456e7-8314-4925-87e1-235ab371110c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29325521-172.17.0.6-1598648810400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-9d5b7f2d-99fe-4520-9be0-cef5acb8846b,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-6aa4bdb7-ebcd-4c05-94fa-5f5fb33da9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-77011ba6-9f6d-4bfa-8bf5-b3ea6033f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-51dea322-2781-4575-9748-9840a1b9b441,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-66d266b7-f98e-44bf-9510-6fa41f7e5094,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-24de156a-8ad8-4f5e-9e5f-53f6a1102e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-e3abe9b6-b352-49fa-907e-a40ac45cd364,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-6b9456e7-8314-4925-87e1-235ab371110c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968747703-172.17.0.6-1598649032036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-26c68c1f-240e-46f1-92a4-d570684c024f,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-5230daa6-a5c2-41ab-8323-4ad2236f5d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-a8da2bb7-a824-4088-babe-af362edaad11,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-3a1f514e-1bbd-4f26-b3ea-5ea3d86f7660,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5b6d97ca-f6a8-4cc2-b447-256072348be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-ccbb1b56-1d3f-4107-8100-715d571a6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-66284393-211f-48e2-9f56-1bd532cc2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c07dce03-f919-404a-ad32-b2658e01aa06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968747703-172.17.0.6-1598649032036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-26c68c1f-240e-46f1-92a4-d570684c024f,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-5230daa6-a5c2-41ab-8323-4ad2236f5d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-a8da2bb7-a824-4088-babe-af362edaad11,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-3a1f514e-1bbd-4f26-b3ea-5ea3d86f7660,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-5b6d97ca-f6a8-4cc2-b447-256072348be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-ccbb1b56-1d3f-4107-8100-715d571a6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-66284393-211f-48e2-9f56-1bd532cc2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c07dce03-f919-404a-ad32-b2658e01aa06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152096782-172.17.0.6-1598649274660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-b63ded92-a378-4103-8cca-32674af8544e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-62acc59e-af35-4015-a52f-c07b4fa2b983,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-a45b47fb-4e57-41ba-9c79-3cac58c49ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-eb0addb5-72ab-4ff8-b59d-196557289f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-e8743dd5-90d8-4bb8-971e-f5855e35394b,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-03cf0d7e-65e5-4727-bb5c-8fda893c336d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-76475fb6-6790-400b-b238-c5314b83e5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b7a8d9a7-57d8-47b9-b4d1-c5f8aca36839,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152096782-172.17.0.6-1598649274660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-b63ded92-a378-4103-8cca-32674af8544e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-62acc59e-af35-4015-a52f-c07b4fa2b983,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-a45b47fb-4e57-41ba-9c79-3cac58c49ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-eb0addb5-72ab-4ff8-b59d-196557289f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-e8743dd5-90d8-4bb8-971e-f5855e35394b,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-03cf0d7e-65e5-4727-bb5c-8fda893c336d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-76475fb6-6790-400b-b238-c5314b83e5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b7a8d9a7-57d8-47b9-b4d1-c5f8aca36839,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336319996-172.17.0.6-1598649389549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-33db2cd2-ba00-4a53-a7c6-2c47134a3032,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-468456b9-297e-4923-b5af-b9f521b4e402,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ee1dd7cb-07cb-4f6e-8efc-fd5621210a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-98d76672-4484-46ee-a7c5-62c985ebb917,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-6093a3b8-1a1b-45b7-b4b3-bfc5ba624ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-160db683-7cd2-42a9-8430-979bb023644d,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-d61ee9c7-4721-4ae9-a1e9-593aff46ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-e93d671e-ee6b-4efa-8278-09c7b18fea3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336319996-172.17.0.6-1598649389549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-33db2cd2-ba00-4a53-a7c6-2c47134a3032,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-468456b9-297e-4923-b5af-b9f521b4e402,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ee1dd7cb-07cb-4f6e-8efc-fd5621210a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-98d76672-4484-46ee-a7c5-62c985ebb917,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-6093a3b8-1a1b-45b7-b4b3-bfc5ba624ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-160db683-7cd2-42a9-8430-979bb023644d,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-d61ee9c7-4721-4ae9-a1e9-593aff46ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-e93d671e-ee6b-4efa-8278-09c7b18fea3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320196415-172.17.0.6-1598649415064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-f180b3fb-7905-4d63-9cd5-36824dfd82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ccf3c8e-f537-4a2a-9994-77fb17646305,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-901bacf2-c4d9-4e9a-a21e-8789bb316be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b208b221-a812-49ee-aca0-f1098ba3507d,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-d49d6f64-4b17-4e27-8f06-56b4d348fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-5f3163a0-3fbb-4ea8-b4cc-ca5d4ffad508,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-19af9313-91b3-4a69-9a96-d17466ffd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-144069ed-5ef1-45b2-8efc-f6e765f6b881,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320196415-172.17.0.6-1598649415064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46104,DS-f180b3fb-7905-4d63-9cd5-36824dfd82b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ccf3c8e-f537-4a2a-9994-77fb17646305,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-901bacf2-c4d9-4e9a-a21e-8789bb316be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b208b221-a812-49ee-aca0-f1098ba3507d,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-d49d6f64-4b17-4e27-8f06-56b4d348fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-5f3163a0-3fbb-4ea8-b4cc-ca5d4ffad508,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-19af9313-91b3-4a69-9a96-d17466ffd43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-144069ed-5ef1-45b2-8efc-f6e765f6b881,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315013176-172.17.0.6-1598649447542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-9a7a534b-3d2f-45a6-8ffb-e1c9f9a2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-812fe78c-48fa-4906-ab0b-58efcb46c341,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-12234956-e04b-40a9-b355-a87f59f318ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-0d7a9c6c-5379-4e50-9cc9-3f0f6610b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-45ff53e1-5677-4238-8db7-35db385f8103,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-251deb12-9b6b-409b-bb69-b3e71a2255b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-96254b14-9eca-49b5-8e0b-605c296bfe45,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-db2fbbea-5787-4a63-8f77-d99e4da25933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315013176-172.17.0.6-1598649447542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-9a7a534b-3d2f-45a6-8ffb-e1c9f9a2500d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-812fe78c-48fa-4906-ab0b-58efcb46c341,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-12234956-e04b-40a9-b355-a87f59f318ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-0d7a9c6c-5379-4e50-9cc9-3f0f6610b2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-45ff53e1-5677-4238-8db7-35db385f8103,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-251deb12-9b6b-409b-bb69-b3e71a2255b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-96254b14-9eca-49b5-8e0b-605c296bfe45,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-db2fbbea-5787-4a63-8f77-d99e4da25933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216427255-172.17.0.6-1598649522409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-b73e5d14-8a4f-4831-9460-66c32964c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-3bc54a2a-0afb-46e2-aaa8-3c07c4c4460b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-598bb6f4-4699-48e4-8a17-beb839e315b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6b070e3c-c910-4647-a8bf-0a863d4095af,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5025e768-ecad-4b2d-83e1-82002bac5c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-7d3cdf4a-c04d-413a-8a46-fd085cef57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-8b63ab7a-3811-4037-b98c-285a127a003e,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-552b9c97-f9c5-4457-8ff2-d0beba256bd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216427255-172.17.0.6-1598649522409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-b73e5d14-8a4f-4831-9460-66c32964c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-3bc54a2a-0afb-46e2-aaa8-3c07c4c4460b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-598bb6f4-4699-48e4-8a17-beb839e315b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-6b070e3c-c910-4647-a8bf-0a863d4095af,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-5025e768-ecad-4b2d-83e1-82002bac5c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-7d3cdf4a-c04d-413a-8a46-fd085cef57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-8b63ab7a-3811-4037-b98c-285a127a003e,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-552b9c97-f9c5-4457-8ff2-d0beba256bd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691011889-172.17.0.6-1598649592980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-8fcd13f4-7f25-4453-848f-69f7685d245f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-0272e963-8f64-4f20-8067-66be8a92f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-13e9be7f-cea5-44a0-97c9-03d82d2a3461,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-ec8a2049-e90c-4fc2-84e6-7775b4613435,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-60978ce4-729e-4b2d-b1f3-5ecebfce68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-065718ea-5580-41f7-9627-6785d9eb34dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-7fda3d2d-43f6-433b-afdb-67cd6bbc99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-9ee015c5-2af0-4253-9aaa-226043ada927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691011889-172.17.0.6-1598649592980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-8fcd13f4-7f25-4453-848f-69f7685d245f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-0272e963-8f64-4f20-8067-66be8a92f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-13e9be7f-cea5-44a0-97c9-03d82d2a3461,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-ec8a2049-e90c-4fc2-84e6-7775b4613435,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-60978ce4-729e-4b2d-b1f3-5ecebfce68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-065718ea-5580-41f7-9627-6785d9eb34dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-7fda3d2d-43f6-433b-afdb-67cd6bbc99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-9ee015c5-2af0-4253-9aaa-226043ada927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991976694-172.17.0.6-1598649741917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-e45a3c99-8859-45c0-ad9b-3b0c5fe8c04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3bc2bf28-2f43-4149-b135-6802319cc69b,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-6b394d80-d0e4-415f-8251-e8d0bb050aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a0cc6c75-d1e6-470a-b54d-4d4dcbaa3462,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-82318e2f-810f-4f11-9002-37bc5b0d74c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-7b432e78-e476-42f8-accf-80e8597061cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-751f6b1a-90d2-43d6-a041-15c5822179a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-33d887ea-e25b-4231-85e3-39aaa2545292,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991976694-172.17.0.6-1598649741917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-e45a3c99-8859-45c0-ad9b-3b0c5fe8c04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3bc2bf28-2f43-4149-b135-6802319cc69b,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-6b394d80-d0e4-415f-8251-e8d0bb050aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-a0cc6c75-d1e6-470a-b54d-4d4dcbaa3462,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-82318e2f-810f-4f11-9002-37bc5b0d74c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-7b432e78-e476-42f8-accf-80e8597061cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-751f6b1a-90d2-43d6-a041-15c5822179a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-33d887ea-e25b-4231-85e3-39aaa2545292,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117431859-172.17.0.6-1598649774087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-82f7b1f2-fd4f-401f-bdf9-3e1b39fa381d,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-11f15f16-d66d-43b4-be8b-9a384c3a0795,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-cec50e39-388e-4445-8e0f-b55c60167243,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-8117b981-f628-4858-8a98-e8c52179e175,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-16a5caf4-8769-4bfe-a9f0-939bbcb7d187,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-07eeeaf1-3e74-4fc2-9e64-0dfb1068b565,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-cfa1b85a-dd15-4dd1-9e25-c07ab74fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-70e58b0b-a2bc-484e-b95f-f81888044927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117431859-172.17.0.6-1598649774087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-82f7b1f2-fd4f-401f-bdf9-3e1b39fa381d,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-11f15f16-d66d-43b4-be8b-9a384c3a0795,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-cec50e39-388e-4445-8e0f-b55c60167243,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-8117b981-f628-4858-8a98-e8c52179e175,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-16a5caf4-8769-4bfe-a9f0-939bbcb7d187,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-07eeeaf1-3e74-4fc2-9e64-0dfb1068b565,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-cfa1b85a-dd15-4dd1-9e25-c07ab74fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-70e58b0b-a2bc-484e-b95f-f81888044927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246609495-172.17.0.6-1598649900172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-449bd0f9-35b7-4eee-8cc2-94b179a25009,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f976a370-ab91-425c-8d15-679248391efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-18229e46-d22b-4716-81bf-b82c3df6e510,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-6ed5df29-65f1-434f-a6f9-24ff698f2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-95f73ff0-1adc-4895-8710-57a1130b40a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-aa624082-a43e-4512-8245-f411cb550eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-383152cf-a38f-429c-b6d2-8691bc04ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-959a8dc1-48cd-4389-97aa-c0b9d7c3bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246609495-172.17.0.6-1598649900172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-449bd0f9-35b7-4eee-8cc2-94b179a25009,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f976a370-ab91-425c-8d15-679248391efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-18229e46-d22b-4716-81bf-b82c3df6e510,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-6ed5df29-65f1-434f-a6f9-24ff698f2e75,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-95f73ff0-1adc-4895-8710-57a1130b40a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-aa624082-a43e-4512-8245-f411cb550eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-383152cf-a38f-429c-b6d2-8691bc04ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-959a8dc1-48cd-4389-97aa-c0b9d7c3bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430699948-172.17.0.6-1598650154679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-92cab6c6-e943-4d57-a417-1a40bbe7d925,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6295c065-75df-4bb2-9062-9ac1ec4ec71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-b7753999-eddd-4fe4-a61a-b15c1165652d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-263ebe7d-0047-4ea3-b1bb-164e3d181c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-e98b6099-7902-4567-a4d6-27d4825a4e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-b287d7b9-8807-418a-a6ae-a39c85287591,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-48bf5922-ca9f-469e-9bc4-314c80bb8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-ed75e169-be5d-42f5-b918-58cdfb51c928,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430699948-172.17.0.6-1598650154679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-92cab6c6-e943-4d57-a417-1a40bbe7d925,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-6295c065-75df-4bb2-9062-9ac1ec4ec71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-b7753999-eddd-4fe4-a61a-b15c1165652d,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-263ebe7d-0047-4ea3-b1bb-164e3d181c37,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-e98b6099-7902-4567-a4d6-27d4825a4e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-b287d7b9-8807-418a-a6ae-a39c85287591,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-48bf5922-ca9f-469e-9bc4-314c80bb8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-ed75e169-be5d-42f5-b918-58cdfb51c928,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911028967-172.17.0.6-1598650223147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-2d4c2b49-78f4-4ba4-996a-0d0ff42099d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-03777210-4623-4e54-8411-00dfa22170fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-97bc6e3f-9525-42a7-b9d7-8d4c6721f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-01fbf16f-02ec-4d23-95e8-2bf2f5ed1b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-a2fd70f6-ffc1-4f79-aebc-b7d6f1fab316,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-eedfd323-0122-468f-9ab6-c147701acbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-d40d1179-7d7f-4b8b-8d4e-28b0b10b243f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-0a3e3d3f-0917-4659-a58c-e40487f16f39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911028967-172.17.0.6-1598650223147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-2d4c2b49-78f4-4ba4-996a-0d0ff42099d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-03777210-4623-4e54-8411-00dfa22170fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-97bc6e3f-9525-42a7-b9d7-8d4c6721f87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-01fbf16f-02ec-4d23-95e8-2bf2f5ed1b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-a2fd70f6-ffc1-4f79-aebc-b7d6f1fab316,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-eedfd323-0122-468f-9ab6-c147701acbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-d40d1179-7d7f-4b8b-8d4e-28b0b10b243f,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-0a3e3d3f-0917-4659-a58c-e40487f16f39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420747929-172.17.0.6-1598650257775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-1c02ec2c-9f9a-49bd-8666-2da29e20cf33,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-49bc4a9c-d0db-4c28-9813-51b327fd8385,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-05f70d17-eace-479d-b1c0-987ec11e663c,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-c0b0cab7-6601-4d75-a414-0855637f3e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-41f8507b-8b06-4ac1-8c78-4aa0dd522c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-d92d4fff-066a-48fd-8173-7cd70101b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-730eb0ff-e047-438c-a090-a5d1bef60b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-060e267d-76cf-43c9-8b75-da5263875403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420747929-172.17.0.6-1598650257775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-1c02ec2c-9f9a-49bd-8666-2da29e20cf33,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-49bc4a9c-d0db-4c28-9813-51b327fd8385,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-05f70d17-eace-479d-b1c0-987ec11e663c,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-c0b0cab7-6601-4d75-a414-0855637f3e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-41f8507b-8b06-4ac1-8c78-4aa0dd522c57,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-d92d4fff-066a-48fd-8173-7cd70101b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-730eb0ff-e047-438c-a090-a5d1bef60b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-060e267d-76cf-43c9-8b75-da5263875403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929561909-172.17.0.6-1598650483376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-1701d915-ae0c-453c-808e-ddef8912f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-b940f6d2-fd0c-4fd7-a215-dffe9b65f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b216e8ea-baa0-466f-837d-d66f1177d960,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-cd7f8a55-a17d-40fd-97f4-59bd3d51c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-1e140984-b6ab-4c69-a86f-a2dcde0e0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-cf14b7d1-58fc-47f4-acb1-8b9c2126583e,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-c3cf3780-c485-4957-a262-b1923dec7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-b1dee915-efe7-42ac-906d-089c573487f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929561909-172.17.0.6-1598650483376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-1701d915-ae0c-453c-808e-ddef8912f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-b940f6d2-fd0c-4fd7-a215-dffe9b65f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-b216e8ea-baa0-466f-837d-d66f1177d960,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-cd7f8a55-a17d-40fd-97f4-59bd3d51c4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-1e140984-b6ab-4c69-a86f-a2dcde0e0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-cf14b7d1-58fc-47f4-acb1-8b9c2126583e,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-c3cf3780-c485-4957-a262-b1923dec7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-b1dee915-efe7-42ac-906d-089c573487f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021308856-172.17.0.6-1598650596666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-4e4cb26b-001f-4bea-af28-fb81494b93c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-03ec4865-e802-4d12-a16a-e8c1fb61265e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-451fd8e5-d3ce-4f31-876d-d7ee5278e295,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3f384a1f-8d2e-444b-910f-b13197e0c862,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-6a705c29-6608-410f-90f6-063d027c9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-c91bfc87-ac3f-4a4d-bee2-5dd6c4f372e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-0df88d98-0135-46a8-bfd4-d43238ae9313,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-be75c8a8-514e-4ad8-8e01-af7ed97e7a52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021308856-172.17.0.6-1598650596666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-4e4cb26b-001f-4bea-af28-fb81494b93c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-03ec4865-e802-4d12-a16a-e8c1fb61265e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-451fd8e5-d3ce-4f31-876d-d7ee5278e295,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3f384a1f-8d2e-444b-910f-b13197e0c862,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-6a705c29-6608-410f-90f6-063d027c9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-c91bfc87-ac3f-4a4d-bee2-5dd6c4f372e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-0df88d98-0135-46a8-bfd4-d43238ae9313,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-be75c8a8-514e-4ad8-8e01-af7ed97e7a52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954983884-172.17.0.6-1598650707630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-bf6483ca-d451-449e-9d02-a1f50a517c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-d2269dc9-22da-460b-a1e4-26d09026a784,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-23949907-4d24-462b-a11b-069970e4ab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9b5568e9-196b-469c-a7ac-016e8f645136,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-50a56d6c-535f-41ef-b96e-43f2ba72186b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-2afb1942-0a4a-4d8e-907c-a337de602cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-b43b2f32-8d0f-4de7-8a89-e134ca90d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-6cb50eea-6e1c-46bc-99b9-11c5c89d9583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954983884-172.17.0.6-1598650707630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-bf6483ca-d451-449e-9d02-a1f50a517c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-d2269dc9-22da-460b-a1e4-26d09026a784,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-23949907-4d24-462b-a11b-069970e4ab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9b5568e9-196b-469c-a7ac-016e8f645136,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-50a56d6c-535f-41ef-b96e-43f2ba72186b,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-2afb1942-0a4a-4d8e-907c-a337de602cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-b43b2f32-8d0f-4de7-8a89-e134ca90d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-6cb50eea-6e1c-46bc-99b9-11c5c89d9583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9380961-172.17.0.6-1598650885155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-a8c2be8c-7a4a-48ba-aa1b-e77037c6fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-88aa3e3b-2648-4b9a-86b8-f1be9cca66ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-2d40b2eb-472a-45ce-9a74-cee8491383bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-9538db1e-7dc3-469b-a16d-6bb2801b9de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-c78dea30-a60a-4c99-b346-36d2f8b28b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-4ce5b9eb-d700-42da-9924-9c1122c45508,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-4888b10d-ec72-41cc-bd27-720198513a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9c64f822-5040-4b46-a164-50298d8cecf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9380961-172.17.0.6-1598650885155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-a8c2be8c-7a4a-48ba-aa1b-e77037c6fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-88aa3e3b-2648-4b9a-86b8-f1be9cca66ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-2d40b2eb-472a-45ce-9a74-cee8491383bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-9538db1e-7dc3-469b-a16d-6bb2801b9de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-c78dea30-a60a-4c99-b346-36d2f8b28b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-4ce5b9eb-d700-42da-9924-9c1122c45508,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-4888b10d-ec72-41cc-bd27-720198513a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9c64f822-5040-4b46-a164-50298d8cecf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330050396-172.17.0.6-1598650925713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-c323557e-dff0-40bf-bef4-f1ba5da79a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-1e710f89-2da5-43eb-9c0c-241b5af4a872,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-4c7f9d57-1757-42a1-ae40-b03ca4456de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-b7b101e2-b9ef-4882-9c5c-025a4cfb3296,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1b0b5573-8013-4b4c-a132-55ceef397400,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-191b0698-f507-4ed6-b437-021f36e2a599,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-b01b99f3-6d29-40fa-95b3-78d6f7333109,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-5874e3a6-69e1-451e-a256-45e88805729a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330050396-172.17.0.6-1598650925713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-c323557e-dff0-40bf-bef4-f1ba5da79a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-1e710f89-2da5-43eb-9c0c-241b5af4a872,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-4c7f9d57-1757-42a1-ae40-b03ca4456de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-b7b101e2-b9ef-4882-9c5c-025a4cfb3296,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1b0b5573-8013-4b4c-a132-55ceef397400,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-191b0698-f507-4ed6-b437-021f36e2a599,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-b01b99f3-6d29-40fa-95b3-78d6f7333109,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-5874e3a6-69e1-451e-a256-45e88805729a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735750048-172.17.0.6-1598651022088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-542bac46-dd5c-4047-85d0-ecb1a64b7912,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-e5a591db-cb38-4ae9-ad31-acc54b442d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-52620986-6fd8-442f-82ef-ed2a9a2ae4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c73d0fc4-42b7-4f1c-90a2-a949f2f3e342,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-62a12361-27d5-4b14-b2a5-6663baf3027b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-a693c364-c518-4931-bfe7-2bf262c66251,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-c57a0d37-0c9c-4124-bbd3-679329744ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-8ab01518-4a8c-4957-af71-7814c4f12d11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735750048-172.17.0.6-1598651022088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36901,DS-542bac46-dd5c-4047-85d0-ecb1a64b7912,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-e5a591db-cb38-4ae9-ad31-acc54b442d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-52620986-6fd8-442f-82ef-ed2a9a2ae4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c73d0fc4-42b7-4f1c-90a2-a949f2f3e342,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-62a12361-27d5-4b14-b2a5-6663baf3027b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-a693c364-c518-4931-bfe7-2bf262c66251,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-c57a0d37-0c9c-4124-bbd3-679329744ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-8ab01518-4a8c-4957-af71-7814c4f12d11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40975884-172.17.0.6-1598651058578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-3fb9649c-0186-455f-8cb4-2d3c34a868ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1fbbb219-6987-4390-a8df-e9c5aef37d44,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-da7bcc0d-5867-4177-8d29-25cae668c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-f32faae6-a43b-4d56-a0e3-a8aff4cdeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a3fb2392-5845-424c-8406-ed6aace97b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-e3aa3be0-30f3-43fc-9adc-9d0e8b374c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-4c308674-14dd-4839-943d-5508c41daac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-87c726ac-5ac7-44a3-b79f-e1b160648acc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40975884-172.17.0.6-1598651058578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-3fb9649c-0186-455f-8cb4-2d3c34a868ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1fbbb219-6987-4390-a8df-e9c5aef37d44,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-da7bcc0d-5867-4177-8d29-25cae668c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-f32faae6-a43b-4d56-a0e3-a8aff4cdeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a3fb2392-5845-424c-8406-ed6aace97b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-e3aa3be0-30f3-43fc-9adc-9d0e8b374c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-4c308674-14dd-4839-943d-5508c41daac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-87c726ac-5ac7-44a3-b79f-e1b160648acc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5494
