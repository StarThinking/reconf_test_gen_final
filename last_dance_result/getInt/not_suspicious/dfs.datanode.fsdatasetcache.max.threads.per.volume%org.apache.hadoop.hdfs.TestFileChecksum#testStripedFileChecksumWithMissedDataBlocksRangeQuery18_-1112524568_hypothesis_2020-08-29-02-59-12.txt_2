reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934868688-172.17.0.19-1598670241375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-b47930aa-6d81-40fe-905f-007dfa0c27f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-32e5ca4d-68d6-41c3-bbed-842fe62a0544,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-ffffd30d-cbdc-4b48-b885-0b709ec8fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-1f574ecd-a5eb-45a5-8d4c-98ecb690e292,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e14d1a9a-7119-4afb-9be9-f2a4c1e8f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-e0c0b5b7-49c4-420d-9b0f-06258e492e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-32b21f12-ab80-4ff8-8eb0-a282cbca064c,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-8e4b89f7-4e9e-438b-82af-63157ec5d68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934868688-172.17.0.19-1598670241375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-b47930aa-6d81-40fe-905f-007dfa0c27f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-32e5ca4d-68d6-41c3-bbed-842fe62a0544,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-ffffd30d-cbdc-4b48-b885-0b709ec8fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-1f574ecd-a5eb-45a5-8d4c-98ecb690e292,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e14d1a9a-7119-4afb-9be9-f2a4c1e8f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-e0c0b5b7-49c4-420d-9b0f-06258e492e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-32b21f12-ab80-4ff8-8eb0-a282cbca064c,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-8e4b89f7-4e9e-438b-82af-63157ec5d68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925736080-172.17.0.19-1598670279682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37252,DS-dad0fac3-8b5f-4aef-9b83-edc5b897b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-9cdffd5a-8add-4e16-9f7e-dfdc8a2dba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-560d35f2-43c5-4743-ae69-6280639556c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-90cc7ed6-be68-4e4b-ae8a-132c5becffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-296deaec-5d06-4e4c-8fe2-bb7cbccb892f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b30f3d27-d453-439c-bcee-c9b0636d27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-23b115cc-71b3-44d5-9145-eef2f7abb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-b6af603b-4ee5-4f8d-a141-faac09422121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925736080-172.17.0.19-1598670279682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37252,DS-dad0fac3-8b5f-4aef-9b83-edc5b897b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-9cdffd5a-8add-4e16-9f7e-dfdc8a2dba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-560d35f2-43c5-4743-ae69-6280639556c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-90cc7ed6-be68-4e4b-ae8a-132c5becffc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-296deaec-5d06-4e4c-8fe2-bb7cbccb892f,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-b30f3d27-d453-439c-bcee-c9b0636d27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-23b115cc-71b3-44d5-9145-eef2f7abb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-b6af603b-4ee5-4f8d-a141-faac09422121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466013977-172.17.0.19-1598670346457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-10db1be7-e0b9-4c3d-8638-3076eaee455c,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-3307848f-0268-414c-9f84-cccb16a10ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-eee75f5a-1033-4b3c-874b-f0bf4e05d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c447e33c-9fe3-4079-9f73-41b895352479,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-c8c1219e-1d88-444e-a6c6-b0b0314eb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-a3165ff1-e36a-4de9-a089-ea6ed65d62e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-d0843abf-a7ee-45fd-a876-ea94682c4da5,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-7c65d052-625d-4fc5-9dfb-071a40d31217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466013977-172.17.0.19-1598670346457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37833,DS-10db1be7-e0b9-4c3d-8638-3076eaee455c,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-3307848f-0268-414c-9f84-cccb16a10ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-eee75f5a-1033-4b3c-874b-f0bf4e05d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c447e33c-9fe3-4079-9f73-41b895352479,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-c8c1219e-1d88-444e-a6c6-b0b0314eb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-a3165ff1-e36a-4de9-a089-ea6ed65d62e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-d0843abf-a7ee-45fd-a876-ea94682c4da5,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-7c65d052-625d-4fc5-9dfb-071a40d31217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796842566-172.17.0.19-1598670510106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-d8f736ef-fcd4-445c-ab2a-9c4a08adefec,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-cc2b9d9f-fa91-4d99-a375-64c62ece7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-cc608418-162a-48d3-af2c-e6e84568114a,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64e8befc-bc63-4390-8383-bcfdd546c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-9a8d2bac-02c3-4332-9993-61dfd866c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-50536168-c9b1-40c3-8ed8-d0dc66945e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-f52e6210-1dee-4e4a-bd68-48a5a6a309c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-bddef12b-ae52-4d3b-bbdc-2f5023d7bf78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796842566-172.17.0.19-1598670510106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-d8f736ef-fcd4-445c-ab2a-9c4a08adefec,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-cc2b9d9f-fa91-4d99-a375-64c62ece7fed,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-cc608418-162a-48d3-af2c-e6e84568114a,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64e8befc-bc63-4390-8383-bcfdd546c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-9a8d2bac-02c3-4332-9993-61dfd866c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-50536168-c9b1-40c3-8ed8-d0dc66945e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-f52e6210-1dee-4e4a-bd68-48a5a6a309c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-bddef12b-ae52-4d3b-bbdc-2f5023d7bf78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121155900-172.17.0.19-1598670619716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-44ab1f11-b019-4953-87ac-62c7d4cea9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-df4499e0-ea95-4934-a579-bf538fec0ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-79f2d5ee-c88d-4314-bd2f-9a836973b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-efe1660d-e131-4aaa-8ec8-308c6d3a8072,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-eb45ac8a-a499-49f1-89af-f97b988fcc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-4b8c4823-1729-4125-bc26-6a075fac72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-230a078c-9051-4ac3-ae6f-214d04b9a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-f4725ad2-e997-4cb5-9d69-fa30d9dedb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121155900-172.17.0.19-1598670619716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-44ab1f11-b019-4953-87ac-62c7d4cea9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-df4499e0-ea95-4934-a579-bf538fec0ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-79f2d5ee-c88d-4314-bd2f-9a836973b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-efe1660d-e131-4aaa-8ec8-308c6d3a8072,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-eb45ac8a-a499-49f1-89af-f97b988fcc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-4b8c4823-1729-4125-bc26-6a075fac72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-230a078c-9051-4ac3-ae6f-214d04b9a2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-f4725ad2-e997-4cb5-9d69-fa30d9dedb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143774474-172.17.0.19-1598671462945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d02e5a2c-ae86-417b-a338-2f5edd694ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-57cf7517-bd4d-46c4-b446-07ed83f701f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-b43c309f-5351-4494-807d-9a209622c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-26b085b5-0c48-48f2-85f7-1217bb4b045f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-14b53ca1-bb15-4361-9bbe-4e0960f77c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-b0590d6d-9a7e-42f6-b68b-edce4e092d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-1f56230b-3b9f-4df0-bd7d-8db52285c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-0acab4e3-adf4-4666-a47d-2a02b4cadb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143774474-172.17.0.19-1598671462945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d02e5a2c-ae86-417b-a338-2f5edd694ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-57cf7517-bd4d-46c4-b446-07ed83f701f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-b43c309f-5351-4494-807d-9a209622c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-26b085b5-0c48-48f2-85f7-1217bb4b045f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-14b53ca1-bb15-4361-9bbe-4e0960f77c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-b0590d6d-9a7e-42f6-b68b-edce4e092d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-1f56230b-3b9f-4df0-bd7d-8db52285c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-0acab4e3-adf4-4666-a47d-2a02b4cadb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626256545-172.17.0.19-1598671682244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-66aa0d8c-1542-4e0e-8f83-516e3bc9dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-254061e3-f2f5-423b-a359-00088059266a,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-c0f6c0a8-e36d-4f0d-ac71-17016a3d8b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-e4b52728-0d6e-4cfa-87fa-58f20a336ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-8ad757fd-2bf4-4fd5-af29-31048bc6f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-38b5a095-b56f-41cb-8ccc-e0494a239ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-79ccfaf4-8f35-4bef-a741-3b8b19fb49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-51ae9b46-6614-42ed-b6c3-cae5963a697e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626256545-172.17.0.19-1598671682244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-66aa0d8c-1542-4e0e-8f83-516e3bc9dad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-254061e3-f2f5-423b-a359-00088059266a,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-c0f6c0a8-e36d-4f0d-ac71-17016a3d8b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-e4b52728-0d6e-4cfa-87fa-58f20a336ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-8ad757fd-2bf4-4fd5-af29-31048bc6f0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-38b5a095-b56f-41cb-8ccc-e0494a239ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-79ccfaf4-8f35-4bef-a741-3b8b19fb49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-51ae9b46-6614-42ed-b6c3-cae5963a697e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938955529-172.17.0.19-1598671959599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-80472b3e-288e-40bc-abc0-a01652de4b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-3f65d0aa-1863-4a89-a8f4-313601745083,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b9e28c82-d8ad-49bf-8825-440f72998bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-7f532bd6-1b3e-4d11-8bec-a5ac724e877f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-f6e512b5-4790-4b0f-9067-6d4e4afca3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-553cfe3c-390d-4432-8321-f179dc131cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-cc604c84-d447-41a4-93eb-a94815d87ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-c1ae1eff-d5b5-4f77-807b-e8b58363441a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938955529-172.17.0.19-1598671959599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-80472b3e-288e-40bc-abc0-a01652de4b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-3f65d0aa-1863-4a89-a8f4-313601745083,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b9e28c82-d8ad-49bf-8825-440f72998bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-7f532bd6-1b3e-4d11-8bec-a5ac724e877f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-f6e512b5-4790-4b0f-9067-6d4e4afca3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-553cfe3c-390d-4432-8321-f179dc131cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-cc604c84-d447-41a4-93eb-a94815d87ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-c1ae1eff-d5b5-4f77-807b-e8b58363441a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960716781-172.17.0.19-1598672220967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-ca5dd32e-b22f-4e01-a304-51723f70ea25,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-adf632d5-5540-4228-b658-916598a23f82,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-f54627ae-937c-43c8-89d0-a3c5b762792d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-9dfba857-35bd-49ba-b680-4afbb53353fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-2a5ebc27-15b8-4ac7-901b-24455d21c734,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-4835f294-4743-437b-85f8-701cf8189eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-8b67c281-6833-46e8-81b2-e5eaccc12ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-e20bc62d-9b9b-4381-af24-bfa45d96f803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960716781-172.17.0.19-1598672220967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-ca5dd32e-b22f-4e01-a304-51723f70ea25,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-adf632d5-5540-4228-b658-916598a23f82,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-f54627ae-937c-43c8-89d0-a3c5b762792d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-9dfba857-35bd-49ba-b680-4afbb53353fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-2a5ebc27-15b8-4ac7-901b-24455d21c734,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-4835f294-4743-437b-85f8-701cf8189eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-8b67c281-6833-46e8-81b2-e5eaccc12ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-e20bc62d-9b9b-4381-af24-bfa45d96f803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969882161-172.17.0.19-1598672742333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35596,DS-0f051623-c978-4e21-b2ad-5793ebb8c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-50f613ee-8a29-47d0-b690-d59cf68cb58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-cc02d56f-06ff-43f0-8962-34037a44847e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-8e636a1e-28dc-450b-8fcf-e5c91cb28580,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-7a12fea9-7a56-45f4-82ad-efb9ff548d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-ec86d305-6c47-4460-87bc-3800b7b3925a,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-8958dbe3-546d-40c1-af00-1581f8ab5ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c9b8651a-c946-4190-9cf2-1a8b6e7dca3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969882161-172.17.0.19-1598672742333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35596,DS-0f051623-c978-4e21-b2ad-5793ebb8c50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-50f613ee-8a29-47d0-b690-d59cf68cb58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-cc02d56f-06ff-43f0-8962-34037a44847e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-8e636a1e-28dc-450b-8fcf-e5c91cb28580,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-7a12fea9-7a56-45f4-82ad-efb9ff548d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-ec86d305-6c47-4460-87bc-3800b7b3925a,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-8958dbe3-546d-40c1-af00-1581f8ab5ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c9b8651a-c946-4190-9cf2-1a8b6e7dca3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139519520-172.17.0.19-1598672924046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-e6d983ae-6679-4081-976e-ff1c9d3224b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-8a77abe2-f139-4483-a35f-ed6c662af2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-fe89e4dc-8f60-4db6-8d2c-449d7ed5d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-282d5851-2edb-4edf-8a59-6a11ba3b457f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-eecd13c0-ceaf-400b-af1c-c50e7acc137f,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-cbbff6e1-7d04-468d-81a2-121d7f1ae41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-17a1de74-ab7e-4cba-8357-c30cf91045be,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-6fe6f244-5d73-4249-ab8f-f269b444e25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139519520-172.17.0.19-1598672924046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-e6d983ae-6679-4081-976e-ff1c9d3224b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-8a77abe2-f139-4483-a35f-ed6c662af2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-fe89e4dc-8f60-4db6-8d2c-449d7ed5d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-282d5851-2edb-4edf-8a59-6a11ba3b457f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-eecd13c0-ceaf-400b-af1c-c50e7acc137f,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-cbbff6e1-7d04-468d-81a2-121d7f1ae41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-17a1de74-ab7e-4cba-8357-c30cf91045be,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-6fe6f244-5d73-4249-ab8f-f269b444e25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638617423-172.17.0.19-1598673029095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-31f276f8-65a9-451f-b4c4-4341fbd71b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-825b6194-4889-4804-8ab7-251c10179112,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-0319c074-ec3c-423c-92fc-3d4dba2dbf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-53144392-12d6-4a9e-98ca-1ffaf0c192d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-fc40041f-8230-4e59-96aa-9213d27691df,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-1a03fedc-1688-4748-b837-b19ffdee0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b82b3e54-a522-4eed-9b69-27c4d9712d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-6d51d921-2ec4-460a-b100-2a92320ff3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638617423-172.17.0.19-1598673029095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-31f276f8-65a9-451f-b4c4-4341fbd71b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-825b6194-4889-4804-8ab7-251c10179112,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-0319c074-ec3c-423c-92fc-3d4dba2dbf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-53144392-12d6-4a9e-98ca-1ffaf0c192d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-fc40041f-8230-4e59-96aa-9213d27691df,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-1a03fedc-1688-4748-b837-b19ffdee0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-b82b3e54-a522-4eed-9b69-27c4d9712d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-6d51d921-2ec4-460a-b100-2a92320ff3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154635831-172.17.0.19-1598673247893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-041ef7a9-0e28-4f01-9586-51d236c26c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d0ba5b47-5c89-43d3-83b6-e8bec4126f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9c4afbf7-415a-4bf8-bf31-f4d9afeeb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-f8901a26-d59d-4c67-8433-38952031e469,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-cf4fc70b-5dcb-422d-afb1-013e5f58074d,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-bb5d4af6-c4ef-4cdd-883e-2d8206ed7020,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-2e9e31f4-9dd3-4d90-ace4-62796d1d79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-a7de388e-dda6-45dc-8b5f-938f4107d456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154635831-172.17.0.19-1598673247893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-041ef7a9-0e28-4f01-9586-51d236c26c27,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-d0ba5b47-5c89-43d3-83b6-e8bec4126f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9c4afbf7-415a-4bf8-bf31-f4d9afeeb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-f8901a26-d59d-4c67-8433-38952031e469,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-cf4fc70b-5dcb-422d-afb1-013e5f58074d,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-bb5d4af6-c4ef-4cdd-883e-2d8206ed7020,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-2e9e31f4-9dd3-4d90-ace4-62796d1d79e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-a7de388e-dda6-45dc-8b5f-938f4107d456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858401964-172.17.0.19-1598673510503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-e3fcc262-cb3d-4a06-8afb-bdb6af6b4a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-914211c1-9d8b-40e7-821c-8cd085e825ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-07a70dd6-f643-4518-b9c7-6abb4b54dcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-191f6b38-abfb-4725-9af4-5bb903a52f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a147ef43-7a52-43b0-a3e9-75b24e8b515a,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-92eecbfb-9dc8-4db6-9307-351c863a9bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-b22cb281-153b-4a91-b02c-267a207cb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-542d64c0-182d-4f11-88cb-59f373244506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858401964-172.17.0.19-1598673510503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-e3fcc262-cb3d-4a06-8afb-bdb6af6b4a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-914211c1-9d8b-40e7-821c-8cd085e825ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-07a70dd6-f643-4518-b9c7-6abb4b54dcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-191f6b38-abfb-4725-9af4-5bb903a52f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a147ef43-7a52-43b0-a3e9-75b24e8b515a,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-92eecbfb-9dc8-4db6-9307-351c863a9bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-b22cb281-153b-4a91-b02c-267a207cb6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-542d64c0-182d-4f11-88cb-59f373244506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964546996-172.17.0.19-1598673897084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-acf913eb-8b7d-4871-b676-71e1668ba895,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d7cd4c86-ae33-4a8c-88b0-04e2e87ad74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-79e01055-74c5-4a57-9393-e6d1e5a36482,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-223f09ac-b8fa-408c-9972-3255416f89dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-6baa4b9a-a16a-4d48-a960-189fd41c71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-59540b51-2390-43bf-bc55-62b8c6809f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-c4f132f1-9b5f-4463-880a-1f3940f0886d,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-91ef2bfc-6502-4f9e-a50d-0d0ef60db821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964546996-172.17.0.19-1598673897084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-acf913eb-8b7d-4871-b676-71e1668ba895,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d7cd4c86-ae33-4a8c-88b0-04e2e87ad74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-79e01055-74c5-4a57-9393-e6d1e5a36482,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-223f09ac-b8fa-408c-9972-3255416f89dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-6baa4b9a-a16a-4d48-a960-189fd41c71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-59540b51-2390-43bf-bc55-62b8c6809f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-c4f132f1-9b5f-4463-880a-1f3940f0886d,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-91ef2bfc-6502-4f9e-a50d-0d0ef60db821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216654229-172.17.0.19-1598674708132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-2d90d66a-6445-4a0b-973b-69c5c9bc26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7440f620-3edb-4747-9559-8db5bf604c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-151ff221-16d9-4e50-a08f-5223a1b88d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-e96cffaa-b755-4756-b758-8dc444f8c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-3cb459fe-62e0-476d-beb8-85a0b8d90cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-55b60fef-6de1-4f60-ba61-839ac90c935d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-29008831-f65c-4df3-ab1f-84a52aacbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-6ad85a0c-2e48-444a-b608-2653826ee45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216654229-172.17.0.19-1598674708132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-2d90d66a-6445-4a0b-973b-69c5c9bc26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7440f620-3edb-4747-9559-8db5bf604c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-151ff221-16d9-4e50-a08f-5223a1b88d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-e96cffaa-b755-4756-b758-8dc444f8c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-3cb459fe-62e0-476d-beb8-85a0b8d90cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-55b60fef-6de1-4f60-ba61-839ac90c935d,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-29008831-f65c-4df3-ab1f-84a52aacbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-6ad85a0c-2e48-444a-b608-2653826ee45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297983967-172.17.0.19-1598674774117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-bdbd1f45-d519-482d-a193-ae3f0aee3652,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-999fb5b1-dea7-4904-b882-246b11627321,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-562f55c0-955d-4ec8-bc26-211359d30d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-5dc727f2-0532-48a6-b26a-f8077d9b9720,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-5c16f3a9-2c64-4023-9135-36300135d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-01b0d12e-a9bf-4cae-84bc-2892edf66753,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-876502ae-4713-4934-8211-2468c1d857e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-f882caa1-669e-458f-bae2-363944e9eeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297983967-172.17.0.19-1598674774117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-bdbd1f45-d519-482d-a193-ae3f0aee3652,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-999fb5b1-dea7-4904-b882-246b11627321,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-562f55c0-955d-4ec8-bc26-211359d30d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-5dc727f2-0532-48a6-b26a-f8077d9b9720,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-5c16f3a9-2c64-4023-9135-36300135d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-01b0d12e-a9bf-4cae-84bc-2892edf66753,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-876502ae-4713-4934-8211-2468c1d857e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-f882caa1-669e-458f-bae2-363944e9eeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331398767-172.17.0.19-1598675029922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39283,DS-2cafca0e-34ee-4a00-b2a2-09808c156ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-49a63080-03d9-43d0-bc6c-18299b623137,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-dacebe43-3102-4594-8aba-20ae9950cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-98770b05-8f2f-41eb-b19a-1eb78353cd80,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-7797b89c-bd65-46e5-9285-e5d9f3d66c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-a1188140-e25d-4feb-addb-4c9e49e2c900,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-c1ef44f9-8811-49e8-9f5f-7fdab8921e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-e7422f1c-560f-4f93-9fe0-cf4a48e17731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331398767-172.17.0.19-1598675029922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39283,DS-2cafca0e-34ee-4a00-b2a2-09808c156ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-49a63080-03d9-43d0-bc6c-18299b623137,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-dacebe43-3102-4594-8aba-20ae9950cb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-98770b05-8f2f-41eb-b19a-1eb78353cd80,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-7797b89c-bd65-46e5-9285-e5d9f3d66c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-a1188140-e25d-4feb-addb-4c9e49e2c900,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-c1ef44f9-8811-49e8-9f5f-7fdab8921e11,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-e7422f1c-560f-4f93-9fe0-cf4a48e17731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5172
