reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735745046-172.17.0.21-1598527736704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39805,DS-c33a9808-29e6-4fcc-a40f-795f0975c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-d5d1da00-a595-49ab-9935-1dc6d7200519,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-94ddae2a-a495-4b7e-97a7-fbd408b349fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-d6b5d5c7-57df-4518-a9fc-e6c28986d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-e65e83d3-cfa3-4fa5-85c2-fe8a00eea404,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2a3c8cef-7123-4ae4-be4b-222f37576f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5846a5c0-662e-43b9-b2bf-ca6cd15fa81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-a699b1cb-dde6-4915-a65e-b7eaf7b238dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735745046-172.17.0.21-1598527736704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39805,DS-c33a9808-29e6-4fcc-a40f-795f0975c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-d5d1da00-a595-49ab-9935-1dc6d7200519,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-94ddae2a-a495-4b7e-97a7-fbd408b349fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-d6b5d5c7-57df-4518-a9fc-e6c28986d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-e65e83d3-cfa3-4fa5-85c2-fe8a00eea404,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2a3c8cef-7123-4ae4-be4b-222f37576f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-5846a5c0-662e-43b9-b2bf-ca6cd15fa81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-a699b1cb-dde6-4915-a65e-b7eaf7b238dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933116986-172.17.0.21-1598527857427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-5b30434d-6189-4b02-b091-96704b2f6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-220fc21d-7c80-489f-a02e-f42584cf035b,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-92f3f5de-b6ad-4c37-ac34-fa9287972e08,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1beab94d-9e45-4216-9576-a47518ceb529,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-52b572f8-02c3-479e-a6f4-10a4ddfc134a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-07392701-36c7-4d45-9c81-fd9ab36d31bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-30346782-6038-483a-a812-b6b34795070a,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-7bc1954a-71f6-4cde-a069-0abe28fed846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933116986-172.17.0.21-1598527857427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-5b30434d-6189-4b02-b091-96704b2f6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-220fc21d-7c80-489f-a02e-f42584cf035b,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-92f3f5de-b6ad-4c37-ac34-fa9287972e08,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1beab94d-9e45-4216-9576-a47518ceb529,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-52b572f8-02c3-479e-a6f4-10a4ddfc134a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-07392701-36c7-4d45-9c81-fd9ab36d31bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-30346782-6038-483a-a812-b6b34795070a,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-7bc1954a-71f6-4cde-a069-0abe28fed846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189159637-172.17.0.21-1598529732355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34985,DS-cbd46980-b111-4f92-9dac-7472c391c7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-84a5d394-e7cd-4482-8f9b-27e6b43730c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-2a850f4e-2cb9-4189-a747-e983e3349a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-52d77863-8ec8-4878-9d4a-aed436a4754d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-530d5eec-4d90-41a9-a7c3-556212785484,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-73485245-ec2f-4a68-a098-ad1f6899b51b,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-95699ce0-326f-4e7d-aa53-2dac07b976b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-7dd85558-7301-4afd-902f-069e6c8f4352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189159637-172.17.0.21-1598529732355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34985,DS-cbd46980-b111-4f92-9dac-7472c391c7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-84a5d394-e7cd-4482-8f9b-27e6b43730c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-2a850f4e-2cb9-4189-a747-e983e3349a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-52d77863-8ec8-4878-9d4a-aed436a4754d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-530d5eec-4d90-41a9-a7c3-556212785484,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-73485245-ec2f-4a68-a098-ad1f6899b51b,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-95699ce0-326f-4e7d-aa53-2dac07b976b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-7dd85558-7301-4afd-902f-069e6c8f4352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921784858-172.17.0.21-1598529816213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-a255de7f-e5aa-4097-95fa-a34e0519d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-2d6f7155-7037-4b36-8bb9-3aceb6384a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-45ba3854-b3f1-437d-903a-4f707a836eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-58413c1f-c3a4-4668-a5e8-e0a77cc7288a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-84fa32fe-5ac2-4a76-9f40-bb6bb0086a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-43ecea4d-ec2a-48d4-a4a6-19aa21dd51a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-5c32efa3-60a6-4a71-b8ba-eeded36c61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-fa4ce366-e818-4693-8ae4-715d3ad30a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921784858-172.17.0.21-1598529816213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-a255de7f-e5aa-4097-95fa-a34e0519d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-2d6f7155-7037-4b36-8bb9-3aceb6384a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-45ba3854-b3f1-437d-903a-4f707a836eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-58413c1f-c3a4-4668-a5e8-e0a77cc7288a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-84fa32fe-5ac2-4a76-9f40-bb6bb0086a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-43ecea4d-ec2a-48d4-a4a6-19aa21dd51a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-5c32efa3-60a6-4a71-b8ba-eeded36c61e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-fa4ce366-e818-4693-8ae4-715d3ad30a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849346290-172.17.0.21-1598530274894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-46840434-8688-4398-b56b-66dd40935faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-640160a6-f63a-4bc2-9cb7-af8384289770,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fcd6a395-b6e2-4b73-9789-95030125c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-03a3280c-89c6-4d2c-b93a-f74ad5fdfd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-4ddae58e-c884-40e3-8b49-3f345ed406aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-73393cfe-7df3-432f-bcfc-71d68c06ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-2c571233-6a33-4ed5-81ef-90b5f507627d,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-c09fe107-8131-417a-b25c-dccd8aa4a1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849346290-172.17.0.21-1598530274894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-46840434-8688-4398-b56b-66dd40935faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-640160a6-f63a-4bc2-9cb7-af8384289770,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fcd6a395-b6e2-4b73-9789-95030125c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-03a3280c-89c6-4d2c-b93a-f74ad5fdfd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-4ddae58e-c884-40e3-8b49-3f345ed406aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-73393cfe-7df3-432f-bcfc-71d68c06ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-2c571233-6a33-4ed5-81ef-90b5f507627d,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-c09fe107-8131-417a-b25c-dccd8aa4a1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604605770-172.17.0.21-1598530569755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-e2322a05-4d5e-4700-a726-b31850c54403,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-2d6e9caf-5615-43a9-b191-b97a2c87cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-4c69a461-0306-4572-8c99-b0fac526a938,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-4699d3fe-3531-4444-b252-6d319a38b583,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-d7108e02-32f3-4624-a631-4038160db0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-cb1dd9fb-c631-406b-b414-c7d0f5ab3b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-b8129dc5-1015-4cb1-a105-09e4b63de2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-aae56101-f0de-4477-888b-8abfabf473d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604605770-172.17.0.21-1598530569755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-e2322a05-4d5e-4700-a726-b31850c54403,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-2d6e9caf-5615-43a9-b191-b97a2c87cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-4c69a461-0306-4572-8c99-b0fac526a938,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-4699d3fe-3531-4444-b252-6d319a38b583,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-d7108e02-32f3-4624-a631-4038160db0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-cb1dd9fb-c631-406b-b414-c7d0f5ab3b82,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-b8129dc5-1015-4cb1-a105-09e4b63de2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-aae56101-f0de-4477-888b-8abfabf473d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367880599-172.17.0.21-1598530736439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-857592f2-b765-4622-9853-f803c9706a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-02a7772a-4cda-4e17-a304-f98eee3398e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-8cc1180d-c0b8-415b-adcc-072db30a1c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-96831923-0243-4d9a-9668-d0c63ea69750,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-6a729b32-97ec-42c0-b784-04fe7e08330f,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-89bede06-6c32-4699-8248-e0d85dfa7ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-9dd1df95-dae8-4d40-a33f-9064ec6a4412,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-a8688ebb-e008-46b6-a034-6b22065304e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367880599-172.17.0.21-1598530736439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-857592f2-b765-4622-9853-f803c9706a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-02a7772a-4cda-4e17-a304-f98eee3398e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-8cc1180d-c0b8-415b-adcc-072db30a1c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-96831923-0243-4d9a-9668-d0c63ea69750,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-6a729b32-97ec-42c0-b784-04fe7e08330f,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-89bede06-6c32-4699-8248-e0d85dfa7ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-9dd1df95-dae8-4d40-a33f-9064ec6a4412,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-a8688ebb-e008-46b6-a034-6b22065304e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450007273-172.17.0.21-1598530890228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-0a069d8d-5a8f-435e-a132-84ce236b4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-9d2057a9-9092-4d06-b8a1-3843d351b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-9b624c29-49ba-4a4c-a0e8-c172178689a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-5a03b8f1-3002-41d1-8e23-d7bdedc7cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-ad1b4c8f-9f5e-446b-9cab-6304dc408f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-1803992b-ca9e-4076-9653-f845fccebe53,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-ec899455-6355-4079-8edb-a5f89180966b,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-56a8732d-17c9-45d1-a5ed-c0f290f76acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450007273-172.17.0.21-1598530890228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34984,DS-0a069d8d-5a8f-435e-a132-84ce236b4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-9d2057a9-9092-4d06-b8a1-3843d351b96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-9b624c29-49ba-4a4c-a0e8-c172178689a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-5a03b8f1-3002-41d1-8e23-d7bdedc7cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-ad1b4c8f-9f5e-446b-9cab-6304dc408f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-1803992b-ca9e-4076-9653-f845fccebe53,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-ec899455-6355-4079-8edb-a5f89180966b,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-56a8732d-17c9-45d1-a5ed-c0f290f76acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342773395-172.17.0.21-1598531203654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37055,DS-30a451dc-8e02-44ac-ae33-37e92c852371,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-84e08e6c-0ca1-4506-88a9-75811ab388c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-ac7ae313-e4c7-4ca6-aa28-e40a88e479c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-c8dad9cf-f100-48bc-b0a1-21558236a997,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-8ada9fca-7e11-4d60-898e-6006c3381a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e0e382e0-3592-407f-9cef-759b0ed74459,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-bec9c134-4a5b-49ee-8162-b9624c3682b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-a63ba174-dd00-46ef-8b08-8da0cd930c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342773395-172.17.0.21-1598531203654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37055,DS-30a451dc-8e02-44ac-ae33-37e92c852371,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-84e08e6c-0ca1-4506-88a9-75811ab388c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-ac7ae313-e4c7-4ca6-aa28-e40a88e479c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-c8dad9cf-f100-48bc-b0a1-21558236a997,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-8ada9fca-7e11-4d60-898e-6006c3381a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-e0e382e0-3592-407f-9cef-759b0ed74459,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-bec9c134-4a5b-49ee-8162-b9624c3682b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-a63ba174-dd00-46ef-8b08-8da0cd930c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698245261-172.17.0.21-1598531281058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-cd48c515-a58b-4457-9c54-aa9886b5ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-0b9f1c61-09a8-4795-829c-ab53f5d25739,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-68ebb5ed-a7c3-496b-b248-4c79145ce077,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-39c11393-d584-4031-9f38-65b76dd8f913,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-79f8cec7-6678-4e6b-a4f2-4bb9e83e8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-27f3126f-94f2-4d30-998c-727b01345319,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-3cd70638-56d9-468a-8cc0-c5840016ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-b95362c4-dc3d-4ba8-81d2-41fe6a7d11e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698245261-172.17.0.21-1598531281058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-cd48c515-a58b-4457-9c54-aa9886b5ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-0b9f1c61-09a8-4795-829c-ab53f5d25739,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-68ebb5ed-a7c3-496b-b248-4c79145ce077,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-39c11393-d584-4031-9f38-65b76dd8f913,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-79f8cec7-6678-4e6b-a4f2-4bb9e83e8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-27f3126f-94f2-4d30-998c-727b01345319,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-3cd70638-56d9-468a-8cc0-c5840016ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-b95362c4-dc3d-4ba8-81d2-41fe6a7d11e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153297905-172.17.0.21-1598531500971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34709,DS-ce4c248e-c680-4bc8-af00-39eab814a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-fb5b8460-b78d-439b-832a-c08eb5d264f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-386e83da-94e5-49f6-9074-75b5a7d7a404,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-481ec61c-d93e-493e-a547-9c9f59b5dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-4594fd1d-031b-4627-af7d-d1b4f2afd093,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-717b3284-e42f-436a-958f-b3de635110eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-b1bae532-a301-4330-9301-1291abdced69,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0cf0b9c1-047a-4fd6-820d-a387c1fb2ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153297905-172.17.0.21-1598531500971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34709,DS-ce4c248e-c680-4bc8-af00-39eab814a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-fb5b8460-b78d-439b-832a-c08eb5d264f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-386e83da-94e5-49f6-9074-75b5a7d7a404,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-481ec61c-d93e-493e-a547-9c9f59b5dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-4594fd1d-031b-4627-af7d-d1b4f2afd093,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-717b3284-e42f-436a-958f-b3de635110eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-b1bae532-a301-4330-9301-1291abdced69,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0cf0b9c1-047a-4fd6-820d-a387c1fb2ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979345545-172.17.0.21-1598531609181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-2e41657c-9583-4ee3-bd0c-88a53a2be135,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-0c9ea95f-1e27-4d31-a878-62cb47ba13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-ae04e3cc-bdc6-4bc4-9910-20a59d3dc5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-29cc9c42-dd57-4f47-a17b-5d39676006a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-e021057c-d762-4d4d-b98c-b43bbdaf25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-d8b72481-76d7-4383-a39c-c6d1cc462a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-67bf9834-3fb2-4b92-9bb3-559450b52cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-6e97b4c2-adc6-4e17-864e-a63d94c5b67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979345545-172.17.0.21-1598531609181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-2e41657c-9583-4ee3-bd0c-88a53a2be135,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-0c9ea95f-1e27-4d31-a878-62cb47ba13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-ae04e3cc-bdc6-4bc4-9910-20a59d3dc5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-29cc9c42-dd57-4f47-a17b-5d39676006a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-e021057c-d762-4d4d-b98c-b43bbdaf25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-d8b72481-76d7-4383-a39c-c6d1cc462a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-67bf9834-3fb2-4b92-9bb3-559450b52cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-6e97b4c2-adc6-4e17-864e-a63d94c5b67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707966569-172.17.0.21-1598531984649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-add5dcbd-87db-4bf8-87cd-62c318e6cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-d64df203-3ddd-4db5-ab2f-f24bd1a15342,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-748dab01-8fa1-4df0-9c02-3b2bfa46adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-db570582-7daf-4c4c-87da-6f6d09aaea55,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-335f73ad-cdc2-4977-8fb8-c5d1f5f48b81,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-9e5f4fba-0dcc-4bb8-8219-e5c78b2145ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-62d99563-e7b4-440d-8d08-fa4719cac402,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-371b25fa-5d42-484e-96d7-ff78cd6292ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707966569-172.17.0.21-1598531984649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-add5dcbd-87db-4bf8-87cd-62c318e6cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-d64df203-3ddd-4db5-ab2f-f24bd1a15342,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-748dab01-8fa1-4df0-9c02-3b2bfa46adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-db570582-7daf-4c4c-87da-6f6d09aaea55,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-335f73ad-cdc2-4977-8fb8-c5d1f5f48b81,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-9e5f4fba-0dcc-4bb8-8219-e5c78b2145ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-62d99563-e7b4-440d-8d08-fa4719cac402,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-371b25fa-5d42-484e-96d7-ff78cd6292ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56071892-172.17.0.21-1598532125170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-39f293b9-006b-4270-8902-576862e6b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6d885a07-624e-44e2-966c-158272487e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-239b705f-71cf-410f-8984-a4c8b53774d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-f933b5f2-e178-4d6e-8206-f3c275521e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-0ce40733-276a-419e-8b21-d678557c6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-4c321777-7ce4-4b31-9524-4d2affd9f266,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f9899be6-7257-445c-99c7-8eed625e8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-18a69c8c-4abf-48c1-bc02-ae70f7edc74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56071892-172.17.0.21-1598532125170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-39f293b9-006b-4270-8902-576862e6b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6d885a07-624e-44e2-966c-158272487e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-239b705f-71cf-410f-8984-a4c8b53774d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-f933b5f2-e178-4d6e-8206-f3c275521e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-0ce40733-276a-419e-8b21-d678557c6db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-4c321777-7ce4-4b31-9524-4d2affd9f266,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f9899be6-7257-445c-99c7-8eed625e8b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-18a69c8c-4abf-48c1-bc02-ae70f7edc74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930528225-172.17.0.21-1598532237653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-97f32c90-14f7-4554-b918-9724643a795c,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9263ed7a-7db4-4161-9655-e5ad4d1a4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-792c298e-d937-4bf6-bee4-28f9c659f932,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-d8b8b327-6ddb-47e9-9352-0839e3c116c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-ba211f99-5017-44bc-9fe5-1f1e5a29e255,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-034c129b-2cb1-47fd-a4e9-a007594b53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-a21e58db-91ba-4840-ba50-a2c500d141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-4350e96a-1257-4a8b-b13d-cfcd96587fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930528225-172.17.0.21-1598532237653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44729,DS-97f32c90-14f7-4554-b918-9724643a795c,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9263ed7a-7db4-4161-9655-e5ad4d1a4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-792c298e-d937-4bf6-bee4-28f9c659f932,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-d8b8b327-6ddb-47e9-9352-0839e3c116c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-ba211f99-5017-44bc-9fe5-1f1e5a29e255,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-034c129b-2cb1-47fd-a4e9-a007594b53f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-a21e58db-91ba-4840-ba50-a2c500d141a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-4350e96a-1257-4a8b-b13d-cfcd96587fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5736
