reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422570414-172.17.0.20-1598585124926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-185b6e71-84bb-4ded-abe0-95cb548578a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-4f147572-a01b-448c-8136-9bb2ea633f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-8ca20093-3eda-483d-89c6-9f6c17bfa520,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-b3527507-b404-431b-88b1-5dda82dde710,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-0f11eb10-c418-4624-94ee-072c3e9b1354,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-46080f71-1365-4687-b429-fa1e2a5901e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3e43a2ea-5205-4907-a896-ede402fa981c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-137d6226-1f18-4253-8877-1eaab515cd63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422570414-172.17.0.20-1598585124926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-185b6e71-84bb-4ded-abe0-95cb548578a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-4f147572-a01b-448c-8136-9bb2ea633f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-8ca20093-3eda-483d-89c6-9f6c17bfa520,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-b3527507-b404-431b-88b1-5dda82dde710,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-0f11eb10-c418-4624-94ee-072c3e9b1354,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-46080f71-1365-4687-b429-fa1e2a5901e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3e43a2ea-5205-4907-a896-ede402fa981c,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-137d6226-1f18-4253-8877-1eaab515cd63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404024761-172.17.0.20-1598585229222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44699,DS-77c2dcc7-cf66-4153-9cab-8f96592d6185,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-f544bc33-686f-4ebe-878f-8098733a1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-1deb5cc4-4fb2-4bab-b0b7-57f6b7bd2736,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-cd234d25-7d1c-437e-83f5-7d94afb15d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-f83ca6b9-75b0-4cab-879f-916412f83a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-a1cd5012-f653-4979-ae27-eaba0661cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-35e43ed2-7039-49f1-ab58-d13c4040b870,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-add50be0-324b-4c3e-b47c-c1e1058f459f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404024761-172.17.0.20-1598585229222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44699,DS-77c2dcc7-cf66-4153-9cab-8f96592d6185,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-f544bc33-686f-4ebe-878f-8098733a1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-1deb5cc4-4fb2-4bab-b0b7-57f6b7bd2736,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-cd234d25-7d1c-437e-83f5-7d94afb15d57,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-f83ca6b9-75b0-4cab-879f-916412f83a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-a1cd5012-f653-4979-ae27-eaba0661cfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-35e43ed2-7039-49f1-ab58-d13c4040b870,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-add50be0-324b-4c3e-b47c-c1e1058f459f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418045968-172.17.0.20-1598585516866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-e103dbf1-a800-4c82-b089-d76769381a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-f6927d68-3cb1-438c-837c-11a8ff1b7450,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-608ec7aa-b45c-416f-a375-3ad4a66f8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-1304ea75-e34e-4d92-ab95-5e6cffc220ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-cf87fab7-0a0b-458e-9c6b-e956c86e8702,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-2f6ce88a-d45e-4415-bee9-f2c1301ca1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-3dcf4021-2cbc-456f-ae24-d5229623da60,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-eb5da9dc-580d-42cb-b1ba-b23b499ba478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418045968-172.17.0.20-1598585516866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46736,DS-e103dbf1-a800-4c82-b089-d76769381a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-f6927d68-3cb1-438c-837c-11a8ff1b7450,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-608ec7aa-b45c-416f-a375-3ad4a66f8d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-1304ea75-e34e-4d92-ab95-5e6cffc220ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-cf87fab7-0a0b-458e-9c6b-e956c86e8702,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-2f6ce88a-d45e-4415-bee9-f2c1301ca1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-3dcf4021-2cbc-456f-ae24-d5229623da60,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-eb5da9dc-580d-42cb-b1ba-b23b499ba478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229502095-172.17.0.20-1598585747761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-e027c5d3-c310-4932-b5c2-b139b3577abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-a259f3e1-c763-4a9d-a91d-eff76ba864fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-e0925ba6-22ee-4e6d-a209-764f0b09a229,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-13013ac0-be5f-477a-b194-85c1f7b64cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-3ce642c3-283e-4b6a-aa17-64d7f2fba54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-a5bff10c-c01c-4b1a-9975-ac127c4b7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-8924e339-8f21-4031-9237-4b0a6690beee,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-1bfa0f53-8780-4c17-beb3-a077be781a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229502095-172.17.0.20-1598585747761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-e027c5d3-c310-4932-b5c2-b139b3577abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-a259f3e1-c763-4a9d-a91d-eff76ba864fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-e0925ba6-22ee-4e6d-a209-764f0b09a229,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-13013ac0-be5f-477a-b194-85c1f7b64cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-3ce642c3-283e-4b6a-aa17-64d7f2fba54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-a5bff10c-c01c-4b1a-9975-ac127c4b7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-8924e339-8f21-4031-9237-4b0a6690beee,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-1bfa0f53-8780-4c17-beb3-a077be781a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064837496-172.17.0.20-1598585879876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-8cacfaa7-0266-4e0d-ab4f-3dd8145bed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-701301a4-167b-41d4-80dd-b7151a79616a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-db317b0d-9330-41b1-9ade-0754073b3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-77b441ac-80ee-4017-b190-b89241eafb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ec76a062-cbc6-43e8-b765-1dee532162f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-6196c403-38fe-4d01-a8d8-2d2ee7cf401c,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-f500c128-632e-43cb-a8ff-fa72f1aebc96,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-4607ad83-f6a7-448d-b0b0-a063bd38e0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064837496-172.17.0.20-1598585879876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-8cacfaa7-0266-4e0d-ab4f-3dd8145bed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-701301a4-167b-41d4-80dd-b7151a79616a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-db317b0d-9330-41b1-9ade-0754073b3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-77b441ac-80ee-4017-b190-b89241eafb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-ec76a062-cbc6-43e8-b765-1dee532162f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-6196c403-38fe-4d01-a8d8-2d2ee7cf401c,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-f500c128-632e-43cb-a8ff-fa72f1aebc96,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-4607ad83-f6a7-448d-b0b0-a063bd38e0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893540889-172.17.0.20-1598585916631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-cdb7bef1-8182-49ad-8bdc-857a89c3f38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-03d82ae5-0099-48cc-8f58-8b1dffc262c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-0a32972a-eaf8-430f-8b2e-8248c23cfb57,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-85a36154-97dc-4e33-bd5c-df3924b2fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-0c8dce49-e920-42bb-976b-91f088f73ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b1f81e9b-7163-4105-b0e5-ace996eb424a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-7cac43c4-11bf-43a4-9edf-d43b55bd329d,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-1d439ead-c56e-4806-8bda-d6c78985469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893540889-172.17.0.20-1598585916631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40855,DS-cdb7bef1-8182-49ad-8bdc-857a89c3f38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-03d82ae5-0099-48cc-8f58-8b1dffc262c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-0a32972a-eaf8-430f-8b2e-8248c23cfb57,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-85a36154-97dc-4e33-bd5c-df3924b2fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-0c8dce49-e920-42bb-976b-91f088f73ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b1f81e9b-7163-4105-b0e5-ace996eb424a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-7cac43c4-11bf-43a4-9edf-d43b55bd329d,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-1d439ead-c56e-4806-8bda-d6c78985469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316263260-172.17.0.20-1598586075647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-7615d056-b709-4b23-b7ba-ee417db425b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-1c000cc6-aaf1-4493-b45e-c8dd0827e746,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-521f9efc-53ba-42b2-9635-014a228d4d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-f1eb762f-78c4-43e6-8b01-69bf6208592e,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-c0614816-123e-4001-b9c5-cf93de014e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d4691fef-f8cb-4207-975a-a657b00730e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-195d23ac-e3ca-4754-94a9-7d04d469e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-03c6838c-27b8-448c-b625-5b227981e649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316263260-172.17.0.20-1598586075647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39472,DS-7615d056-b709-4b23-b7ba-ee417db425b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-1c000cc6-aaf1-4493-b45e-c8dd0827e746,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-521f9efc-53ba-42b2-9635-014a228d4d48,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-f1eb762f-78c4-43e6-8b01-69bf6208592e,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-c0614816-123e-4001-b9c5-cf93de014e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d4691fef-f8cb-4207-975a-a657b00730e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-195d23ac-e3ca-4754-94a9-7d04d469e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-03c6838c-27b8-448c-b625-5b227981e649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835143306-172.17.0.20-1598586637314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-3686a12e-a1e3-4c9c-9693-b278a14621cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-ad62fe7e-0670-4a25-bafb-1954bd006536,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-a0f37540-795e-47b9-bd7f-70e6d96610aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-042278a1-4cd6-4ce4-b370-5eda8dfcb943,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-815ce907-c563-4720-b13a-8f4c113e9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-cda9ece5-eb23-40d9-9b4b-7bd860a3c665,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-09368a33-e04c-413c-9c06-119d1ac29a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-98794c72-b338-418c-ae9d-e27b5fc0f70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835143306-172.17.0.20-1598586637314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-3686a12e-a1e3-4c9c-9693-b278a14621cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-ad62fe7e-0670-4a25-bafb-1954bd006536,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-a0f37540-795e-47b9-bd7f-70e6d96610aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-042278a1-4cd6-4ce4-b370-5eda8dfcb943,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-815ce907-c563-4720-b13a-8f4c113e9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-cda9ece5-eb23-40d9-9b4b-7bd860a3c665,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-09368a33-e04c-413c-9c06-119d1ac29a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-98794c72-b338-418c-ae9d-e27b5fc0f70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948919096-172.17.0.20-1598586887385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-c3383494-135a-4621-b270-c6dfe7714b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-cf6abf87-4b85-45cc-b4ac-088a0c12c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-079aec55-00fc-4890-8807-b9d65d6dfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b525bb3d-eb6d-4878-8b62-d600ddf950ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-570843bd-f1aa-457c-bf48-3d6f0fb1d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-1ed2cfdf-54fe-483c-bf77-7a08196616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-23457780-3408-443e-a1e9-0b6e4850a8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-e737c3a1-1c5f-4c8c-80b0-be445855fccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948919096-172.17.0.20-1598586887385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-c3383494-135a-4621-b270-c6dfe7714b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-cf6abf87-4b85-45cc-b4ac-088a0c12c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-079aec55-00fc-4890-8807-b9d65d6dfe41,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-b525bb3d-eb6d-4878-8b62-d600ddf950ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-570843bd-f1aa-457c-bf48-3d6f0fb1d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-1ed2cfdf-54fe-483c-bf77-7a08196616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-23457780-3408-443e-a1e9-0b6e4850a8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-e737c3a1-1c5f-4c8c-80b0-be445855fccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988752984-172.17.0.20-1598587172259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36403,DS-2e2b7dbc-1144-4530-80b3-20dee2f0ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-5f81a4e4-ffaa-418a-9d03-d13ebacbb500,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-fe3eb84b-c1c9-4724-9f2f-b539eab7e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-3a0079f2-f88e-476e-b8df-c5043bcc2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-3da479e6-1273-4410-8883-6777ed2c08fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0f5c032b-d769-4086-91c1-dac8da4e27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-af9d79b7-34fc-4d9d-9369-a4da9cfd5cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-2d752797-be62-447d-94e5-fc8621dbd899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988752984-172.17.0.20-1598587172259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36403,DS-2e2b7dbc-1144-4530-80b3-20dee2f0ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-5f81a4e4-ffaa-418a-9d03-d13ebacbb500,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-fe3eb84b-c1c9-4724-9f2f-b539eab7e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-3a0079f2-f88e-476e-b8df-c5043bcc2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-3da479e6-1273-4410-8883-6777ed2c08fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0f5c032b-d769-4086-91c1-dac8da4e27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-af9d79b7-34fc-4d9d-9369-a4da9cfd5cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-2d752797-be62-447d-94e5-fc8621dbd899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737049547-172.17.0.20-1598587313332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-9ed7d2eb-b331-45cb-89b1-ba4db0067c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-97715861-95f1-4ecc-9493-a66b26b87215,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-2adc407a-eb6f-40f1-acbe-4f44fb7c24ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-a80e7f08-ad63-45c9-825f-73b0b1edc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-6f9af329-a505-4d4b-a2f1-1c215b9d2c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-27e24141-b69c-4111-b558-f5196da4171b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-44a90644-b5b1-468a-9282-db41135eb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-1f289839-9565-466c-8598-41a83db0c3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737049547-172.17.0.20-1598587313332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-9ed7d2eb-b331-45cb-89b1-ba4db0067c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-97715861-95f1-4ecc-9493-a66b26b87215,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-2adc407a-eb6f-40f1-acbe-4f44fb7c24ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-a80e7f08-ad63-45c9-825f-73b0b1edc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-6f9af329-a505-4d4b-a2f1-1c215b9d2c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-27e24141-b69c-4111-b558-f5196da4171b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-44a90644-b5b1-468a-9282-db41135eb6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-1f289839-9565-466c-8598-41a83db0c3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155487007-172.17.0.20-1598588073515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-fbdc4db0-1908-4bee-ba26-ad833b388ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-83e00e08-4d6f-461b-9c8d-59eb66f20a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-7a475b68-c558-42b0-bdba-1ffe449b6f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-3dd03704-2c53-4229-bf89-b33ecd8b400f,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-1ee9bcf7-c498-448b-b12d-2c42236fc58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a812e8c0-b60d-4742-8b91-b51900ac9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3d2d5b5f-5a34-4e4d-a487-6395f9784797,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bf272908-6a2e-4f53-9e2e-3993d024742b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155487007-172.17.0.20-1598588073515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-fbdc4db0-1908-4bee-ba26-ad833b388ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-83e00e08-4d6f-461b-9c8d-59eb66f20a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-7a475b68-c558-42b0-bdba-1ffe449b6f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-3dd03704-2c53-4229-bf89-b33ecd8b400f,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-1ee9bcf7-c498-448b-b12d-2c42236fc58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a812e8c0-b60d-4742-8b91-b51900ac9e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-3d2d5b5f-5a34-4e4d-a487-6395f9784797,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bf272908-6a2e-4f53-9e2e-3993d024742b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049982314-172.17.0.20-1598588112823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-089be051-08f3-48a9-97d0-1e939064f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-4b9faa14-312d-4612-9fad-26cb4730ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-22e10b31-f24a-4d1f-8578-f07c289bdb50,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-5952fd3b-b221-4bdf-91b0-3cabab73feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-19123b3a-90a4-4534-a4af-8259b0b67be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-4ca492bc-07f6-4f6c-bed2-8889fdb2819d,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-7d5379e5-a15a-4ec8-a58c-b5aac976f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-7b8ba063-716f-4b80-8b0f-353db5c0595d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049982314-172.17.0.20-1598588112823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-089be051-08f3-48a9-97d0-1e939064f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-4b9faa14-312d-4612-9fad-26cb4730ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-22e10b31-f24a-4d1f-8578-f07c289bdb50,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-5952fd3b-b221-4bdf-91b0-3cabab73feb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-19123b3a-90a4-4534-a4af-8259b0b67be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-4ca492bc-07f6-4f6c-bed2-8889fdb2819d,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-7d5379e5-a15a-4ec8-a58c-b5aac976f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-7b8ba063-716f-4b80-8b0f-353db5c0595d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851855098-172.17.0.20-1598588138998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-b5253429-3317-4d3b-a980-355ebe2b5932,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-ee7e1dca-3a42-4464-9c57-0115e19be277,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-7a4fb10e-dd76-41f1-a695-5aeab49b4235,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-fb61e6a1-fba2-4550-b974-fa279be62c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-7b751c63-521d-438f-a6f4-81764cd03558,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-0761a9f1-077f-4953-89ff-1879eba5b667,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-36fe88e5-5f4e-4806-985f-0b89a19556ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-30013461-2a54-4f06-9376-cab42ab1ac4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851855098-172.17.0.20-1598588138998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-b5253429-3317-4d3b-a980-355ebe2b5932,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-ee7e1dca-3a42-4464-9c57-0115e19be277,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-7a4fb10e-dd76-41f1-a695-5aeab49b4235,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-fb61e6a1-fba2-4550-b974-fa279be62c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-7b751c63-521d-438f-a6f4-81764cd03558,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-0761a9f1-077f-4953-89ff-1879eba5b667,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-36fe88e5-5f4e-4806-985f-0b89a19556ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-30013461-2a54-4f06-9376-cab42ab1ac4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199942016-172.17.0.20-1598588484016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-2d4ac911-4022-46bf-826b-30e8549dbfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-e7549bab-c542-483f-9211-f12ef6036379,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-7ab84b2b-99d1-4d44-96cb-dc5de71c9fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-9a9a45a1-474d-45b1-94bf-3ebd234426b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-aff12e9f-ac5b-4e2f-8e25-6b2595e08ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-2472c3f2-7eeb-4117-90e2-85a2eeeb039d,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-709aa78c-4e0a-44a9-ae5a-b3a0392e6880,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-55ea42b2-0d41-42a0-b438-7b33968f4c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199942016-172.17.0.20-1598588484016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-2d4ac911-4022-46bf-826b-30e8549dbfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-e7549bab-c542-483f-9211-f12ef6036379,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-7ab84b2b-99d1-4d44-96cb-dc5de71c9fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-9a9a45a1-474d-45b1-94bf-3ebd234426b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-aff12e9f-ac5b-4e2f-8e25-6b2595e08ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-2472c3f2-7eeb-4117-90e2-85a2eeeb039d,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-709aa78c-4e0a-44a9-ae5a-b3a0392e6880,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-55ea42b2-0d41-42a0-b438-7b33968f4c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098976108-172.17.0.20-1598589128830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-1d9ed0bd-03af-4336-b018-99916f31eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e37bff81-cd04-4d08-a21e-354596e5d567,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-78716d10-7429-4bca-9fa4-77190e62b484,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-22eb15e1-b0c4-4742-953e-e09d413dc935,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-44835b98-8f82-4ca5-9fe9-b627bc4a39b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-0a4fc0a3-0a49-4a66-8dd7-4956a7e8b606,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-17244569-8864-48a6-9c82-f5aa54062064,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-2e79ed7f-01a1-4fff-8f6b-39a75dbbf0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098976108-172.17.0.20-1598589128830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-1d9ed0bd-03af-4336-b018-99916f31eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e37bff81-cd04-4d08-a21e-354596e5d567,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-78716d10-7429-4bca-9fa4-77190e62b484,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-22eb15e1-b0c4-4742-953e-e09d413dc935,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-44835b98-8f82-4ca5-9fe9-b627bc4a39b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-0a4fc0a3-0a49-4a66-8dd7-4956a7e8b606,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-17244569-8864-48a6-9c82-f5aa54062064,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-2e79ed7f-01a1-4fff-8f6b-39a75dbbf0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141447780-172.17.0.20-1598589301690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43029,DS-15b0c2d0-62c3-4318-a302-8fac7502007f,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-a76b53e1-3987-47e6-b379-04dbce4e5a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-cd91278d-4c62-438c-a0bd-9cf14c8fe6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-d4ab0ec5-1f0b-4bbe-8875-92cb5003f0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-92a3dc5f-3a31-4780-a690-cf968acb5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-c8b9d7d6-2685-47ce-bb89-5ef68e56f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-c805bcdc-678e-4699-8395-93e6b972aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-936f261c-f727-40fa-afec-ad1971346d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141447780-172.17.0.20-1598589301690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43029,DS-15b0c2d0-62c3-4318-a302-8fac7502007f,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-a76b53e1-3987-47e6-b379-04dbce4e5a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-cd91278d-4c62-438c-a0bd-9cf14c8fe6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-d4ab0ec5-1f0b-4bbe-8875-92cb5003f0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-92a3dc5f-3a31-4780-a690-cf968acb5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-c8b9d7d6-2685-47ce-bb89-5ef68e56f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-c805bcdc-678e-4699-8395-93e6b972aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-936f261c-f727-40fa-afec-ad1971346d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554739045-172.17.0.20-1598589713097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-daf654e1-b28a-4b09-9f27-60ceb7cbb8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-4472908e-2c33-47a5-bde9-4ed8f0958e47,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-b57cd5fa-68d3-4e1c-a80a-6c06864b6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-8097a0ab-2378-4b6b-a41d-3712b7e15746,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-168fe060-4fbd-4f6f-915c-b96ba22ac450,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-f272d121-4f69-4229-99ac-e1585a16581a,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-2fa686fb-e705-465c-a67b-fdcf6fb244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d908b54f-21a0-4e6e-a58d-4593e163027a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554739045-172.17.0.20-1598589713097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-daf654e1-b28a-4b09-9f27-60ceb7cbb8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-4472908e-2c33-47a5-bde9-4ed8f0958e47,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-b57cd5fa-68d3-4e1c-a80a-6c06864b6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-8097a0ab-2378-4b6b-a41d-3712b7e15746,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-168fe060-4fbd-4f6f-915c-b96ba22ac450,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-f272d121-4f69-4229-99ac-e1585a16581a,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-2fa686fb-e705-465c-a67b-fdcf6fb244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-d908b54f-21a0-4e6e-a58d-4593e163027a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701370664-172.17.0.20-1598589973255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40305,DS-e6efd713-3588-4d54-aee4-565af987bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-a5e46f48-eec9-41eb-bc05-f56923df3154,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-8e01881a-08e3-409b-abf1-2ef58f00feef,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-65d3717b-6df6-4332-821b-bb519b1e8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-4397900f-0343-4d16-9ae6-b272aae72f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0e8bb6f8-58c3-4ba6-9c70-487bbd3623c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-d05d8ba9-c925-480b-a0f4-e78dce332bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-1f0e922a-9279-4663-85a8-971811982c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701370664-172.17.0.20-1598589973255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40305,DS-e6efd713-3588-4d54-aee4-565af987bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-a5e46f48-eec9-41eb-bc05-f56923df3154,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-8e01881a-08e3-409b-abf1-2ef58f00feef,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-65d3717b-6df6-4332-821b-bb519b1e8edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-4397900f-0343-4d16-9ae6-b272aae72f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0e8bb6f8-58c3-4ba6-9c70-487bbd3623c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-d05d8ba9-c925-480b-a0f4-e78dce332bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-1f0e922a-9279-4663-85a8-971811982c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 512
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199124887-172.17.0.20-1598590056289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-9b73d5aa-ec2d-4f71-a772-8b1904f3348a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4080f86c-8d14-4980-9fc5-de14f23ee1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-20f418f5-9255-46ee-b073-e0f411eeb3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0d9e2c2a-af20-4042-9b0e-6f3961a5d218,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-206bd03b-d04d-40b4-8189-e8ee5c42971c,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-d1e64246-87a6-4348-aebf-4c1cd52bdc02,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-9301cdc8-898a-4a31-8dfd-d70d47e41351,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-c0668090-3a9b-497b-9006-9ccf89c38c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199124887-172.17.0.20-1598590056289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-9b73d5aa-ec2d-4f71-a772-8b1904f3348a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4080f86c-8d14-4980-9fc5-de14f23ee1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-20f418f5-9255-46ee-b073-e0f411eeb3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0d9e2c2a-af20-4042-9b0e-6f3961a5d218,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-206bd03b-d04d-40b4-8189-e8ee5c42971c,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-d1e64246-87a6-4348-aebf-4c1cd52bdc02,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-9301cdc8-898a-4a31-8dfd-d70d47e41351,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-c0668090-3a9b-497b-9006-9ccf89c38c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5239
