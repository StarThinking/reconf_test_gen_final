reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240594398-172.17.0.13-1598562381258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-f8b7bc40-fb62-4fff-964f-9689d33afbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-e0e4a40c-e5eb-4e68-981b-2239f9caa848,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b3aa7756-5a68-474a-bfdb-c805611602c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-fdc3f36b-8dc8-4e72-9e38-6165593c18eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-88c87757-ffb0-4666-90e7-d8580fc3a922,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-5d44115f-a44e-431a-885e-4187157a27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-212b723e-ef09-473f-83b5-5b9cb352bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-a7fb73a4-5b7b-4300-aa32-a77a6fe4215f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240594398-172.17.0.13-1598562381258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-f8b7bc40-fb62-4fff-964f-9689d33afbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-e0e4a40c-e5eb-4e68-981b-2239f9caa848,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b3aa7756-5a68-474a-bfdb-c805611602c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-fdc3f36b-8dc8-4e72-9e38-6165593c18eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-88c87757-ffb0-4666-90e7-d8580fc3a922,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-5d44115f-a44e-431a-885e-4187157a27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-212b723e-ef09-473f-83b5-5b9cb352bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-a7fb73a4-5b7b-4300-aa32-a77a6fe4215f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124568231-172.17.0.13-1598562567459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-15b9dcd4-ca17-4936-9024-2a73d3227b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-e39567d0-115f-4a90-9e7c-6fbc45ab805c,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-d33c6d9c-5084-459c-b572-d51b0afac6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-9e118579-d2bd-44e9-87bc-7a0f08a9657a,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-d0c90a21-1fd7-4f73-88f8-6e49139c52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-d21c1738-0551-4e2f-ba6e-29dcd059313e,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-40499edd-d9a5-4180-a96b-71dd62184873,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-31122ed3-2201-41ea-8767-5218a1cbcb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124568231-172.17.0.13-1598562567459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-15b9dcd4-ca17-4936-9024-2a73d3227b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-e39567d0-115f-4a90-9e7c-6fbc45ab805c,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-d33c6d9c-5084-459c-b572-d51b0afac6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-9e118579-d2bd-44e9-87bc-7a0f08a9657a,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-d0c90a21-1fd7-4f73-88f8-6e49139c52ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-d21c1738-0551-4e2f-ba6e-29dcd059313e,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-40499edd-d9a5-4180-a96b-71dd62184873,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-31122ed3-2201-41ea-8767-5218a1cbcb21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014193173-172.17.0.13-1598562715411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-9318111f-be71-49c8-86ff-f9b04c9afb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b05e46a3-f435-4ad1-bc93-1fb6b5c9b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-16f93927-f4b3-4b97-b165-c8abd6908149,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-eb014c44-93c0-4ef8-8e42-11646a9ae688,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-b875e309-f1d5-44e3-b670-5596b29a3b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1f55c568-9789-4af3-8434-d3196f6467b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-f875397c-e4e1-4122-bd1a-211d7e75b496,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-061e2370-80dc-4965-8642-e532e75b626f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014193173-172.17.0.13-1598562715411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-9318111f-be71-49c8-86ff-f9b04c9afb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-b05e46a3-f435-4ad1-bc93-1fb6b5c9b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-16f93927-f4b3-4b97-b165-c8abd6908149,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-eb014c44-93c0-4ef8-8e42-11646a9ae688,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-b875e309-f1d5-44e3-b670-5596b29a3b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1f55c568-9789-4af3-8434-d3196f6467b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-f875397c-e4e1-4122-bd1a-211d7e75b496,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-061e2370-80dc-4965-8642-e532e75b626f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249108892-172.17.0.13-1598562754688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-4850117a-250a-4bf7-b886-08c6bf943e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-a2b74b25-8ff4-4d51-a946-06c82684053a,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2460f543-9a01-4e65-8d7f-8d9259a6f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-e575b24f-3f23-4a52-b11d-e83a9bcf55e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-2039fa6c-8949-4ab7-8346-97abec508a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-c5285118-0ae8-45dc-a8fb-b23642bfb739,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-b269a5a7-d932-4bc1-a746-38fc6df56a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-86635729-6289-4dd4-a25d-5b086bf760fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249108892-172.17.0.13-1598562754688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-4850117a-250a-4bf7-b886-08c6bf943e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-a2b74b25-8ff4-4d51-a946-06c82684053a,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-2460f543-9a01-4e65-8d7f-8d9259a6f07d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-e575b24f-3f23-4a52-b11d-e83a9bcf55e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-2039fa6c-8949-4ab7-8346-97abec508a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-c5285118-0ae8-45dc-a8fb-b23642bfb739,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-b269a5a7-d932-4bc1-a746-38fc6df56a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-86635729-6289-4dd4-a25d-5b086bf760fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674155120-172.17.0.13-1598563237145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-a99962c4-8166-4c8b-9c29-c28d442d94df,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-e563a1b8-f3db-4c86-a7ba-20516be4840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-7901940b-e90c-4cca-a4ca-9065b12fe267,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-2baef5f7-5ca6-49a8-bc82-bbf817006b52,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-e1fd90a0-65b9-4c07-ad23-95d921522c14,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5dd31101-f7a1-4e32-b3e8-6a887cd76a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2cc78477-cee8-4196-be8d-52be49e78637,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b6c5182b-59f9-46a8-aeae-8b46d559036f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674155120-172.17.0.13-1598563237145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-a99962c4-8166-4c8b-9c29-c28d442d94df,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-e563a1b8-f3db-4c86-a7ba-20516be4840e,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-7901940b-e90c-4cca-a4ca-9065b12fe267,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-2baef5f7-5ca6-49a8-bc82-bbf817006b52,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-e1fd90a0-65b9-4c07-ad23-95d921522c14,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5dd31101-f7a1-4e32-b3e8-6a887cd76a88,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2cc78477-cee8-4196-be8d-52be49e78637,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-b6c5182b-59f9-46a8-aeae-8b46d559036f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15455550-172.17.0.13-1598563313890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-54daccb5-568d-4c89-9ae1-0c0749c4339b,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-f5979d95-64db-4b97-8587-e259e57d4805,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ab0a2f7c-3d3a-43f8-b9f0-684d4b1ccd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a104a507-50da-455f-894c-97ea0ad38390,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-87c21ccb-03e7-4327-a593-d61c67e2a890,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-638d2980-aa42-4497-9c1b-d2f36ce17865,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-974c7abe-a93b-4dc9-a502-c97e1d70c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-b541097a-fc23-4e29-a3de-03977b0d9852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15455550-172.17.0.13-1598563313890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-54daccb5-568d-4c89-9ae1-0c0749c4339b,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-f5979d95-64db-4b97-8587-e259e57d4805,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ab0a2f7c-3d3a-43f8-b9f0-684d4b1ccd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a104a507-50da-455f-894c-97ea0ad38390,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-87c21ccb-03e7-4327-a593-d61c67e2a890,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-638d2980-aa42-4497-9c1b-d2f36ce17865,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-974c7abe-a93b-4dc9-a502-c97e1d70c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-b541097a-fc23-4e29-a3de-03977b0d9852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453703521-172.17.0.13-1598564014495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-ee6d2358-e603-480a-aa65-d2e48032e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-717ade7a-cd6b-4425-931b-19d2c1810210,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-e120273d-8208-4bf1-9a2a-3eba88571af6,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-b0f52023-e4db-41c3-98c1-034f575a9de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-73a32d4b-02d2-458b-a946-dec9f299c898,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-e9217678-cdad-49e4-8745-e752eca8ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-7677145b-0a90-4918-a9a6-f187c1cd999f,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-56395806-d706-46e3-9707-53c1e9591110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453703521-172.17.0.13-1598564014495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-ee6d2358-e603-480a-aa65-d2e48032e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-717ade7a-cd6b-4425-931b-19d2c1810210,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-e120273d-8208-4bf1-9a2a-3eba88571af6,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-b0f52023-e4db-41c3-98c1-034f575a9de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-73a32d4b-02d2-458b-a946-dec9f299c898,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-e9217678-cdad-49e4-8745-e752eca8ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-7677145b-0a90-4918-a9a6-f187c1cd999f,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-56395806-d706-46e3-9707-53c1e9591110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089843524-172.17.0.13-1598564406949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-1a41d4ae-490c-4c52-ab56-ac9869994f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-2b64800d-483c-4d69-be80-6e6e8d27ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-7ea68264-cf8a-4dfc-ad0a-b2948fefeb36,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-9022502a-1a8b-49dc-8361-53d5edb77f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-f5886089-fdeb-49ae-84c5-6b7b5e996f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-22bab30b-0ac2-46a5-93be-1c191c0fe6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-3704bc71-b54e-4e03-9d80-7f19fb9ef8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-7709ee77-7311-45cc-9542-19ce4ec64237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089843524-172.17.0.13-1598564406949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-1a41d4ae-490c-4c52-ab56-ac9869994f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-2b64800d-483c-4d69-be80-6e6e8d27ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-7ea68264-cf8a-4dfc-ad0a-b2948fefeb36,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-9022502a-1a8b-49dc-8361-53d5edb77f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-f5886089-fdeb-49ae-84c5-6b7b5e996f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-22bab30b-0ac2-46a5-93be-1c191c0fe6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-3704bc71-b54e-4e03-9d80-7f19fb9ef8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-7709ee77-7311-45cc-9542-19ce4ec64237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456831452-172.17.0.13-1598564702458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-174100fe-a1db-42b5-bdec-8fa8ea6ec842,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-ad65871f-b2bf-4d32-b037-ea2d72bf542a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-b4ca536f-74ed-49a3-98fb-1f85e3d008a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-5783a2ad-6aae-47f3-a618-a9891576a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-06205eaf-1239-4aa6-83cc-b6a508b3d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-99549b1a-b572-4d2d-943b-930b8cb3e174,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-8e2ec0e4-d889-462f-8593-348177bb77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9574367e-f3b7-474e-8fb2-cc804220310a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456831452-172.17.0.13-1598564702458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-174100fe-a1db-42b5-bdec-8fa8ea6ec842,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-ad65871f-b2bf-4d32-b037-ea2d72bf542a,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-b4ca536f-74ed-49a3-98fb-1f85e3d008a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-5783a2ad-6aae-47f3-a618-a9891576a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-06205eaf-1239-4aa6-83cc-b6a508b3d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-99549b1a-b572-4d2d-943b-930b8cb3e174,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-8e2ec0e4-d889-462f-8593-348177bb77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-9574367e-f3b7-474e-8fb2-cc804220310a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744664836-172.17.0.13-1598565307497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-60c77b81-c63a-4c40-ba01-5e41e0266698,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-aea2ba36-a54f-4ffd-bdbe-56303c474ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-dd78e662-c51b-4506-9530-afd13b6c76e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-970a9fd7-a07b-45ca-945c-90b95cd9fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-b9060a87-df41-4ae7-bcb7-31c1d10aaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-d56244bd-5c95-43da-80f3-329d66d89f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-bb31c4c6-07b6-406f-ae6b-a4e105b75a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-6f0006a7-c907-4561-89d0-7933f8faba0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744664836-172.17.0.13-1598565307497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39412,DS-60c77b81-c63a-4c40-ba01-5e41e0266698,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-aea2ba36-a54f-4ffd-bdbe-56303c474ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-dd78e662-c51b-4506-9530-afd13b6c76e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-970a9fd7-a07b-45ca-945c-90b95cd9fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-b9060a87-df41-4ae7-bcb7-31c1d10aaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-d56244bd-5c95-43da-80f3-329d66d89f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-bb31c4c6-07b6-406f-ae6b-a4e105b75a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-6f0006a7-c907-4561-89d0-7933f8faba0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884091154-172.17.0.13-1598565344800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35101,DS-216a48ab-3805-45a5-887d-22913d026a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-9c6e2e50-be03-4409-9b2f-0b783d60b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-6d65bcd3-591b-4aaa-9555-081b6315c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-b9f87bb7-92a0-4c04-af95-78993d62f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-faa6a17b-467d-47e9-8d51-70f90402d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-d02c87dd-2088-46bb-b3a5-d0f0fde33f22,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-434d4d05-00a1-480e-9a0b-dc116985a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-34e36b35-0778-446b-a424-736001ee8990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884091154-172.17.0.13-1598565344800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35101,DS-216a48ab-3805-45a5-887d-22913d026a33,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-9c6e2e50-be03-4409-9b2f-0b783d60b19d,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-6d65bcd3-591b-4aaa-9555-081b6315c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-b9f87bb7-92a0-4c04-af95-78993d62f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-faa6a17b-467d-47e9-8d51-70f90402d40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-d02c87dd-2088-46bb-b3a5-d0f0fde33f22,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-434d4d05-00a1-480e-9a0b-dc116985a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-34e36b35-0778-446b-a424-736001ee8990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426617216-172.17.0.13-1598565717677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-28a11205-8adb-4c15-8cf7-229009689e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6d11ef3d-0ee4-455a-9acb-12a674bf145b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-13b62704-a421-414f-baaf-e9b730780b29,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-f075bb15-2b16-44f1-a55e-ae44335ba09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-05e1e55a-5b40-4524-bd80-ca97a10ea908,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-56aa390b-7967-413f-842a-5ddfd0f9ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7c9bf9f3-dcba-49ed-9c86-6e3d7762dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-49f2961d-ef88-42d7-8655-5b5b8b436a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426617216-172.17.0.13-1598565717677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-28a11205-8adb-4c15-8cf7-229009689e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6d11ef3d-0ee4-455a-9acb-12a674bf145b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-13b62704-a421-414f-baaf-e9b730780b29,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-f075bb15-2b16-44f1-a55e-ae44335ba09b,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-05e1e55a-5b40-4524-bd80-ca97a10ea908,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-56aa390b-7967-413f-842a-5ddfd0f9ca97,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-7c9bf9f3-dcba-49ed-9c86-6e3d7762dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-49f2961d-ef88-42d7-8655-5b5b8b436a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722909416-172.17.0.13-1598565943585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-9c574dd9-f2ea-4eb5-9968-a45c028f7eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-55cfc9ba-a928-4968-a20f-03d9d0b9dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4693675c-9d26-4ca5-bfc2-6b7de7b85439,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-7980304f-326d-4d91-91af-92f4b5a61d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-6ba77b67-8933-459f-80ed-7539ff9aa0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-d54e2087-48de-44c9-8bb7-702a4bf84470,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-fe5cd0d3-d6ba-4fc0-901e-475c131426b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-bfe62e79-63a7-468f-8018-fa127424206d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722909416-172.17.0.13-1598565943585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-9c574dd9-f2ea-4eb5-9968-a45c028f7eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-55cfc9ba-a928-4968-a20f-03d9d0b9dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-4693675c-9d26-4ca5-bfc2-6b7de7b85439,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-7980304f-326d-4d91-91af-92f4b5a61d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-6ba77b67-8933-459f-80ed-7539ff9aa0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-d54e2087-48de-44c9-8bb7-702a4bf84470,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-fe5cd0d3-d6ba-4fc0-901e-475c131426b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-bfe62e79-63a7-468f-8018-fa127424206d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975067718-172.17.0.13-1598566274739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-89b6d224-e1c0-40c2-be9e-acbe8c2fe74c,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-fb5550b3-460b-4c97-a4f7-13ebba1377cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-f9d1e178-db67-4e6d-9009-ee6fc60011d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-ec3f037e-a9b0-4f8c-a90f-357fa9c39748,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-1ef324d2-fac5-4fdb-a15d-97d83435f977,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-0246494d-285f-4d96-bc02-643c45fd1c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-30b95199-0ee3-4132-b9eb-9f9887443bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6018b93d-49e5-494f-8177-530f38942f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975067718-172.17.0.13-1598566274739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-89b6d224-e1c0-40c2-be9e-acbe8c2fe74c,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-fb5550b3-460b-4c97-a4f7-13ebba1377cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-f9d1e178-db67-4e6d-9009-ee6fc60011d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-ec3f037e-a9b0-4f8c-a90f-357fa9c39748,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-1ef324d2-fac5-4fdb-a15d-97d83435f977,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-0246494d-285f-4d96-bc02-643c45fd1c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-30b95199-0ee3-4132-b9eb-9f9887443bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6018b93d-49e5-494f-8177-530f38942f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844098343-172.17.0.13-1598566527567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-40df58e4-75f4-4e7a-af09-fbbd3a643f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-eb56b43d-9cb2-42d8-a5cb-d74402d0263b,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-43659bfd-b6f6-4bca-854b-404485b003f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-faa3e150-d68e-4dcb-a5ca-eeeb5aaa22a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-8406352c-41b9-4298-9228-0dc94ceb44ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-edae2dd6-8a7f-479e-8c47-b4123702cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-73bd0543-a8da-4049-bc3f-9f7b8068e246,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-3a3b95fa-5ff6-42c4-8cab-0e3edc88f3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844098343-172.17.0.13-1598566527567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-40df58e4-75f4-4e7a-af09-fbbd3a643f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-eb56b43d-9cb2-42d8-a5cb-d74402d0263b,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-43659bfd-b6f6-4bca-854b-404485b003f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-faa3e150-d68e-4dcb-a5ca-eeeb5aaa22a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-8406352c-41b9-4298-9228-0dc94ceb44ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-edae2dd6-8a7f-479e-8c47-b4123702cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-73bd0543-a8da-4049-bc3f-9f7b8068e246,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-3a3b95fa-5ff6-42c4-8cab-0e3edc88f3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98215152-172.17.0.13-1598566739259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37850,DS-1ac0a971-f99e-416c-b39d-bb5ccb2f4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-422ece8a-abd6-4da2-a7ae-c59bcad2a1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-2c79578b-834a-4457-a8f9-58a000c18558,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5a83c26b-4d12-41f4-847a-bef13319b837,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c0e7d3ec-f5c6-49c9-a5fa-2505d45685bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-564fb8c3-100e-4f1d-ad7e-f27da548ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-12ec4dc4-8975-4884-92e4-3caa2fd87262,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-4e3517db-e659-4e60-941d-5dbfee2c23a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98215152-172.17.0.13-1598566739259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37850,DS-1ac0a971-f99e-416c-b39d-bb5ccb2f4b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-422ece8a-abd6-4da2-a7ae-c59bcad2a1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-2c79578b-834a-4457-a8f9-58a000c18558,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5a83c26b-4d12-41f4-847a-bef13319b837,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c0e7d3ec-f5c6-49c9-a5fa-2505d45685bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-564fb8c3-100e-4f1d-ad7e-f27da548ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-12ec4dc4-8975-4884-92e4-3caa2fd87262,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-4e3517db-e659-4e60-941d-5dbfee2c23a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016736704-172.17.0.13-1598566839902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-3c6ef910-db63-41da-94d6-a11cda3214ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ff87a4c1-2666-4636-8038-bc630e65a9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-98f7ada1-fe6b-457d-81b5-339fb398c277,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-0bc36dbb-6fe8-42e0-a5cf-383c461c7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-6c58963d-b7b5-4cd7-b4ca-c7509c5a4ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8ff88741-dce4-40f2-b7f3-27f0e9983f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-a065fadb-c0b3-4eac-adb7-ce1f14c4cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-8ae303e2-43d0-4f07-a394-23feb68d8d61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016736704-172.17.0.13-1598566839902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-3c6ef910-db63-41da-94d6-a11cda3214ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-ff87a4c1-2666-4636-8038-bc630e65a9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-98f7ada1-fe6b-457d-81b5-339fb398c277,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-0bc36dbb-6fe8-42e0-a5cf-383c461c7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-6c58963d-b7b5-4cd7-b4ca-c7509c5a4ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-8ff88741-dce4-40f2-b7f3-27f0e9983f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-a065fadb-c0b3-4eac-adb7-ce1f14c4cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-8ae303e2-43d0-4f07-a394-23feb68d8d61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5557
