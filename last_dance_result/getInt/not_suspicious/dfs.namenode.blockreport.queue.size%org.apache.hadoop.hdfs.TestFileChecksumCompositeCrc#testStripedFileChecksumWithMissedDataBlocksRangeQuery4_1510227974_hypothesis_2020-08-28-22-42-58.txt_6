reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698007800-172.17.0.2-1598655059043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-1fd2e138-9767-4166-a63e-a659d1eeb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-7dfbea9c-3a64-45b6-adb8-aaa31a5402af,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8a4d1b9c-0308-467a-b1bf-db507886e081,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-377708ff-6dea-41f0-8e22-a5ded2d79239,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-a6699bad-cb09-4e71-b8a2-df3f04ec8387,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-bcad8841-6aa8-46ac-a32a-d9b366e6355d,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-6191bb7f-8abb-44cf-aecc-b5ca54da1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-28f2c6c5-8017-4c77-837e-e14f11e4a21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698007800-172.17.0.2-1598655059043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-1fd2e138-9767-4166-a63e-a659d1eeb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-7dfbea9c-3a64-45b6-adb8-aaa31a5402af,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8a4d1b9c-0308-467a-b1bf-db507886e081,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-377708ff-6dea-41f0-8e22-a5ded2d79239,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-a6699bad-cb09-4e71-b8a2-df3f04ec8387,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-bcad8841-6aa8-46ac-a32a-d9b366e6355d,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-6191bb7f-8abb-44cf-aecc-b5ca54da1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-28f2c6c5-8017-4c77-837e-e14f11e4a21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528219413-172.17.0.2-1598655091484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-a70e8523-9db9-42e2-b123-f58ba98942f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-fb424c6c-f0cc-41be-8cac-06d1d8a114f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-fa650a2f-f7f8-4172-9cf1-cc11d3e9a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-5fa81c1a-c704-4393-bc61-f21eca55943a,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-4401e67d-d6b4-4fb4-849d-094d94f6b309,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-9426fcad-f353-4976-a873-9dfb1342f173,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-8b1dbab5-734e-4a04-8b1f-55707ecb2aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-909ed245-fdae-4ab3-bd57-6d29a83c0ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528219413-172.17.0.2-1598655091484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-a70e8523-9db9-42e2-b123-f58ba98942f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-fb424c6c-f0cc-41be-8cac-06d1d8a114f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-fa650a2f-f7f8-4172-9cf1-cc11d3e9a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-5fa81c1a-c704-4393-bc61-f21eca55943a,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-4401e67d-d6b4-4fb4-849d-094d94f6b309,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-9426fcad-f353-4976-a873-9dfb1342f173,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-8b1dbab5-734e-4a04-8b1f-55707ecb2aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-909ed245-fdae-4ab3-bd57-6d29a83c0ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410103305-172.17.0.2-1598655584283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-e568a046-117b-4cf2-8987-2de56c06833c,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-e3ca3b4f-26ae-4546-92fe-4b99c88e66c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-af27a9c3-0c05-45c7-a120-2e2bcbba27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e769b91f-c0ee-422c-9cb0-f4edeebce8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-44fb6e4c-9d1f-4ff2-8829-0a01452f2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d4d3fd5c-4935-44b9-a605-d02732464c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-bb83be46-b6e8-4811-a5c2-45c646546cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-29d338b8-9af6-435b-94db-aee207de7020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410103305-172.17.0.2-1598655584283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-e568a046-117b-4cf2-8987-2de56c06833c,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-e3ca3b4f-26ae-4546-92fe-4b99c88e66c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-af27a9c3-0c05-45c7-a120-2e2bcbba27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e769b91f-c0ee-422c-9cb0-f4edeebce8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-44fb6e4c-9d1f-4ff2-8829-0a01452f2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d4d3fd5c-4935-44b9-a605-d02732464c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-bb83be46-b6e8-4811-a5c2-45c646546cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-29d338b8-9af6-435b-94db-aee207de7020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959021066-172.17.0.2-1598656075643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-8b9ff0df-69bf-45fd-adfc-b54b4cdd880e,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-8d0bef99-af34-4310-96d5-a800aaf2166d,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-eb7ae51b-46c6-4d72-baa7-8d68f42d9503,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-ebf7148d-5503-48de-a801-5a98a211cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-23a4f70f-dc62-41f4-ace5-e1f3a3b029f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-70b8f3c7-4f92-49d3-b540-b1151d267d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-51fb09a2-3494-47d5-a00d-f0552ca74cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-61d5c071-f60c-4542-8a07-372aac75c6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959021066-172.17.0.2-1598656075643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-8b9ff0df-69bf-45fd-adfc-b54b4cdd880e,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-8d0bef99-af34-4310-96d5-a800aaf2166d,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-eb7ae51b-46c6-4d72-baa7-8d68f42d9503,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-ebf7148d-5503-48de-a801-5a98a211cb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-23a4f70f-dc62-41f4-ace5-e1f3a3b029f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-70b8f3c7-4f92-49d3-b540-b1151d267d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-51fb09a2-3494-47d5-a00d-f0552ca74cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-61d5c071-f60c-4542-8a07-372aac75c6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212371763-172.17.0.2-1598656844360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-3caf91a9-11f5-4eeb-88e9-0b8a1ce96127,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4295216f-1af4-4c4a-9366-8c2f2fffbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-995f699b-2e34-4fad-a2bf-03bb77efdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-adbf8262-9f3b-42c8-8937-3711aeb870df,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-2f7ee2c3-36d4-420f-b9d6-8e1055fe757d,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ecf7c587-67d7-4a0d-98ea-4d240521dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-a042f540-9397-46fa-a0c8-557ebedae059,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-de514c8d-a30b-493f-8a81-067c94326477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212371763-172.17.0.2-1598656844360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-3caf91a9-11f5-4eeb-88e9-0b8a1ce96127,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4295216f-1af4-4c4a-9366-8c2f2fffbbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-995f699b-2e34-4fad-a2bf-03bb77efdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-adbf8262-9f3b-42c8-8937-3711aeb870df,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-2f7ee2c3-36d4-420f-b9d6-8e1055fe757d,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-ecf7c587-67d7-4a0d-98ea-4d240521dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-a042f540-9397-46fa-a0c8-557ebedae059,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-de514c8d-a30b-493f-8a81-067c94326477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171867943-172.17.0.2-1598656952155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-6d912d05-7440-4004-b29e-1c0f61d5fef7,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-599ee22a-26e8-43a6-8c47-6c88176c852c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-67ed8290-defb-42c7-ad60-18ea8388c901,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-9b42ec62-ce7b-42c1-be57-5f2f9e235139,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-7cc408b2-3e41-49d2-8d22-27ba7776f668,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ced52f79-f9ef-4793-8278-dc61fe4bdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-17125cb2-0217-4179-afea-5730ad1f402a,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-5e1bb2e0-1de1-4def-9ee1-cbaf3c29566a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171867943-172.17.0.2-1598656952155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-6d912d05-7440-4004-b29e-1c0f61d5fef7,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-599ee22a-26e8-43a6-8c47-6c88176c852c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-67ed8290-defb-42c7-ad60-18ea8388c901,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-9b42ec62-ce7b-42c1-be57-5f2f9e235139,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-7cc408b2-3e41-49d2-8d22-27ba7776f668,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-ced52f79-f9ef-4793-8278-dc61fe4bdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-17125cb2-0217-4179-afea-5730ad1f402a,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-5e1bb2e0-1de1-4def-9ee1-cbaf3c29566a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667666759-172.17.0.2-1598657365432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-8d9a9f01-223e-4391-be44-972bd1f471c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-1bc821d2-4a7d-47de-8083-6f9ae0010042,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-9ddf7dce-6211-4fa0-b13f-1e69f8c8a725,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-1f937dec-4168-4100-9910-f3f529eecc34,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-c07ed7a9-082c-4dad-9c9a-d3be420ffeef,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-29e637be-f389-4bfb-9783-1c7ccd56e897,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-dff3ca18-ea50-484c-8ece-6dfc0fc30ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-08ad42d0-b92b-4dbd-97e1-b0cdec4372ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667666759-172.17.0.2-1598657365432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42378,DS-8d9a9f01-223e-4391-be44-972bd1f471c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-1bc821d2-4a7d-47de-8083-6f9ae0010042,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-9ddf7dce-6211-4fa0-b13f-1e69f8c8a725,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-1f937dec-4168-4100-9910-f3f529eecc34,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-c07ed7a9-082c-4dad-9c9a-d3be420ffeef,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-29e637be-f389-4bfb-9783-1c7ccd56e897,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-dff3ca18-ea50-484c-8ece-6dfc0fc30ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-08ad42d0-b92b-4dbd-97e1-b0cdec4372ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922788516-172.17.0.2-1598657509415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-a711eb44-b90d-40c1-bccf-aeebbfb5dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-6e3f4e6c-27f3-4832-8084-4ca23c3f2d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-8865d760-cad6-411e-9665-939acaf26848,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-c499202c-c250-4d6c-98d5-0a827ca2b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-b64acd33-7e34-4487-9f1a-d52cab74d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-c9ec841a-002a-41e8-a4b6-c88fbbe56e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-2e563837-f3e2-4b23-87d1-edbdc06261e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-5b923387-a502-4e88-b026-536d34436cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922788516-172.17.0.2-1598657509415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35875,DS-a711eb44-b90d-40c1-bccf-aeebbfb5dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-6e3f4e6c-27f3-4832-8084-4ca23c3f2d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-8865d760-cad6-411e-9665-939acaf26848,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-c499202c-c250-4d6c-98d5-0a827ca2b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-b64acd33-7e34-4487-9f1a-d52cab74d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-c9ec841a-002a-41e8-a4b6-c88fbbe56e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-2e563837-f3e2-4b23-87d1-edbdc06261e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-5b923387-a502-4e88-b026-536d34436cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028321907-172.17.0.2-1598657619562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-989a5ad1-591e-4ac1-a1ea-1c1cd95e1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-f865e2b2-77f5-4567-9679-5cc957f0f262,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-9ad37677-76d2-41a5-a8f7-cde0212e923a,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-581115a8-63c1-4cc6-ab38-8c385ef67c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-95c9a8a7-7438-4e93-9835-eb534cce4f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-28586271-0e8d-44d0-ade6-5463c6afc3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-4a87fa01-11db-4025-a72e-99b576f48613,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-642e40f8-dc2c-4f24-b49b-6197f1651ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028321907-172.17.0.2-1598657619562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-989a5ad1-591e-4ac1-a1ea-1c1cd95e1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-f865e2b2-77f5-4567-9679-5cc957f0f262,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-9ad37677-76d2-41a5-a8f7-cde0212e923a,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-581115a8-63c1-4cc6-ab38-8c385ef67c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-95c9a8a7-7438-4e93-9835-eb534cce4f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-28586271-0e8d-44d0-ade6-5463c6afc3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-4a87fa01-11db-4025-a72e-99b576f48613,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-642e40f8-dc2c-4f24-b49b-6197f1651ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647312800-172.17.0.2-1598657820539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39050,DS-642571c6-95cb-41fb-bc7f-27b1e50eebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-8f960aa3-5231-4b66-b392-64b00604337e,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-54a45d98-8a48-418f-9f31-fea21d57f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-9e95c23b-55b4-4717-ab5a-e17169f1ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-e2bd43af-b8be-42ff-8fdc-867bfc539872,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-10a569c8-db9f-46d3-92bc-b9f3fc38382e,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-2d6600f3-fa59-4b13-a182-caad4849e721,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6e968571-fcd0-498c-9196-c7568f803600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647312800-172.17.0.2-1598657820539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39050,DS-642571c6-95cb-41fb-bc7f-27b1e50eebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-8f960aa3-5231-4b66-b392-64b00604337e,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-54a45d98-8a48-418f-9f31-fea21d57f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-9e95c23b-55b4-4717-ab5a-e17169f1ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-e2bd43af-b8be-42ff-8fdc-867bfc539872,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-10a569c8-db9f-46d3-92bc-b9f3fc38382e,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-2d6600f3-fa59-4b13-a182-caad4849e721,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6e968571-fcd0-498c-9196-c7568f803600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249956400-172.17.0.2-1598657871009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-5af5af88-0936-4f85-8b3c-9969e9fbf2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-9e16f13a-7e5a-4ae4-b78d-8bc343b54072,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6592bb8b-8517-451a-8f43-f0ffb3d3bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-298e6586-14e4-45a1-b5d2-97a0c630f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-5b4dc648-2c6d-409d-972e-e2b98fd196ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-70da815b-7de7-4e09-9778-25ef5de8ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-9f4b50b6-2d4c-418b-b7c9-c7fc7ba9eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ab1da15e-06b3-46d5-9f1e-b875d14c4711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249956400-172.17.0.2-1598657871009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-5af5af88-0936-4f85-8b3c-9969e9fbf2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-9e16f13a-7e5a-4ae4-b78d-8bc343b54072,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6592bb8b-8517-451a-8f43-f0ffb3d3bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-298e6586-14e4-45a1-b5d2-97a0c630f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-5b4dc648-2c6d-409d-972e-e2b98fd196ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-70da815b-7de7-4e09-9778-25ef5de8ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-9f4b50b6-2d4c-418b-b7c9-c7fc7ba9eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ab1da15e-06b3-46d5-9f1e-b875d14c4711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765959175-172.17.0.2-1598658028052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-c0218742-ad5a-4728-99b9-9b7f860f8c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-ab918681-e556-44b3-a895-2e5e357f93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-e1f6d6b2-e09c-4fd4-bb89-72044c0dd8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-5eb5d203-65ce-4b1c-88cd-494ba2a7f2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-1c1c5b54-1786-4119-8ab5-0a6847135d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-5a49d242-50fd-45ef-a0ed-1a8c41038ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-1de51a5e-8c98-41cc-89a8-77432c3a60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-fa988192-b793-4df1-9347-4563c5b2d4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765959175-172.17.0.2-1598658028052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-c0218742-ad5a-4728-99b9-9b7f860f8c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-ab918681-e556-44b3-a895-2e5e357f93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-e1f6d6b2-e09c-4fd4-bb89-72044c0dd8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-5eb5d203-65ce-4b1c-88cd-494ba2a7f2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-1c1c5b54-1786-4119-8ab5-0a6847135d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-5a49d242-50fd-45ef-a0ed-1a8c41038ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-1de51a5e-8c98-41cc-89a8-77432c3a60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-fa988192-b793-4df1-9347-4563c5b2d4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795567376-172.17.0.2-1598658193760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-4799a407-7167-4441-bfce-567d333a6038,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-3cba2508-7da4-4d43-87e1-6191b6d66e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-43cf3e26-65bd-4e33-88d4-41f23764366d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-e5428afe-81a9-4396-a4e8-9845cd86f375,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-5d8f7692-aa7f-4bca-83b9-9eba06eac8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b91f5dbd-40c4-4620-88dc-6e90ec5eb146,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-6fe2ed25-abd6-4a63-89f8-260cfa93a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c3578d23-9a31-4c10-adb7-4b9b539584b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795567376-172.17.0.2-1598658193760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-4799a407-7167-4441-bfce-567d333a6038,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-3cba2508-7da4-4d43-87e1-6191b6d66e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-43cf3e26-65bd-4e33-88d4-41f23764366d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-e5428afe-81a9-4396-a4e8-9845cd86f375,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-5d8f7692-aa7f-4bca-83b9-9eba06eac8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-b91f5dbd-40c4-4620-88dc-6e90ec5eb146,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-6fe2ed25-abd6-4a63-89f8-260cfa93a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c3578d23-9a31-4c10-adb7-4b9b539584b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784572575-172.17.0.2-1598658267633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40719,DS-ae7eb1eb-c2ed-4cd4-b763-8e45781f6f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-4918849e-7dc9-447b-930f-88fda0a1b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e397e2d4-a574-4e4a-9509-50f9dd90c140,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8b22d117-6994-4e4b-8699-513519e01aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-4298a16a-7c33-424b-a03b-fae6817e7786,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-9dca5853-07ff-4cc5-8db5-6515884dfe97,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-a13549f9-054c-4f88-832f-da4057ff6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-aa8ae53d-8935-4533-a3e4-8293d102d6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784572575-172.17.0.2-1598658267633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40719,DS-ae7eb1eb-c2ed-4cd4-b763-8e45781f6f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-4918849e-7dc9-447b-930f-88fda0a1b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e397e2d4-a574-4e4a-9509-50f9dd90c140,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8b22d117-6994-4e4b-8699-513519e01aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-4298a16a-7c33-424b-a03b-fae6817e7786,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-9dca5853-07ff-4cc5-8db5-6515884dfe97,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-a13549f9-054c-4f88-832f-da4057ff6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-aa8ae53d-8935-4533-a3e4-8293d102d6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258954036-172.17.0.2-1598658434343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-97c0c21c-0c60-4982-a1cd-6c177a710906,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-63e55f9d-8e3c-43ee-be72-5974c932f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a002bce8-f444-4284-bcbc-6c0c1e8e6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-fcc5c078-fc0d-4e74-b23d-02683022e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-190af762-0679-4c8e-aa6e-cbe23ff7aede,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-86942395-a554-4732-8f5d-000505d1e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-5ce8af2b-2000-4cbb-aaa3-13ea23202e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-b474ce7d-3a06-46d3-87ae-81beecd70ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258954036-172.17.0.2-1598658434343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-97c0c21c-0c60-4982-a1cd-6c177a710906,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-63e55f9d-8e3c-43ee-be72-5974c932f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a002bce8-f444-4284-bcbc-6c0c1e8e6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-fcc5c078-fc0d-4e74-b23d-02683022e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-190af762-0679-4c8e-aa6e-cbe23ff7aede,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-86942395-a554-4732-8f5d-000505d1e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-5ce8af2b-2000-4cbb-aaa3-13ea23202e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-b474ce7d-3a06-46d3-87ae-81beecd70ea8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819316264-172.17.0.2-1598658939845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-2ed47026-955a-4413-a5ff-7586be2f12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-e2f3e7ea-eb43-417d-8e88-6ebc79a35250,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-9e2bfc0e-52cb-4349-93d1-1457de6ccd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-b024cf62-4e7d-4639-9df2-bdb7d2264bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-1323f241-4497-438f-b069-784ec5feef27,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-33ec6ca9-f6a3-4b7f-9599-00a412accd11,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-41c664b7-37e1-42fc-81c9-9ad9bc211545,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-c8902115-9f12-4ae0-9be6-22728fb443a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819316264-172.17.0.2-1598658939845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-2ed47026-955a-4413-a5ff-7586be2f12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-e2f3e7ea-eb43-417d-8e88-6ebc79a35250,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-9e2bfc0e-52cb-4349-93d1-1457de6ccd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-b024cf62-4e7d-4639-9df2-bdb7d2264bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-1323f241-4497-438f-b069-784ec5feef27,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-33ec6ca9-f6a3-4b7f-9599-00a412accd11,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-41c664b7-37e1-42fc-81c9-9ad9bc211545,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-c8902115-9f12-4ae0-9be6-22728fb443a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084261721-172.17.0.2-1598659220782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-78df9fc1-f285-4384-a5a6-be33cba4a989,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-eec6ed48-821e-4b87-941f-5dced3db1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-617159a8-cb8e-4654-b814-ffe5b3e3de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-ddf84d92-f263-4fe4-b7be-f417f0950e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-59c8dae6-8463-4fed-ae2f-19148220bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-115feb47-4961-4fd5-91d4-3439291b0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-4cfdd670-176c-4691-9ec1-d4a238e3890b,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-7659016d-1942-4a4b-a099-cc83e8f0d221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084261721-172.17.0.2-1598659220782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39837,DS-78df9fc1-f285-4384-a5a6-be33cba4a989,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-eec6ed48-821e-4b87-941f-5dced3db1ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-617159a8-cb8e-4654-b814-ffe5b3e3de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-ddf84d92-f263-4fe4-b7be-f417f0950e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-59c8dae6-8463-4fed-ae2f-19148220bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-115feb47-4961-4fd5-91d4-3439291b0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-4cfdd670-176c-4691-9ec1-d4a238e3890b,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-7659016d-1942-4a4b-a099-cc83e8f0d221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152718784-172.17.0.2-1598659337959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-0e18906a-eece-4afb-abae-6c97c01c7449,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-fba2ce6d-9cbe-492c-bc88-2babe22bf84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c7c8ed29-40ae-4f89-ac46-bfb7abcc88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-a0be0f75-a813-4eb2-bd30-d054eca95d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-1e7de181-205b-4540-9458-c33c747968a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-2e3a5fb9-f397-4b67-aeb7-6a4b9979c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-aa828750-153d-43f9-914f-155ddd1dfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-e83edf05-7425-4e69-a1d9-586e0bb601b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152718784-172.17.0.2-1598659337959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36940,DS-0e18906a-eece-4afb-abae-6c97c01c7449,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-fba2ce6d-9cbe-492c-bc88-2babe22bf84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-c7c8ed29-40ae-4f89-ac46-bfb7abcc88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-a0be0f75-a813-4eb2-bd30-d054eca95d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-1e7de181-205b-4540-9458-c33c747968a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-2e3a5fb9-f397-4b67-aeb7-6a4b9979c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-aa828750-153d-43f9-914f-155ddd1dfb14,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-e83edf05-7425-4e69-a1d9-586e0bb601b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406779108-172.17.0.2-1598659602535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-ed992cd0-7dc0-435c-bac9-cd7b4a95e27a,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7c51c453-817d-49df-af23-0cbfb4807f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-d84410b8-6542-4096-a3b7-7c234806b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-61051aae-fc59-4de6-ad1b-f6ac5113837d,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-91d39d46-7e88-48ba-a448-7481f180e2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-1313b915-354e-47e3-9435-c0bf9cfed8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-490d248f-cc29-4e6e-b534-d0f4cdef49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-c3843c76-85c4-4cfc-be03-5a4e6b24905d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406779108-172.17.0.2-1598659602535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-ed992cd0-7dc0-435c-bac9-cd7b4a95e27a,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7c51c453-817d-49df-af23-0cbfb4807f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-d84410b8-6542-4096-a3b7-7c234806b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-61051aae-fc59-4de6-ad1b-f6ac5113837d,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-91d39d46-7e88-48ba-a448-7481f180e2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-1313b915-354e-47e3-9435-c0bf9cfed8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-490d248f-cc29-4e6e-b534-d0f4cdef49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-c3843c76-85c4-4cfc-be03-5a4e6b24905d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 1024
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129581681-172.17.0.2-1598659924424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42896,DS-fd1edb59-c948-44ba-ae77-e8249c3d02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-d65083e4-48a4-4e87-a1ef-24b527d61600,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-b308651a-bebf-47a6-8ffc-656aae2e4099,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-13250add-b9f4-4824-90b2-e5abb9b0d886,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-79ad278f-d22c-4b7f-8cb4-374dcdd6aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-3a164524-ca79-4741-b349-13743a7da00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-7c408dd1-e522-4be3-9ae0-27673be2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-1c69c44d-fc20-4544-bb43-59f966567e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129581681-172.17.0.2-1598659924424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42896,DS-fd1edb59-c948-44ba-ae77-e8249c3d02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-d65083e4-48a4-4e87-a1ef-24b527d61600,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-b308651a-bebf-47a6-8ffc-656aae2e4099,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-13250add-b9f4-4824-90b2-e5abb9b0d886,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-79ad278f-d22c-4b7f-8cb4-374dcdd6aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-3a164524-ca79-4741-b349-13743a7da00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-7c408dd1-e522-4be3-9ae0-27673be2f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-1c69c44d-fc20-4544-bb43-59f966567e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5789
