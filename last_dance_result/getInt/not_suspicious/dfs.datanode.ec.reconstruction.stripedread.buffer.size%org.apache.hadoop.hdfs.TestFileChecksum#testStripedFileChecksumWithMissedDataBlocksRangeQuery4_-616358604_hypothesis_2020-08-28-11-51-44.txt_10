reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543292911-172.17.0.14-1598615606984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-6071aceb-e2c8-4646-8387-60d4b3aee7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-e5fe9d6a-66d5-4615-81e7-b3ad346e4b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-ce40c7fd-1471-4101-ac3e-58fbce2f94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-c616f99f-f3c1-4c49-bb1b-61944b54cbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-e2f681c9-8254-47d4-82e6-a45d4a2c7339,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-0944cd21-e70a-477e-baab-ff60968ae2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-2c27dc9e-c351-430b-b5ef-7f6dd743a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-f20e640c-5946-4fc4-97ca-2f7ccef199f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543292911-172.17.0.14-1598615606984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-6071aceb-e2c8-4646-8387-60d4b3aee7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-e5fe9d6a-66d5-4615-81e7-b3ad346e4b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-ce40c7fd-1471-4101-ac3e-58fbce2f94d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-c616f99f-f3c1-4c49-bb1b-61944b54cbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-e2f681c9-8254-47d4-82e6-a45d4a2c7339,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-0944cd21-e70a-477e-baab-ff60968ae2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-2c27dc9e-c351-430b-b5ef-7f6dd743a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-f20e640c-5946-4fc4-97ca-2f7ccef199f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503854132-172.17.0.14-1598615637014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-cc857fc4-329a-419d-90be-33df2078ccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-3a8747fe-1d17-43f5-9235-ec6294134a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-e5a5017a-4607-4f96-9e97-3684971986d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-90a2afeb-3f27-4ba4-8745-286f11af7811,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-19960731-6e2a-4b06-ab6b-fec66b2fffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-3d8cc83a-4823-4fa2-8b2b-717d052c7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-bd30c223-e40a-4f0d-8e7b-dfe9f87ba621,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-c4ac84df-0b09-41f7-80e7-045b8fe37d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503854132-172.17.0.14-1598615637014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-cc857fc4-329a-419d-90be-33df2078ccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-3a8747fe-1d17-43f5-9235-ec6294134a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-e5a5017a-4607-4f96-9e97-3684971986d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-90a2afeb-3f27-4ba4-8745-286f11af7811,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-19960731-6e2a-4b06-ab6b-fec66b2fffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-3d8cc83a-4823-4fa2-8b2b-717d052c7e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-bd30c223-e40a-4f0d-8e7b-dfe9f87ba621,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-c4ac84df-0b09-41f7-80e7-045b8fe37d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593408559-172.17.0.14-1598616524435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-42fb355d-2e3d-4678-a9f1-fa431df53c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-cc177775-e3c6-4712-ae7f-217ce62387d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-9087f1d6-a091-4e79-97b9-e53feac6be79,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-685afd9c-f2a4-4547-b7aa-2a3dacaff42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-ffe93dd7-5342-4e7d-87eb-5e95d3d10621,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-312fb5ef-6d36-4007-a897-2f5e70c194f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-179cb0a1-d578-41ce-9eaa-4c78f7741263,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-a16b3978-a478-4ae5-9092-b06fb6f66814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593408559-172.17.0.14-1598616524435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-42fb355d-2e3d-4678-a9f1-fa431df53c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-cc177775-e3c6-4712-ae7f-217ce62387d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-9087f1d6-a091-4e79-97b9-e53feac6be79,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-685afd9c-f2a4-4547-b7aa-2a3dacaff42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-ffe93dd7-5342-4e7d-87eb-5e95d3d10621,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-312fb5ef-6d36-4007-a897-2f5e70c194f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-179cb0a1-d578-41ce-9eaa-4c78f7741263,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-a16b3978-a478-4ae5-9092-b06fb6f66814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264236008-172.17.0.14-1598616566244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-a2c71cae-909e-448c-8e7e-8d0b13a9c689,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-33ac522f-9495-44f0-b844-7562889f6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-610802a3-13a8-4b3b-86de-5b3522eef768,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-7c31a5ef-bc3f-4196-a732-e1de06ae6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-dfb9489e-064e-4b9a-8212-fc284a0471ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-04bf00f9-740b-495d-892e-26f0b458a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-e6971c3e-f822-47b0-8f24-17f2d160c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-cc3e748a-5b99-49f0-a425-fce149ee0e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264236008-172.17.0.14-1598616566244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-a2c71cae-909e-448c-8e7e-8d0b13a9c689,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-33ac522f-9495-44f0-b844-7562889f6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-610802a3-13a8-4b3b-86de-5b3522eef768,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-7c31a5ef-bc3f-4196-a732-e1de06ae6c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-dfb9489e-064e-4b9a-8212-fc284a0471ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-04bf00f9-740b-495d-892e-26f0b458a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-e6971c3e-f822-47b0-8f24-17f2d160c3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-cc3e748a-5b99-49f0-a425-fce149ee0e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372362113-172.17.0.14-1598616671023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-cff9b5eb-3f3e-49bc-a1b3-b58334a3e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-913baa98-9300-4ba9-8b28-3a14d9f76fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-30b4d2dd-fa73-4cd5-bb1b-9bf6d7b72961,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-45746159-3f2a-48b0-b015-0ab6f1244947,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-52239644-9ce1-4e1a-9430-18bd86431690,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-c82f545f-9123-442f-8cc3-d6efe8d0aed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-9b30a5e9-5b73-4e31-9cc7-2191cafae2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-5376598a-1bdf-47e5-b3e6-fc691d3e9daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372362113-172.17.0.14-1598616671023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-cff9b5eb-3f3e-49bc-a1b3-b58334a3e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-913baa98-9300-4ba9-8b28-3a14d9f76fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-30b4d2dd-fa73-4cd5-bb1b-9bf6d7b72961,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-45746159-3f2a-48b0-b015-0ab6f1244947,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-52239644-9ce1-4e1a-9430-18bd86431690,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-c82f545f-9123-442f-8cc3-d6efe8d0aed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-9b30a5e9-5b73-4e31-9cc7-2191cafae2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-5376598a-1bdf-47e5-b3e6-fc691d3e9daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614176371-172.17.0.14-1598616858351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-d6f00ebb-77e5-40fe-ad8c-c0a4b8cc9050,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-ba85e9f5-59a3-4c35-aeb4-bcf4694a3a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-504b01ca-b99d-4cca-95a9-94272b600690,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-de178496-58c0-4190-b18b-24423e61ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-1f9298a4-0e5b-4291-a566-5dba667d8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-e0844dd2-f9b9-439b-841c-422bd59e48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-d4a98dbe-78d5-448b-bf94-28475b04fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-9eb1ae56-e727-437e-835b-572e182bb42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614176371-172.17.0.14-1598616858351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-d6f00ebb-77e5-40fe-ad8c-c0a4b8cc9050,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-ba85e9f5-59a3-4c35-aeb4-bcf4694a3a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-504b01ca-b99d-4cca-95a9-94272b600690,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-de178496-58c0-4190-b18b-24423e61ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-1f9298a4-0e5b-4291-a566-5dba667d8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-e0844dd2-f9b9-439b-841c-422bd59e48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-d4a98dbe-78d5-448b-bf94-28475b04fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-9eb1ae56-e727-437e-835b-572e182bb42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460543729-172.17.0.14-1598617324730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-9407cb91-1490-4c3a-80ba-3c2b1ecacea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b8e23bf2-8a72-427e-a191-0b174e2ef9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4cfbec14-9b6b-4aae-8ca8-4a5be6b9de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-6b83d6d6-12ce-4728-ab71-7c9544211841,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-d77e02f6-2696-4041-a976-ea05c5ad0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-4c39e795-3f2a-4a82-9453-8fc92e9b08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-1ee40197-c68c-4ecf-a825-449c85345aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-5feeda12-e7b3-4ad5-a6ce-01cbb64c3876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460543729-172.17.0.14-1598617324730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-9407cb91-1490-4c3a-80ba-3c2b1ecacea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b8e23bf2-8a72-427e-a191-0b174e2ef9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4cfbec14-9b6b-4aae-8ca8-4a5be6b9de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-6b83d6d6-12ce-4728-ab71-7c9544211841,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-d77e02f6-2696-4041-a976-ea05c5ad0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-4c39e795-3f2a-4a82-9453-8fc92e9b08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-1ee40197-c68c-4ecf-a825-449c85345aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-5feeda12-e7b3-4ad5-a6ce-01cbb64c3876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140118547-172.17.0.14-1598618285701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-30d84720-d0ee-4428-a7fe-1c2077ba5cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-5f23bd9a-cf66-44e7-89bf-55ed6bd400e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-ac66a4a5-d6dc-4d9d-98ef-3e935f7012ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2b834ca0-72c5-4d51-8241-3a10c7b9c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-132609d4-8eee-45bd-8c98-9d085b7b6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-bae252a4-5601-432c-a8f1-f91929d8ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-d976e42b-5489-4e3e-b612-ea6cd7604c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-6e60c18a-19df-4882-9d85-9a07675037f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140118547-172.17.0.14-1598618285701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-30d84720-d0ee-4428-a7fe-1c2077ba5cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-5f23bd9a-cf66-44e7-89bf-55ed6bd400e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-ac66a4a5-d6dc-4d9d-98ef-3e935f7012ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2b834ca0-72c5-4d51-8241-3a10c7b9c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-132609d4-8eee-45bd-8c98-9d085b7b6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-bae252a4-5601-432c-a8f1-f91929d8ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-d976e42b-5489-4e3e-b612-ea6cd7604c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-6e60c18a-19df-4882-9d85-9a07675037f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616080043-172.17.0.14-1598618419922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-c88ddc02-3446-470c-8195-ecf798de2924,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-af318bc4-6850-408b-8631-ec35df4de4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-edc8e834-ed5c-47b4-8a26-32d3b403f7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-65806fc2-e080-4b96-ab95-f0f1af66c955,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-69cf4c3a-99fa-4323-b981-345939a72e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-b035604e-e1f3-476a-b746-044ab471d054,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-aa398e32-1996-4a83-b13f-57ebfc88e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-df2070a1-4826-4a86-9c4e-d459e685391b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616080043-172.17.0.14-1598618419922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-c88ddc02-3446-470c-8195-ecf798de2924,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-af318bc4-6850-408b-8631-ec35df4de4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-edc8e834-ed5c-47b4-8a26-32d3b403f7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-65806fc2-e080-4b96-ab95-f0f1af66c955,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-69cf4c3a-99fa-4323-b981-345939a72e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-b035604e-e1f3-476a-b746-044ab471d054,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-aa398e32-1996-4a83-b13f-57ebfc88e86d,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-df2070a1-4826-4a86-9c4e-d459e685391b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332066400-172.17.0.14-1598618453310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-85af9783-fa74-42c6-8b3e-b27f190b394d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-81436532-5128-4a05-b748-99b278bb53a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-a639acab-9da5-4bf2-917a-65939ee27415,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-5d2c346a-8f11-4f51-9afa-0f60d270bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-8bfffaf0-4bad-43f7-989d-62b80be107ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-09cdda2c-90dc-442d-87ec-fb8fca193a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-6213f7cd-a29e-447c-8264-722532144a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-c1c56eaa-dfaa-4d19-b403-515d4b9fe466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332066400-172.17.0.14-1598618453310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40667,DS-85af9783-fa74-42c6-8b3e-b27f190b394d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-81436532-5128-4a05-b748-99b278bb53a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-a639acab-9da5-4bf2-917a-65939ee27415,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-5d2c346a-8f11-4f51-9afa-0f60d270bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-8bfffaf0-4bad-43f7-989d-62b80be107ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-09cdda2c-90dc-442d-87ec-fb8fca193a55,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-6213f7cd-a29e-447c-8264-722532144a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-c1c56eaa-dfaa-4d19-b403-515d4b9fe466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086482471-172.17.0.14-1598618582201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-003f089f-bcd6-412a-a94a-fe595c6b0634,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-be4122e3-b03f-4988-9f72-30348ce610db,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f451e8cb-b5c9-4ed7-b0fb-63ca39693a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-2f417c34-7b12-4b33-b54a-9392c75e34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-2af7ffc1-e8c7-4d54-a8dd-8f38ccc8bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-764763f8-6307-425d-9af0-ca5d5a0c502b,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-b435f4bf-532f-40ea-be60-a8dc92146a32,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-4af46d18-bd6e-468e-bd4f-5dc731763caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086482471-172.17.0.14-1598618582201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-003f089f-bcd6-412a-a94a-fe595c6b0634,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-be4122e3-b03f-4988-9f72-30348ce610db,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f451e8cb-b5c9-4ed7-b0fb-63ca39693a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-2f417c34-7b12-4b33-b54a-9392c75e34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-2af7ffc1-e8c7-4d54-a8dd-8f38ccc8bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-764763f8-6307-425d-9af0-ca5d5a0c502b,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-b435f4bf-532f-40ea-be60-a8dc92146a32,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-4af46d18-bd6e-468e-bd4f-5dc731763caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921992827-172.17.0.14-1598618695597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-f7f2ced6-d53e-497c-ae31-df504b11e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-03adab2e-739f-4b2a-9ad5-501a67648842,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ec54e909-d964-4670-8841-f7549bc43c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-99731c48-5951-4b49-85fc-5ef31c83b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-10391f6c-8d93-4277-ad2e-1a80dd7afc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-49c46d86-438d-4b5f-8398-2e186113e865,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-9edd5789-9a62-4999-9d5f-d21a160202b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-86eb7925-94b3-433f-aa64-9cb30284df28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921992827-172.17.0.14-1598618695597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-f7f2ced6-d53e-497c-ae31-df504b11e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-03adab2e-739f-4b2a-9ad5-501a67648842,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ec54e909-d964-4670-8841-f7549bc43c99,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-99731c48-5951-4b49-85fc-5ef31c83b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-10391f6c-8d93-4277-ad2e-1a80dd7afc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-49c46d86-438d-4b5f-8398-2e186113e865,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-9edd5789-9a62-4999-9d5f-d21a160202b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-86eb7925-94b3-433f-aa64-9cb30284df28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84820494-172.17.0.14-1598619008474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-a081fc5c-9fba-4bba-946a-2281ab55b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-00cf20d1-aef0-4e0b-9359-5259a093df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-41b669c4-0c9a-4d13-9370-baf038bc875d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-45643e1f-ab5a-4c5b-a976-3e5ea7699199,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-5ab23138-e11a-4508-a675-fe6ccd04b657,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-86481dd2-1c7e-4cfc-b406-155cb025fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-682160b5-5380-4f6a-90c3-1aa5b274132b,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-92809022-6398-4c1f-832e-83402be93740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84820494-172.17.0.14-1598619008474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-a081fc5c-9fba-4bba-946a-2281ab55b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-00cf20d1-aef0-4e0b-9359-5259a093df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-41b669c4-0c9a-4d13-9370-baf038bc875d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-45643e1f-ab5a-4c5b-a976-3e5ea7699199,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-5ab23138-e11a-4508-a675-fe6ccd04b657,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-86481dd2-1c7e-4cfc-b406-155cb025fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-682160b5-5380-4f6a-90c3-1aa5b274132b,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-92809022-6398-4c1f-832e-83402be93740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114864478-172.17.0.14-1598619333534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36925,DS-9b5f0984-976a-4716-9aaf-e2a15bbec4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-025cf77c-c2ec-47e5-a858-9d9779fd00ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-11995be7-8dd4-4903-875b-cac9d1d27c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-b48c2f3e-6f40-4de0-9c74-74e7e557a572,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-f2556145-4fd5-4280-b0f9-179d08703e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c83b20af-63ef-448c-88e2-1c49101d30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-f583a8d5-2cc8-446e-9757-b6bda0d34aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-fd1f88fd-e0d0-48ef-b808-d2fe8f5128c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114864478-172.17.0.14-1598619333534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36925,DS-9b5f0984-976a-4716-9aaf-e2a15bbec4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-025cf77c-c2ec-47e5-a858-9d9779fd00ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-11995be7-8dd4-4903-875b-cac9d1d27c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-b48c2f3e-6f40-4de0-9c74-74e7e557a572,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-f2556145-4fd5-4280-b0f9-179d08703e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-c83b20af-63ef-448c-88e2-1c49101d30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-f583a8d5-2cc8-446e-9757-b6bda0d34aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34160,DS-fd1f88fd-e0d0-48ef-b808-d2fe8f5128c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604477035-172.17.0.14-1598620123560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-68303dee-80bb-4716-bfcd-24127ae93e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-54b07562-ca02-45a4-a29d-06424ab72f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-551effe0-3280-4ec8-9661-88487fe666b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-91f184f6-b2c3-4283-ac32-93d5d8098975,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-3e862035-2e31-4a8a-b17a-22fded66e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-d72c9f65-5601-4b5f-b457-f5409f1c5e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-b84d37b9-4e3f-4916-8d2c-68e06c412439,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-fb5c6aff-2b3f-41e5-92e5-19d230ba9c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604477035-172.17.0.14-1598620123560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-68303dee-80bb-4716-bfcd-24127ae93e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-54b07562-ca02-45a4-a29d-06424ab72f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-551effe0-3280-4ec8-9661-88487fe666b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-91f184f6-b2c3-4283-ac32-93d5d8098975,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-3e862035-2e31-4a8a-b17a-22fded66e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-d72c9f65-5601-4b5f-b457-f5409f1c5e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-b84d37b9-4e3f-4916-8d2c-68e06c412439,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-fb5c6aff-2b3f-41e5-92e5-19d230ba9c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462238192-172.17.0.14-1598620257874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-1d21ced1-4f34-4794-b928-57c5f54435f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c2ac0bff-8e83-4ded-9bf1-fbf11081d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-f915a2b6-b9c8-4b25-9c36-23cb49cbb3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-7ee77899-8893-40d2-adbb-85e8ae235ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-63cc8e13-367b-4aa3-b3db-66fad7a7c736,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-55b433a2-5c4d-4ae8-a643-b6e03d62ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-435a93ab-3c7e-40e4-a51c-8ad1afb2560c,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-cf832dce-08b6-4c6c-bc6c-dc133fc3d45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462238192-172.17.0.14-1598620257874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-1d21ced1-4f34-4794-b928-57c5f54435f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c2ac0bff-8e83-4ded-9bf1-fbf11081d9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-f915a2b6-b9c8-4b25-9c36-23cb49cbb3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-7ee77899-8893-40d2-adbb-85e8ae235ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-63cc8e13-367b-4aa3-b3db-66fad7a7c736,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-55b433a2-5c4d-4ae8-a643-b6e03d62ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-435a93ab-3c7e-40e4-a51c-8ad1afb2560c,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-cf832dce-08b6-4c6c-bc6c-dc133fc3d45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804906876-172.17.0.14-1598620421736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-ec938054-038f-41ed-a057-c03d873f9818,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-a7b2d797-1d83-47c1-a5a0-44aa5acf33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-5e836026-f7d5-42f5-9887-e9e432112af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-a7ada8f6-6eca-45e3-b37a-1d970e12b494,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-6a119de6-c4d9-4317-a8c6-860db92dec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-58e5ae69-b57f-4ba9-8447-5beb10e78d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-5d7367dc-d22c-42b0-b829-9d502803fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-40d3a2ec-50e0-468d-8f69-eeb283741c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804906876-172.17.0.14-1598620421736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-ec938054-038f-41ed-a057-c03d873f9818,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-a7b2d797-1d83-47c1-a5a0-44aa5acf33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-5e836026-f7d5-42f5-9887-e9e432112af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-a7ada8f6-6eca-45e3-b37a-1d970e12b494,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-6a119de6-c4d9-4317-a8c6-860db92dec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-58e5ae69-b57f-4ba9-8447-5beb10e78d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-5d7367dc-d22c-42b0-b829-9d502803fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-40d3a2ec-50e0-468d-8f69-eeb283741c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.stripedread.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350599979-172.17.0.14-1598620449181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-15ff1d2b-439a-4c0f-a163-08b46cda1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-da89ea58-531d-406f-bdb0-080db0675118,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-40db2a80-f03f-4cb0-aff0-85c902dd837e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-6f4305ce-63e7-4aaa-915f-0f85a7ac51fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-0a226259-40d2-4cb7-956d-ec779521fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-26a88fba-f554-4271-82b9-ff88086a83a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-8703579f-39d1-46aa-a1c0-ebe2eb6d1314,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-d396269f-e91d-4e16-8b51-a8350fb1d640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350599979-172.17.0.14-1598620449181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-15ff1d2b-439a-4c0f-a163-08b46cda1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-da89ea58-531d-406f-bdb0-080db0675118,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-40db2a80-f03f-4cb0-aff0-85c902dd837e,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-6f4305ce-63e7-4aaa-915f-0f85a7ac51fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-0a226259-40d2-4cb7-956d-ec779521fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-26a88fba-f554-4271-82b9-ff88086a83a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-8703579f-39d1-46aa-a1c0-ebe2eb6d1314,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-d396269f-e91d-4e16-8b51-a8350fb1d640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4992
