reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940683441-172.17.0.19-1598568088034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-c338a62b-fcdd-41b5-8378-cab2925e2344,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-ef86d606-b38e-44e5-acd6-42a01f28aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-fe152c13-61c6-490b-8db8-c56944059958,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-7a154a7d-7d0b-45bc-83ba-a189d54bc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-72ad61b9-665b-48ff-a3d6-f69f2f13b531,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb1b3338-0d73-4fd4-969a-dbcd4d12abef,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a2c61db2-c031-4c9c-bec3-0c890e806518,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-e915b104-7d9e-49bf-a2a4-0a2e02876ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940683441-172.17.0.19-1598568088034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-c338a62b-fcdd-41b5-8378-cab2925e2344,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-ef86d606-b38e-44e5-acd6-42a01f28aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-fe152c13-61c6-490b-8db8-c56944059958,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-7a154a7d-7d0b-45bc-83ba-a189d54bc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-72ad61b9-665b-48ff-a3d6-f69f2f13b531,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb1b3338-0d73-4fd4-969a-dbcd4d12abef,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a2c61db2-c031-4c9c-bec3-0c890e806518,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-e915b104-7d9e-49bf-a2a4-0a2e02876ab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752342720-172.17.0.19-1598568435719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-b89fea4e-2b58-4add-a2a9-79b0de26cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-92eb8f3b-3c56-44a6-b4b8-e6dc1e610b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-b53b4ba5-d3b2-41d0-81c8-256857194a84,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-d57f87fb-96c1-4a5e-84ad-72638b0a2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-fb225e38-96f6-4bb8-b9ab-9ebb982b5518,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-e78cce27-dda9-43dd-a8dc-303d09c5e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-74ffda47-0797-40e5-83df-4ec31c67133c,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-e6a0da25-363a-4f1a-87b6-2a768436ffc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752342720-172.17.0.19-1598568435719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-b89fea4e-2b58-4add-a2a9-79b0de26cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-92eb8f3b-3c56-44a6-b4b8-e6dc1e610b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-b53b4ba5-d3b2-41d0-81c8-256857194a84,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-d57f87fb-96c1-4a5e-84ad-72638b0a2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-fb225e38-96f6-4bb8-b9ab-9ebb982b5518,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-e78cce27-dda9-43dd-a8dc-303d09c5e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-74ffda47-0797-40e5-83df-4ec31c67133c,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-e6a0da25-363a-4f1a-87b6-2a768436ffc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690820911-172.17.0.19-1598568542365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-f2a71b9f-08e6-4bb1-98e5-e522bd1243d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-3cf7feca-fb0d-4c55-a506-26655f72d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-faa7707a-94c6-4205-b970-ce9627b5181b,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-1e8f16b0-e2a3-48d3-8edd-19c793ce47ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-a8f285dc-b743-458f-b500-56453da2aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-3c781559-d8f9-4dd4-9666-f09fe5c5bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-366b15ed-2a1b-46b3-8a77-3b1a853c4599,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-3bd74813-cd19-47a3-8a12-d55f9e5addc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690820911-172.17.0.19-1598568542365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-f2a71b9f-08e6-4bb1-98e5-e522bd1243d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-3cf7feca-fb0d-4c55-a506-26655f72d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-faa7707a-94c6-4205-b970-ce9627b5181b,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-1e8f16b0-e2a3-48d3-8edd-19c793ce47ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-a8f285dc-b743-458f-b500-56453da2aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-3c781559-d8f9-4dd4-9666-f09fe5c5bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-366b15ed-2a1b-46b3-8a77-3b1a853c4599,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-3bd74813-cd19-47a3-8a12-d55f9e5addc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416909661-172.17.0.19-1598568619389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-09b3292e-9dac-4f03-8bf0-890b1ad4dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-fba9e440-1cf2-4ca4-a21c-967b73d7d5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-b29ec7d6-74cc-4b2f-b047-96fe0544ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-82ab8051-78f3-4343-a1da-8ffbff899dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-54048b35-8702-48b4-92dd-a5b63dbb29f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-75604d3b-95c5-4caf-b972-601786e1ea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-b3bc9427-f358-4d73-94d3-80f1a180fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-4055bde5-3515-492b-86f9-f2deda050c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416909661-172.17.0.19-1598568619389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-09b3292e-9dac-4f03-8bf0-890b1ad4dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-fba9e440-1cf2-4ca4-a21c-967b73d7d5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-b29ec7d6-74cc-4b2f-b047-96fe0544ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-82ab8051-78f3-4343-a1da-8ffbff899dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-54048b35-8702-48b4-92dd-a5b63dbb29f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-75604d3b-95c5-4caf-b972-601786e1ea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-b3bc9427-f358-4d73-94d3-80f1a180fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-4055bde5-3515-492b-86f9-f2deda050c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046860336-172.17.0.19-1598568696688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-a1ad9303-2c13-44a2-9dc9-9ba3a468534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-28979244-edf8-40b2-b266-426c46a3e928,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-1105e0f3-b25b-4b3f-99a7-545ca14b2535,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-4559dac8-f61b-4a5c-a173-dc958218405f,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-fb25b33d-d14b-4ea4-b384-189cd369c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-15961db0-2c23-4995-9637-f8ca9278e596,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-5e52d561-5bf2-41f9-960c-aab4d852531b,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-25959557-03ac-4747-b248-5a0fe19b13ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046860336-172.17.0.19-1598568696688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-a1ad9303-2c13-44a2-9dc9-9ba3a468534b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-28979244-edf8-40b2-b266-426c46a3e928,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-1105e0f3-b25b-4b3f-99a7-545ca14b2535,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-4559dac8-f61b-4a5c-a173-dc958218405f,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-fb25b33d-d14b-4ea4-b384-189cd369c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-15961db0-2c23-4995-9637-f8ca9278e596,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-5e52d561-5bf2-41f9-960c-aab4d852531b,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-25959557-03ac-4747-b248-5a0fe19b13ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254553397-172.17.0.19-1598568851351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-41922fa2-4f71-4b16-9f79-670f45eb95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-03b385fe-22cf-4504-85b7-38d8a8ff3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a95e9944-7592-492a-bd27-70aaa9cf81de,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-198af735-8b99-4eb7-909b-7f44e6e3cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-f231df47-1346-4346-9f1d-90747c6adf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-940ad2da-f2a3-4799-8bb2-e240cfc578a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-5536391c-10b8-40a1-a880-ba4f78d12d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-671dddbb-1acf-496c-a6f4-ba43d492e912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254553397-172.17.0.19-1598568851351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40799,DS-41922fa2-4f71-4b16-9f79-670f45eb95c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-03b385fe-22cf-4504-85b7-38d8a8ff3bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a95e9944-7592-492a-bd27-70aaa9cf81de,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-198af735-8b99-4eb7-909b-7f44e6e3cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-f231df47-1346-4346-9f1d-90747c6adf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-940ad2da-f2a3-4799-8bb2-e240cfc578a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-5536391c-10b8-40a1-a880-ba4f78d12d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-671dddbb-1acf-496c-a6f4-ba43d492e912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797488003-172.17.0.19-1598569080266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-e3e703e1-3a75-4d11-a6ec-73f81b72a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-b8e57a95-bd37-4fc0-9791-b9ee85219d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-7800147c-fbe4-40db-a5a4-5af1e57d3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-5e6b0009-0d09-4da5-94d3-ea1ad5d6465d,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-575805bf-ecac-4565-8168-bff590439d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-3f9574bd-422e-4677-9974-7b026e5c853d,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-62554b49-7805-43c4-9a9a-319881deaadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-d715283a-0800-42e6-b4ad-b005c9759dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797488003-172.17.0.19-1598569080266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36157,DS-e3e703e1-3a75-4d11-a6ec-73f81b72a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-b8e57a95-bd37-4fc0-9791-b9ee85219d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-7800147c-fbe4-40db-a5a4-5af1e57d3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-5e6b0009-0d09-4da5-94d3-ea1ad5d6465d,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-575805bf-ecac-4565-8168-bff590439d35,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-3f9574bd-422e-4677-9974-7b026e5c853d,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-62554b49-7805-43c4-9a9a-319881deaadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-d715283a-0800-42e6-b4ad-b005c9759dcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915349449-172.17.0.19-1598569162079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-521bd054-42ba-4528-93a4-307e65a9f486,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-31627588-f4bb-4c50-9a31-08a994d6f374,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-1c3321b2-8883-4eec-a440-a7ce8946f646,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-6e0304b7-b115-4ad5-9b3c-758894a43128,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-9930da38-46b3-42c3-92ae-e63e83c8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-122822d0-827f-41fa-8789-4a6025b184a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-5c999805-ae15-49f8-8a0f-e4962f4d6ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-3ad6a453-9c5d-4afb-9758-bf0f21dafec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915349449-172.17.0.19-1598569162079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-521bd054-42ba-4528-93a4-307e65a9f486,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-31627588-f4bb-4c50-9a31-08a994d6f374,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-1c3321b2-8883-4eec-a440-a7ce8946f646,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-6e0304b7-b115-4ad5-9b3c-758894a43128,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-9930da38-46b3-42c3-92ae-e63e83c8c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-122822d0-827f-41fa-8789-4a6025b184a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-5c999805-ae15-49f8-8a0f-e4962f4d6ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-3ad6a453-9c5d-4afb-9758-bf0f21dafec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562438858-172.17.0.19-1598569192109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-218238b3-25e6-4795-b276-0049a6b457fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-9ed93728-f70d-484c-b67d-6e91265b5ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-30103e29-0d74-4122-8a08-d0d9d5395a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-d1c0a476-b9e0-478a-8146-152cd4c58d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-14df5f25-bda2-4418-8934-777e572e46de,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-752fb3b1-f37f-4873-9d6f-cb7503606de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-93ee9503-c65c-4705-9e10-240c1054e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-1355aaf9-cd91-496f-a1bf-7c9ea606a991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562438858-172.17.0.19-1598569192109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-218238b3-25e6-4795-b276-0049a6b457fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-9ed93728-f70d-484c-b67d-6e91265b5ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-30103e29-0d74-4122-8a08-d0d9d5395a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-d1c0a476-b9e0-478a-8146-152cd4c58d91,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-14df5f25-bda2-4418-8934-777e572e46de,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-752fb3b1-f37f-4873-9d6f-cb7503606de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-93ee9503-c65c-4705-9e10-240c1054e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-1355aaf9-cd91-496f-a1bf-7c9ea606a991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071823945-172.17.0.19-1598569752372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-35de0f8e-ffac-4d08-bf28-dc8575b6756d,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2cf59420-3f90-4671-95af-56c55b47e027,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e5af1139-d94c-455f-afd4-6cb1b1a2407f,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-4215988b-1b8c-4531-9ae8-720dec5b4cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-4ede7935-13a2-4925-ab57-84bf6f9aba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-e65b7523-6453-495b-a8aa-cc4ee055b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-bf487c2c-b8c1-4a7a-8abf-50591e5673a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-04dbb2ae-51d1-4bbe-9d9c-fe6caef16033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071823945-172.17.0.19-1598569752372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-35de0f8e-ffac-4d08-bf28-dc8575b6756d,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2cf59420-3f90-4671-95af-56c55b47e027,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e5af1139-d94c-455f-afd4-6cb1b1a2407f,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-4215988b-1b8c-4531-9ae8-720dec5b4cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-4ede7935-13a2-4925-ab57-84bf6f9aba6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-e65b7523-6453-495b-a8aa-cc4ee055b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-bf487c2c-b8c1-4a7a-8abf-50591e5673a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-04dbb2ae-51d1-4bbe-9d9c-fe6caef16033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684183771-172.17.0.19-1598569832855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-5b109b96-ea5b-4a01-b6a8-9b76c3450292,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-6465e655-ddd3-4a68-9457-3c6e37168fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-26a19082-7620-43b7-b04d-c5cd02ad31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-9a60d1c2-a50b-4c7c-971e-df8dda903bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-105447e1-82d0-4a23-bdf5-986245a38682,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-4886fbef-c8d5-4480-b27a-1eff1b55d332,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-59f15ef3-6df0-43f8-bd61-de7f616a6d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-2e082b1f-bdb2-4a96-8e1c-0b6449c900a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684183771-172.17.0.19-1598569832855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-5b109b96-ea5b-4a01-b6a8-9b76c3450292,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-6465e655-ddd3-4a68-9457-3c6e37168fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-26a19082-7620-43b7-b04d-c5cd02ad31f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-9a60d1c2-a50b-4c7c-971e-df8dda903bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-105447e1-82d0-4a23-bdf5-986245a38682,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-4886fbef-c8d5-4480-b27a-1eff1b55d332,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-59f15ef3-6df0-43f8-bd61-de7f616a6d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-2e082b1f-bdb2-4a96-8e1c-0b6449c900a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134562947-172.17.0.19-1598570332612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-aaae4622-9dff-419e-b990-08fc8d234bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-af6da236-613c-42cb-8f6e-e9fa8f5b5d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-150ad36c-5252-4dfb-bcfe-d37da73d0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-7fc26907-efdc-4426-9ea9-728af2e53af0,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-c2634468-816c-47c0-b410-2bcaebe3f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-a25b57d4-dfb3-4f87-bcc0-bfded04712e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-4edcfabb-d2f0-4c1b-a24d-c7ef858017a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-94ac9f36-199f-4b58-b179-5b40cd80e9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134562947-172.17.0.19-1598570332612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-aaae4622-9dff-419e-b990-08fc8d234bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-af6da236-613c-42cb-8f6e-e9fa8f5b5d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-150ad36c-5252-4dfb-bcfe-d37da73d0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-7fc26907-efdc-4426-9ea9-728af2e53af0,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-c2634468-816c-47c0-b410-2bcaebe3f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-a25b57d4-dfb3-4f87-bcc0-bfded04712e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-4edcfabb-d2f0-4c1b-a24d-c7ef858017a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-94ac9f36-199f-4b58-b179-5b40cd80e9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799555810-172.17.0.19-1598570565490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-0607fcfa-2dfc-4b02-afe8-5394a06e317f,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a1fadcf8-568a-4b9d-a5a4-49d4e160faac,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-4157c36f-52eb-40c0-937e-8a5687cc472d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-ac1cfd23-6bc7-48eb-9da5-12b78d743636,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-2b0648d0-9db3-49e7-8822-6d1a676ec603,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-b527afa2-5194-4c5e-b68a-c41150394095,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-a4528065-9362-4a01-9710-4efa033aa7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-37138a5d-7f39-4aac-8ca6-b5f45197a731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799555810-172.17.0.19-1598570565490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-0607fcfa-2dfc-4b02-afe8-5394a06e317f,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a1fadcf8-568a-4b9d-a5a4-49d4e160faac,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-4157c36f-52eb-40c0-937e-8a5687cc472d,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-ac1cfd23-6bc7-48eb-9da5-12b78d743636,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-2b0648d0-9db3-49e7-8822-6d1a676ec603,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-b527afa2-5194-4c5e-b68a-c41150394095,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-a4528065-9362-4a01-9710-4efa033aa7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-37138a5d-7f39-4aac-8ca6-b5f45197a731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056195210-172.17.0.19-1598571786850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-fbbd4102-ea7c-4f60-a2ac-6c9898a53f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-f7671e3f-b196-407a-b09a-2176dc87c326,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-034cf325-bee4-40f2-97d9-c7933e58db79,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-99981880-ab87-405b-8d7d-adf5758f2836,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-5b19439f-56d9-465c-bfc2-6ae6f2f2bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1a817c90-97c2-4d77-8b41-8f9e21c20843,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-277f18a4-9e67-454e-a0f3-911481d850b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-52dc8797-f60c-4106-9b59-a5eaac880ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056195210-172.17.0.19-1598571786850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-fbbd4102-ea7c-4f60-a2ac-6c9898a53f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-f7671e3f-b196-407a-b09a-2176dc87c326,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-034cf325-bee4-40f2-97d9-c7933e58db79,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-99981880-ab87-405b-8d7d-adf5758f2836,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-5b19439f-56d9-465c-bfc2-6ae6f2f2bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-1a817c90-97c2-4d77-8b41-8f9e21c20843,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-277f18a4-9e67-454e-a0f3-911481d850b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-52dc8797-f60c-4106-9b59-a5eaac880ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084897959-172.17.0.19-1598573133822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-492917aa-c216-4d2d-b7fb-2d87b0c974d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-cfe6b3b0-eb58-4657-854f-495531699d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-8cea3463-4109-4eee-90e7-98b0ef50e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-2d7303fc-2672-4374-9102-2ad7deb6dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-9fa056ed-67e1-4ac9-8cf6-790292dd10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-00c5f01e-6b13-40f8-8a3a-d7a73ccd8ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-004c5e52-0283-4dba-8b7d-9edd88fc9538,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7fbcc362-6cd4-469b-8201-4e63f0d55d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084897959-172.17.0.19-1598573133822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-492917aa-c216-4d2d-b7fb-2d87b0c974d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-cfe6b3b0-eb58-4657-854f-495531699d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-8cea3463-4109-4eee-90e7-98b0ef50e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-2d7303fc-2672-4374-9102-2ad7deb6dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-9fa056ed-67e1-4ac9-8cf6-790292dd10c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-00c5f01e-6b13-40f8-8a3a-d7a73ccd8ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-004c5e52-0283-4dba-8b7d-9edd88fc9538,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7fbcc362-6cd4-469b-8201-4e63f0d55d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126503289-172.17.0.19-1598573415675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-0d0b742b-4a3e-49d4-a88c-3fd7085ce7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-5c071b14-b876-41a8-b396-5a92822e28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-10e32183-19ae-4fb3-9a72-2ecb23d6b215,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-0ed1eec4-33b0-4db1-8d16-8f0c160d3a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-9148b0ff-0843-4a66-bd56-ec98272b89e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-da7c4c12-f2c8-4449-9747-912d6b5e3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-08b24dda-d4c0-40d5-9e46-b68d60d7e555,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-764ebad6-5085-42c5-be8b-8b582a0098f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126503289-172.17.0.19-1598573415675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-0d0b742b-4a3e-49d4-a88c-3fd7085ce7db,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-5c071b14-b876-41a8-b396-5a92822e28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-10e32183-19ae-4fb3-9a72-2ecb23d6b215,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-0ed1eec4-33b0-4db1-8d16-8f0c160d3a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-9148b0ff-0843-4a66-bd56-ec98272b89e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-da7c4c12-f2c8-4449-9747-912d6b5e3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-08b24dda-d4c0-40d5-9e46-b68d60d7e555,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-764ebad6-5085-42c5-be8b-8b582a0098f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5631
