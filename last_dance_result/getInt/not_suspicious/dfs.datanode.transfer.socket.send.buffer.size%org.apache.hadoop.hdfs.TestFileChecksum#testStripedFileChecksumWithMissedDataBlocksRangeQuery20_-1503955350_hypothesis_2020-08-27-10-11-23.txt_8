reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670609169-172.17.0.14-1598523159410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-ecbb4263-fb82-478f-bf76-4b4d8e56aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-ace7c737-9eda-4d90-9688-0a65b9763ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-f0130fb1-ca18-4b1e-adaf-cc3cd60f5457,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-25d6db3b-6e9c-4120-8726-05eddf185c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-60376822-ecec-406e-8c98-a3590354767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-9c098970-4d4e-4164-a77b-4352c4bb793e,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b3ccfadb-9fd0-4865-877f-0c1f69e3f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-1b0ff3e1-5d14-41b7-919a-6c1082b56e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670609169-172.17.0.14-1598523159410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-ecbb4263-fb82-478f-bf76-4b4d8e56aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-ace7c737-9eda-4d90-9688-0a65b9763ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-f0130fb1-ca18-4b1e-adaf-cc3cd60f5457,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-25d6db3b-6e9c-4120-8726-05eddf185c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-60376822-ecec-406e-8c98-a3590354767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-9c098970-4d4e-4164-a77b-4352c4bb793e,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-b3ccfadb-9fd0-4865-877f-0c1f69e3f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-1b0ff3e1-5d14-41b7-919a-6c1082b56e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698699954-172.17.0.14-1598523611927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-80759ce8-dfdd-4342-86dc-482aaa2bcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-333632c5-4650-4dc7-9b62-95fe21001d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-66385df7-7d19-413d-a95c-0c0f131c4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c04af757-c447-4780-9af7-b5221cc12d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-c3e844ab-119c-4693-97b9-08eb7cd16454,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-118d6164-daaf-4f43-91ef-4d4bf7b78916,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-7d5df32e-b5da-4e70-977d-7a8890de6b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-8574cc5a-d20a-4924-969f-5c30177b4e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-698699954-172.17.0.14-1598523611927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-80759ce8-dfdd-4342-86dc-482aaa2bcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-333632c5-4650-4dc7-9b62-95fe21001d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-66385df7-7d19-413d-a95c-0c0f131c4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-c04af757-c447-4780-9af7-b5221cc12d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-c3e844ab-119c-4693-97b9-08eb7cd16454,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-118d6164-daaf-4f43-91ef-4d4bf7b78916,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-7d5df32e-b5da-4e70-977d-7a8890de6b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-8574cc5a-d20a-4924-969f-5c30177b4e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695654135-172.17.0.14-1598523894057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-91eeff6b-1420-4726-a05e-95179e403ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-706a253d-c7af-4094-843e-6b61272c299e,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-a22a2f55-d655-46b1-aff8-c68c12ced135,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-420b4060-0526-4195-ac61-a70dbca905e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8c60148b-ab4f-43dd-8412-28b3cab2a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-278cf796-637f-4f34-8459-0d0d1c0083de,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-c3276ee8-2c07-408e-b004-ed76dce87675,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-cf858ea9-ed99-4bdd-8cbb-b9a6f500c2d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695654135-172.17.0.14-1598523894057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39290,DS-91eeff6b-1420-4726-a05e-95179e403ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-706a253d-c7af-4094-843e-6b61272c299e,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-a22a2f55-d655-46b1-aff8-c68c12ced135,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-420b4060-0526-4195-ac61-a70dbca905e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8c60148b-ab4f-43dd-8412-28b3cab2a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-278cf796-637f-4f34-8459-0d0d1c0083de,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-c3276ee8-2c07-408e-b004-ed76dce87675,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-cf858ea9-ed99-4bdd-8cbb-b9a6f500c2d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45502428-172.17.0.14-1598523958630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-44ccf6e9-a929-48db-a3e4-b0ad63a0b796,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b30bde8a-5a94-421f-8bcb-ce39aea332a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-aa692708-dd1c-453c-9165-a96514de5bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-304aa744-101f-490e-b397-579d8f5907e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9038c505-ba17-440a-bc5c-8eb0e7099888,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-f4447fc8-fe12-4817-963e-da5a00d8e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-d0738231-470a-4a2f-8a47-817762c6a0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-42dab0a1-7421-431e-bcab-dc04a813b7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45502428-172.17.0.14-1598523958630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-44ccf6e9-a929-48db-a3e4-b0ad63a0b796,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-b30bde8a-5a94-421f-8bcb-ce39aea332a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-aa692708-dd1c-453c-9165-a96514de5bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-304aa744-101f-490e-b397-579d8f5907e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-9038c505-ba17-440a-bc5c-8eb0e7099888,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-f4447fc8-fe12-4817-963e-da5a00d8e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-d0738231-470a-4a2f-8a47-817762c6a0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-42dab0a1-7421-431e-bcab-dc04a813b7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030831183-172.17.0.14-1598524256474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-633ca01e-0bd3-4f68-a397-8b3108c4cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-2455da02-59a7-4bdb-9772-4000834ac823,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-f5c59db1-1b10-47d7-b94e-20f29fa1e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-b8b91c5b-a391-47ea-9c77-0d9ae15442f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-16f40c84-0df4-4e2c-ad4a-93fea61bb125,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-2e2c9521-dc93-440d-a731-8d8152ea5b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-93614322-2ef4-4e55-ade6-9ca3e01473d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-9386a4b6-9ba0-433b-8c7d-2a8a125a9d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030831183-172.17.0.14-1598524256474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-633ca01e-0bd3-4f68-a397-8b3108c4cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-2455da02-59a7-4bdb-9772-4000834ac823,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-f5c59db1-1b10-47d7-b94e-20f29fa1e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-b8b91c5b-a391-47ea-9c77-0d9ae15442f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-16f40c84-0df4-4e2c-ad4a-93fea61bb125,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-2e2c9521-dc93-440d-a731-8d8152ea5b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-93614322-2ef4-4e55-ade6-9ca3e01473d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-9386a4b6-9ba0-433b-8c7d-2a8a125a9d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070392379-172.17.0.14-1598524406822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-a8bb3b15-8832-451d-9c6f-c317d565014d,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-411c7f31-5b88-422c-9446-52bc1d56391f,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-e984a473-791f-4b7d-b37d-52ac4e09dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-7f9907fe-9e5e-445a-b72b-768a308f14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-875c7a9a-8dc7-4636-b931-c00cd2d7ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-851ef55a-3433-4a9e-90a5-4a9691ae48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-bea98a1a-c476-465d-9969-c967f76e512d,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-4e391082-fb34-4c5b-91d3-0d93cdeb0982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070392379-172.17.0.14-1598524406822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-a8bb3b15-8832-451d-9c6f-c317d565014d,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-411c7f31-5b88-422c-9446-52bc1d56391f,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-e984a473-791f-4b7d-b37d-52ac4e09dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-7f9907fe-9e5e-445a-b72b-768a308f14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-875c7a9a-8dc7-4636-b931-c00cd2d7ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-851ef55a-3433-4a9e-90a5-4a9691ae48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-bea98a1a-c476-465d-9969-c967f76e512d,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-4e391082-fb34-4c5b-91d3-0d93cdeb0982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378700603-172.17.0.14-1598524495955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-d60f28d2-cee7-426a-91e8-ba47b5b0f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-abe55fb1-5cfd-4b50-95e7-ff1ca0183089,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-e33dbd10-3161-4829-9f8a-041ed0e55e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-68e75ea8-6c0f-4e38-8bfe-2a7e9bf2e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-b5b311e8-6c80-4f76-b682-2e644d2a28da,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-06a2b200-b2b3-49da-9c02-1a725bda6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-80f9f5df-6ff4-4f20-94ba-cdf3337c79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-1a37336b-c74b-4372-9737-2b116ab97484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378700603-172.17.0.14-1598524495955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-d60f28d2-cee7-426a-91e8-ba47b5b0f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-abe55fb1-5cfd-4b50-95e7-ff1ca0183089,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-e33dbd10-3161-4829-9f8a-041ed0e55e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-68e75ea8-6c0f-4e38-8bfe-2a7e9bf2e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-b5b311e8-6c80-4f76-b682-2e644d2a28da,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-06a2b200-b2b3-49da-9c02-1a725bda6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-80f9f5df-6ff4-4f20-94ba-cdf3337c79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-1a37336b-c74b-4372-9737-2b116ab97484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324102510-172.17.0.14-1598524530397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-26976f6d-191c-469b-8b9d-ab266bc524b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-b1ef38a4-8e92-4cd9-a238-9b1c25b39f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-ffc972c5-d791-4ade-b606-1e05a545f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-87e3580f-68df-4cdc-95a9-245da04e1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-673cf83b-4601-43fc-812d-84304e8b189e,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-70d980fc-d328-458d-acdd-36eff2d4a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-11421fb9-440a-40da-b741-0aefa3c9da86,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-9fd059e9-f61e-4afb-bcd7-169e1f7fe3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324102510-172.17.0.14-1598524530397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-26976f6d-191c-469b-8b9d-ab266bc524b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-b1ef38a4-8e92-4cd9-a238-9b1c25b39f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-ffc972c5-d791-4ade-b606-1e05a545f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-87e3580f-68df-4cdc-95a9-245da04e1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-673cf83b-4601-43fc-812d-84304e8b189e,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-70d980fc-d328-458d-acdd-36eff2d4a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-11421fb9-440a-40da-b741-0aefa3c9da86,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-9fd059e9-f61e-4afb-bcd7-169e1f7fe3ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357704488-172.17.0.14-1598524656538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-225cd0f3-23e9-4c52-8c34-c677f9f9d821,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-5a9cec96-d259-4ce9-adea-182accc025da,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-b7e962b0-5063-4457-bc8a-ab7379ccf313,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-23f56a12-10e4-4430-ab96-ff435554190b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-d2c457ac-09e1-4bbc-9cf7-60f45afa81f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-8e9486ff-b008-42f8-bbbf-0ce00b23aae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-9c4819ea-4e0a-46f4-937e-83da0abca408,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e2d07040-0172-46b2-8989-f1dec6cdca6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357704488-172.17.0.14-1598524656538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-225cd0f3-23e9-4c52-8c34-c677f9f9d821,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-5a9cec96-d259-4ce9-adea-182accc025da,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-b7e962b0-5063-4457-bc8a-ab7379ccf313,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-23f56a12-10e4-4430-ab96-ff435554190b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-d2c457ac-09e1-4bbc-9cf7-60f45afa81f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-8e9486ff-b008-42f8-bbbf-0ce00b23aae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-9c4819ea-4e0a-46f4-937e-83da0abca408,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e2d07040-0172-46b2-8989-f1dec6cdca6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750185523-172.17.0.14-1598525349426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-2a03bd94-0d25-491a-a5a3-628d5a3d1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-69492977-9232-423b-af72-08aabf640060,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-5c4ac21f-774c-4350-93ec-95f172a8705a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-dc3a3bef-4e71-451f-b501-1557edb0bded,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-ce4665ae-ad56-4096-bcbb-5ed40119d954,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-52d97268-8374-4a34-81d0-dde5755fc328,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-4bceeea4-eaa2-4276-8b4d-196a6e1eb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-6c4ab7a9-5205-4524-bae3-f38b38322396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750185523-172.17.0.14-1598525349426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-2a03bd94-0d25-491a-a5a3-628d5a3d1c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-69492977-9232-423b-af72-08aabf640060,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-5c4ac21f-774c-4350-93ec-95f172a8705a,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-dc3a3bef-4e71-451f-b501-1557edb0bded,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-ce4665ae-ad56-4096-bcbb-5ed40119d954,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-52d97268-8374-4a34-81d0-dde5755fc328,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-4bceeea4-eaa2-4276-8b4d-196a6e1eb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-6c4ab7a9-5205-4524-bae3-f38b38322396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023210722-172.17.0.14-1598525531068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-e0b23612-d4d3-4e59-b37f-739b0f4d16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-4746b21d-c1c1-4e82-94e3-f288ef12dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-88b81d2e-c23d-4b77-b952-fe630bb2515a,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-5b3561fc-3aef-47ed-afa9-83b364931400,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5fa00970-5dab-46bd-8158-8c81aa820a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-74f31f31-62bd-4e7f-9326-44c3b41d2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-c2c48ed9-8fd8-4a01-b193-59619f918797,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7c8e0541-47d4-4e78-810a-d84dca47b36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023210722-172.17.0.14-1598525531068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-e0b23612-d4d3-4e59-b37f-739b0f4d16bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-4746b21d-c1c1-4e82-94e3-f288ef12dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-88b81d2e-c23d-4b77-b952-fe630bb2515a,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-5b3561fc-3aef-47ed-afa9-83b364931400,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5fa00970-5dab-46bd-8158-8c81aa820a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-74f31f31-62bd-4e7f-9326-44c3b41d2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-c2c48ed9-8fd8-4a01-b193-59619f918797,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7c8e0541-47d4-4e78-810a-d84dca47b36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523254760-172.17.0.14-1598525969239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-320c49f4-768f-4183-bb07-e988a713a532,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3a0a650a-716f-440a-a0c7-6526b6b5b484,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-b294b4a1-49f4-4ac0-afc8-51768085c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-2a07b95c-715f-4435-be38-223eb03b2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-a813bd49-e3e4-4202-b490-e881d405f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-d64e7937-2474-4912-8f3c-9786e7e7805d,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-06018ddd-9597-43e2-b87f-1b730de2ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-3e0e2931-328f-4ff2-ba14-688d7dee9fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523254760-172.17.0.14-1598525969239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-320c49f4-768f-4183-bb07-e988a713a532,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3a0a650a-716f-440a-a0c7-6526b6b5b484,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-b294b4a1-49f4-4ac0-afc8-51768085c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-2a07b95c-715f-4435-be38-223eb03b2b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-a813bd49-e3e4-4202-b490-e881d405f68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-d64e7937-2474-4912-8f3c-9786e7e7805d,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-06018ddd-9597-43e2-b87f-1b730de2ba98,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-3e0e2931-328f-4ff2-ba14-688d7dee9fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557735648-172.17.0.14-1598526189865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36466,DS-d711c512-2e44-4a11-97a9-7239b59c65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-04e44d4b-c101-48fa-af3d-f871ddd56f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-74bd9467-ef3e-4020-8f30-6a34613bb192,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-338c9cae-8a8b-43fe-a04e-27a159e3d338,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fa0eed73-c4aa-4e6f-8579-ed8511876781,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-df2ea533-a6c9-4647-a654-fd53de7291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-61d3de0c-ff4c-4642-8f4b-ceeca65a2cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-1c90ad2f-c24d-4ada-8be0-a02a6a09d5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557735648-172.17.0.14-1598526189865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36466,DS-d711c512-2e44-4a11-97a9-7239b59c65b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-04e44d4b-c101-48fa-af3d-f871ddd56f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-74bd9467-ef3e-4020-8f30-6a34613bb192,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-338c9cae-8a8b-43fe-a04e-27a159e3d338,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fa0eed73-c4aa-4e6f-8579-ed8511876781,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-df2ea533-a6c9-4647-a654-fd53de7291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-61d3de0c-ff4c-4642-8f4b-ceeca65a2cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-1c90ad2f-c24d-4ada-8be0-a02a6a09d5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271198312-172.17.0.14-1598526399023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-4c6cf391-5d0a-498f-b192-f7df6b7918c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-f5bbe202-bf4d-438a-9053-07b22010fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-c8ab8560-c5d3-4183-bb01-8de8d0a4d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-2eeeb073-00dd-4a33-8f57-c50db70a4558,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-f42e763e-3696-425f-bb6f-1804fc523121,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7cc04208-9dd6-4a52-a5af-ea7079396630,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-29c2e571-8314-4a00-9b30-149c3f0ea9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-47e03c7d-5642-4a1b-a1ca-489d68667881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271198312-172.17.0.14-1598526399023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-4c6cf391-5d0a-498f-b192-f7df6b7918c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-f5bbe202-bf4d-438a-9053-07b22010fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-c8ab8560-c5d3-4183-bb01-8de8d0a4d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-2eeeb073-00dd-4a33-8f57-c50db70a4558,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-f42e763e-3696-425f-bb6f-1804fc523121,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7cc04208-9dd6-4a52-a5af-ea7079396630,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-29c2e571-8314-4a00-9b30-149c3f0ea9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-47e03c7d-5642-4a1b-a1ca-489d68667881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541308292-172.17.0.14-1598526690529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-080126c9-c351-4918-b666-5c3c364fd203,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-428bbafa-3ab1-4f32-ad3f-a4ec24956829,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-2f5736fe-661c-47ae-8f9f-3ee379bcb0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-46fd897f-7294-4c0d-a095-bfe688981d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-e525d9d6-b7a9-41d7-a46a-eb9016220a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-8015255e-adbc-4715-a768-a2aa33035f32,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-18b9c7b6-32f5-4a3b-a5e3-e6b9fdfdfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-69750ada-8cd8-4660-b853-bb501250af89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541308292-172.17.0.14-1598526690529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39466,DS-080126c9-c351-4918-b666-5c3c364fd203,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-428bbafa-3ab1-4f32-ad3f-a4ec24956829,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-2f5736fe-661c-47ae-8f9f-3ee379bcb0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-46fd897f-7294-4c0d-a095-bfe688981d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-e525d9d6-b7a9-41d7-a46a-eb9016220a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-8015255e-adbc-4715-a768-a2aa33035f32,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-18b9c7b6-32f5-4a3b-a5e3-e6b9fdfdfef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-69750ada-8cd8-4660-b853-bb501250af89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442623255-172.17.0.14-1598527020775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-1d92227a-8a21-4a80-87bf-d5c8c53e79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-5c81d62c-31c6-4b49-aaa4-be4c673b25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-872b4722-770d-4085-85c9-fad5324aa5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-ea5a5b6c-44ea-44d7-9f2a-5f82fd5f0196,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-f0624600-74d3-43d8-b542-4a7d95c34c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-5430a234-3e30-4d7d-8e5d-fa9d7c4b4825,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-6086d6b9-a318-42de-8bce-a2470c50ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-fc4d8098-87ab-4456-94f0-bbb901f8b048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442623255-172.17.0.14-1598527020775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34637,DS-1d92227a-8a21-4a80-87bf-d5c8c53e79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-5c81d62c-31c6-4b49-aaa4-be4c673b25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-872b4722-770d-4085-85c9-fad5324aa5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-ea5a5b6c-44ea-44d7-9f2a-5f82fd5f0196,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-f0624600-74d3-43d8-b542-4a7d95c34c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-5430a234-3e30-4d7d-8e5d-fa9d7c4b4825,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-6086d6b9-a318-42de-8bce-a2470c50ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-fc4d8098-87ab-4456-94f0-bbb901f8b048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601467744-172.17.0.14-1598527258774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-9f1a70f9-bec7-431d-9dab-50328182e443,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-f0709bb5-1961-4b12-9fe0-6405cc6ac96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-54c07913-f96f-4b77-a8a8-31ade1cd6dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-7fb2b94c-1181-4e1e-b980-be00e9a273d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-18f5a53e-e7f8-48bf-84fd-8c9a0de50274,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f876d41e-a232-47b2-8cd7-8790749b4609,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-75f30ff9-479e-49db-8fe5-e5b79ed978ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-f99b4c05-74b6-4694-a707-62df02b90742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601467744-172.17.0.14-1598527258774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-9f1a70f9-bec7-431d-9dab-50328182e443,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-f0709bb5-1961-4b12-9fe0-6405cc6ac96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-54c07913-f96f-4b77-a8a8-31ade1cd6dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-7fb2b94c-1181-4e1e-b980-be00e9a273d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-18f5a53e-e7f8-48bf-84fd-8c9a0de50274,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f876d41e-a232-47b2-8cd7-8790749b4609,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-75f30ff9-479e-49db-8fe5-e5b79ed978ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-f99b4c05-74b6-4694-a707-62df02b90742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351774427-172.17.0.14-1598527290934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-c4eab1f1-1f74-4e82-8b1b-506314c7ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-87374144-16ec-449d-bbe6-ec7460822437,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-fd211dfd-3b25-4187-ad31-ab210d0b9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-4c234eb3-d63b-449f-948f-3670190e2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a1d456eb-de03-4ad3-8e69-12843dbde9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-c23753eb-eaed-46d1-9e49-06e90080f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-f6ad38f9-ada6-462b-b140-00f8bc208914,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-be6b2778-e123-4c41-8816-8cb6f96dcd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351774427-172.17.0.14-1598527290934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-c4eab1f1-1f74-4e82-8b1b-506314c7ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-87374144-16ec-449d-bbe6-ec7460822437,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-fd211dfd-3b25-4187-ad31-ab210d0b9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-4c234eb3-d63b-449f-948f-3670190e2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a1d456eb-de03-4ad3-8e69-12843dbde9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-c23753eb-eaed-46d1-9e49-06e90080f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-f6ad38f9-ada6-462b-b140-00f8bc208914,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-be6b2778-e123-4c41-8816-8cb6f96dcd7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765090785-172.17.0.14-1598527464447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-4de3b1d5-2d47-4007-ab4a-243a5cb02cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-b4fd57c7-4ce5-4af8-931e-f82ce06365c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-b406a61c-68c4-4538-918f-50b9453d28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-f7a46b1d-5b57-4a65-8fd5-9f6a0b6f7399,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-e57f0eac-9d56-4c18-8649-0f6a360c9d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-e8eba898-249d-4662-92b2-6c67f02175d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-5bbc20c4-e893-475f-acf6-5cc43938d450,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-1323f71a-528f-40e8-b040-f12e5a30e0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765090785-172.17.0.14-1598527464447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-4de3b1d5-2d47-4007-ab4a-243a5cb02cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-b4fd57c7-4ce5-4af8-931e-f82ce06365c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-b406a61c-68c4-4538-918f-50b9453d28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-f7a46b1d-5b57-4a65-8fd5-9f6a0b6f7399,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-e57f0eac-9d56-4c18-8649-0f6a360c9d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-e8eba898-249d-4662-92b2-6c67f02175d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-5bbc20c4-e893-475f-acf6-5cc43938d450,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-1323f71a-528f-40e8-b040-f12e5a30e0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500017324-172.17.0.14-1598527573951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-64ca88c5-4428-4d68-9ebc-8781e955720e,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-23146fc4-5d4b-45fc-9970-69f719417f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c94cd6c2-32fb-4003-b2bd-f517c6853486,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-f78d8830-cc7f-48f3-9c15-a40fcd0ddf59,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-e524344f-cf14-41c2-ae5f-c8f5c68fb463,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-36e4eaa2-4bf6-47be-b204-5d951719a570,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-9b82f2fd-3633-4192-be42-86024036058d,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-b551028f-091b-4db4-beb0-5841547273a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500017324-172.17.0.14-1598527573951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39739,DS-64ca88c5-4428-4d68-9ebc-8781e955720e,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-23146fc4-5d4b-45fc-9970-69f719417f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c94cd6c2-32fb-4003-b2bd-f517c6853486,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-f78d8830-cc7f-48f3-9c15-a40fcd0ddf59,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-e524344f-cf14-41c2-ae5f-c8f5c68fb463,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-36e4eaa2-4bf6-47be-b204-5d951719a570,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-9b82f2fd-3633-4192-be42-86024036058d,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-b551028f-091b-4db4-beb0-5841547273a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665856352-172.17.0.14-1598527989350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-1843d47b-3458-4bc3-b728-e67fd9df2428,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-75e9003c-7400-4fc0-978e-df351f0be16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-60959b73-3e9d-4228-9437-6c1efe2e159e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-67d1684a-353c-43c0-ba6f-e4c186dd2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-1a03f21b-af74-4ff0-a6cd-4e9055b18105,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-e5079adf-bd84-4292-8954-3a6805a4a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-643478a0-913c-433d-b916-e3ace31bcf99,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-b2fe4dd5-50af-44b4-b6d7-60a94f6736e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665856352-172.17.0.14-1598527989350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-1843d47b-3458-4bc3-b728-e67fd9df2428,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-75e9003c-7400-4fc0-978e-df351f0be16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-60959b73-3e9d-4228-9437-6c1efe2e159e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-67d1684a-353c-43c0-ba6f-e4c186dd2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-1a03f21b-af74-4ff0-a6cd-4e9055b18105,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-e5079adf-bd84-4292-8954-3a6805a4a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-643478a0-913c-433d-b916-e3ace31bcf99,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-b2fe4dd5-50af-44b4-b6d7-60a94f6736e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4960
