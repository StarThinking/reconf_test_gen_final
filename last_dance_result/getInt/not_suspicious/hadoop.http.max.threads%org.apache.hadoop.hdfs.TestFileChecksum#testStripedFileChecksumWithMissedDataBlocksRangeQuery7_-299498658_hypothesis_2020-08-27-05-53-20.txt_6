reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193981282-172.17.0.18-1598507877924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-fa80f512-889a-4b7a-bb4b-d1ebb959a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-645dbef8-e53f-4cd2-b11a-6e13fe97e203,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-5de05c93-c9d4-46fc-8a0b-687a7627327d,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-695c3560-e739-47df-aac8-c6fd7d30d816,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e2620448-e332-48b9-b720-505650cb08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-5de5fb9f-5743-4101-b3d4-565f6b9fcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a420ce3b-cb36-4380-80b8-be0b249def49,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-14ccd227-2468-4cb4-ac1c-b8379efb58b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193981282-172.17.0.18-1598507877924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-fa80f512-889a-4b7a-bb4b-d1ebb959a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-645dbef8-e53f-4cd2-b11a-6e13fe97e203,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-5de05c93-c9d4-46fc-8a0b-687a7627327d,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-695c3560-e739-47df-aac8-c6fd7d30d816,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-e2620448-e332-48b9-b720-505650cb08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-5de5fb9f-5743-4101-b3d4-565f6b9fcd84,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a420ce3b-cb36-4380-80b8-be0b249def49,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-14ccd227-2468-4cb4-ac1c-b8379efb58b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896930552-172.17.0.18-1598508055357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-220845b5-ea2a-4ecb-81ac-6fdc7ae376d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-3d613e53-cc12-4d8c-a035-85af950da771,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-8713e7bb-784f-4886-98cb-bf6f48f08fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-af8fc0a4-4048-4cc5-9e2d-b43370e02c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-812b2e80-c590-4a48-b53b-06cbd889a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-f05fe1dc-aa03-497e-8681-de0f6186eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-14ea38db-112b-46a6-9f52-338de9b423ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-7e7dd813-64fb-4902-add4-cc0920fef903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896930552-172.17.0.18-1598508055357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-220845b5-ea2a-4ecb-81ac-6fdc7ae376d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-3d613e53-cc12-4d8c-a035-85af950da771,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-8713e7bb-784f-4886-98cb-bf6f48f08fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-af8fc0a4-4048-4cc5-9e2d-b43370e02c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-812b2e80-c590-4a48-b53b-06cbd889a2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-f05fe1dc-aa03-497e-8681-de0f6186eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-14ea38db-112b-46a6-9f52-338de9b423ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-7e7dd813-64fb-4902-add4-cc0920fef903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106504681-172.17.0.18-1598508091697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-bb9dc4cf-4196-46bf-a59b-cc02ff536d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-dc6a6ee2-0c02-4703-b9b1-e85d348cf43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-446e3ea8-4fc1-47d4-8242-95e026f120c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-acb62801-fc3b-4160-8ecd-e4d7226a8031,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-79875b18-f7cf-4466-b468-81ce8cb3f166,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-23ded88c-37f0-4027-9f96-879ec79493aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5b4477b2-88f4-42ce-b412-af9c17505eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-12f3181a-ccc7-40b4-b232-6ccded39afc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106504681-172.17.0.18-1598508091697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-bb9dc4cf-4196-46bf-a59b-cc02ff536d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-dc6a6ee2-0c02-4703-b9b1-e85d348cf43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-446e3ea8-4fc1-47d4-8242-95e026f120c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-acb62801-fc3b-4160-8ecd-e4d7226a8031,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-79875b18-f7cf-4466-b468-81ce8cb3f166,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-23ded88c-37f0-4027-9f96-879ec79493aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5b4477b2-88f4-42ce-b412-af9c17505eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-12f3181a-ccc7-40b4-b232-6ccded39afc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410735589-172.17.0.18-1598508128634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-ee84d890-b03c-4c6b-9598-74edeea7b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-bae958e5-0b30-4af2-b330-b3ff893df1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-376df4e0-906a-4354-91e3-a7c23121e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-2a7c1743-4565-4836-811f-3da165ae8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-a97453a6-ab8e-4551-8bb6-6129fe6d7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-16d9c483-f382-4412-aef7-d4848f6101b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-3077a6fc-4e97-48c9-8408-5f053f4199a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-1357e441-3c75-4a6b-90e5-218ef2acc517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410735589-172.17.0.18-1598508128634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-ee84d890-b03c-4c6b-9598-74edeea7b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-bae958e5-0b30-4af2-b330-b3ff893df1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-376df4e0-906a-4354-91e3-a7c23121e33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-2a7c1743-4565-4836-811f-3da165ae8d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-a97453a6-ab8e-4551-8bb6-6129fe6d7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-16d9c483-f382-4412-aef7-d4848f6101b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-3077a6fc-4e97-48c9-8408-5f053f4199a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-1357e441-3c75-4a6b-90e5-218ef2acc517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804158424-172.17.0.18-1598508236304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-113096c4-4e61-4cec-9c53-301e3fecb1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d5e09a7a-94a0-4b4e-ab95-efbed69fd083,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-e95d0ebb-5c60-41ac-99d6-c5a4e3a3692c,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-acb19907-c82c-4fc6-90dc-e5363df0720d,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-09a6e375-0798-4d8a-b64c-832da9bfcdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-817854b0-06cf-44e9-b600-5fd964fc8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-a0298f9c-6747-4497-bddc-66bc4ee4d966,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e12cc12a-744b-4895-a124-3395313714ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804158424-172.17.0.18-1598508236304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-113096c4-4e61-4cec-9c53-301e3fecb1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d5e09a7a-94a0-4b4e-ab95-efbed69fd083,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-e95d0ebb-5c60-41ac-99d6-c5a4e3a3692c,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-acb19907-c82c-4fc6-90dc-e5363df0720d,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-09a6e375-0798-4d8a-b64c-832da9bfcdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-817854b0-06cf-44e9-b600-5fd964fc8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-a0298f9c-6747-4497-bddc-66bc4ee4d966,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e12cc12a-744b-4895-a124-3395313714ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436104998-172.17.0.18-1598508732945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46624,DS-7f87ebce-3cd9-4fe7-8f21-8ff49c5cf712,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-99977c36-076a-4eea-9c62-0b30b550d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-afbd2277-ba6c-4467-a333-170c97d42343,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-bcd4bd56-e41f-43a4-87f5-92f98dac8555,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-0e13978c-7aa1-477f-9392-72cd051aa1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-78dfb806-26e8-49c9-a0ce-c5af02f8f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-129cccc4-d57c-4fb3-a484-b1b33f5b2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-02482ff3-418b-4ce5-93f5-a0b05455694a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436104998-172.17.0.18-1598508732945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46624,DS-7f87ebce-3cd9-4fe7-8f21-8ff49c5cf712,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-99977c36-076a-4eea-9c62-0b30b550d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-afbd2277-ba6c-4467-a333-170c97d42343,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-bcd4bd56-e41f-43a4-87f5-92f98dac8555,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-0e13978c-7aa1-477f-9392-72cd051aa1da,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-78dfb806-26e8-49c9-a0ce-c5af02f8f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-129cccc4-d57c-4fb3-a484-b1b33f5b2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-02482ff3-418b-4ce5-93f5-a0b05455694a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087624293-172.17.0.18-1598509253529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-9b7f9b3b-fe4b-4d2b-86ac-28dcf453bc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-55b3a2e9-f4b4-4c59-915e-6b3414ab15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-667dcf01-54ae-4851-a37e-eaaf6fa08459,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-79c207d6-9b4b-469d-8702-eb43a04dab19,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-ad551e00-6e19-43a4-9ae3-d8d9a33a15ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-d9707d42-81ae-4885-9a42-feb89ccb53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-41be0430-46a7-4a1b-a8c3-7497d06155e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-4209753a-9440-4798-8a35-aab7aea988b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087624293-172.17.0.18-1598509253529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44938,DS-9b7f9b3b-fe4b-4d2b-86ac-28dcf453bc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-55b3a2e9-f4b4-4c59-915e-6b3414ab15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-667dcf01-54ae-4851-a37e-eaaf6fa08459,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-79c207d6-9b4b-469d-8702-eb43a04dab19,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-ad551e00-6e19-43a4-9ae3-d8d9a33a15ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-d9707d42-81ae-4885-9a42-feb89ccb53bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-41be0430-46a7-4a1b-a8c3-7497d06155e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-4209753a-9440-4798-8a35-aab7aea988b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804392192-172.17.0.18-1598509441309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-ee1377d5-da86-4a42-b5b3-56e732aebf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-3ebcba75-f9ed-4014-81c3-245fdeda962c,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ffe08450-0d1e-4436-b16a-e5571e4312a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-98640dc5-47f6-4279-80d6-dc79bef220ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-65c03ddf-2505-45b0-bc24-de87cae48399,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-275d8f84-8cc3-441b-b22c-e97fbbddaca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d5a5a269-3ca3-49e2-a8c7-f4774de2607c,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-3159490b-1938-4dc1-a745-b4e78ddb0078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804392192-172.17.0.18-1598509441309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-ee1377d5-da86-4a42-b5b3-56e732aebf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-3ebcba75-f9ed-4014-81c3-245fdeda962c,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ffe08450-0d1e-4436-b16a-e5571e4312a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-98640dc5-47f6-4279-80d6-dc79bef220ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-65c03ddf-2505-45b0-bc24-de87cae48399,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-275d8f84-8cc3-441b-b22c-e97fbbddaca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d5a5a269-3ca3-49e2-a8c7-f4774de2607c,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-3159490b-1938-4dc1-a745-b4e78ddb0078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976379663-172.17.0.18-1598509506201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-1945ad1f-6741-43c1-8508-6a448e8dcc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-00d040d6-364c-4489-a3d6-cfc965ae82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-227a51bb-c2d0-41d9-8b3e-0cc36fc8e39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-c084a453-c520-4bb0-b83c-b6a972c0ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-ae76ea71-b26c-42e0-a198-967df5b39962,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-a90adad8-4b04-4ddf-8962-60b13c0d3d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-fcc2e7b0-d594-4153-b904-3e0a3af6f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-a58febeb-cbca-4e6a-a2cc-f701d497e1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976379663-172.17.0.18-1598509506201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-1945ad1f-6741-43c1-8508-6a448e8dcc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-00d040d6-364c-4489-a3d6-cfc965ae82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-227a51bb-c2d0-41d9-8b3e-0cc36fc8e39f,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-c084a453-c520-4bb0-b83c-b6a972c0ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-ae76ea71-b26c-42e0-a198-967df5b39962,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-a90adad8-4b04-4ddf-8962-60b13c0d3d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-fcc2e7b0-d594-4153-b904-3e0a3af6f3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-a58febeb-cbca-4e6a-a2cc-f701d497e1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988863754-172.17.0.18-1598509547843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-da7f1c14-a0e5-4910-ac6e-539ee2313d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-f4d2be43-97a7-4d47-b198-b73e667b49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-9210794b-875d-4411-a376-f1a6c49ad735,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-59733b20-35d2-48ba-9b5e-19a367fb45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-90237b32-5b23-43d0-ade5-f696587794a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-2535a81e-e378-49ba-9f6e-a2ddb3a8cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-998fd0dd-3c23-4764-a792-f43955c02625,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-83d70f54-4961-461e-b233-9fb1b7e6d6a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988863754-172.17.0.18-1598509547843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-da7f1c14-a0e5-4910-ac6e-539ee2313d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-f4d2be43-97a7-4d47-b198-b73e667b49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-9210794b-875d-4411-a376-f1a6c49ad735,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-59733b20-35d2-48ba-9b5e-19a367fb45a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-90237b32-5b23-43d0-ade5-f696587794a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-2535a81e-e378-49ba-9f6e-a2ddb3a8cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-998fd0dd-3c23-4764-a792-f43955c02625,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-83d70f54-4961-461e-b233-9fb1b7e6d6a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438247534-172.17.0.18-1598509761797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-5eb4a82f-56e8-4aa4-9287-2e66a1fab496,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-eb9bd8e5-337d-4124-a377-3e6ba5895321,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-4ad5c72d-52d5-4fd1-a1fd-da650efe736c,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-b87d1311-b16f-4fd3-b712-45888fe417c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-0cf417a0-1454-4096-b84c-049479c7c281,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b9126745-1b25-4acc-95b2-c8f1fbfb69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-10c27099-b633-4dea-8999-31f6aadbb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2349f1ee-9ce6-4ce8-87ba-125eb8d1c35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438247534-172.17.0.18-1598509761797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-5eb4a82f-56e8-4aa4-9287-2e66a1fab496,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-eb9bd8e5-337d-4124-a377-3e6ba5895321,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-4ad5c72d-52d5-4fd1-a1fd-da650efe736c,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-b87d1311-b16f-4fd3-b712-45888fe417c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-0cf417a0-1454-4096-b84c-049479c7c281,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b9126745-1b25-4acc-95b2-c8f1fbfb69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-10c27099-b633-4dea-8999-31f6aadbb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2349f1ee-9ce6-4ce8-87ba-125eb8d1c35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011767377-172.17.0.18-1598509901597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-7ea96801-095f-4275-b7e1-5f3ce8df2dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-79073166-832b-4182-b42b-05e95d773890,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-33cf6437-0733-409c-a2dc-ebafdca32287,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-a328799d-403d-4e6f-b8fe-babaff52a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-26ff5a63-6b8d-4f28-b4c2-91aae7a6b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-3d3f68ec-b724-4f8f-b692-94be4e8a52ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-f320b426-ebcd-4401-86a2-1ed8fcb5bea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-06c7df1a-04a1-4f71-a4b4-c38a76331f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011767377-172.17.0.18-1598509901597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-7ea96801-095f-4275-b7e1-5f3ce8df2dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-79073166-832b-4182-b42b-05e95d773890,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-33cf6437-0733-409c-a2dc-ebafdca32287,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-a328799d-403d-4e6f-b8fe-babaff52a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-26ff5a63-6b8d-4f28-b4c2-91aae7a6b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-3d3f68ec-b724-4f8f-b692-94be4e8a52ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-f320b426-ebcd-4401-86a2-1ed8fcb5bea4,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-06c7df1a-04a1-4f71-a4b4-c38a76331f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584838061-172.17.0.18-1598510071160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34246,DS-196f22b3-a890-4259-b1fe-90f7bd256560,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-169e0bdd-e206-4d22-bd0c-a945e8c9b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-f82fd7fc-317c-4c3c-a942-1292097cba16,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-f27d10c9-c9d3-4dc5-a257-94e0cb2b3cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-d0d76654-73c1-41f0-a17a-2f1709bb126f,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-835c55f8-a2c4-4be3-883a-b94fe011eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-c3a07c78-0390-48c9-a31a-c8e5f4642245,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-86d723df-44ee-4b0b-9c51-ee6fd301f1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584838061-172.17.0.18-1598510071160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34246,DS-196f22b3-a890-4259-b1fe-90f7bd256560,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-169e0bdd-e206-4d22-bd0c-a945e8c9b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-f82fd7fc-317c-4c3c-a942-1292097cba16,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-f27d10c9-c9d3-4dc5-a257-94e0cb2b3cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-d0d76654-73c1-41f0-a17a-2f1709bb126f,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-835c55f8-a2c4-4be3-883a-b94fe011eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-c3a07c78-0390-48c9-a31a-c8e5f4642245,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-86d723df-44ee-4b0b-9c51-ee6fd301f1bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961149060-172.17.0.18-1598510140156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-84c8296c-6aaa-448c-88c8-4e077ae63bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-d0b74d58-26d5-419b-97cf-c8210515e7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-a5899a87-e11c-400a-9145-77681a65c973,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-80cb69f4-5524-4750-a773-81f63215081f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-a91424e1-61d5-462e-b13c-635c39f275b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-79ccfedb-dc94-4dd5-9a23-d29582df62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-30911d96-cd96-4e6f-8f28-6269ec6d4240,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-f0b6b23f-e8ff-40c1-a1b5-06dd00e8e090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961149060-172.17.0.18-1598510140156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-84c8296c-6aaa-448c-88c8-4e077ae63bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-d0b74d58-26d5-419b-97cf-c8210515e7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-a5899a87-e11c-400a-9145-77681a65c973,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-80cb69f4-5524-4750-a773-81f63215081f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-a91424e1-61d5-462e-b13c-635c39f275b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-79ccfedb-dc94-4dd5-9a23-d29582df62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-30911d96-cd96-4e6f-8f28-6269ec6d4240,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-f0b6b23f-e8ff-40c1-a1b5-06dd00e8e090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132961798-172.17.0.18-1598510288818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-df38a9db-ecba-40aa-a468-1b18b5658497,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e29518e3-5458-4cd9-9a8b-a58a77b22831,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-56dd54a8-674b-4d67-92da-ff03a53cd7df,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-f6ce725b-6232-4e4b-a2d0-f6c4fdce6784,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-8eaadab8-1d30-4945-b985-32cbd758eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-db964dd6-b61c-4026-ab65-c2c148ba0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-baa0977d-455a-45ee-bef0-e1a1d31198b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-9d6242c7-44fc-46f9-92c3-2a9ae614e238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132961798-172.17.0.18-1598510288818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-df38a9db-ecba-40aa-a468-1b18b5658497,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e29518e3-5458-4cd9-9a8b-a58a77b22831,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-56dd54a8-674b-4d67-92da-ff03a53cd7df,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-f6ce725b-6232-4e4b-a2d0-f6c4fdce6784,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-8eaadab8-1d30-4945-b985-32cbd758eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-db964dd6-b61c-4026-ab65-c2c148ba0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-baa0977d-455a-45ee-bef0-e1a1d31198b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-9d6242c7-44fc-46f9-92c3-2a9ae614e238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644571555-172.17.0.18-1598510401543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-b0bbaccf-be65-49bf-a688-ef9acb4b3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-b8f4cf68-ec9c-4a8f-8557-c63bcff6445a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-4bdc7d41-a75e-4844-99b3-81c109d9581e,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-6897bcda-b65e-4e3f-bfa8-9ff5cc5f05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-6821785f-19a4-4ee2-8a16-8de10bf7aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-0cdbfb61-e677-4728-9c09-717a145cfc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-cd9c6f33-8cb9-4dc4-8489-10eca8fa9275,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-99fd7f7c-9df4-4333-8940-dd8fd3322c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644571555-172.17.0.18-1598510401543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44573,DS-b0bbaccf-be65-49bf-a688-ef9acb4b3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-b8f4cf68-ec9c-4a8f-8557-c63bcff6445a,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-4bdc7d41-a75e-4844-99b3-81c109d9581e,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-6897bcda-b65e-4e3f-bfa8-9ff5cc5f05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-6821785f-19a4-4ee2-8a16-8de10bf7aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-0cdbfb61-e677-4728-9c09-717a145cfc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-cd9c6f33-8cb9-4dc4-8489-10eca8fa9275,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-99fd7f7c-9df4-4333-8940-dd8fd3322c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031201318-172.17.0.18-1598510634004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-3b152203-8ab4-45c0-bfa4-8a7bcdf4437f,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-6eb26c37-a032-48fe-b61d-86179a4612d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-fcc49654-eb73-4e0c-9496-516836748f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-10969944-14b9-4861-9698-203788275f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-ba11648e-fe0f-40be-8193-a37c44ce616f,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-4a4a0be0-4892-47bc-828e-19c7bf996268,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-538338b2-3549-4be1-bfe2-2f80050958de,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-53e425f2-99c2-46d1-931f-f32962fada66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031201318-172.17.0.18-1598510634004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-3b152203-8ab4-45c0-bfa4-8a7bcdf4437f,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-6eb26c37-a032-48fe-b61d-86179a4612d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-fcc49654-eb73-4e0c-9496-516836748f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-10969944-14b9-4861-9698-203788275f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-ba11648e-fe0f-40be-8193-a37c44ce616f,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-4a4a0be0-4892-47bc-828e-19c7bf996268,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-538338b2-3549-4be1-bfe2-2f80050958de,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-53e425f2-99c2-46d1-931f-f32962fada66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710661196-172.17.0.18-1598510662718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-dcee228f-0ce4-4d4d-a1fe-d7af97ccbf61,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-f5ae585d-dfbf-4aca-b15b-9353951a9a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-feb8a68d-5e0a-4eeb-8e2d-ad2d5d88844f,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-ce8f2e12-97bf-4b7e-9858-8a54a7e08a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-52158398-7bf5-4f78-ac7a-1a26d33f56ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-f054da00-7639-40a4-9dc7-4fcea318bc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-dbd671ee-37bc-4cff-820c-912aa850667b,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-3b8b6ca0-a79b-4d2a-91ed-22cdc48b3289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710661196-172.17.0.18-1598510662718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-dcee228f-0ce4-4d4d-a1fe-d7af97ccbf61,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-f5ae585d-dfbf-4aca-b15b-9353951a9a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-feb8a68d-5e0a-4eeb-8e2d-ad2d5d88844f,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-ce8f2e12-97bf-4b7e-9858-8a54a7e08a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-52158398-7bf5-4f78-ac7a-1a26d33f56ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-f054da00-7639-40a4-9dc7-4fcea318bc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-dbd671ee-37bc-4cff-820c-912aa850667b,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-3b8b6ca0-a79b-4d2a-91ed-22cdc48b3289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420385033-172.17.0.18-1598510769149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-f4a74f82-426b-4ea7-8486-088c2b606f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1e5d25b8-41cc-4c48-bba1-3c7bcd6daa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-c97edfa1-752c-4a7e-bc62-f697b37fc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2f3055f2-f46c-419c-a822-4ff84d3338aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-8429a4ff-d4ce-482e-93cb-cfa6dbd92f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-f2f9c148-dc9c-4c7e-b7ef-1cd5a7775e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-49d3f416-4336-4843-a154-4dcf7298b4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-aa9a2355-0cbe-4f0e-bca0-5cf640ac159c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420385033-172.17.0.18-1598510769149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-f4a74f82-426b-4ea7-8486-088c2b606f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-1e5d25b8-41cc-4c48-bba1-3c7bcd6daa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-c97edfa1-752c-4a7e-bc62-f697b37fc9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-2f3055f2-f46c-419c-a822-4ff84d3338aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-8429a4ff-d4ce-482e-93cb-cfa6dbd92f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-f2f9c148-dc9c-4c7e-b7ef-1cd5a7775e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-49d3f416-4336-4843-a154-4dcf7298b4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-aa9a2355-0cbe-4f0e-bca0-5cf640ac159c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905973797-172.17.0.18-1598510880376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-2d3f13b8-13f6-4f42-a1ad-1356fa3bb73c,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-75839a68-ee13-4ad1-aa32-f669bb9d9008,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-3b91e947-0501-42e1-912a-07161e8e00be,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-d7fd3873-f110-4df5-9ca5-22935fa05f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-0e9692db-b73d-4259-bb8a-de638aca6055,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-d75749e3-d79e-48b8-a9e2-bafa6410b703,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-f1fd523d-3e74-4ede-b317-5ce590d7e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-88f07b2d-bc05-421b-a1f0-da417f8e77e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905973797-172.17.0.18-1598510880376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-2d3f13b8-13f6-4f42-a1ad-1356fa3bb73c,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-75839a68-ee13-4ad1-aa32-f669bb9d9008,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-3b91e947-0501-42e1-912a-07161e8e00be,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-d7fd3873-f110-4df5-9ca5-22935fa05f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-0e9692db-b73d-4259-bb8a-de638aca6055,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-d75749e3-d79e-48b8-a9e2-bafa6410b703,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-f1fd523d-3e74-4ede-b317-5ce590d7e3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-88f07b2d-bc05-421b-a1f0-da417f8e77e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679133505-172.17.0.18-1598510946552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-f3853b67-6d41-420d-8ee0-53e3bdbdea24,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-6fc72d83-8380-4814-abb4-075b435b56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-8dac412f-3259-4d80-9e89-0531b541a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-03c50469-64a2-4ffa-8a2f-21de34787b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-a7432999-11e3-4e98-94e7-f41a808659b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-4c31723f-9a52-49a9-ad10-15a2ee721de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-ed2de980-647a-4b18-ac21-b58810038975,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-f96095bd-ee3c-4274-ac49-7cbab7256b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679133505-172.17.0.18-1598510946552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-f3853b67-6d41-420d-8ee0-53e3bdbdea24,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-6fc72d83-8380-4814-abb4-075b435b56ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-8dac412f-3259-4d80-9e89-0531b541a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-03c50469-64a2-4ffa-8a2f-21de34787b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-a7432999-11e3-4e98-94e7-f41a808659b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-4c31723f-9a52-49a9-ad10-15a2ee721de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-ed2de980-647a-4b18-ac21-b58810038975,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-f96095bd-ee3c-4274-ac49-7cbab7256b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122456666-172.17.0.18-1598510980882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-b0e7cd68-cb4c-4ade-a9ba-19ccb0f6582a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-1c579555-0207-479f-af32-51dbc18d904e,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-8179da29-3016-4110-b288-ae83256c0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-8c692c01-fe8c-4322-bd93-fe76aa3a22e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-9899b99e-f48d-476c-a097-f8d64af071b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5e86218d-c2c6-4234-8a21-f0ae50b200bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-9083852e-fa31-475f-b334-959f2a3bb0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-c25c1d5e-cb87-4a11-b16b-b5d81bbce6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122456666-172.17.0.18-1598510980882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34066,DS-b0e7cd68-cb4c-4ade-a9ba-19ccb0f6582a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-1c579555-0207-479f-af32-51dbc18d904e,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-8179da29-3016-4110-b288-ae83256c0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-8c692c01-fe8c-4322-bd93-fe76aa3a22e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-9899b99e-f48d-476c-a097-f8d64af071b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5e86218d-c2c6-4234-8a21-f0ae50b200bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-9083852e-fa31-475f-b334-959f2a3bb0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-c25c1d5e-cb87-4a11-b16b-b5d81bbce6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032875998-172.17.0.18-1598511081782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33740,DS-98dd5dd8-908e-46b4-8d4a-411e1f4116bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-6257ed6a-e05b-473c-9905-ab55a7787db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-b15076c2-1961-480f-98d6-ab739b5b7456,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-997af789-b120-46dc-bb4f-2d7974e036ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-724ab870-c36c-489c-8019-9f2db124d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-ffa86abd-a157-4aa8-b83f-157ea744c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-68c8c7dc-2e70-4e36-b3a1-ce360d9d281e,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-14d7f984-db5c-4daf-9c9b-99e562d54551,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032875998-172.17.0.18-1598511081782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33740,DS-98dd5dd8-908e-46b4-8d4a-411e1f4116bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-6257ed6a-e05b-473c-9905-ab55a7787db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-b15076c2-1961-480f-98d6-ab739b5b7456,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-997af789-b120-46dc-bb4f-2d7974e036ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-724ab870-c36c-489c-8019-9f2db124d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-ffa86abd-a157-4aa8-b83f-157ea744c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-68c8c7dc-2e70-4e36-b3a1-ce360d9d281e,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-14d7f984-db5c-4daf-9c9b-99e562d54551,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170330302-172.17.0.18-1598511317405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-670ee4a0-0549-4f7b-a482-b590994b0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-bd5d57df-85c8-4b79-a85b-b556b6fe1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-0c68c316-7174-4a50-ad0e-148c0f732184,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-27cf0686-0509-4147-95e2-a6f7ede4b374,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-54d33ff2-4745-4229-852b-3edeb93b4491,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-48120400-840c-4985-b3dd-6eaa6449a27a,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-99cbaa71-8579-48b6-986b-e48501ed9d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-4605eec9-e4b3-4011-9655-1353602ab78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170330302-172.17.0.18-1598511317405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36987,DS-670ee4a0-0549-4f7b-a482-b590994b0d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-bd5d57df-85c8-4b79-a85b-b556b6fe1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-0c68c316-7174-4a50-ad0e-148c0f732184,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-27cf0686-0509-4147-95e2-a6f7ede4b374,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-54d33ff2-4745-4229-852b-3edeb93b4491,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-48120400-840c-4985-b3dd-6eaa6449a27a,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-99cbaa71-8579-48b6-986b-e48501ed9d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-4605eec9-e4b3-4011-9655-1353602ab78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637916326-172.17.0.18-1598511454034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-d69bd28f-2556-498e-84a8-5900eafed019,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-fb3db671-7130-4da6-948a-f6464d3ac1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-4a14dc54-6b2c-4ab0-ba39-bfcc85d9b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-78c61730-39cb-4cb4-873b-2ff00fa46deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-34f088b5-1b5c-493b-89e5-e3b1b66302eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-62466865-7337-4454-810d-e6504557fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-fa99e09e-7812-40bd-96ce-6cc12f72ffd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c5fec417-963c-437a-ab7e-96d2bd21708b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637916326-172.17.0.18-1598511454034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-d69bd28f-2556-498e-84a8-5900eafed019,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-fb3db671-7130-4da6-948a-f6464d3ac1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-4a14dc54-6b2c-4ab0-ba39-bfcc85d9b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-78c61730-39cb-4cb4-873b-2ff00fa46deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-34f088b5-1b5c-493b-89e5-e3b1b66302eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-62466865-7337-4454-810d-e6504557fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-fa99e09e-7812-40bd-96ce-6cc12f72ffd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c5fec417-963c-437a-ab7e-96d2bd21708b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995373512-172.17.0.18-1598511784010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-c0d1489e-de57-4467-a097-fab869b1d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-5d4fbcec-a906-4d52-ae43-c70bfdbd1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-284ca474-e0e5-4c8f-a145-515dcb314653,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-73728b35-27dd-432e-b2fa-de5023d1e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-a314a369-7996-4a03-a105-a9aab534f419,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-f7826461-5510-48f8-935c-8c26b9d898d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-7157708a-861c-42e3-a55f-c42eaa10b232,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-37a138e9-e9b2-446e-97a2-9f635d533d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995373512-172.17.0.18-1598511784010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-c0d1489e-de57-4467-a097-fab869b1d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-5d4fbcec-a906-4d52-ae43-c70bfdbd1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-284ca474-e0e5-4c8f-a145-515dcb314653,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-73728b35-27dd-432e-b2fa-de5023d1e19b,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-a314a369-7996-4a03-a105-a9aab534f419,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-f7826461-5510-48f8-935c-8c26b9d898d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-7157708a-861c-42e3-a55f-c42eaa10b232,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-37a138e9-e9b2-446e-97a2-9f635d533d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723691775-172.17.0.18-1598511877086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-1fe6f351-b84b-4638-9e00-50e71459c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2466e41d-d259-43b9-8235-d8202abbd152,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-0b454cdc-12ac-4898-a682-64e5a0c59078,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-d197f631-4d79-4cd0-83ff-dd84a11978ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-10a1dee5-ef7f-43b5-8dc5-9e0a1219b896,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8e17a613-8b3c-4609-ba4a-8b14190ca289,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-d2ca28f9-86bd-4129-b48c-fab5407b7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-52755e79-e6e1-4e6e-8900-6ef5b87535b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723691775-172.17.0.18-1598511877086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-1fe6f351-b84b-4638-9e00-50e71459c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2466e41d-d259-43b9-8235-d8202abbd152,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-0b454cdc-12ac-4898-a682-64e5a0c59078,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-d197f631-4d79-4cd0-83ff-dd84a11978ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-10a1dee5-ef7f-43b5-8dc5-9e0a1219b896,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-8e17a613-8b3c-4609-ba4a-8b14190ca289,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-d2ca28f9-86bd-4129-b48c-fab5407b7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-52755e79-e6e1-4e6e-8900-6ef5b87535b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928947598-172.17.0.18-1598512012698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-47894004-dcfa-4bd6-a073-0d511cd592ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-2404a02c-459e-40a7-89da-7af7d6f0a899,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-141d9cfe-3f2b-4185-8395-1cb45b3c0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-eb3f6b04-7803-42d9-9f91-23606e8f069e,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-47c30f08-0dc7-49d9-bc0b-0d35c28082c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-ddc5ffea-3cab-425b-97bd-f5302e1fd27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-a934ba85-71b0-446b-ab35-62017b524b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-773ad431-fd24-436c-b910-147aaf21d34f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928947598-172.17.0.18-1598512012698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-47894004-dcfa-4bd6-a073-0d511cd592ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-2404a02c-459e-40a7-89da-7af7d6f0a899,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-141d9cfe-3f2b-4185-8395-1cb45b3c0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-eb3f6b04-7803-42d9-9f91-23606e8f069e,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-47c30f08-0dc7-49d9-bc0b-0d35c28082c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-ddc5ffea-3cab-425b-97bd-f5302e1fd27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-a934ba85-71b0-446b-ab35-62017b524b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-773ad431-fd24-436c-b910-147aaf21d34f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310998996-172.17.0.18-1598512085023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-4c01ebfa-3f97-43a6-a6a8-c57880de1aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-733a38dd-335b-46cc-89cf-4f3850deb7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-32c0b23f-ab83-4df8-84ea-cc3dbf3918bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-3e0bc13e-fd16-41d1-a25d-16d7a677a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-713c59c3-cecb-4fec-828b-d6bc3bb8346a,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-709cab1c-729f-4b63-8f6a-60453c1c1175,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-61c7220d-846a-42af-b83f-18ace4041308,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-fe7b63c4-2a1a-4a91-bf83-9775ca52e049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310998996-172.17.0.18-1598512085023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-4c01ebfa-3f97-43a6-a6a8-c57880de1aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-733a38dd-335b-46cc-89cf-4f3850deb7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-32c0b23f-ab83-4df8-84ea-cc3dbf3918bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-3e0bc13e-fd16-41d1-a25d-16d7a677a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-713c59c3-cecb-4fec-828b-d6bc3bb8346a,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-709cab1c-729f-4b63-8f6a-60453c1c1175,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-61c7220d-846a-42af-b83f-18ace4041308,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-fe7b63c4-2a1a-4a91-bf83-9775ca52e049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565270254-172.17.0.18-1598512283706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-e9dec36f-a9ff-4d47-a360-3abc4bb59cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-28eeb406-77d3-4953-a749-56d53a70b013,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-00fc501d-f9c6-41fd-b188-2c13c170f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-c09a4daf-c7bc-48ba-995d-821a852ef106,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-20488c28-082c-4a55-9a63-47ce2f87833a,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-78b13a26-72f2-41ef-9958-712aaddc078b,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-7d61eb7a-750f-4a5a-a103-9d40cb3eb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-4fff32aa-a51f-4592-ae98-51a0efe017bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565270254-172.17.0.18-1598512283706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39320,DS-e9dec36f-a9ff-4d47-a360-3abc4bb59cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-28eeb406-77d3-4953-a749-56d53a70b013,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-00fc501d-f9c6-41fd-b188-2c13c170f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-c09a4daf-c7bc-48ba-995d-821a852ef106,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-20488c28-082c-4a55-9a63-47ce2f87833a,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-78b13a26-72f2-41ef-9958-712aaddc078b,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-7d61eb7a-750f-4a5a-a103-9d40cb3eb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-4fff32aa-a51f-4592-ae98-51a0efe017bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669100122-172.17.0.18-1598512548251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-6a90a177-f11d-4b79-b734-0cec7b7bd440,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-6439553d-6c28-47f9-ab96-9d7868881270,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-fe9b0bf6-bff1-4fe5-a198-63e55d0990a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-c7ea0ff1-e0d3-4477-b218-33d9f4e020ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-168cae68-434d-4f91-a3f7-d79b4bbbdd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-0552b32a-095b-4c80-a583-6033d8c1a775,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-91cdd121-9199-4d1a-b876-27e4672f652d,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-9f5fca9b-7b72-43cb-a9d8-7be82863a037,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669100122-172.17.0.18-1598512548251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-6a90a177-f11d-4b79-b734-0cec7b7bd440,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-6439553d-6c28-47f9-ab96-9d7868881270,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-fe9b0bf6-bff1-4fe5-a198-63e55d0990a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-c7ea0ff1-e0d3-4477-b218-33d9f4e020ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-168cae68-434d-4f91-a3f7-d79b4bbbdd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-0552b32a-095b-4c80-a583-6033d8c1a775,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-91cdd121-9199-4d1a-b876-27e4672f652d,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-9f5fca9b-7b72-43cb-a9d8-7be82863a037,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958432682-172.17.0.18-1598512671515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-7bb8ab37-6791-482b-afd7-3d6accd6ae87,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-6b0622ab-bed2-4d35-8215-fd895a0384a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9f84e6cd-8615-42e4-8dfc-3813fd2a1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-d8f8fd53-d65b-4ef7-9e3f-f3928a9b4889,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-cf7581f2-6273-4460-b75e-063438dc7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8a036ee5-ba38-46f4-b275-eab23da34110,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-12250cec-2829-4404-94e4-4fae7e31e594,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9ed5f369-eef2-495f-ad86-e065b23916dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958432682-172.17.0.18-1598512671515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46796,DS-7bb8ab37-6791-482b-afd7-3d6accd6ae87,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-6b0622ab-bed2-4d35-8215-fd895a0384a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9f84e6cd-8615-42e4-8dfc-3813fd2a1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-d8f8fd53-d65b-4ef7-9e3f-f3928a9b4889,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-cf7581f2-6273-4460-b75e-063438dc7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8a036ee5-ba38-46f4-b275-eab23da34110,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-12250cec-2829-4404-94e4-4fae7e31e594,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-9ed5f369-eef2-495f-ad86-e065b23916dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375813103-172.17.0.18-1598512913125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-ebdd9b1f-79dc-4af9-8640-a509b63d3493,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-34cfe3f3-b00e-432f-9083-04de636bd369,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-b3d4b648-4f90-4635-84ca-c6c9918e8e75,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8a540a5b-bc1e-4887-963e-9712b27020c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-9cf8f94d-b92a-4b9b-af2b-031d2bc3b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-41f4882c-0dcb-426f-96e0-e331252e3fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-6692fd42-1626-45fd-9ba6-c49a0ebf70dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-a18f81f9-f2e9-43c5-ab2e-16570cc66e51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375813103-172.17.0.18-1598512913125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-ebdd9b1f-79dc-4af9-8640-a509b63d3493,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-34cfe3f3-b00e-432f-9083-04de636bd369,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-b3d4b648-4f90-4635-84ca-c6c9918e8e75,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-8a540a5b-bc1e-4887-963e-9712b27020c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-9cf8f94d-b92a-4b9b-af2b-031d2bc3b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-41f4882c-0dcb-426f-96e0-e331252e3fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-6692fd42-1626-45fd-9ba6-c49a0ebf70dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-a18f81f9-f2e9-43c5-ab2e-16570cc66e51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456129830-172.17.0.18-1598512997437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-35abbd18-760b-4552-9982-f078b2205273,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-0aa696de-f2f1-4286-9ea0-54931aa68699,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-fd412697-8a14-4d18-8bb4-7cc20be83d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-29fcaaaa-635d-4484-bc11-20da0d38226d,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-038070b6-0e64-4b81-8576-46e95b03ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-4b26d736-45ae-4332-abe8-2ad010a1309e,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-4a129ff7-3c3e-4e22-9e65-557acd79b3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-980663e6-ef26-4d8e-9011-8c29433f4cd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456129830-172.17.0.18-1598512997437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-35abbd18-760b-4552-9982-f078b2205273,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-0aa696de-f2f1-4286-9ea0-54931aa68699,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-fd412697-8a14-4d18-8bb4-7cc20be83d91,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-29fcaaaa-635d-4484-bc11-20da0d38226d,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-038070b6-0e64-4b81-8576-46e95b03ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-4b26d736-45ae-4332-abe8-2ad010a1309e,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-4a129ff7-3c3e-4e22-9e65-557acd79b3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-980663e6-ef26-4d8e-9011-8c29433f4cd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134983874-172.17.0.18-1598513036579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-351364ec-81d2-4423-941d-c4ff917fe7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-69b79a9d-15e0-4f61-8db1-adf2de449c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-35e9d515-77e1-4bfc-abc6-b884d17f7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-1e73e740-98af-4c3e-9ea0-e28de27e42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-00f6946c-a2d5-4c0a-ab49-8695e4ec8724,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-df61bfb7-d7f8-48d4-9efd-357e7f773b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-477541c6-d807-4036-9e8c-1f960ae01149,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-34d9e9ed-051b-4700-94b2-2e3cbb3e4b57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134983874-172.17.0.18-1598513036579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-351364ec-81d2-4423-941d-c4ff917fe7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-69b79a9d-15e0-4f61-8db1-adf2de449c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-35e9d515-77e1-4bfc-abc6-b884d17f7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-1e73e740-98af-4c3e-9ea0-e28de27e42f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-00f6946c-a2d5-4c0a-ab49-8695e4ec8724,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-df61bfb7-d7f8-48d4-9efd-357e7f773b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-477541c6-d807-4036-9e8c-1f960ae01149,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-34d9e9ed-051b-4700-94b2-2e3cbb3e4b57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5457
