reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348088143-172.17.0.2-1598676807830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-9aa2b41a-a80d-417e-8f18-6e83dd655711,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-0708a7df-a958-4e58-80f0-c08c8b30162d,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3a3d823f-5ac1-40f2-ac92-fa822077365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-0d3a0b23-d88d-4a83-9e9b-98d538aa147a,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-8f4ae8f8-2614-4832-bcca-30151546eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-f72aebcf-2de4-4c41-9ada-9e5d7b7f9190,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-32a7163f-a89d-4339-8395-f3b0936787ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-44e3067a-eda1-4fe2-990d-e106ad5183a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348088143-172.17.0.2-1598676807830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35151,DS-9aa2b41a-a80d-417e-8f18-6e83dd655711,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-0708a7df-a958-4e58-80f0-c08c8b30162d,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3a3d823f-5ac1-40f2-ac92-fa822077365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-0d3a0b23-d88d-4a83-9e9b-98d538aa147a,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-8f4ae8f8-2614-4832-bcca-30151546eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-f72aebcf-2de4-4c41-9ada-9e5d7b7f9190,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-32a7163f-a89d-4339-8395-f3b0936787ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-44e3067a-eda1-4fe2-990d-e106ad5183a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380097929-172.17.0.2-1598676882867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-19aaa295-2647-46db-b51d-8d16afc5f091,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-4c7eeb37-7dfd-49a6-aea4-b1191ff3c276,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-6d5fd22b-ca35-4379-9710-5b77f203aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-0015e5a1-9851-4ead-b14a-8fca7c5bb320,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-d33e353b-d375-46bd-b43a-8e48696053d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-fba6f7e5-0286-4951-a419-eba858d5e870,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5917c774-3d84-45ee-a503-46dd65b2f073,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-49ffe451-b58d-4a1e-8dcd-009333751191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380097929-172.17.0.2-1598676882867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-19aaa295-2647-46db-b51d-8d16afc5f091,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-4c7eeb37-7dfd-49a6-aea4-b1191ff3c276,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-6d5fd22b-ca35-4379-9710-5b77f203aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-0015e5a1-9851-4ead-b14a-8fca7c5bb320,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-d33e353b-d375-46bd-b43a-8e48696053d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-fba6f7e5-0286-4951-a419-eba858d5e870,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5917c774-3d84-45ee-a503-46dd65b2f073,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-49ffe451-b58d-4a1e-8dcd-009333751191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141603997-172.17.0.2-1598677234031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-149bd59e-e0a4-438c-895a-217b8001d509,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-eec7983e-6f89-4c12-a44e-3fca07d12b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-b6ecbc72-6270-476e-95d6-029d424b443f,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-9ba60150-3434-4fa0-804a-3c8149ae9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-bbfe68aa-ab4a-4211-a793-159d1c0f56c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-23995703-6c2a-416c-a791-38ce89a55528,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1da84ad3-54ae-4b11-a693-3eba02010972,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-ae5f397c-c3c6-477b-90cd-5db00118cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141603997-172.17.0.2-1598677234031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41817,DS-149bd59e-e0a4-438c-895a-217b8001d509,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-eec7983e-6f89-4c12-a44e-3fca07d12b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-b6ecbc72-6270-476e-95d6-029d424b443f,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-9ba60150-3434-4fa0-804a-3c8149ae9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-bbfe68aa-ab4a-4211-a793-159d1c0f56c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-23995703-6c2a-416c-a791-38ce89a55528,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1da84ad3-54ae-4b11-a693-3eba02010972,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-ae5f397c-c3c6-477b-90cd-5db00118cbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351277747-172.17.0.2-1598678223324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-b2356b21-9c18-4aad-8ca6-f327920a96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-eba1e2c7-816e-421c-a467-5c728feb7140,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-c085bf39-e11d-4074-848b-028c608dc095,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-8bbbada6-f259-4a98-89e6-5e25021418ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-23c4108c-9e10-4cde-92d8-b02c35ca480c,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-2be7629f-6be1-496b-89c6-151b2f217d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-8d4c11cf-85e1-4ada-9878-0dfd10801175,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-b85c4567-5805-43ad-9de9-bdcb1bffa868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351277747-172.17.0.2-1598678223324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-b2356b21-9c18-4aad-8ca6-f327920a96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-eba1e2c7-816e-421c-a467-5c728feb7140,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-c085bf39-e11d-4074-848b-028c608dc095,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-8bbbada6-f259-4a98-89e6-5e25021418ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-23c4108c-9e10-4cde-92d8-b02c35ca480c,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-2be7629f-6be1-496b-89c6-151b2f217d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-8d4c11cf-85e1-4ada-9878-0dfd10801175,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-b85c4567-5805-43ad-9de9-bdcb1bffa868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907518683-172.17.0.2-1598678300808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-c90fa961-315f-4613-b78b-9617e34b8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b53863cc-087b-418c-b627-1661d3d64c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-e728538c-9a6c-46be-9afd-67c852d9498f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-bbb4c675-6445-4134-a211-f3631c139eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-68524014-8c81-4895-af80-3d5d3cc51504,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-524dbabd-bc8f-4b51-a1cc-bf70b45dd115,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-2df077c9-7c8b-4856-8c13-b8abe7eb5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a711a747-75e2-4e5f-9e07-cb0a6a6c28b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907518683-172.17.0.2-1598678300808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-c90fa961-315f-4613-b78b-9617e34b8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-b53863cc-087b-418c-b627-1661d3d64c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-e728538c-9a6c-46be-9afd-67c852d9498f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-bbb4c675-6445-4134-a211-f3631c139eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-68524014-8c81-4895-af80-3d5d3cc51504,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-524dbabd-bc8f-4b51-a1cc-bf70b45dd115,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-2df077c9-7c8b-4856-8c13-b8abe7eb5ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-a711a747-75e2-4e5f-9e07-cb0a6a6c28b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982541692-172.17.0.2-1598678638901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-1e1fb62f-5996-4103-9653-48912198b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-e31da9ca-bd1f-47d7-bbd6-fe130b1bec72,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-59806f1a-e6be-4bc2-a1ce-3abd91234a08,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-afd71602-20f1-4cf1-ba65-ec944afaccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-3fffbb99-8b13-407a-9b98-a29a404c2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-a72c42e7-c468-4567-813a-2a11717f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-ee073354-4f93-4ff0-92e4-f4273f7884ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-9befaef6-a176-46a1-a527-2187dec42449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982541692-172.17.0.2-1598678638901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-1e1fb62f-5996-4103-9653-48912198b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-e31da9ca-bd1f-47d7-bbd6-fe130b1bec72,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-59806f1a-e6be-4bc2-a1ce-3abd91234a08,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-afd71602-20f1-4cf1-ba65-ec944afaccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-3fffbb99-8b13-407a-9b98-a29a404c2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-a72c42e7-c468-4567-813a-2a11717f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-ee073354-4f93-4ff0-92e4-f4273f7884ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-9befaef6-a176-46a1-a527-2187dec42449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380796330-172.17.0.2-1598678788525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-4ffa0508-cd0c-4522-aa2d-e2d7a54ada51,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-0ccf8668-0ed3-4fcd-a44e-888626433041,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-eb1a317e-0300-4eca-8461-059a28930247,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-9c81d427-dca1-4fe8-9a72-58ef761a0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-57193f73-9796-4bd2-b131-c7b1e8d9e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-9d35bc0c-f048-471b-a380-8a4de9f2907d,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-abbbf76a-41f9-4bbe-adaf-019b0802acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7acc4350-5651-4981-b2cc-6668e0788d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380796330-172.17.0.2-1598678788525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-4ffa0508-cd0c-4522-aa2d-e2d7a54ada51,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-0ccf8668-0ed3-4fcd-a44e-888626433041,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-eb1a317e-0300-4eca-8461-059a28930247,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-9c81d427-dca1-4fe8-9a72-58ef761a0e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-57193f73-9796-4bd2-b131-c7b1e8d9e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-9d35bc0c-f048-471b-a380-8a4de9f2907d,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-abbbf76a-41f9-4bbe-adaf-019b0802acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7acc4350-5651-4981-b2cc-6668e0788d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966898350-172.17.0.2-1598679118225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-17daf7a9-8e56-442c-9fd5-0c4813d4a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-d91dd8d7-a9ff-444e-ae61-7e3388a4dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-e2fb183a-9728-48f6-8b5d-5a1bef3ee012,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-af6a65b5-6512-4710-9cac-ef51923f6448,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-b8ed4230-7878-4604-810a-adcffdf9c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-692c8ec7-27d1-46ae-8dfc-c71f92861dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-45c247e7-0b3f-4537-bae8-6c3a7588a2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-ebe494cf-8bd9-4c1b-837f-f6d959755773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966898350-172.17.0.2-1598679118225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-17daf7a9-8e56-442c-9fd5-0c4813d4a7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-d91dd8d7-a9ff-444e-ae61-7e3388a4dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-e2fb183a-9728-48f6-8b5d-5a1bef3ee012,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-af6a65b5-6512-4710-9cac-ef51923f6448,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-b8ed4230-7878-4604-810a-adcffdf9c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-692c8ec7-27d1-46ae-8dfc-c71f92861dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-45c247e7-0b3f-4537-bae8-6c3a7588a2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-ebe494cf-8bd9-4c1b-837f-f6d959755773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725553023-172.17.0.2-1598679326635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46572,DS-e1e9743e-fd1e-4eaf-bc77-6b0c3e937b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-39658b7a-f92d-45b1-a7b8-a2f76e70d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-9dbb50aa-b722-4476-b557-98a5432e0241,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-d36d0685-6191-408d-9a55-8194460dd009,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-e6c2f332-b89d-4633-8fc2-5bc20c1f21b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d2574d9b-2f6e-4861-b51f-39b1b26a78bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-8e8494ee-3b75-4151-ab67-2b1d96e3301e,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-fe7d6222-d010-4baa-b9fb-a434146b07d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725553023-172.17.0.2-1598679326635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46572,DS-e1e9743e-fd1e-4eaf-bc77-6b0c3e937b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-39658b7a-f92d-45b1-a7b8-a2f76e70d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-9dbb50aa-b722-4476-b557-98a5432e0241,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-d36d0685-6191-408d-9a55-8194460dd009,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-e6c2f332-b89d-4633-8fc2-5bc20c1f21b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d2574d9b-2f6e-4861-b51f-39b1b26a78bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-8e8494ee-3b75-4151-ab67-2b1d96e3301e,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-fe7d6222-d010-4baa-b9fb-a434146b07d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340883063-172.17.0.2-1598679554519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43777,DS-10468944-5203-4ed0-bb28-66d6e091e171,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-970ed427-ea6f-4998-9cfe-aa4995dff5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-32082ad1-2b91-45eb-8dee-914e74dde67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-1c00bef9-7c8d-4883-8eef-98d53db1d396,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-f444e742-4476-4545-8575-4f1dd63faf41,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-904d84b5-9e09-44e4-b274-5474d4079bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-e3c1c970-21ef-4eb5-a531-918551a9eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-3a359c1a-8199-4646-b4aa-09d5e290b38c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340883063-172.17.0.2-1598679554519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43777,DS-10468944-5203-4ed0-bb28-66d6e091e171,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-970ed427-ea6f-4998-9cfe-aa4995dff5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-32082ad1-2b91-45eb-8dee-914e74dde67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-1c00bef9-7c8d-4883-8eef-98d53db1d396,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-f444e742-4476-4545-8575-4f1dd63faf41,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-904d84b5-9e09-44e4-b274-5474d4079bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-e3c1c970-21ef-4eb5-a531-918551a9eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-3a359c1a-8199-4646-b4aa-09d5e290b38c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750564988-172.17.0.2-1598679813551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-4c13a76c-c0af-4255-8250-2729b6f78b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-048a86d4-7ff9-4b9e-bef5-5ac25824fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-d4ac7db7-ca39-4424-a0cc-362f63a6acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-06f8ab9f-9f69-49d7-9dc6-067353114e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-0b49c82e-d534-4e64-bb67-f8db80992beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-72c57fcb-2e9b-4248-b5e1-adcf21494980,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5d98b2b0-82c0-498f-9654-1a103012265b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-6674bf31-4d09-4025-826a-ac00c1445a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750564988-172.17.0.2-1598679813551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-4c13a76c-c0af-4255-8250-2729b6f78b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-048a86d4-7ff9-4b9e-bef5-5ac25824fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-d4ac7db7-ca39-4424-a0cc-362f63a6acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-06f8ab9f-9f69-49d7-9dc6-067353114e88,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-0b49c82e-d534-4e64-bb67-f8db80992beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-72c57fcb-2e9b-4248-b5e1-adcf21494980,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5d98b2b0-82c0-498f-9654-1a103012265b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-6674bf31-4d09-4025-826a-ac00c1445a69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692008392-172.17.0.2-1598680007956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-e23c9f07-dc0b-4a98-9822-8b549f9cb764,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-a2e67a2f-c5b4-43c7-b3e8-28c957e764d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-5be20628-c42d-4922-b44b-475f30b4660b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-eeb23d75-9bc7-4f60-94a9-77fc4a994e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-89e941c9-2e54-4e4a-9260-6bc2ccc0750e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-d1bef22a-1fa0-4e0b-8f24-cc9bff4e042c,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-8e58ee90-b080-4426-a101-11fcb317d761,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-24d4ea96-a9c2-44ab-8367-d6c9986e48cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692008392-172.17.0.2-1598680007956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32777,DS-e23c9f07-dc0b-4a98-9822-8b549f9cb764,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-a2e67a2f-c5b4-43c7-b3e8-28c957e764d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-5be20628-c42d-4922-b44b-475f30b4660b,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-eeb23d75-9bc7-4f60-94a9-77fc4a994e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-89e941c9-2e54-4e4a-9260-6bc2ccc0750e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-d1bef22a-1fa0-4e0b-8f24-cc9bff4e042c,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-8e58ee90-b080-4426-a101-11fcb317d761,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-24d4ea96-a9c2-44ab-8367-d6c9986e48cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606591241-172.17.0.2-1598680126728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44465,DS-71dd3dc7-7691-4890-b707-da656fff6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-a636bf55-91af-48a9-a969-e20b69d50c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-f89e1ff0-3ef2-4f14-ac9f-1b586f1e7b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f14778b7-9fcf-4d8e-b107-d1634e3605c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-cf6a3ba9-697e-4676-826f-708a20283043,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7d702aee-c0a6-4293-a39a-cbac57bcca15,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-32dbba7c-1904-4f05-9360-6270ed3b4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0eab3fb7-1ba5-4e71-b972-08998b4ea461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606591241-172.17.0.2-1598680126728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44465,DS-71dd3dc7-7691-4890-b707-da656fff6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-a636bf55-91af-48a9-a969-e20b69d50c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-f89e1ff0-3ef2-4f14-ac9f-1b586f1e7b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f14778b7-9fcf-4d8e-b107-d1634e3605c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-cf6a3ba9-697e-4676-826f-708a20283043,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7d702aee-c0a6-4293-a39a-cbac57bcca15,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-32dbba7c-1904-4f05-9360-6270ed3b4dab,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-0eab3fb7-1ba5-4e71-b972-08998b4ea461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335868008-172.17.0.2-1598680169930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-6aa5e093-190b-4b34-b2b0-42766b83064c,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-08d11b66-6bf9-4337-bd56-23bc23f85e89,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-50fbf6fc-8007-40c7-b8f8-d8564ecbffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-663b9e6e-6fb0-4c51-bc32-76a299703af2,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-114dff42-4c96-4071-ba38-5800b30f25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-c23bb987-6bf7-4bea-aeec-da01f49c01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-b51dce2d-286b-4a32-b0f8-6b518ee2fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-b001b35c-d7b2-49b0-a409-e24ea8e3697d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335868008-172.17.0.2-1598680169930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-6aa5e093-190b-4b34-b2b0-42766b83064c,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-08d11b66-6bf9-4337-bd56-23bc23f85e89,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-50fbf6fc-8007-40c7-b8f8-d8564ecbffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-663b9e6e-6fb0-4c51-bc32-76a299703af2,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-114dff42-4c96-4071-ba38-5800b30f25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-c23bb987-6bf7-4bea-aeec-da01f49c01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-b51dce2d-286b-4a32-b0f8-6b518ee2fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-b001b35c-d7b2-49b0-a409-e24ea8e3697d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795759974-172.17.0.2-1598680561986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-3e6a6ab6-f390-46bc-9af0-9419f04b36b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-6dd9a7aa-80ce-4bbd-8674-df1646990f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-19e66233-dea6-4acf-809b-3d19a07fa339,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-09198950-7d38-4d7d-a730-c9f60c6d0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-db13caf9-0d2f-4c1f-808e-dca9a6bee080,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-c40e02ec-2536-409a-80b1-ce829db4c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-a40b18cf-9c16-41b0-83e9-3d0a17398ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-e0980de9-a75e-431e-a44d-109dccfb6bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795759974-172.17.0.2-1598680561986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-3e6a6ab6-f390-46bc-9af0-9419f04b36b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-6dd9a7aa-80ce-4bbd-8674-df1646990f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-19e66233-dea6-4acf-809b-3d19a07fa339,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-09198950-7d38-4d7d-a730-c9f60c6d0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-db13caf9-0d2f-4c1f-808e-dca9a6bee080,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-c40e02ec-2536-409a-80b1-ce829db4c4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-a40b18cf-9c16-41b0-83e9-3d0a17398ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-e0980de9-a75e-431e-a44d-109dccfb6bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171747290-172.17.0.2-1598680815103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-22798ee8-900c-40ba-83ab-165b22ca9ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-32224075-7de4-440d-a045-511240f8d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9d8eed6f-4510-4dd1-8d1e-f7b6047c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-aa3bc5dc-22c8-47ef-a326-fbcc4b6a9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-528020d0-666d-4408-99cc-8196bba9f7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-3a81d8f5-0955-4a69-a18c-50c79c6d373c,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-c494bb31-3df1-4b47-91d5-bd3eafe0ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cae2cd36-7e6d-45c6-9c47-ab50560408db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171747290-172.17.0.2-1598680815103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-22798ee8-900c-40ba-83ab-165b22ca9ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-32224075-7de4-440d-a045-511240f8d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-9d8eed6f-4510-4dd1-8d1e-f7b6047c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-aa3bc5dc-22c8-47ef-a326-fbcc4b6a9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-528020d0-666d-4408-99cc-8196bba9f7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-3a81d8f5-0955-4a69-a18c-50c79c6d373c,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-c494bb31-3df1-4b47-91d5-bd3eafe0ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-cae2cd36-7e6d-45c6-9c47-ab50560408db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805955537-172.17.0.2-1598681103986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-52e75607-d897-4223-b030-41df0a2d4098,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-0c1cdcd5-4be4-445e-bbab-d34980c45a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-560e0e06-106d-4617-9911-481fb12ed991,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-2c694720-3a01-4974-81f0-6d06b3b89fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2f9c8bbd-1aee-4e2e-83f9-bfb0aeb25657,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-d408ebf9-461e-4634-a083-689e7001742f,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-b31d90eb-7ee0-4608-9d31-b1d66ef986a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-3d0a5431-1dcd-4aba-9b0c-dd7da9bef08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805955537-172.17.0.2-1598681103986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-52e75607-d897-4223-b030-41df0a2d4098,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-0c1cdcd5-4be4-445e-bbab-d34980c45a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-560e0e06-106d-4617-9911-481fb12ed991,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-2c694720-3a01-4974-81f0-6d06b3b89fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2f9c8bbd-1aee-4e2e-83f9-bfb0aeb25657,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-d408ebf9-461e-4634-a083-689e7001742f,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-b31d90eb-7ee0-4608-9d31-b1d66ef986a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-3d0a5431-1dcd-4aba-9b0c-dd7da9bef08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668321275-172.17.0.2-1598681242934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4f956357-a057-4aa1-ac0c-3a688deec910,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-29c1bd65-c5e8-4181-9964-e9469e99d38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-dc8b84dd-a4ec-49b2-ac22-af247a8e2edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-cd275267-1aae-44ea-af97-f65a5c4f1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-6fe4e14a-e683-4cb6-9ad1-a529120cd0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-d6cbf69f-5db8-4e40-b049-9fa2e85aca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-1dc8b650-67df-437e-ad55-dcae386ebc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-8544fcd2-ff0e-48ce-8738-8984461aac76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668321275-172.17.0.2-1598681242934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4f956357-a057-4aa1-ac0c-3a688deec910,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-29c1bd65-c5e8-4181-9964-e9469e99d38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-dc8b84dd-a4ec-49b2-ac22-af247a8e2edf,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-cd275267-1aae-44ea-af97-f65a5c4f1d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-6fe4e14a-e683-4cb6-9ad1-a529120cd0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-d6cbf69f-5db8-4e40-b049-9fa2e85aca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-1dc8b650-67df-437e-ad55-dcae386ebc36,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-8544fcd2-ff0e-48ce-8738-8984461aac76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099826539-172.17.0.2-1598681497885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-04d99a16-b2f1-469a-8bb4-24716c0e4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-f6185658-30ce-41fc-86f2-427497d35685,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-6f79f7ee-0269-4ee9-9524-656b08269c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f0e69a0-8860-41d8-a85e-fd4daad0bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-a97e5314-e34d-4aed-8253-b4769f70ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-ffdf31d1-3536-416f-a8e1-b18a69848c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-24919697-fb07-4e66-8875-00563090fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e5a6838c-afe4-41eb-bd36-3b96d11f0a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099826539-172.17.0.2-1598681497885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-04d99a16-b2f1-469a-8bb4-24716c0e4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-f6185658-30ce-41fc-86f2-427497d35685,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-6f79f7ee-0269-4ee9-9524-656b08269c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f0e69a0-8860-41d8-a85e-fd4daad0bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-a97e5314-e34d-4aed-8253-b4769f70ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-ffdf31d1-3536-416f-a8e1-b18a69848c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-24919697-fb07-4e66-8875-00563090fb75,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e5a6838c-afe4-41eb-bd36-3b96d11f0a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195806853-172.17.0.2-1598681644884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-74ebfa2f-2b5e-4448-b7c9-c4f5bf8bfd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-78b686ec-6b56-4702-a832-1d7e2b617769,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-4fe51829-c79e-4183-ac29-2924d23f4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-698dbb32-35c1-40f7-9db9-129fba8401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-2b885fd2-6949-4034-b9b0-04ec9b676a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-74c5d3a7-f11b-47dd-a0d7-e1102e38153b,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-60102b34-35c6-4853-a9d0-dbfd37f27630,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-612479ea-ec8d-4b87-85f7-8a68a5533b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195806853-172.17.0.2-1598681644884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-74ebfa2f-2b5e-4448-b7c9-c4f5bf8bfd15,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-78b686ec-6b56-4702-a832-1d7e2b617769,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-4fe51829-c79e-4183-ac29-2924d23f4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-698dbb32-35c1-40f7-9db9-129fba8401fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-2b885fd2-6949-4034-b9b0-04ec9b676a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-74c5d3a7-f11b-47dd-a0d7-e1102e38153b,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-60102b34-35c6-4853-a9d0-dbfd37f27630,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-612479ea-ec8d-4b87-85f7-8a68a5533b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497235159-172.17.0.2-1598681724843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-abe52933-5d27-421b-be4b-10f306a22e51,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-0f3a4ff9-6f14-419f-933e-ddb4018f0164,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-6e708866-9282-457b-84b2-3535e0958cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-dc9abca0-1674-41a2-9b8b-930e8aa13f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-21076c45-a714-42f2-8b7b-03d302186e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-3b3ba962-0684-4f96-9ff1-6f004ab0a786,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-51920976-23ff-4d93-ac52-fa397a8be343,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6e36f437-a3b3-4f11-94af-d463bcac6f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497235159-172.17.0.2-1598681724843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36480,DS-abe52933-5d27-421b-be4b-10f306a22e51,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-0f3a4ff9-6f14-419f-933e-ddb4018f0164,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-6e708866-9282-457b-84b2-3535e0958cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-dc9abca0-1674-41a2-9b8b-930e8aa13f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-21076c45-a714-42f2-8b7b-03d302186e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-3b3ba962-0684-4f96-9ff1-6f004ab0a786,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-51920976-23ff-4d93-ac52-fa397a8be343,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6e36f437-a3b3-4f11-94af-d463bcac6f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5615
