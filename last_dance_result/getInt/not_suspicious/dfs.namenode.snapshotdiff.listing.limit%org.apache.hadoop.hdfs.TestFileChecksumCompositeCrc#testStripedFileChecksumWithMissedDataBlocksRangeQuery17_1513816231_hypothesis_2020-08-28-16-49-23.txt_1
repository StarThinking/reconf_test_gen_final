reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717243699-172.17.0.4-1598634145576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-7b7a2834-052e-445d-9c1f-a921a5c9412e,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-80983cf3-9900-4f9e-9d03-e56abaafcbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-ad9ee8ba-7e68-47aa-aa80-a5cc64109102,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-886ed959-1d9b-413e-834a-3766fc19a096,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-103ca5e1-5b2a-45ee-93a2-fbee6c971db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c90aade9-4ba9-4411-88ed-49c29875dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-755a5c5b-18fe-42fc-8902-394bc78959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-800e1aae-c3b1-4b0e-8553-cc3ce5a854ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717243699-172.17.0.4-1598634145576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-7b7a2834-052e-445d-9c1f-a921a5c9412e,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-80983cf3-9900-4f9e-9d03-e56abaafcbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-ad9ee8ba-7e68-47aa-aa80-a5cc64109102,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-886ed959-1d9b-413e-834a-3766fc19a096,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-103ca5e1-5b2a-45ee-93a2-fbee6c971db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-c90aade9-4ba9-4411-88ed-49c29875dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-755a5c5b-18fe-42fc-8902-394bc78959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-800e1aae-c3b1-4b0e-8553-cc3ce5a854ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968879679-172.17.0.4-1598634328576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46559,DS-0be5968f-2a1c-4545-8761-ff1124272bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dbfec8aa-0139-4b74-a9bf-13e788e078c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-852fd293-6c40-4deb-aa50-effacd069cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-5c631c5a-3373-4dfb-832c-ad1606160c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-f7d6ce07-ee35-4f13-8c28-2a38db3ee5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b2328063-caf8-4405-bf65-b44be1e3669d,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-477172ab-e484-4af1-a32d-4d09008955df,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9070a587-30d7-475c-b53e-3c4c549fa43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968879679-172.17.0.4-1598634328576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46559,DS-0be5968f-2a1c-4545-8761-ff1124272bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dbfec8aa-0139-4b74-a9bf-13e788e078c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-852fd293-6c40-4deb-aa50-effacd069cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-5c631c5a-3373-4dfb-832c-ad1606160c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-f7d6ce07-ee35-4f13-8c28-2a38db3ee5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b2328063-caf8-4405-bf65-b44be1e3669d,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-477172ab-e484-4af1-a32d-4d09008955df,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-9070a587-30d7-475c-b53e-3c4c549fa43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838623380-172.17.0.4-1598634586270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-6cb55e6b-69aa-4a97-bcba-68336d2f7dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-21cc02fb-a5ad-412b-963c-1dd691d0cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-ed2dd77c-bd47-4b0d-b7e0-d4a8b2ea3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ae1008b1-977f-4978-abab-9db3f174cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-043e91a1-d916-49d2-914c-210ff3972893,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-adef9785-29b2-4be7-b9fa-977b71a0e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-044b542c-b184-47a6-88d5-198298026eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-08c82e64-6678-48ee-a0c1-b05a7b675019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838623380-172.17.0.4-1598634586270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-6cb55e6b-69aa-4a97-bcba-68336d2f7dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-21cc02fb-a5ad-412b-963c-1dd691d0cf49,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-ed2dd77c-bd47-4b0d-b7e0-d4a8b2ea3dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-ae1008b1-977f-4978-abab-9db3f174cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-043e91a1-d916-49d2-914c-210ff3972893,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-adef9785-29b2-4be7-b9fa-977b71a0e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-044b542c-b184-47a6-88d5-198298026eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-08c82e64-6678-48ee-a0c1-b05a7b675019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963273388-172.17.0.4-1598634626755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-5c1312ef-b8c4-4ec3-9b07-fae1043a28e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-96b3a113-33e0-472a-9518-f70dd1b36b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2ca31fa1-8cb4-4d06-80d5-847def85975c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-9e28ecad-875e-4302-a562-95dacbd951eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-22510305-8c47-473e-a3bd-408414fcf454,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-80e7befa-0c5d-4298-8d38-336c27fe01f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-436735c4-df96-4d0c-8659-fd3a9436264a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-1e5ef1a7-1780-47aa-a1d2-e078974c4e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963273388-172.17.0.4-1598634626755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39867,DS-5c1312ef-b8c4-4ec3-9b07-fae1043a28e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-96b3a113-33e0-472a-9518-f70dd1b36b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-2ca31fa1-8cb4-4d06-80d5-847def85975c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-9e28ecad-875e-4302-a562-95dacbd951eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-22510305-8c47-473e-a3bd-408414fcf454,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-80e7befa-0c5d-4298-8d38-336c27fe01f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-436735c4-df96-4d0c-8659-fd3a9436264a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-1e5ef1a7-1780-47aa-a1d2-e078974c4e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159776968-172.17.0.4-1598634736222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-302c893a-3eb7-426b-90c1-5e20d46d2871,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-b8ccdfa6-d9e9-4762-b539-4aa6613e4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-e613681a-cd43-4df9-95c2-241adb6cbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-030fb59a-2d5e-4b64-b21b-e944ecc937c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-815c52c0-5975-4fe2-ad9b-ecde29e2fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-6743c0e7-189f-442c-b18f-5d9d516d797f,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-79947883-49f2-4626-8a84-430c9106680d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-0fc19c1b-f4cb-476d-a589-66764de3153a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159776968-172.17.0.4-1598634736222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43791,DS-302c893a-3eb7-426b-90c1-5e20d46d2871,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-b8ccdfa6-d9e9-4762-b539-4aa6613e4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-e613681a-cd43-4df9-95c2-241adb6cbaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-030fb59a-2d5e-4b64-b21b-e944ecc937c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-815c52c0-5975-4fe2-ad9b-ecde29e2fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-6743c0e7-189f-442c-b18f-5d9d516d797f,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-79947883-49f2-4626-8a84-430c9106680d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-0fc19c1b-f4cb-476d-a589-66764de3153a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769896858-172.17.0.4-1598634776731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-fca7fbab-43c6-4122-8f25-430e007f263a,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-db3eeb20-f332-4b5c-89ea-6e62997c5659,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-bfe4eac4-086c-4ba3-abab-49df4faefb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-1fd4aa93-55dc-4654-be26-5d554578d402,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-fec2dc8d-ddae-4a36-9e84-6b1912406498,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-235fb27c-8bb5-4983-97a5-af334760f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-325855f3-1a73-4b0f-b675-30b5bc17a933,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-805a5fd9-e2ca-4e7d-9ba7-bc14b609db63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769896858-172.17.0.4-1598634776731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-fca7fbab-43c6-4122-8f25-430e007f263a,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-db3eeb20-f332-4b5c-89ea-6e62997c5659,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-bfe4eac4-086c-4ba3-abab-49df4faefb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-1fd4aa93-55dc-4654-be26-5d554578d402,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-fec2dc8d-ddae-4a36-9e84-6b1912406498,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-235fb27c-8bb5-4983-97a5-af334760f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-325855f3-1a73-4b0f-b675-30b5bc17a933,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-805a5fd9-e2ca-4e7d-9ba7-bc14b609db63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530016762-172.17.0.4-1598635143894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-ac5032c6-30f2-475f-a14f-1f2944038ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f76fab70-db81-4513-9b0b-97d90de7df62,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-19ea2658-8d19-4e2d-ad34-65f08f90c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-bf876be1-6dfb-41e8-a2e4-3033346419bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-4c8e6e6e-c745-4825-9594-1bd542774069,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-570e3557-9e4d-4d3b-9561-02681e7c4ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-a87c1d53-6906-4cd0-a3dd-e3431b00a4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-181dbe0b-9a4e-4586-b76a-a919f66cf1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530016762-172.17.0.4-1598635143894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-ac5032c6-30f2-475f-a14f-1f2944038ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-f76fab70-db81-4513-9b0b-97d90de7df62,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-19ea2658-8d19-4e2d-ad34-65f08f90c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-bf876be1-6dfb-41e8-a2e4-3033346419bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-4c8e6e6e-c745-4825-9594-1bd542774069,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-570e3557-9e4d-4d3b-9561-02681e7c4ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-a87c1d53-6906-4cd0-a3dd-e3431b00a4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-181dbe0b-9a4e-4586-b76a-a919f66cf1a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961311042-172.17.0.4-1598635245553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-a9834457-2ccf-4dad-a0f6-ad9357c132ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-53c77b09-588f-43df-9a00-cfb6cc5becab,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-838406ad-d07a-42f9-a911-1e7274b820ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-3d014006-6796-445f-a559-1a2898b9557d,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-d07463a1-9968-417e-9212-24bd5ada3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-38877d3e-6696-4d85-9436-51632e1ed977,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-6bf959fb-b362-4ed1-a371-c3902eea635e,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e5288ce5-53f1-44f8-97c9-b4eb30f279c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961311042-172.17.0.4-1598635245553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-a9834457-2ccf-4dad-a0f6-ad9357c132ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-53c77b09-588f-43df-9a00-cfb6cc5becab,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-838406ad-d07a-42f9-a911-1e7274b820ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-3d014006-6796-445f-a559-1a2898b9557d,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-d07463a1-9968-417e-9212-24bd5ada3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-38877d3e-6696-4d85-9436-51632e1ed977,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-6bf959fb-b362-4ed1-a371-c3902eea635e,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e5288ce5-53f1-44f8-97c9-b4eb30f279c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202979979-172.17.0.4-1598635939444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-9dbade5f-fc16-4e63-b21d-272b29e97e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-a8b87d04-f342-47a6-9004-7636cdd51c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-7490e027-7593-4b0f-9f90-1514f44fa524,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-9097f10d-cc65-4295-bec1-f00e0133fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9e6e95b3-7256-494c-adcf-11da49f12511,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-15780501-48b9-4985-9f50-f4b201df5998,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-6a4c4d3b-8b5b-47e2-89ce-8f0bbdc08618,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-06852c82-5be8-4457-945d-f4aeb9c0b607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202979979-172.17.0.4-1598635939444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-9dbade5f-fc16-4e63-b21d-272b29e97e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-a8b87d04-f342-47a6-9004-7636cdd51c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-7490e027-7593-4b0f-9f90-1514f44fa524,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-9097f10d-cc65-4295-bec1-f00e0133fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-9e6e95b3-7256-494c-adcf-11da49f12511,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-15780501-48b9-4985-9f50-f4b201df5998,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-6a4c4d3b-8b5b-47e2-89ce-8f0bbdc08618,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-06852c82-5be8-4457-945d-f4aeb9c0b607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031509289-172.17.0.4-1598636910477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-344ff691-33cb-4e4b-a654-8e4161cae86b,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-56618883-e4e3-43c9-8046-aba06abcef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-c252469a-dbdf-4fff-891a-e7f646543d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5d728b62-322e-4ce7-9267-f5b9022d6ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ba14e0de-85cb-413e-8d55-9fc8e4041eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-d349547c-d12e-4bbe-89ab-d8b0ebb83775,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-585b9999-a8e7-4145-92b2-654aa9189784,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-bfb3c49d-b9f1-4a39-bbb4-8282d9a28dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031509289-172.17.0.4-1598636910477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34351,DS-344ff691-33cb-4e4b-a654-8e4161cae86b,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-56618883-e4e3-43c9-8046-aba06abcef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-c252469a-dbdf-4fff-891a-e7f646543d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-5d728b62-322e-4ce7-9267-f5b9022d6ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ba14e0de-85cb-413e-8d55-9fc8e4041eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-d349547c-d12e-4bbe-89ab-d8b0ebb83775,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-585b9999-a8e7-4145-92b2-654aa9189784,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-bfb3c49d-b9f1-4a39-bbb4-8282d9a28dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358865497-172.17.0.4-1598637380164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34367,DS-a8260d53-5567-4fc6-8cf3-c5376022b066,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-8ad9eee5-c46f-4d31-8c06-87c3045ff186,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-f0ad3651-5ff4-4fe2-ac63-d5bc5763a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-3e061cea-a160-481d-b6ec-79606c1f8620,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-60edfd40-3886-4a0a-a234-f49cdc42c773,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-e0263d0f-b064-4afe-9418-bacf6739bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-e7741382-9ce1-4f4f-9f99-1707ee93dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-25d999c5-a4a9-441c-b8ae-17514f2ec985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358865497-172.17.0.4-1598637380164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34367,DS-a8260d53-5567-4fc6-8cf3-c5376022b066,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-8ad9eee5-c46f-4d31-8c06-87c3045ff186,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-f0ad3651-5ff4-4fe2-ac63-d5bc5763a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-3e061cea-a160-481d-b6ec-79606c1f8620,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-60edfd40-3886-4a0a-a234-f49cdc42c773,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-e0263d0f-b064-4afe-9418-bacf6739bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-e7741382-9ce1-4f4f-9f99-1707ee93dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-25d999c5-a4a9-441c-b8ae-17514f2ec985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976853545-172.17.0.4-1598638544777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-47cb33ce-0f93-4edf-9526-b11f80f19a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-e89f9914-3f02-4261-bd04-24e16ae6c982,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-e8616f58-be6a-4dfc-a8c7-fb40c66e8121,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-03696dbb-848b-422a-b662-68082addfe36,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-90ee4d7e-ca10-445f-80b1-59b4265bd784,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-751cf528-41b9-4578-a135-f0acd7dd14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-bf067093-2398-43d1-86c1-df287a2ff04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-37e930b9-c3a0-4d37-961c-7a88f7c4885e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976853545-172.17.0.4-1598638544777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-47cb33ce-0f93-4edf-9526-b11f80f19a45,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-e89f9914-3f02-4261-bd04-24e16ae6c982,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-e8616f58-be6a-4dfc-a8c7-fb40c66e8121,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-03696dbb-848b-422a-b662-68082addfe36,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-90ee4d7e-ca10-445f-80b1-59b4265bd784,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-751cf528-41b9-4578-a135-f0acd7dd14c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-bf067093-2398-43d1-86c1-df287a2ff04c,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-37e930b9-c3a0-4d37-961c-7a88f7c4885e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshotdiff.listing.limit
component: hdfs:NameNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688270588-172.17.0.4-1598638580948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-4397f3a7-bde4-4913-8a8c-42fbc394ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-f74f4986-3d7f-4740-be69-c415d2409c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-0bc91685-705b-4196-9cb9-c664c7430bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-febb3ac7-834a-4a31-8342-7f227f1c33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-add76df7-c845-46b6-98c8-8aeb90de8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-7b5a765c-a687-4539-801b-bade7c580f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-c74b8828-7c51-4cf7-acf2-155b06eeee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-8aff4513-ad6c-4765-bb1d-3b0edba9fbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688270588-172.17.0.4-1598638580948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-4397f3a7-bde4-4913-8a8c-42fbc394ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-f74f4986-3d7f-4740-be69-c415d2409c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-0bc91685-705b-4196-9cb9-c664c7430bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-febb3ac7-834a-4a31-8342-7f227f1c33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-add76df7-c845-46b6-98c8-8aeb90de8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-7b5a765c-a687-4539-801b-bade7c580f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-c74b8828-7c51-4cf7-acf2-155b06eeee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-8aff4513-ad6c-4765-bb1d-3b0edba9fbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5481
