reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110973731-172.17.0.15-1598568018357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-9132619e-43e7-47b0-9a62-6304f720ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-901921fc-fd39-4b84-80b7-e007d99d3736,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-5c54f67b-3e92-4d17-a67e-90e7bf2b4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-7cc6e7da-fdc4-4260-9df4-d9bce46e7e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-240f56f5-358e-4cba-8400-2fb26e5cb7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e5b8799e-23b2-4a8b-b12e-04ecf7e02abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-7077798e-eca3-468f-8852-e34bdf20fff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-18d0a5f6-28e3-4d06-a325-67347a74fff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110973731-172.17.0.15-1598568018357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-9132619e-43e7-47b0-9a62-6304f720ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-901921fc-fd39-4b84-80b7-e007d99d3736,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-5c54f67b-3e92-4d17-a67e-90e7bf2b4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-7cc6e7da-fdc4-4260-9df4-d9bce46e7e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-240f56f5-358e-4cba-8400-2fb26e5cb7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e5b8799e-23b2-4a8b-b12e-04ecf7e02abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-7077798e-eca3-468f-8852-e34bdf20fff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-18d0a5f6-28e3-4d06-a325-67347a74fff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548101189-172.17.0.15-1598568051166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-4b72f354-1c80-4380-ad9b-804a9767cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-fcf0c93e-b289-4ee7-9b78-bd39cc917ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-8527b2d6-b99b-4870-94b7-a001a24d8868,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-01841c85-bbac-4d07-80f1-ae106376be90,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-573e430d-7697-43c9-b90a-4bab6c64918e,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d9b6bae8-3470-4bd1-acc1-2843c04a3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-d5c961b8-9e60-4d64-a222-d593fef3f585,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d00b760b-7ad1-4e2f-b542-9be44a9c1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548101189-172.17.0.15-1598568051166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-4b72f354-1c80-4380-ad9b-804a9767cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-fcf0c93e-b289-4ee7-9b78-bd39cc917ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-8527b2d6-b99b-4870-94b7-a001a24d8868,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-01841c85-bbac-4d07-80f1-ae106376be90,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-573e430d-7697-43c9-b90a-4bab6c64918e,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-d9b6bae8-3470-4bd1-acc1-2843c04a3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-d5c961b8-9e60-4d64-a222-d593fef3f585,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-d00b760b-7ad1-4e2f-b542-9be44a9c1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080405257-172.17.0.15-1598568147523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-258707ce-62ef-49c8-862a-71e617f66f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-27647d7d-c450-4d5c-a62c-e648cb6b30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-b937e9d0-399e-4202-acee-e5570730d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-c2e586da-a30e-4dde-a723-19c4f484662b,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-38c8533f-bdbd-49c5-8703-0161a37e00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-bc76fe1e-1aa8-4e64-8971-b6c06d4ee7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f7975f8d-8c11-4374-955b-b9eb4292308d,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-676d5066-452d-49e6-a342-5d66920b97a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080405257-172.17.0.15-1598568147523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-258707ce-62ef-49c8-862a-71e617f66f07,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-27647d7d-c450-4d5c-a62c-e648cb6b30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-b937e9d0-399e-4202-acee-e5570730d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-c2e586da-a30e-4dde-a723-19c4f484662b,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-38c8533f-bdbd-49c5-8703-0161a37e00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-bc76fe1e-1aa8-4e64-8971-b6c06d4ee7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f7975f8d-8c11-4374-955b-b9eb4292308d,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-676d5066-452d-49e6-a342-5d66920b97a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175865000-172.17.0.15-1598568472184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-7c4a83e0-083b-4f55-9ef9-7b71737d3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-33a584c5-aa03-44ec-b8af-f8bddb9e80d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-bec96f8f-7cb7-46e6-8699-70ba9f6e52d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-1c73fc97-3a3c-432c-b778-867739eff754,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4587eded-6280-46d7-a8b5-4d604bea952e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-e884900b-8738-452b-b78b-dfc96ead2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-3a9b91d3-0575-4326-871b-8865fad9115a,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-7cae0c1a-e924-4da9-aa2b-a7f2eb5151aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175865000-172.17.0.15-1598568472184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-7c4a83e0-083b-4f55-9ef9-7b71737d3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-33a584c5-aa03-44ec-b8af-f8bddb9e80d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-bec96f8f-7cb7-46e6-8699-70ba9f6e52d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-1c73fc97-3a3c-432c-b778-867739eff754,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4587eded-6280-46d7-a8b5-4d604bea952e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-e884900b-8738-452b-b78b-dfc96ead2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-3a9b91d3-0575-4326-871b-8865fad9115a,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-7cae0c1a-e924-4da9-aa2b-a7f2eb5151aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242375549-172.17.0.15-1598568604489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39480,DS-135472ef-2413-43fa-b75e-9f77b9b05d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-cfc0ec8c-3f29-4b8b-9ed1-5d7f3e04610f,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-db126299-cc8e-4481-b3e1-678c6e9f94a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-cc473815-b3a3-42fc-932b-9140b50a8475,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-893dd56a-0a0c-4a84-8c26-1ffe62af75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-32ec2f4b-5d84-4ee1-a1f2-54501a807a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-5ead1ced-d589-4acf-b59c-123655de525a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-5328a114-f711-48bf-a61b-acae97e767cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242375549-172.17.0.15-1598568604489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39480,DS-135472ef-2413-43fa-b75e-9f77b9b05d96,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-cfc0ec8c-3f29-4b8b-9ed1-5d7f3e04610f,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-db126299-cc8e-4481-b3e1-678c6e9f94a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-cc473815-b3a3-42fc-932b-9140b50a8475,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-893dd56a-0a0c-4a84-8c26-1ffe62af75d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-32ec2f4b-5d84-4ee1-a1f2-54501a807a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-5ead1ced-d589-4acf-b59c-123655de525a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-5328a114-f711-48bf-a61b-acae97e767cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617998323-172.17.0.15-1598568678093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-9f513695-5047-4be6-be0a-57b99da4c898,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-91ebbe30-5746-4333-9bfb-175607af02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-26d36565-f042-4c19-9d8a-070a827d5266,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-015a21e6-f82f-4462-af31-6bf31f1f746d,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-9c1c1042-c5c2-4db1-a502-922485bffa00,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-a9d12592-c5f4-4ffa-9fc0-16080b6a7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-3f97dcdf-e850-479e-b1f9-894b2de54d37,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-f7a1f1cc-43dc-43d1-a00b-26ff026d1dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617998323-172.17.0.15-1598568678093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46794,DS-9f513695-5047-4be6-be0a-57b99da4c898,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-91ebbe30-5746-4333-9bfb-175607af02b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-26d36565-f042-4c19-9d8a-070a827d5266,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-015a21e6-f82f-4462-af31-6bf31f1f746d,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-9c1c1042-c5c2-4db1-a502-922485bffa00,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-a9d12592-c5f4-4ffa-9fc0-16080b6a7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-3f97dcdf-e850-479e-b1f9-894b2de54d37,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-f7a1f1cc-43dc-43d1-a00b-26ff026d1dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747967796-172.17.0.15-1598568792049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-66b62223-7c27-45ca-9e1d-6a7c540ad45b,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-e872bc9e-4f41-4b2e-8af7-0ab3df840455,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-751349dc-f6d9-4fcd-9fb9-b5e08c30530b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a9ba3cf9-0b29-4141-b63e-d862daead166,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-1b97f1c6-d73c-48f4-8261-49df1672c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-779a233d-579a-4c94-a2c4-d4b27a2fa87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-d7f92b1d-1ba3-45ef-9567-35b720ccd5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-e63199c1-fe3a-4710-ae6f-2e35fb740629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747967796-172.17.0.15-1598568792049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-66b62223-7c27-45ca-9e1d-6a7c540ad45b,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-e872bc9e-4f41-4b2e-8af7-0ab3df840455,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-751349dc-f6d9-4fcd-9fb9-b5e08c30530b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a9ba3cf9-0b29-4141-b63e-d862daead166,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-1b97f1c6-d73c-48f4-8261-49df1672c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-779a233d-579a-4c94-a2c4-d4b27a2fa87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-d7f92b1d-1ba3-45ef-9567-35b720ccd5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-e63199c1-fe3a-4710-ae6f-2e35fb740629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438519610-172.17.0.15-1598569512835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-f5b64904-e153-4efc-88be-a267248aed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-b1b24367-dc48-442d-a3a5-ca45797f350d,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-bbbc9314-c3fa-4283-898d-23bcc9bbeb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2ef57aad-bf2d-4301-8116-504e99a3f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-e7277b32-0fdd-4908-b4db-607fda6219ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-e6128a1f-72ee-4481-8ba5-b8e30aacfa32,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-a89750cf-44cc-42dc-8354-aa8e00aa43ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-14f43f8c-cab6-4ea5-9d9e-5b3cf227e2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438519610-172.17.0.15-1598569512835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-f5b64904-e153-4efc-88be-a267248aed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-b1b24367-dc48-442d-a3a5-ca45797f350d,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-bbbc9314-c3fa-4283-898d-23bcc9bbeb16,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2ef57aad-bf2d-4301-8116-504e99a3f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-e7277b32-0fdd-4908-b4db-607fda6219ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-e6128a1f-72ee-4481-8ba5-b8e30aacfa32,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-a89750cf-44cc-42dc-8354-aa8e00aa43ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-14f43f8c-cab6-4ea5-9d9e-5b3cf227e2b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640148309-172.17.0.15-1598569995873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-69db186e-15f0-4db9-927a-5704ad696163,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-8cfbdcb9-ae67-40f1-8b81-3b1df140be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-5c581ef0-647e-4dab-bc73-83fc190907eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-4a109cb7-8beb-4d3f-bdb3-c342853e10cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-19d0ea8e-1957-4272-9478-10af1faccc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-04d91d09-0f25-4e30-88f3-ba7414d1cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-25ea8f37-50e0-4ad3-9ec0-72c1475a0a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-5bd6582a-53f2-441f-b1d6-d8a86c568d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640148309-172.17.0.15-1598569995873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-69db186e-15f0-4db9-927a-5704ad696163,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-8cfbdcb9-ae67-40f1-8b81-3b1df140be7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-5c581ef0-647e-4dab-bc73-83fc190907eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-4a109cb7-8beb-4d3f-bdb3-c342853e10cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-19d0ea8e-1957-4272-9478-10af1faccc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-04d91d09-0f25-4e30-88f3-ba7414d1cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-25ea8f37-50e0-4ad3-9ec0-72c1475a0a22,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-5bd6582a-53f2-441f-b1d6-d8a86c568d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547473756-172.17.0.15-1598570108969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-bfaefb95-17f1-4b6b-a9c5-7937c0091bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-4912c0a3-1ff7-4552-bb8f-0e6e61f0f175,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0a98c18e-5c3c-4a18-b54c-32e96912bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-52a366ac-60a9-4c84-9f3c-33ad5721e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-d353954b-3eac-40a2-a25d-68e4bf3012b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-29e92108-1f99-457d-ae89-780e6efa2080,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5315b547-4b89-4d84-8393-fb75055ba1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-92ed62fa-c56f-4e14-8d8c-e3e7890351dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547473756-172.17.0.15-1598570108969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-bfaefb95-17f1-4b6b-a9c5-7937c0091bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-4912c0a3-1ff7-4552-bb8f-0e6e61f0f175,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0a98c18e-5c3c-4a18-b54c-32e96912bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-52a366ac-60a9-4c84-9f3c-33ad5721e792,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-d353954b-3eac-40a2-a25d-68e4bf3012b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-29e92108-1f99-457d-ae89-780e6efa2080,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5315b547-4b89-4d84-8393-fb75055ba1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-92ed62fa-c56f-4e14-8d8c-e3e7890351dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471033485-172.17.0.15-1598570242250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-2dcb83ba-363f-4b44-a5e1-3c5b9d377ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-56736e64-ce08-42bf-87c6-ed9e30b3c469,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-89c703f4-0239-4a59-a1ed-b3b9410b988e,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-373724dd-134c-4ef7-bd29-93c69ceea75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-caf8414b-1729-453e-93b7-41a061de4010,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0fe1822c-69b4-4a32-9dba-34285af3fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-ded98ae4-fafb-41de-8600-14cd60edf3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-fb8bee3d-35a5-4647-baf3-bddb7cb00182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-471033485-172.17.0.15-1598570242250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-2dcb83ba-363f-4b44-a5e1-3c5b9d377ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-56736e64-ce08-42bf-87c6-ed9e30b3c469,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-89c703f4-0239-4a59-a1ed-b3b9410b988e,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-373724dd-134c-4ef7-bd29-93c69ceea75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-caf8414b-1729-453e-93b7-41a061de4010,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0fe1822c-69b4-4a32-9dba-34285af3fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-ded98ae4-fafb-41de-8600-14cd60edf3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-fb8bee3d-35a5-4647-baf3-bddb7cb00182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388970006-172.17.0.15-1598570350569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-3c2b010d-36cb-4f4f-930a-bdd5c00ddee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-9ddef913-7555-45c6-9b17-8e635898f165,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e25f95a7-5d90-41e9-9e58-680b317f72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0948a96d-ff53-4188-99f1-f3149821edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-c9c4c880-f0c8-44c4-a40e-bace1ed3775b,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-9b19bd3f-c31e-4c68-adca-8173666a99a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-fa6bc249-f51d-4d7f-a0df-bda296191c54,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-a096de57-57f7-4d31-9009-76e2d0101283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388970006-172.17.0.15-1598570350569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-3c2b010d-36cb-4f4f-930a-bdd5c00ddee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-9ddef913-7555-45c6-9b17-8e635898f165,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e25f95a7-5d90-41e9-9e58-680b317f72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-0948a96d-ff53-4188-99f1-f3149821edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-c9c4c880-f0c8-44c4-a40e-bace1ed3775b,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-9b19bd3f-c31e-4c68-adca-8173666a99a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-fa6bc249-f51d-4d7f-a0df-bda296191c54,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-a096de57-57f7-4d31-9009-76e2d0101283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738486024-172.17.0.15-1598570794162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-f8e2a948-a50a-43a1-b45c-67b8f54ee832,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-5da194f0-0ea9-4a61-bba6-d2d319bd81e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-7b22af86-647b-4f5a-b2ef-dd67bea92b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-ae75a325-ab7d-4cf9-a2ff-4ccc45fb0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-77a414c8-ef83-4979-abc3-882252a2ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-dd25a2eb-45cf-4860-9999-c106f34a76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c9f99464-39b2-425a-9444-643f3d71a931,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6abd1c0f-ed53-4189-9798-7970662209b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738486024-172.17.0.15-1598570794162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-f8e2a948-a50a-43a1-b45c-67b8f54ee832,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-5da194f0-0ea9-4a61-bba6-d2d319bd81e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-7b22af86-647b-4f5a-b2ef-dd67bea92b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-ae75a325-ab7d-4cf9-a2ff-4ccc45fb0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-77a414c8-ef83-4979-abc3-882252a2ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-dd25a2eb-45cf-4860-9999-c106f34a76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c9f99464-39b2-425a-9444-643f3d71a931,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6abd1c0f-ed53-4189-9798-7970662209b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517539985-172.17.0.15-1598570899723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-ade3cebb-a073-4354-b8b7-48869544b648,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-f58aae73-c468-4d43-973b-ca706f30155d,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-ef7f54dc-bc52-4aa1-b6e8-e5b8a25797f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ad5d492d-63b2-4c6b-bb98-bc5046d44974,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-698a2406-ca45-4c97-86c5-117b1d198b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-cf3157fd-d678-4cb7-abd3-b0eaa7d40224,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-86549b73-83e7-4bcf-8028-6bcbcfb40478,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-06bb7b9c-6e51-4b2e-9444-5e2a3c2fc4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517539985-172.17.0.15-1598570899723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-ade3cebb-a073-4354-b8b7-48869544b648,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-f58aae73-c468-4d43-973b-ca706f30155d,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-ef7f54dc-bc52-4aa1-b6e8-e5b8a25797f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ad5d492d-63b2-4c6b-bb98-bc5046d44974,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-698a2406-ca45-4c97-86c5-117b1d198b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-cf3157fd-d678-4cb7-abd3-b0eaa7d40224,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-86549b73-83e7-4bcf-8028-6bcbcfb40478,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-06bb7b9c-6e51-4b2e-9444-5e2a3c2fc4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188127682-172.17.0.15-1598571109322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41247,DS-69c9e059-13cd-4dc2-86d7-539bde354231,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-00b4e6fa-531b-4177-9406-7bfae106c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d482bbb7-ed6c-47bf-b59e-916782e59b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e7506d68-264e-49d8-9698-a5d5791485d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-10e9910e-47a3-4d06-9faa-3a01b5d15a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-ca9b1e8b-20c5-4847-b05f-28a8e1b798a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0c777d3a-2dbe-405c-ba38-9984abdfa9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-7a080981-5011-4b84-997a-8f427c921336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188127682-172.17.0.15-1598571109322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41247,DS-69c9e059-13cd-4dc2-86d7-539bde354231,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-00b4e6fa-531b-4177-9406-7bfae106c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d482bbb7-ed6c-47bf-b59e-916782e59b64,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-e7506d68-264e-49d8-9698-a5d5791485d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-10e9910e-47a3-4d06-9faa-3a01b5d15a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-ca9b1e8b-20c5-4847-b05f-28a8e1b798a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0c777d3a-2dbe-405c-ba38-9984abdfa9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-7a080981-5011-4b84-997a-8f427c921336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234007863-172.17.0.15-1598571636470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-e3a9b739-6e6e-49c1-b7fb-88670635aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-9cf5be7f-2290-4de9-b367-967174c88f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-8f142925-d98d-4a0f-a87e-2cc093dd159b,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-8438570b-0655-443e-bcb0-6eb94c8cb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-21adf833-b474-409b-b94a-127f408815ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-3dbb42b7-3ea0-448d-865d-781459056f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a3697673-0f7e-41b2-a2fc-0c93df787a08,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-64fdc22a-7038-4bbb-9c2b-fb5ec740d4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234007863-172.17.0.15-1598571636470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-e3a9b739-6e6e-49c1-b7fb-88670635aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-9cf5be7f-2290-4de9-b367-967174c88f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-8f142925-d98d-4a0f-a87e-2cc093dd159b,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-8438570b-0655-443e-bcb0-6eb94c8cb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-21adf833-b474-409b-b94a-127f408815ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-3dbb42b7-3ea0-448d-865d-781459056f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-a3697673-0f7e-41b2-a2fc-0c93df787a08,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-64fdc22a-7038-4bbb-9c2b-fb5ec740d4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016690587-172.17.0.15-1598571971762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-3233e04c-893b-446a-9331-e044c659a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-36cf4e0e-2544-43c6-8952-b0a9ea8f1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-e67732e1-dd83-48af-a43d-e338e4c4543c,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-51eb6d0d-01c6-4421-9e1f-72062e1a917a,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-d5c99c77-e625-45b2-a684-4d6f6fe77a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-3ea6f2dc-0203-4348-ad93-c4627f4a7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-08d24574-ac6b-404e-ab82-4295ccc7ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-a9564799-ee90-43e2-98a0-e66416be80f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016690587-172.17.0.15-1598571971762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-3233e04c-893b-446a-9331-e044c659a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-36cf4e0e-2544-43c6-8952-b0a9ea8f1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-e67732e1-dd83-48af-a43d-e338e4c4543c,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-51eb6d0d-01c6-4421-9e1f-72062e1a917a,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-d5c99c77-e625-45b2-a684-4d6f6fe77a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-3ea6f2dc-0203-4348-ad93-c4627f4a7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-08d24574-ac6b-404e-ab82-4295ccc7ac18,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-a9564799-ee90-43e2-98a0-e66416be80f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953668235-172.17.0.15-1598572216376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42567,DS-d15d0b1a-07e8-44cb-8397-ab4559a4ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-662d52ba-4363-4bf3-94ce-7b72f4d632da,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-4ca78822-1fd0-4775-8926-54cd02cc3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-981da40d-9abe-4e7c-a867-0132b1b5154e,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-eac0ede3-6865-4933-b5e0-6a0b533f0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-2182602c-0193-47c4-bed3-ae78a02a84b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-a023fee2-7036-41f2-a36b-395fe57f6d38,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-a0b970c6-3183-493c-a0a9-df0262cc0294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953668235-172.17.0.15-1598572216376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42567,DS-d15d0b1a-07e8-44cb-8397-ab4559a4ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-662d52ba-4363-4bf3-94ce-7b72f4d632da,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-4ca78822-1fd0-4775-8926-54cd02cc3baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-981da40d-9abe-4e7c-a867-0132b1b5154e,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-eac0ede3-6865-4933-b5e0-6a0b533f0d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-2182602c-0193-47c4-bed3-ae78a02a84b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-a023fee2-7036-41f2-a36b-395fe57f6d38,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-a0b970c6-3183-493c-a0a9-df0262cc0294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510860632-172.17.0.15-1598572458191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35941,DS-ca260116-63a5-42b0-9988-1cd0e2d4db50,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-d3c44e45-d64d-49d7-bdef-132b06aa782f,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-e6f1fb7e-71be-473c-be6f-31ce4b8136a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-7b9f5ecf-9557-44a4-a4ef-02f96a836f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-61bfe700-fb67-43ba-97bc-cbb2b3180f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-fb898cc6-41ce-434c-86ee-7a56f27e689c,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-cae86595-c818-4ac4-9538-1c548e51412a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-a91c23b0-4967-43a6-b577-d5c3d481ab99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510860632-172.17.0.15-1598572458191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35941,DS-ca260116-63a5-42b0-9988-1cd0e2d4db50,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-d3c44e45-d64d-49d7-bdef-132b06aa782f,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-e6f1fb7e-71be-473c-be6f-31ce4b8136a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-7b9f5ecf-9557-44a4-a4ef-02f96a836f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-61bfe700-fb67-43ba-97bc-cbb2b3180f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-fb898cc6-41ce-434c-86ee-7a56f27e689c,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-cae86595-c818-4ac4-9538-1c548e51412a,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-a91c23b0-4967-43a6-b577-d5c3d481ab99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5174
