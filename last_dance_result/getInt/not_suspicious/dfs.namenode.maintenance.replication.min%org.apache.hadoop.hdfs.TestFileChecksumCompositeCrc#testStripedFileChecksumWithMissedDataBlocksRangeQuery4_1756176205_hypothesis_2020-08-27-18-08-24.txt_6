reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270425150-172.17.0.9-1598551716689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-0a99b2c0-0d38-48dd-94ca-e410d01b0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-1bbd8d23-27c8-4358-8202-c86e5f0df2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-7f4f7207-31fe-4d34-be06-7f8bbe2e9128,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ae86f19e-9e1b-4c06-b55f-9a8fb9b470b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-bab82a68-da14-4c92-8e0e-e0b900cbfa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-bc48b606-7e57-41a6-ac62-8e14a1d1d9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d729bf22-6d60-4165-85f8-2328cb9113f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-8fcedc4c-4ff7-430b-8e0c-928d8213eff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270425150-172.17.0.9-1598551716689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-0a99b2c0-0d38-48dd-94ca-e410d01b0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-1bbd8d23-27c8-4358-8202-c86e5f0df2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-7f4f7207-31fe-4d34-be06-7f8bbe2e9128,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ae86f19e-9e1b-4c06-b55f-9a8fb9b470b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-bab82a68-da14-4c92-8e0e-e0b900cbfa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-bc48b606-7e57-41a6-ac62-8e14a1d1d9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-d729bf22-6d60-4165-85f8-2328cb9113f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-8fcedc4c-4ff7-430b-8e0c-928d8213eff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376545888-172.17.0.9-1598551751375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-0eef5dcc-6a7c-4d14-9e99-db420748cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-9f37c35f-8e43-47b8-bedc-8e887306e493,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-11c8fa0d-4fe0-4891-b82f-941c9462f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-dff08f4d-adaa-4e26-b868-2bd24e4569de,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-dc9952db-b842-4928-99a5-693617d0c565,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-aae2c784-0b66-472c-ad45-8d6cdcbc5c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-99e35544-47b9-4676-906b-864754ca69df,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-9cf056a6-c904-47d6-ace5-e57f3d4bc722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376545888-172.17.0.9-1598551751375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-0eef5dcc-6a7c-4d14-9e99-db420748cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-9f37c35f-8e43-47b8-bedc-8e887306e493,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-11c8fa0d-4fe0-4891-b82f-941c9462f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-dff08f4d-adaa-4e26-b868-2bd24e4569de,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-dc9952db-b842-4928-99a5-693617d0c565,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-aae2c784-0b66-472c-ad45-8d6cdcbc5c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-99e35544-47b9-4676-906b-864754ca69df,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-9cf056a6-c904-47d6-ace5-e57f3d4bc722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625534866-172.17.0.9-1598551808379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-a4759d16-07e7-4eef-bd60-71f237fb5a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-7675f529-44a7-4d46-8651-550ffac72992,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-fef524df-5dd4-474b-8b69-7835b47dd2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-9063bd15-ec97-4c73-9c50-4ca5dddb31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-076d0c6e-116b-4674-b308-7c607ad4a094,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-ef86f25d-40de-4d37-a429-d7ca8ddb4699,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-c64e8658-ad17-49a7-9adc-19cca58982a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-b0506ce3-4dad-43eb-b473-5e0a484b74a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625534866-172.17.0.9-1598551808379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-a4759d16-07e7-4eef-bd60-71f237fb5a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-7675f529-44a7-4d46-8651-550ffac72992,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-fef524df-5dd4-474b-8b69-7835b47dd2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-9063bd15-ec97-4c73-9c50-4ca5dddb31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-076d0c6e-116b-4674-b308-7c607ad4a094,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-ef86f25d-40de-4d37-a429-d7ca8ddb4699,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-c64e8658-ad17-49a7-9adc-19cca58982a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-b0506ce3-4dad-43eb-b473-5e0a484b74a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596921850-172.17.0.9-1598551844363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-92224f8f-43f7-4c52-bc6f-efa346894edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-b70ef12d-6695-47d2-8db1-da8eae91ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-dc7ac323-1b3a-4cbe-bac9-89da242babf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-5c0eeca4-7c62-4106-9a93-e8d286d8a360,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-a7bb9a3a-9fd4-4d1e-abab-8053c9891bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-f0ef7f71-5477-4519-b329-cfd08033d011,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-0149b17c-b3e6-404c-9837-33781558f375,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d04f9f88-3181-4c96-9f2c-f8790c70c20d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596921850-172.17.0.9-1598551844363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-92224f8f-43f7-4c52-bc6f-efa346894edd,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-b70ef12d-6695-47d2-8db1-da8eae91ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-dc7ac323-1b3a-4cbe-bac9-89da242babf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-5c0eeca4-7c62-4106-9a93-e8d286d8a360,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-a7bb9a3a-9fd4-4d1e-abab-8053c9891bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-f0ef7f71-5477-4519-b329-cfd08033d011,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-0149b17c-b3e6-404c-9837-33781558f375,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d04f9f88-3181-4c96-9f2c-f8790c70c20d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475381450-172.17.0.9-1598552023470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-6a8fac30-5d63-423e-b219-1a443e3e9491,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-6d55e6b9-004d-4dc2-9612-b05f2538efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6743096c-71dd-48eb-a86e-8949db80fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-8c580391-663d-44d1-9dec-20910f945576,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-d7901202-feb5-4a29-87a1-3e9ad24c1c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-dfba06cd-acd1-4c5d-b87e-bd21cc3c8ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-38c2c654-1879-41bf-af95-f10829d65108,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b930ae5e-0adf-41fb-9f9a-4f09c03bd301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475381450-172.17.0.9-1598552023470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-6a8fac30-5d63-423e-b219-1a443e3e9491,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-6d55e6b9-004d-4dc2-9612-b05f2538efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6743096c-71dd-48eb-a86e-8949db80fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-8c580391-663d-44d1-9dec-20910f945576,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-d7901202-feb5-4a29-87a1-3e9ad24c1c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-dfba06cd-acd1-4c5d-b87e-bd21cc3c8ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-38c2c654-1879-41bf-af95-f10829d65108,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b930ae5e-0adf-41fb-9f9a-4f09c03bd301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590548156-172.17.0.9-1598552134290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-874c4472-6dd7-427b-a6c2-b7f97a66c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-1dd3653f-04f3-4e54-a6c0-f3581c4d4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-17f7962d-08e8-4062-ab58-fd84a284ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7c2714e3-1389-475d-ae2a-abfa2060ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-8e126c6c-2ab0-4007-b578-439fd596b8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-e38b948c-d673-47b4-84f8-d3d6e5fa1696,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-02095686-4f60-4b4f-92f5-0822b85ecbea,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-610fbe44-2bc9-449e-b350-b892835353b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590548156-172.17.0.9-1598552134290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-874c4472-6dd7-427b-a6c2-b7f97a66c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-1dd3653f-04f3-4e54-a6c0-f3581c4d4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-17f7962d-08e8-4062-ab58-fd84a284ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-7c2714e3-1389-475d-ae2a-abfa2060ce44,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-8e126c6c-2ab0-4007-b578-439fd596b8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-e38b948c-d673-47b4-84f8-d3d6e5fa1696,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-02095686-4f60-4b4f-92f5-0822b85ecbea,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-610fbe44-2bc9-449e-b350-b892835353b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959313349-172.17.0.9-1598552281968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-1302545c-b3e1-41fa-94d2-2213ef8b4f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d40da993-8119-46cd-af0c-1972f58c1919,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-e52d2a7f-6693-4d86-9fbf-5f802df58c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-c0ccadda-4545-4b07-98da-8b59a4ba8ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-263e82dc-5869-4d6a-bfaa-0c94873d2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-38247ebd-2ef1-471d-ba94-64da8be45b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-71b5bf91-538a-41f9-9bea-cf44e01ac754,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-8815be80-aecc-41f6-ab60-dc0cbaa45988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959313349-172.17.0.9-1598552281968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-1302545c-b3e1-41fa-94d2-2213ef8b4f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-d40da993-8119-46cd-af0c-1972f58c1919,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-e52d2a7f-6693-4d86-9fbf-5f802df58c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-c0ccadda-4545-4b07-98da-8b59a4ba8ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-263e82dc-5869-4d6a-bfaa-0c94873d2acf,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-38247ebd-2ef1-471d-ba94-64da8be45b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-71b5bf91-538a-41f9-9bea-cf44e01ac754,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-8815be80-aecc-41f6-ab60-dc0cbaa45988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796959914-172.17.0.9-1598552545728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-28df65e8-ecf9-41f9-899d-1aa30034f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-2b022de6-8948-4c68-b5ab-28ba1d0c37e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-4a1d7203-c7ed-40c6-870b-e2f1dce6b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-06341b7b-e172-4c4f-b951-07aa0af73ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8f2d9b06-f5c7-4998-a446-a035f963f8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8a92e252-ddf8-41ba-85cc-2044a922adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-0bd2b0c2-c0f0-498a-8070-ed4c308a962c,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-462f569c-fccc-49ee-8cd8-b3973e992c88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796959914-172.17.0.9-1598552545728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-28df65e8-ecf9-41f9-899d-1aa30034f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-2b022de6-8948-4c68-b5ab-28ba1d0c37e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-4a1d7203-c7ed-40c6-870b-e2f1dce6b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-06341b7b-e172-4c4f-b951-07aa0af73ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8f2d9b06-f5c7-4998-a446-a035f963f8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8a92e252-ddf8-41ba-85cc-2044a922adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-0bd2b0c2-c0f0-498a-8070-ed4c308a962c,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-462f569c-fccc-49ee-8cd8-b3973e992c88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507761136-172.17.0.9-1598553945932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33684,DS-bd4f539f-15ae-462e-ae84-4549c84c0195,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-9d57fc66-8d79-4e0f-8cff-23fb29772510,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9506ebc1-98ba-42ce-b409-e6f50239e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-57a06f43-2cc7-4058-b630-7476943de6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-5ad7d598-85be-460a-bee3-02dd9af78026,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-42ccef65-d5f6-461b-a649-a9ec71a9e231,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-c14babad-2dc8-4871-846a-8f47246d6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-d622452e-e7c8-463a-86e6-d42d63fd4628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507761136-172.17.0.9-1598553945932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33684,DS-bd4f539f-15ae-462e-ae84-4549c84c0195,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-9d57fc66-8d79-4e0f-8cff-23fb29772510,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9506ebc1-98ba-42ce-b409-e6f50239e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-57a06f43-2cc7-4058-b630-7476943de6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-5ad7d598-85be-460a-bee3-02dd9af78026,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-42ccef65-d5f6-461b-a649-a9ec71a9e231,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-c14babad-2dc8-4871-846a-8f47246d6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-d622452e-e7c8-463a-86e6-d42d63fd4628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095586700-172.17.0.9-1598554211161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-7220b728-4370-478d-95b4-45e61845b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-3c28a34e-1352-458e-a5f4-38d1852b4526,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-3a2c0167-987d-4c9f-803e-7baffc582532,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-6a7a8095-28d3-42d3-b74b-aea381336950,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-3e39a41e-5dfa-46ca-a9f5-fffe881c9983,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-c4d6528f-7ed1-4105-b7eb-61e1b5597b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-eba2ba06-8482-48eb-afc8-cdd1406729d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-eba72772-4eeb-45d1-a947-294922eecca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095586700-172.17.0.9-1598554211161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-7220b728-4370-478d-95b4-45e61845b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-3c28a34e-1352-458e-a5f4-38d1852b4526,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-3a2c0167-987d-4c9f-803e-7baffc582532,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-6a7a8095-28d3-42d3-b74b-aea381336950,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-3e39a41e-5dfa-46ca-a9f5-fffe881c9983,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-c4d6528f-7ed1-4105-b7eb-61e1b5597b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-eba2ba06-8482-48eb-afc8-cdd1406729d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-eba72772-4eeb-45d1-a947-294922eecca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217272203-172.17.0.9-1598554526874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-c45c70f5-9ba4-4bb0-8109-e2398b22f250,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-9648d35b-c1ea-4436-9522-e5d63d7f6645,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-01c195dd-885e-490f-90d0-da39cdf3dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-fa4a2533-52ac-4645-947d-9444248cf1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-a06806ef-9899-4dc1-ad8d-8e014a33cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-30e3ce6b-dc20-4c39-8c00-5eaedf25bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-b9b2c263-600b-4241-8bdb-5a7f42e24b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-6668c383-4a8c-4e0b-b829-61f423828c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217272203-172.17.0.9-1598554526874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-c45c70f5-9ba4-4bb0-8109-e2398b22f250,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-9648d35b-c1ea-4436-9522-e5d63d7f6645,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-01c195dd-885e-490f-90d0-da39cdf3dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-fa4a2533-52ac-4645-947d-9444248cf1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-a06806ef-9899-4dc1-ad8d-8e014a33cfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-30e3ce6b-dc20-4c39-8c00-5eaedf25bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-b9b2c263-600b-4241-8bdb-5a7f42e24b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-6668c383-4a8c-4e0b-b829-61f423828c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346808502-172.17.0.9-1598554837083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-0a25d5f6-f866-47c3-8df8-e5aed3806fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b84c8f12-818b-4582-9fff-1e6f6b0af15b,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-86de33aa-83a9-4d4e-b750-3abe643740fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ab726f7-e95f-40d7-ad7e-65ccd35f5c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-45b29cad-95db-4b7e-b41c-6e5463dcad02,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-62f630e1-9850-4f91-aede-1df65cc59c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e954c70b-2c9e-4a6f-85a7-2733acb9a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-6c8558d9-168d-499e-ab8c-e360a2dbabc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346808502-172.17.0.9-1598554837083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-0a25d5f6-f866-47c3-8df8-e5aed3806fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-b84c8f12-818b-4582-9fff-1e6f6b0af15b,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-86de33aa-83a9-4d4e-b750-3abe643740fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ab726f7-e95f-40d7-ad7e-65ccd35f5c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-45b29cad-95db-4b7e-b41c-6e5463dcad02,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-62f630e1-9850-4f91-aede-1df65cc59c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e954c70b-2c9e-4a6f-85a7-2733acb9a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-6c8558d9-168d-499e-ab8c-e360a2dbabc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013065074-172.17.0.9-1598554956077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41205,DS-cb3520f2-5aff-40a4-8757-36974039d678,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4a1982da-415b-46df-a520-bd7684ec5d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2a9a9f27-1382-4116-85c6-3960dfa59f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-47de6c50-af05-4a5d-a0f4-4783759789f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-706661ad-26e3-4a8d-8e77-c24a4276cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5e9c967f-4b36-480a-943d-0416840c711d,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-9b8c0d2f-28d5-4d3e-b9e4-1d832ca71a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d80d05d1-eb43-4b41-b3e8-5794e01a99a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013065074-172.17.0.9-1598554956077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41205,DS-cb3520f2-5aff-40a4-8757-36974039d678,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4a1982da-415b-46df-a520-bd7684ec5d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-2a9a9f27-1382-4116-85c6-3960dfa59f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-47de6c50-af05-4a5d-a0f4-4783759789f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-706661ad-26e3-4a8d-8e77-c24a4276cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5e9c967f-4b36-480a-943d-0416840c711d,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-9b8c0d2f-28d5-4d3e-b9e4-1d832ca71a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d80d05d1-eb43-4b41-b3e8-5794e01a99a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12691957-172.17.0.9-1598555379344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-e7c5844d-edcb-446f-86c8-fcee4251af50,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-5852d8c8-957f-48fb-b2cc-e55857b963cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-aad5d6d4-d5bc-4c2e-862f-b89e17133f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-4b53b5dd-8a12-4336-8117-f77fdb6242e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-6474a249-d660-4865-86d1-542433e56c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c62b0686-0c57-4487-90c6-65141b194345,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-9d90c9fb-99bd-4acc-b609-dba84b6e6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-ceeecab3-76ec-4b8b-996a-dc7e9b458c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12691957-172.17.0.9-1598555379344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-e7c5844d-edcb-446f-86c8-fcee4251af50,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-5852d8c8-957f-48fb-b2cc-e55857b963cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-aad5d6d4-d5bc-4c2e-862f-b89e17133f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-4b53b5dd-8a12-4336-8117-f77fdb6242e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-6474a249-d660-4865-86d1-542433e56c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c62b0686-0c57-4487-90c6-65141b194345,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-9d90c9fb-99bd-4acc-b609-dba84b6e6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-ceeecab3-76ec-4b8b-996a-dc7e9b458c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023741430-172.17.0.9-1598555650628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-9ea56faf-f5a1-4717-a8c2-a4273252e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-cfb5c325-3c8b-4914-a7f6-718c24dac4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-c415fe1b-650c-4f16-95db-27079006f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-1e947a5c-2889-4a29-8750-0a0e6b95da40,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-9905589d-0a2d-4524-9e14-7a8708fc2664,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-e80fdd89-3497-4f06-92d8-a8e918deda0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-89f0bfcb-ba5b-4b2f-a0f3-329fc0bea028,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-3d61486f-2d7d-446a-8cbd-1dfa7d047d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023741430-172.17.0.9-1598555650628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38324,DS-9ea56faf-f5a1-4717-a8c2-a4273252e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-cfb5c325-3c8b-4914-a7f6-718c24dac4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-c415fe1b-650c-4f16-95db-27079006f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-1e947a5c-2889-4a29-8750-0a0e6b95da40,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-9905589d-0a2d-4524-9e14-7a8708fc2664,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-e80fdd89-3497-4f06-92d8-a8e918deda0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-89f0bfcb-ba5b-4b2f-a0f3-329fc0bea028,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-3d61486f-2d7d-446a-8cbd-1dfa7d047d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339043284-172.17.0.9-1598556059669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-e7eef251-8ccb-4618-94cc-bb16d8c5632c,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-de72936a-40d9-4c2d-98a1-2923d5a6af51,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-0b90e53e-94ab-49d4-bac7-d4930e6f2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-de33b378-6253-49e3-aa15-720ca69dc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-4eefecab-f7ff-4c47-99d9-79ba4b21abff,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-a232250f-a1bf-4c04-bebc-beef3f6a422e,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e9d26520-124e-4d43-9e98-2fdb6d4cdeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-4f77776f-3567-429b-b617-8d1f5648c3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339043284-172.17.0.9-1598556059669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-e7eef251-8ccb-4618-94cc-bb16d8c5632c,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-de72936a-40d9-4c2d-98a1-2923d5a6af51,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-0b90e53e-94ab-49d4-bac7-d4930e6f2d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-de33b378-6253-49e3-aa15-720ca69dc75d,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-4eefecab-f7ff-4c47-99d9-79ba4b21abff,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-a232250f-a1bf-4c04-bebc-beef3f6a422e,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e9d26520-124e-4d43-9e98-2fdb6d4cdeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-4f77776f-3567-429b-b617-8d1f5648c3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627174661-172.17.0.9-1598556699193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-bfb28bb9-5e0b-4d1b-9dd6-626ef54f9f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-386095c7-c4dd-4d58-aeb5-729e2e83dd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-b94d619a-e146-4932-8e75-d6e5d3eb6926,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-282774e1-54ba-4360-a1d3-e60874cf50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-ef37d51a-c94b-406e-83a5-735279df3881,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-8969a781-f646-4340-a0fd-a555c94112a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-c757f975-6d66-4009-831f-35451d7d6135,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-8f3bfe2b-3341-49f2-b86e-8b913c928f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627174661-172.17.0.9-1598556699193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38912,DS-bfb28bb9-5e0b-4d1b-9dd6-626ef54f9f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-386095c7-c4dd-4d58-aeb5-729e2e83dd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-b94d619a-e146-4932-8e75-d6e5d3eb6926,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-282774e1-54ba-4360-a1d3-e60874cf50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-ef37d51a-c94b-406e-83a5-735279df3881,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-8969a781-f646-4340-a0fd-a555c94112a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-c757f975-6d66-4009-831f-35451d7d6135,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-8f3bfe2b-3341-49f2-b86e-8b913c928f24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188172648-172.17.0.9-1598556772549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-dae9af51-f634-467a-a04f-f2b877c20ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a693f964-4acf-4136-b8ad-966d6b5dc8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-b9c545cf-ebe2-4eaf-a266-fc5f9a414782,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-4ef4b14a-eeda-4f54-a88c-77e42aa897c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-ff350efa-96a2-47c4-9de5-3564aeb8e508,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-812050a8-31e0-42be-8335-dbad11fafc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-43878648-b3fc-4749-a6dd-30dd4f5624e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-6b622784-65fa-4e13-b469-053c4ffe291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188172648-172.17.0.9-1598556772549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-dae9af51-f634-467a-a04f-f2b877c20ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a693f964-4acf-4136-b8ad-966d6b5dc8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-b9c545cf-ebe2-4eaf-a266-fc5f9a414782,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-4ef4b14a-eeda-4f54-a88c-77e42aa897c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-ff350efa-96a2-47c4-9de5-3564aeb8e508,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-812050a8-31e0-42be-8335-dbad11fafc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-43878648-b3fc-4749-a6dd-30dd4f5624e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-6b622784-65fa-4e13-b469-053c4ffe291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5651
