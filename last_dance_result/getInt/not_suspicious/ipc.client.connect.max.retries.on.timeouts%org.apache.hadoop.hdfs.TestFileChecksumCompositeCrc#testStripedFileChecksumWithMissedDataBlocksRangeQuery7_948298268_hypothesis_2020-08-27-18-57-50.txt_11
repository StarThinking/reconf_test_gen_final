reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730681469-172.17.0.19-1598554687561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-84fd030b-9786-40cd-a06b-5de154bc0ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-2548ef2f-a25e-4783-a7ec-4175670e8ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-ed914ba2-9337-4285-8fb8-10c24e3a787b,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-dfa5bac1-3dc5-4e00-a9ad-81013467ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-25660d79-23d3-4901-9120-26ef3851f282,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-80371c2f-f71a-4c29-ac10-be422aafec70,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-b87ee571-b856-4848-977c-9f626488f934,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-35c27dbf-54e8-4d1d-9d65-8f96213db47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730681469-172.17.0.19-1598554687561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-84fd030b-9786-40cd-a06b-5de154bc0ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-2548ef2f-a25e-4783-a7ec-4175670e8ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-ed914ba2-9337-4285-8fb8-10c24e3a787b,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-dfa5bac1-3dc5-4e00-a9ad-81013467ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-25660d79-23d3-4901-9120-26ef3851f282,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-80371c2f-f71a-4c29-ac10-be422aafec70,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-b87ee571-b856-4848-977c-9f626488f934,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-35c27dbf-54e8-4d1d-9d65-8f96213db47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079524347-172.17.0.19-1598554860333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-0a28effc-503e-49c6-a698-7dea069bc7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-7fd5d177-e7c7-4bcd-9999-2e8985b34a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-3f72d23c-d3e8-44b9-a605-c79f076a7782,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-48c9b036-da21-4224-9727-7d1384de8817,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-ed5f7be9-63b8-4665-a50a-36c5d5229ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-4a4f568b-444d-41aa-902f-8f2a4ac43d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-bb7ded0f-a204-4cdd-a33a-147b502bc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-887edbb1-9123-42cf-9633-97db289b5576,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079524347-172.17.0.19-1598554860333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39866,DS-0a28effc-503e-49c6-a698-7dea069bc7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-7fd5d177-e7c7-4bcd-9999-2e8985b34a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-3f72d23c-d3e8-44b9-a605-c79f076a7782,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-48c9b036-da21-4224-9727-7d1384de8817,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-ed5f7be9-63b8-4665-a50a-36c5d5229ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-4a4f568b-444d-41aa-902f-8f2a4ac43d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-bb7ded0f-a204-4cdd-a33a-147b502bc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-887edbb1-9123-42cf-9633-97db289b5576,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543837712-172.17.0.19-1598555087009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40713,DS-7fe022be-5478-45a5-89c4-ad605f45f62d,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-92776aa5-8b3a-4a08-ba7a-0920bb7c77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-4ce8ab9f-d650-424d-bf33-80af2bbc393a,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-76e83fad-44c0-453d-84e6-ea22aecddffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-4df7c933-ffcd-453d-8dd1-e9debdc0eeae,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-08f86bef-23b6-43a2-8e44-c92a792370cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7d636fd2-bdf2-4d0a-8689-3026121dbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-d748d03a-68cb-4de5-96ad-e2c270536a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543837712-172.17.0.19-1598555087009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40713,DS-7fe022be-5478-45a5-89c4-ad605f45f62d,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-92776aa5-8b3a-4a08-ba7a-0920bb7c77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-4ce8ab9f-d650-424d-bf33-80af2bbc393a,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-76e83fad-44c0-453d-84e6-ea22aecddffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-4df7c933-ffcd-453d-8dd1-e9debdc0eeae,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-08f86bef-23b6-43a2-8e44-c92a792370cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-7d636fd2-bdf2-4d0a-8689-3026121dbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-d748d03a-68cb-4de5-96ad-e2c270536a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051742323-172.17.0.19-1598555171939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39588,DS-7ca8d609-c18c-4c6b-bdcd-fb5a0a2137b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-75fd1a6e-4a4a-408d-9c10-7db835743c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-c998db03-bf80-4477-a81d-a7be97370b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-24392837-ff9e-4a2a-a036-0373823ba9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e636306c-a0cd-406f-b27b-07098138d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-eaab17a8-c445-4c4d-abdc-343f0ccf7870,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-6f9a4391-da08-4c91-99fe-fd9ba0813b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-841643c6-f439-46f9-b6e1-24414d009f6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051742323-172.17.0.19-1598555171939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39588,DS-7ca8d609-c18c-4c6b-bdcd-fb5a0a2137b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-75fd1a6e-4a4a-408d-9c10-7db835743c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-c998db03-bf80-4477-a81d-a7be97370b19,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-24392837-ff9e-4a2a-a036-0373823ba9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e636306c-a0cd-406f-b27b-07098138d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-eaab17a8-c445-4c4d-abdc-343f0ccf7870,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-6f9a4391-da08-4c91-99fe-fd9ba0813b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-841643c6-f439-46f9-b6e1-24414d009f6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379749295-172.17.0.19-1598555467652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-387b0125-85e9-4553-874d-73c9afc87816,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-30c5bce3-3b16-47e2-9988-1183228e5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3d482b42-db24-4f0e-bc06-814a04408437,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-43d6e45c-3f0d-4cf3-b44a-5c819af2138d,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-78b5433f-5333-4c3d-a2df-6c840cdc65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-312988de-642e-4761-8b86-e4e1047e0e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1d40edaa-4a90-4326-8899-273778f1bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-d223a46d-c266-4a64-9f11-8d94c7e99df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379749295-172.17.0.19-1598555467652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-387b0125-85e9-4553-874d-73c9afc87816,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-30c5bce3-3b16-47e2-9988-1183228e5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-3d482b42-db24-4f0e-bc06-814a04408437,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-43d6e45c-3f0d-4cf3-b44a-5c819af2138d,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-78b5433f-5333-4c3d-a2df-6c840cdc65a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-312988de-642e-4761-8b86-e4e1047e0e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1d40edaa-4a90-4326-8899-273778f1bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-d223a46d-c266-4a64-9f11-8d94c7e99df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171140792-172.17.0.19-1598555666455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-61d9d8c6-f58a-4929-8e6b-eba2a4817e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-cfacc3a9-030a-4ca1-a8f9-c45ebd35f102,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-b48ab5e4-6068-44e3-9a2b-26240b0adb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-988b6fcf-3b5d-4478-a20c-72d61a5da3be,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-b4e7c9e4-7b24-499f-8430-41390d72d088,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-2f697696-96ae-4129-9df2-4e397dc7c306,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-884fdb2f-cee0-457e-90d5-80ca8c87d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-f191dd1b-525b-41d2-8f40-2cc0a1136f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171140792-172.17.0.19-1598555666455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44021,DS-61d9d8c6-f58a-4929-8e6b-eba2a4817e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-cfacc3a9-030a-4ca1-a8f9-c45ebd35f102,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-b48ab5e4-6068-44e3-9a2b-26240b0adb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-988b6fcf-3b5d-4478-a20c-72d61a5da3be,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-b4e7c9e4-7b24-499f-8430-41390d72d088,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-2f697696-96ae-4129-9df2-4e397dc7c306,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-884fdb2f-cee0-457e-90d5-80ca8c87d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-f191dd1b-525b-41d2-8f40-2cc0a1136f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463716490-172.17.0.19-1598556023996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37000,DS-ac24ddbc-2d5e-4c7e-a4b8-5173e981b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-39819831-7038-419e-ba02-e956baeab82a,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-aa0cfc93-2742-466f-89cf-addcc714e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-58ab99f9-47bb-4cd0-a932-38dfa595e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-2901779d-dc16-492c-8ef0-4c1240c7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-19745ca7-8a2c-4817-9f7e-069cc1955e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-d8514c7d-8d40-4729-ba01-391341a6eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-2a3716c9-0720-4eab-a90f-2e4abfc599e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463716490-172.17.0.19-1598556023996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37000,DS-ac24ddbc-2d5e-4c7e-a4b8-5173e981b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-39819831-7038-419e-ba02-e956baeab82a,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-aa0cfc93-2742-466f-89cf-addcc714e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-58ab99f9-47bb-4cd0-a932-38dfa595e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-2901779d-dc16-492c-8ef0-4c1240c7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-19745ca7-8a2c-4817-9f7e-069cc1955e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-d8514c7d-8d40-4729-ba01-391341a6eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-2a3716c9-0720-4eab-a90f-2e4abfc599e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327426246-172.17.0.19-1598556061077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-0d65ca1a-3e76-48bc-b51a-78217e8c736b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-2f0172ac-1760-415b-b2b5-46b9f7c397ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-317e7fde-a7cc-4e32-a3a0-217d43095779,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-5b4f7e1e-1c6f-4336-a5e4-24a73bc64e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-c4e0051f-82ec-484d-9a2e-c4e3e171d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-2ee24790-963c-47fe-a13e-dc4876ee2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-2296facb-04ab-4f01-a06b-b15d7fb9aede,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-4648b065-fffc-408e-8928-e3764b3449f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327426246-172.17.0.19-1598556061077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-0d65ca1a-3e76-48bc-b51a-78217e8c736b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-2f0172ac-1760-415b-b2b5-46b9f7c397ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-317e7fde-a7cc-4e32-a3a0-217d43095779,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-5b4f7e1e-1c6f-4336-a5e4-24a73bc64e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-c4e0051f-82ec-484d-9a2e-c4e3e171d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-2ee24790-963c-47fe-a13e-dc4876ee2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-2296facb-04ab-4f01-a06b-b15d7fb9aede,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-4648b065-fffc-408e-8928-e3764b3449f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590730243-172.17.0.19-1598556107799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-942bea33-4d42-4713-a6a8-10567b14de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-52e135c4-779e-4438-ade8-b09af17ffe11,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8d4b1b01-2601-40b0-a3b1-5c3923da011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4e0ac410-d304-4223-b46c-73d3fd737ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-d1690f65-d5b3-4ad1-8ee3-6a2b66836c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-4b7db372-c8e4-45aa-99fa-616d6daa1cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-48703890-35e9-430b-a778-6b080b6bc544,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-3d53c0ad-ffdf-4df8-b251-2784d04ee323,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590730243-172.17.0.19-1598556107799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43666,DS-942bea33-4d42-4713-a6a8-10567b14de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-52e135c4-779e-4438-ade8-b09af17ffe11,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8d4b1b01-2601-40b0-a3b1-5c3923da011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4e0ac410-d304-4223-b46c-73d3fd737ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-d1690f65-d5b3-4ad1-8ee3-6a2b66836c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-4b7db372-c8e4-45aa-99fa-616d6daa1cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-48703890-35e9-430b-a778-6b080b6bc544,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-3d53c0ad-ffdf-4df8-b251-2784d04ee323,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639999037-172.17.0.19-1598556368853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-3d57015b-4ea5-4c17-8c0b-ec9c4a510b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-1ad19ffe-bdae-49d5-a2fc-3992422fd147,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-9999a3eb-4df6-4a8b-9dc5-7f47a239c54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-13fb727e-8eb2-4346-ad3b-0dcbb7fff1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-aebff2de-f7c2-44e5-9315-eb53b163240b,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b855c40a-75ab-4472-925b-cc1e1fedf42c,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-2de6819a-058e-4ff2-90af-58997f567a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-677b9b63-a0e7-4c58-b447-773f91c03d9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639999037-172.17.0.19-1598556368853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-3d57015b-4ea5-4c17-8c0b-ec9c4a510b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-1ad19ffe-bdae-49d5-a2fc-3992422fd147,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-9999a3eb-4df6-4a8b-9dc5-7f47a239c54f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-13fb727e-8eb2-4346-ad3b-0dcbb7fff1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-aebff2de-f7c2-44e5-9315-eb53b163240b,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b855c40a-75ab-4472-925b-cc1e1fedf42c,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-2de6819a-058e-4ff2-90af-58997f567a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-677b9b63-a0e7-4c58-b447-773f91c03d9b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575465519-172.17.0.19-1598556402837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-4938929f-3be1-4061-aeca-4b621d0adf71,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-7fa7808e-4330-4c3b-9bbd-7bd033a84f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-9e556845-6bc9-47a1-848e-aa4328df1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-9f0a1b02-44e0-4b56-b9a5-129c7c3c2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-2c5bf1a4-8d35-433c-8220-581688900527,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-7536ec2d-3400-43c1-a4ac-b27cbb1d5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-aa6709d0-6d78-4331-8f73-dc9ebaaed938,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-d213276e-d978-4fa2-bdea-af042017a01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575465519-172.17.0.19-1598556402837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-4938929f-3be1-4061-aeca-4b621d0adf71,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-7fa7808e-4330-4c3b-9bbd-7bd033a84f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-9e556845-6bc9-47a1-848e-aa4328df1fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-9f0a1b02-44e0-4b56-b9a5-129c7c3c2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-2c5bf1a4-8d35-433c-8220-581688900527,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-7536ec2d-3400-43c1-a4ac-b27cbb1d5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-aa6709d0-6d78-4331-8f73-dc9ebaaed938,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-d213276e-d978-4fa2-bdea-af042017a01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147982364-172.17.0.19-1598556668286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-ffbc3896-a0e9-48ee-8d2a-6d6aba5791ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-4e5f4c50-501f-4eb6-a28c-8c3dea02c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-6e52f448-4a35-4561-8159-c97158e82ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ac92c239-71b3-4e6e-982b-fce28ec04b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ae241fa9-231f-4b62-b7b8-1fb7f5409d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-4c64f014-b6dc-4616-b41c-d8eae7a5d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-075177b1-1514-4c4d-ac5d-a2078d027e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-fa83df16-5cd0-41d2-b507-8c70552924df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147982364-172.17.0.19-1598556668286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-ffbc3896-a0e9-48ee-8d2a-6d6aba5791ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-4e5f4c50-501f-4eb6-a28c-8c3dea02c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-6e52f448-4a35-4561-8159-c97158e82ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ac92c239-71b3-4e6e-982b-fce28ec04b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ae241fa9-231f-4b62-b7b8-1fb7f5409d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-4c64f014-b6dc-4616-b41c-d8eae7a5d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-075177b1-1514-4c4d-ac5d-a2078d027e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-fa83df16-5cd0-41d2-b507-8c70552924df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593140730-172.17.0.19-1598556731820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-8c116593-9ff5-49ca-b531-2b7299efdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-22a9ccc0-a8b3-451f-ab87-a83ba2ec46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-db677c3a-00e4-475a-8116-37f01e4fcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-86228853-a63d-45b3-8fd2-bfcc2b81c263,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-b8867813-c617-41b7-ae95-1639d1e44f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-e9d92e0f-7a84-4f3b-aa78-8a84747ed4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-2c05b012-a1a1-4bd3-9e50-7b2c9399a1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-849294dc-dead-4c83-a286-f7fa044b4abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593140730-172.17.0.19-1598556731820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-8c116593-9ff5-49ca-b531-2b7299efdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-22a9ccc0-a8b3-451f-ab87-a83ba2ec46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-db677c3a-00e4-475a-8116-37f01e4fcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-86228853-a63d-45b3-8fd2-bfcc2b81c263,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-b8867813-c617-41b7-ae95-1639d1e44f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-e9d92e0f-7a84-4f3b-aa78-8a84747ed4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-2c05b012-a1a1-4bd3-9e50-7b2c9399a1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-849294dc-dead-4c83-a286-f7fa044b4abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711738656-172.17.0.19-1598556852088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-53b7948f-aa34-4432-a3c3-f44cf77fa27e,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b6cd98c-4b62-4771-9c10-85d2c6773cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-726cf040-4cab-410e-9855-5365afbd0736,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-adc0a2d6-879f-449d-abba-b65a2cfd21fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c9c178d3-133d-47bf-a121-f58139577ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-8479b307-47f8-4e78-9901-93ad264951dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-52f007d8-1f7a-47b7-8f98-6360d10da59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-b474f33d-502f-4b60-975e-f46b890e2c9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711738656-172.17.0.19-1598556852088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-53b7948f-aa34-4432-a3c3-f44cf77fa27e,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-0b6cd98c-4b62-4771-9c10-85d2c6773cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-726cf040-4cab-410e-9855-5365afbd0736,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-adc0a2d6-879f-449d-abba-b65a2cfd21fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c9c178d3-133d-47bf-a121-f58139577ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-8479b307-47f8-4e78-9901-93ad264951dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-52f007d8-1f7a-47b7-8f98-6360d10da59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-b474f33d-502f-4b60-975e-f46b890e2c9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489024497-172.17.0.19-1598557049884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-6967b1d8-d688-468e-b7d1-d632d34b7806,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-85f97b1a-709b-4531-bdad-c55d37496902,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-62d8be49-7860-4acc-9ceb-b9d6cdfa3c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-df31118b-689e-450d-8357-75e76278dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-f112f057-6c06-4beb-b168-5f9cc3fe3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-cb0dc0a6-d89c-4f5b-9d11-e80cba515bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-fb24bb75-cdc1-429d-a9b0-138acad4c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-8061f638-405b-4da6-a630-5d9376558e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489024497-172.17.0.19-1598557049884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-6967b1d8-d688-468e-b7d1-d632d34b7806,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-85f97b1a-709b-4531-bdad-c55d37496902,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-62d8be49-7860-4acc-9ceb-b9d6cdfa3c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-df31118b-689e-450d-8357-75e76278dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-f112f057-6c06-4beb-b168-5f9cc3fe3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-cb0dc0a6-d89c-4f5b-9d11-e80cba515bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-fb24bb75-cdc1-429d-a9b0-138acad4c21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-8061f638-405b-4da6-a630-5d9376558e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712216558-172.17.0.19-1598557232943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-96df7fc9-be4b-483f-a2f9-63c0eb695276,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-b534bc86-2a57-4eca-9ec8-28f318fc0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c38a2dde-fa87-48c3-b2e0-c95b53815418,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-3149cca5-4b54-44b3-a7dd-68f73530e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-91d1fa05-2a8f-4a5d-a8da-d4f0ebdc7787,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-1c3e44c3-9132-46b2-bedb-087fb9bc81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-ad290856-dc4d-44a0-bd7c-f05bdeb58224,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-f1c792bd-a65e-4e05-a969-264f79cad6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712216558-172.17.0.19-1598557232943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-96df7fc9-be4b-483f-a2f9-63c0eb695276,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-b534bc86-2a57-4eca-9ec8-28f318fc0c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-c38a2dde-fa87-48c3-b2e0-c95b53815418,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-3149cca5-4b54-44b3-a7dd-68f73530e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-91d1fa05-2a8f-4a5d-a8da-d4f0ebdc7787,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-1c3e44c3-9132-46b2-bedb-087fb9bc81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-ad290856-dc4d-44a0-bd7c-f05bdeb58224,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-f1c792bd-a65e-4e05-a969-264f79cad6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915331803-172.17.0.19-1598557420147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-bbcbdb62-9cba-426a-aec2-f7cd032367ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-d8f68ecd-ea1b-4521-bf3f-79db38b082b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-4c3dfeff-49a9-470d-928c-dc9545446d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-f6b745c1-c67e-4acb-a498-6ad706cb8230,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-55c35714-c220-45a2-8282-8b97ee9ebe30,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-e71ffe0e-5ee9-4f55-b880-6ba4b7eba5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4b90bde9-891d-459b-a902-fee87dda47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-0643cb7e-d338-454c-8ddb-295289bdada0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915331803-172.17.0.19-1598557420147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-bbcbdb62-9cba-426a-aec2-f7cd032367ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-d8f68ecd-ea1b-4521-bf3f-79db38b082b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-4c3dfeff-49a9-470d-928c-dc9545446d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-f6b745c1-c67e-4acb-a498-6ad706cb8230,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-55c35714-c220-45a2-8282-8b97ee9ebe30,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-e71ffe0e-5ee9-4f55-b880-6ba4b7eba5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4b90bde9-891d-459b-a902-fee87dda47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-0643cb7e-d338-454c-8ddb-295289bdada0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690062940-172.17.0.19-1598557550231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-7c36bc01-504a-4441-ad64-102cd57edf58,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-a73600e3-0b33-4d47-8c77-bf77fd2cbb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f11a0704-f336-406d-924a-a5459f74f887,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-87204135-aead-4659-abae-b36cd292f361,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-825f7ea8-a9a9-4f22-afe0-d95b0dfc77be,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-70f627b8-fae0-421c-b787-3f3d797617bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-e6f359eb-3f6c-4abe-82e4-4fa65c0648f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b0c4018f-4c55-42f1-a72f-31b256678d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690062940-172.17.0.19-1598557550231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-7c36bc01-504a-4441-ad64-102cd57edf58,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-a73600e3-0b33-4d47-8c77-bf77fd2cbb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f11a0704-f336-406d-924a-a5459f74f887,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-87204135-aead-4659-abae-b36cd292f361,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-825f7ea8-a9a9-4f22-afe0-d95b0dfc77be,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-70f627b8-fae0-421c-b787-3f3d797617bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-e6f359eb-3f6c-4abe-82e4-4fa65c0648f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b0c4018f-4c55-42f1-a72f-31b256678d54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768260647-172.17.0.19-1598557764732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-285d49e7-a3cc-4547-9d62-f209f4c1f316,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-7fc0001e-4d35-4e8f-96a7-fda0f2412b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-4db09445-dd6c-42c3-a7e0-d5ba13c15d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-b67ef924-bb27-4034-adc5-ccecc3aea11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-aaf8054c-4843-4bea-88e1-32793c407dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02d44147-0719-478e-b0e2-fd59ed120e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-179d558b-bb1e-42f1-9906-af9214d18f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-156464ea-110d-4e68-b6ec-e5054f01aad9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768260647-172.17.0.19-1598557764732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-285d49e7-a3cc-4547-9d62-f209f4c1f316,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-7fc0001e-4d35-4e8f-96a7-fda0f2412b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-4db09445-dd6c-42c3-a7e0-d5ba13c15d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-b67ef924-bb27-4034-adc5-ccecc3aea11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-aaf8054c-4843-4bea-88e1-32793c407dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02d44147-0719-478e-b0e2-fd59ed120e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-179d558b-bb1e-42f1-9906-af9214d18f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-156464ea-110d-4e68-b6ec-e5054f01aad9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090462270-172.17.0.19-1598557917479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-eafb08de-f59e-41eb-9a00-efe7c8be2213,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-c466b940-bd21-4581-bd44-31f926e9b924,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f939da2b-9cd0-4229-bd68-a69a63cc5aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-fd53440f-c1f9-42ca-9edb-7cf92131d767,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-2dd28ce1-2d91-433c-bb8f-5518293f9663,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-0a161c64-29a7-4b39-a7f1-815639f1308f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-d9d97723-670d-4fb3-b0b0-9ba7f1a5d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-b8bf18eb-25a2-4806-80c4-442ebf4913cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090462270-172.17.0.19-1598557917479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-eafb08de-f59e-41eb-9a00-efe7c8be2213,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-c466b940-bd21-4581-bd44-31f926e9b924,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f939da2b-9cd0-4229-bd68-a69a63cc5aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-fd53440f-c1f9-42ca-9edb-7cf92131d767,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-2dd28ce1-2d91-433c-bb8f-5518293f9663,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-0a161c64-29a7-4b39-a7f1-815639f1308f,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-d9d97723-670d-4fb3-b0b0-9ba7f1a5d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-b8bf18eb-25a2-4806-80c4-442ebf4913cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021983226-172.17.0.19-1598557991719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-687e6e7a-02d3-4fe9-8c75-5703c33f3789,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-cdb28557-3c9d-48c5-b784-efc05656c937,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-cd656ed3-57da-4b9d-86f2-fe8600dbff30,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-ff90d6c3-70aa-460f-a083-b4e9f6a3c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-1f700bb1-0a21-41c9-9818-c9c35cd86194,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-4c6a88d0-dfe5-44d5-9287-6592b5d5544b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-9126cbea-5659-4078-9628-0fb510c2c2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-bd3f4fd3-5040-4927-ad30-4c4232411cae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021983226-172.17.0.19-1598557991719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-687e6e7a-02d3-4fe9-8c75-5703c33f3789,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-cdb28557-3c9d-48c5-b784-efc05656c937,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-cd656ed3-57da-4b9d-86f2-fe8600dbff30,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-ff90d6c3-70aa-460f-a083-b4e9f6a3c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-1f700bb1-0a21-41c9-9818-c9c35cd86194,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-4c6a88d0-dfe5-44d5-9287-6592b5d5544b,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-9126cbea-5659-4078-9628-0fb510c2c2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-bd3f4fd3-5040-4927-ad30-4c4232411cae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692007153-172.17.0.19-1598558028873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-8f977b08-9c95-481b-bd2d-1d0478e4c451,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4ead8f01-2335-4032-a699-9384cdb382ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-da5dfff1-ed66-4680-88a9-1dbe91c033cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c5ea03ba-243d-43de-925a-a14d309abe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-796c3d84-c8f1-4c2a-86bd-dd562594ae29,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-4c21bcff-696c-4498-8e3b-53dbc0a3f9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-cab8d4e8-f502-49f1-b613-29f6742fc934,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-6e81f0b8-8c46-46ef-99ff-cca5f1068dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692007153-172.17.0.19-1598558028873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-8f977b08-9c95-481b-bd2d-1d0478e4c451,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4ead8f01-2335-4032-a699-9384cdb382ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-da5dfff1-ed66-4680-88a9-1dbe91c033cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-c5ea03ba-243d-43de-925a-a14d309abe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-796c3d84-c8f1-4c2a-86bd-dd562594ae29,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-4c21bcff-696c-4498-8e3b-53dbc0a3f9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-cab8d4e8-f502-49f1-b613-29f6742fc934,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-6e81f0b8-8c46-46ef-99ff-cca5f1068dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879551670-172.17.0.19-1598558103015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-9a4d2935-685f-40f9-9aa5-dcbb8b9e6808,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a9cee2fc-5375-4f82-915f-dd08b33edf93,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-9937b580-7880-46c5-9089-0b4a39038dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1b70fa88-d867-4149-b1e7-98d93732ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-8faabfe3-4bd0-44bb-9b93-5670851c532d,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-2bb7bcbc-5413-47c3-994f-10d57b34f411,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-0642e989-a93f-48c9-ab87-9d1a6f1f053b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-c31f049a-e0a5-4909-af46-25fd796c3b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879551670-172.17.0.19-1598558103015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-9a4d2935-685f-40f9-9aa5-dcbb8b9e6808,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a9cee2fc-5375-4f82-915f-dd08b33edf93,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-9937b580-7880-46c5-9089-0b4a39038dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1b70fa88-d867-4149-b1e7-98d93732ca00,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-8faabfe3-4bd0-44bb-9b93-5670851c532d,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-2bb7bcbc-5413-47c3-994f-10d57b34f411,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-0642e989-a93f-48c9-ab87-9d1a6f1f053b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-c31f049a-e0a5-4909-af46-25fd796c3b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444719818-172.17.0.19-1598558135909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-fc02ec81-24d4-4f80-85bb-190ddfd7b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-82fd249a-417d-4622-9198-4cc4604b6154,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-fcf1ff76-e8a0-4a2f-aa46-284eec2978fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-56a89217-58ff-4808-ad0e-5810530263a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1876c987-c738-4115-9594-ca25e2d9c066,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-f53160cf-4564-4edf-b3dc-68386c9afd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-493d3d19-d260-4851-8793-cddbbdb0f953,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-88372d61-46a3-40c1-9808-22ab45dd30bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444719818-172.17.0.19-1598558135909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-fc02ec81-24d4-4f80-85bb-190ddfd7b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-82fd249a-417d-4622-9198-4cc4604b6154,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-fcf1ff76-e8a0-4a2f-aa46-284eec2978fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-56a89217-58ff-4808-ad0e-5810530263a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1876c987-c738-4115-9594-ca25e2d9c066,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-f53160cf-4564-4edf-b3dc-68386c9afd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-493d3d19-d260-4851-8793-cddbbdb0f953,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-88372d61-46a3-40c1-9808-22ab45dd30bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146942411-172.17.0.19-1598558311189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-0aff7401-64e2-4f53-9166-f949701857ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-2bbb19b9-628c-4755-b4ca-9029aea4a918,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a992e3fe-7306-4e35-8f22-17c19a66f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-fffb3d3c-566d-4c7b-bfd8-94e98ad99f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-121f7db2-28e5-44dc-98e8-a3a0eecb91e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-46173393-2596-4db6-9dbb-5b8f89f6ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7b92ff3d-5d87-4d8f-b4c3-82506654d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-24d48dd9-6556-4cf3-931c-925745d51388,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146942411-172.17.0.19-1598558311189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-0aff7401-64e2-4f53-9166-f949701857ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-2bbb19b9-628c-4755-b4ca-9029aea4a918,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-a992e3fe-7306-4e35-8f22-17c19a66f4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-fffb3d3c-566d-4c7b-bfd8-94e98ad99f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-121f7db2-28e5-44dc-98e8-a3a0eecb91e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-46173393-2596-4db6-9dbb-5b8f89f6ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7b92ff3d-5d87-4d8f-b4c3-82506654d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-24d48dd9-6556-4cf3-931c-925745d51388,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751557960-172.17.0.19-1598558466688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-07361fdf-8395-4fc9-938a-a55bb6ce4982,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-b4df65c8-0ae0-449a-b973-4745e899019f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-73f08be0-853b-48d7-8d70-a247c9bac6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-61f88b3f-e8bc-4e83-bbfc-424efbf8fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-24dd5671-dca5-466f-a070-2e320589cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-e248227a-1fe5-4ef9-ae0f-0808f6c70f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-45262c9a-e7d3-4f8c-b70b-354d25c56d88,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a74936a9-ea9e-412e-9545-1a373c906793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751557960-172.17.0.19-1598558466688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-07361fdf-8395-4fc9-938a-a55bb6ce4982,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-b4df65c8-0ae0-449a-b973-4745e899019f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-73f08be0-853b-48d7-8d70-a247c9bac6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-61f88b3f-e8bc-4e83-bbfc-424efbf8fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-24dd5671-dca5-466f-a070-2e320589cf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-e248227a-1fe5-4ef9-ae0f-0808f6c70f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-45262c9a-e7d3-4f8c-b70b-354d25c56d88,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a74936a9-ea9e-412e-9545-1a373c906793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277312460-172.17.0.19-1598558506793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-f597b08f-8d88-4824-b8fd-caea714a5557,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-9432b142-9ce5-4158-a242-624593f7852d,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-88a8cd2f-4155-4fc7-b2c8-1dd118c32f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-477e6d13-5e2c-4063-92da-948a8e3b2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-50d869c3-2400-4b72-bcc9-501912167b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-8e5e279a-dda1-4ef3-94af-cb73ebd6bbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-38e60736-508b-4f7f-9f40-b9e569de3eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-59d7f67c-9483-4f0d-9013-1407afe677b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277312460-172.17.0.19-1598558506793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-f597b08f-8d88-4824-b8fd-caea714a5557,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-9432b142-9ce5-4158-a242-624593f7852d,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-88a8cd2f-4155-4fc7-b2c8-1dd118c32f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-477e6d13-5e2c-4063-92da-948a8e3b2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-50d869c3-2400-4b72-bcc9-501912167b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-8e5e279a-dda1-4ef3-94af-cb73ebd6bbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-38e60736-508b-4f7f-9f40-b9e569de3eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-59d7f67c-9483-4f0d-9013-1407afe677b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989934541-172.17.0.19-1598558615999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-176145b6-f5bd-40b7-be9e-4848be054ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e748f32e-1ea8-4d73-b260-ab20bdb3566b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-175974d1-3e26-435c-9baa-576d264d6317,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-9e049fc0-dedd-4e5b-9e6b-5225094142b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-80a83ffa-3805-4e86-963d-62dd99e99f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-fa341798-8b6d-4484-a821-fb42f33122a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-13bdc5fd-2aa7-4c32-81cd-ca605d0fe47f,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-ab60e36a-9f19-49f2-8ab7-3a2b370da15a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989934541-172.17.0.19-1598558615999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-176145b6-f5bd-40b7-be9e-4848be054ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-e748f32e-1ea8-4d73-b260-ab20bdb3566b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-175974d1-3e26-435c-9baa-576d264d6317,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-9e049fc0-dedd-4e5b-9e6b-5225094142b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-80a83ffa-3805-4e86-963d-62dd99e99f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-fa341798-8b6d-4484-a821-fb42f33122a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-13bdc5fd-2aa7-4c32-81cd-ca605d0fe47f,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-ab60e36a-9f19-49f2-8ab7-3a2b370da15a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463116923-172.17.0.19-1598558727230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-6a65be8a-2786-40e1-a977-aa555ab9a6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-6c433d0f-fc75-458b-b1e0-0b5ca147b38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-49036d4c-1bc0-46c2-b00b-f299fcac315c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-28f1cbd9-b051-4f97-9141-7e21c918b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-51636ff2-da9e-4394-af8e-2dc582e38adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7cf0a575-5591-447d-b049-c6048096c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-1e803ea5-d25a-49e7-aff3-52fc73109984,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-656ec43b-39ce-49c2-be59-d23176a05450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463116923-172.17.0.19-1598558727230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40542,DS-6a65be8a-2786-40e1-a977-aa555ab9a6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-6c433d0f-fc75-458b-b1e0-0b5ca147b38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-49036d4c-1bc0-46c2-b00b-f299fcac315c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-28f1cbd9-b051-4f97-9141-7e21c918b0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-51636ff2-da9e-4394-af8e-2dc582e38adf,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7cf0a575-5591-447d-b049-c6048096c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-1e803ea5-d25a-49e7-aff3-52fc73109984,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-656ec43b-39ce-49c2-be59-d23176a05450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756203946-172.17.0.19-1598558793591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-cbade520-3e10-48bc-ab62-0b90c32308c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-3056e837-125f-405f-95f2-0aadc8d85ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-30ff7253-9d5e-4c41-96ba-e2e2c6b7d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-f4b1a9b8-c94b-4762-99fa-2b14f11f21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-7aa42c82-72ef-4075-84d1-95f4bfa800f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-baa846e8-a25c-4915-a8f4-ffc88ff12fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-323c26ca-9e42-47dc-951c-fc0005e8ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-877571d1-bd83-4f4b-bef7-f11884a1e8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756203946-172.17.0.19-1598558793591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-cbade520-3e10-48bc-ab62-0b90c32308c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-3056e837-125f-405f-95f2-0aadc8d85ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-30ff7253-9d5e-4c41-96ba-e2e2c6b7d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-f4b1a9b8-c94b-4762-99fa-2b14f11f21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-7aa42c82-72ef-4075-84d1-95f4bfa800f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-baa846e8-a25c-4915-a8f4-ffc88ff12fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-323c26ca-9e42-47dc-951c-fc0005e8ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-877571d1-bd83-4f4b-bef7-f11884a1e8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154362893-172.17.0.19-1598558901281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37875,DS-7c21f9aa-9140-442f-9f95-2a43d31c7182,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0c1bc6c4-cbfc-4634-b1ce-9ad1dc45181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-102f2810-7f9d-46d1-8bed-fbd9cad3e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-e7a6e613-5d85-4261-b9c2-a0be37bb234f,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-007844bc-22d5-462f-a7af-2fc1720be124,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-4a07b90f-1c49-4c0e-964e-068f01828578,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-ea8e73f4-0932-45d6-8acb-ae1173dd65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-8ec23c86-4498-4c92-8646-e0a89d098f06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154362893-172.17.0.19-1598558901281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37875,DS-7c21f9aa-9140-442f-9f95-2a43d31c7182,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0c1bc6c4-cbfc-4634-b1ce-9ad1dc45181b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-102f2810-7f9d-46d1-8bed-fbd9cad3e5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-e7a6e613-5d85-4261-b9c2-a0be37bb234f,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-007844bc-22d5-462f-a7af-2fc1720be124,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-4a07b90f-1c49-4c0e-964e-068f01828578,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-ea8e73f4-0932-45d6-8acb-ae1173dd65e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-8ec23c86-4498-4c92-8646-e0a89d098f06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190540148-172.17.0.19-1598558973090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-b4d1acc1-0271-40f5-a79a-4aebf7395647,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-64655ff8-f876-4ea8-9c27-40a2c89db9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-920b820e-3e31-4631-a42d-a86a659e00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-c183fde1-2497-4d07-9d5b-259ed92f8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-7d3d81f5-f04d-47a5-ac94-7ab8c8eb5b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-9dec9752-1a6f-4170-a7d5-864481d885ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-c9f9962d-e762-458a-8524-698091489194,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-d54dc8ee-c3f2-4c28-9ad1-61714c190cd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190540148-172.17.0.19-1598558973090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-b4d1acc1-0271-40f5-a79a-4aebf7395647,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-64655ff8-f876-4ea8-9c27-40a2c89db9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-920b820e-3e31-4631-a42d-a86a659e00fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-c183fde1-2497-4d07-9d5b-259ed92f8b59,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-7d3d81f5-f04d-47a5-ac94-7ab8c8eb5b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-9dec9752-1a6f-4170-a7d5-864481d885ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-c9f9962d-e762-458a-8524-698091489194,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-d54dc8ee-c3f2-4c28-9ad1-61714c190cd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324743792-172.17.0.19-1598559317114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-ca66190c-f0ca-4412-98b2-bb45501b0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-3685b392-745f-450e-b952-d5dbcde112c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-80baecd3-79e5-4439-84d2-41667587fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-f9e643cf-4005-4586-95ba-0885a8ce720a,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-16e70054-9b10-487c-8f08-d4b59bd9c953,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4f319a3c-f4a0-4955-a1ee-ae36a86b9fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-266cdaa7-6a59-4f78-864b-5c31cc06967c,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-f0ce0d83-4f0d-4b70-b211-e5d81037b315,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324743792-172.17.0.19-1598559317114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-ca66190c-f0ca-4412-98b2-bb45501b0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-3685b392-745f-450e-b952-d5dbcde112c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-80baecd3-79e5-4439-84d2-41667587fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-f9e643cf-4005-4586-95ba-0885a8ce720a,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-16e70054-9b10-487c-8f08-d4b59bd9c953,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4f319a3c-f4a0-4955-a1ee-ae36a86b9fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-266cdaa7-6a59-4f78-864b-5c31cc06967c,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-f0ce0d83-4f0d-4b70-b211-e5d81037b315,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12695268-172.17.0.19-1598559359277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-54664f4b-8d4d-4fc5-8480-e335d0234c23,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-83608dda-fd90-4dc6-a82f-e1f96592a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-57686112-beae-4c5a-865e-7360333f8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-2d60d525-5785-43ec-b1aa-8c8d71227964,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-456a2aad-7b1b-4582-a730-d77867a49228,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-9d48d5ad-7e61-4169-8c51-180c41383970,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-de1bce21-5465-4ae3-90e5-4559d85f8635,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-c776f247-af78-402a-9013-d0b3aedf3db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12695268-172.17.0.19-1598559359277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-54664f4b-8d4d-4fc5-8480-e335d0234c23,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-83608dda-fd90-4dc6-a82f-e1f96592a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-57686112-beae-4c5a-865e-7360333f8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-2d60d525-5785-43ec-b1aa-8c8d71227964,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-456a2aad-7b1b-4582-a730-d77867a49228,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-9d48d5ad-7e61-4169-8c51-180c41383970,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-de1bce21-5465-4ae3-90e5-4559d85f8635,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-c776f247-af78-402a-9013-d0b3aedf3db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316014536-172.17.0.19-1598559422023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-6497e195-4f04-4e20-b51f-e408ec8f7e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-f0bc9791-7ee1-48d7-9ce9-0d567dbe5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-80ec9a01-2b2a-49da-9838-043582086318,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-1f502317-0dea-406a-b51d-3a60031782e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-3a893dde-e432-40f5-8484-a8008dd2ef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-0e4c8957-171f-4062-b48e-50b9266082ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-5ddc82a9-e44a-4d7c-a2b3-d2eadcfa5f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-b0b65097-373d-477b-b9fb-6c2a4578c1ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316014536-172.17.0.19-1598559422023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38345,DS-6497e195-4f04-4e20-b51f-e408ec8f7e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-f0bc9791-7ee1-48d7-9ce9-0d567dbe5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-80ec9a01-2b2a-49da-9838-043582086318,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-1f502317-0dea-406a-b51d-3a60031782e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-3a893dde-e432-40f5-8484-a8008dd2ef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-0e4c8957-171f-4062-b48e-50b9266082ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-5ddc82a9-e44a-4d7c-a2b3-d2eadcfa5f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-b0b65097-373d-477b-b9fb-6c2a4578c1ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912720950-172.17.0.19-1598559498342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-ab71c951-67d8-4e2d-93f8-16a8ea00e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-736504c7-cce0-417c-a55c-3f1fdb1684b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-e3b5304d-6d9f-4cea-9f80-d15f7b8ebc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1530a0e1-b18a-48b5-97b1-59bf7d1303f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-e428c880-c657-48a8-bcd3-6b98faef7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-0313276c-a349-4fd7-b138-2600a9af2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-ddd33e28-5cc8-491e-a31f-240432b92d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3bb3c037-94fb-4ab4-b165-fe0dc55e35d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912720950-172.17.0.19-1598559498342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-ab71c951-67d8-4e2d-93f8-16a8ea00e4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-736504c7-cce0-417c-a55c-3f1fdb1684b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-e3b5304d-6d9f-4cea-9f80-d15f7b8ebc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-1530a0e1-b18a-48b5-97b1-59bf7d1303f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-e428c880-c657-48a8-bcd3-6b98faef7a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-0313276c-a349-4fd7-b138-2600a9af2f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-ddd33e28-5cc8-491e-a31f-240432b92d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3bb3c037-94fb-4ab4-b165-fe0dc55e35d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391059025-172.17.0.19-1598559535768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-391827d8-472e-4c82-b312-246f10ecca96,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-862d93ae-edf5-4ada-8a33-e862aac3282c,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-73f038e3-199f-4540-b906-81b459f8b673,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-dc89f918-8142-4f2a-a8f7-e288ea43e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-4388e2ff-e3b7-4c8e-aca3-39c49eceb165,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-efb0f129-ba11-45fb-841e-0bfe02508d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-bb027f8a-209d-4a4c-914d-063d72aafc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-7d0fb601-351f-4d67-b367-6a11776fd798,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391059025-172.17.0.19-1598559535768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-391827d8-472e-4c82-b312-246f10ecca96,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-862d93ae-edf5-4ada-8a33-e862aac3282c,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-73f038e3-199f-4540-b906-81b459f8b673,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-dc89f918-8142-4f2a-a8f7-e288ea43e8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-4388e2ff-e3b7-4c8e-aca3-39c49eceb165,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-efb0f129-ba11-45fb-841e-0bfe02508d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-bb027f8a-209d-4a4c-914d-063d72aafc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-7d0fb601-351f-4d67-b367-6a11776fd798,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200476230-172.17.0.19-1598559595031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-43c91583-5cf6-42bc-a133-4d07c287cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-11244143-e46c-46e4-8ed9-775c81798cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-de6e46b2-aab6-4326-8d40-7515c3b337a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-45efc2a0-3b7e-44a3-b274-c00fa2780ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-14983e6b-93ee-45b0-b91c-32ae3a39d680,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8e519f27-9bd3-49b6-8ee8-b477ceceaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-3369f68b-3eba-4f91-8d31-b4820f254992,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9acc606c-0830-4703-a56c-ec5dca6039f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200476230-172.17.0.19-1598559595031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-43c91583-5cf6-42bc-a133-4d07c287cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-11244143-e46c-46e4-8ed9-775c81798cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-de6e46b2-aab6-4326-8d40-7515c3b337a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-45efc2a0-3b7e-44a3-b274-c00fa2780ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-14983e6b-93ee-45b0-b91c-32ae3a39d680,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8e519f27-9bd3-49b6-8ee8-b477ceceaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-3369f68b-3eba-4f91-8d31-b4820f254992,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9acc606c-0830-4703-a56c-ec5dca6039f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403332874-172.17.0.19-1598559625456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-7c009ad2-422f-4d47-a74c-1a6992dd83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-485651d1-9ffa-464b-882d-2e3a04e417fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-94de7213-03ea-4837-86d2-9f6213a7bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-aa41e838-f7cd-4d5d-910c-f4615eb07a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-52b24340-c9a0-4db9-868a-468c62d3fb54,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-753eb3a0-4ed1-4ace-8e06-e79709ef1969,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-cdf34c8b-5972-4d99-84de-b2e9a2fa8c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-a0018411-124e-445e-af26-2175ce7e9653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403332874-172.17.0.19-1598559625456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-7c009ad2-422f-4d47-a74c-1a6992dd83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-485651d1-9ffa-464b-882d-2e3a04e417fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-94de7213-03ea-4837-86d2-9f6213a7bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-aa41e838-f7cd-4d5d-910c-f4615eb07a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-52b24340-c9a0-4db9-868a-468c62d3fb54,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-753eb3a0-4ed1-4ace-8e06-e79709ef1969,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-cdf34c8b-5972-4d99-84de-b2e9a2fa8c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-a0018411-124e-445e-af26-2175ce7e9653,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929815232-172.17.0.19-1598559764355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-717ea650-aa5b-4367-bcaa-3db3dcc01b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-bacad27a-d21f-49bc-9a8a-ae204ebe0501,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e24e70ca-270e-4794-920d-a8a0f31beeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-a44ee5b8-b2a0-44a1-9432-33a37e0ac94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4e79e083-0eaf-4488-b8c5-f39e002c45af,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-1afcf355-82a9-4c79-bf57-1818545adcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-88bd69fa-42dd-4741-b8e9-439f85bfbc82,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-7109a7ea-40f9-47f2-833b-ed79013cbe9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929815232-172.17.0.19-1598559764355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-717ea650-aa5b-4367-bcaa-3db3dcc01b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-bacad27a-d21f-49bc-9a8a-ae204ebe0501,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e24e70ca-270e-4794-920d-a8a0f31beeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-a44ee5b8-b2a0-44a1-9432-33a37e0ac94c,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4e79e083-0eaf-4488-b8c5-f39e002c45af,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-1afcf355-82a9-4c79-bf57-1818545adcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-88bd69fa-42dd-4741-b8e9-439f85bfbc82,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-7109a7ea-40f9-47f2-833b-ed79013cbe9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66556959-172.17.0.19-1598559937819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-4a07952f-79ac-4078-af2d-4c23147419f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b69860f9-52b6-4900-83ff-57f76bf7b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-aeb6c1b4-28b2-4fae-9601-a1fc99fa1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-e4b92672-091f-4187-b046-8aa636ac3317,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-39c88838-eb34-4439-81f0-74f76c23d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-8d75c794-216a-44fc-b7d2-291c0a6e705e,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-f07cf8a7-28cc-41f1-bd53-9f0d69bf8dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-69d64072-04ac-4cce-996f-46f5b89d3867,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66556959-172.17.0.19-1598559937819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35543,DS-4a07952f-79ac-4078-af2d-4c23147419f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b69860f9-52b6-4900-83ff-57f76bf7b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-aeb6c1b4-28b2-4fae-9601-a1fc99fa1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-e4b92672-091f-4187-b046-8aa636ac3317,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-39c88838-eb34-4439-81f0-74f76c23d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-8d75c794-216a-44fc-b7d2-291c0a6e705e,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-f07cf8a7-28cc-41f1-bd53-9f0d69bf8dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-69d64072-04ac-4cce-996f-46f5b89d3867,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423491650-172.17.0.19-1598559974942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-88611683-6817-4772-b185-cb2b4167d860,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-176f392e-d30e-422f-8229-aa378e3491b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-8602a64b-d8d7-48e1-b41f-186e705adccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-0d88a358-bbac-482b-8588-25d94fd31f30,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-929983c0-c651-4597-8b62-3a53242ea256,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-223dd67c-0922-49b9-857b-a2cc9a2325f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-bc70f6fc-2ffe-4308-970b-92dca1b32593,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-35ddda98-5428-4782-8849-fbb1c0c5ffba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423491650-172.17.0.19-1598559974942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-88611683-6817-4772-b185-cb2b4167d860,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-176f392e-d30e-422f-8229-aa378e3491b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-8602a64b-d8d7-48e1-b41f-186e705adccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-0d88a358-bbac-482b-8588-25d94fd31f30,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-929983c0-c651-4597-8b62-3a53242ea256,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-223dd67c-0922-49b9-857b-a2cc9a2325f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-bc70f6fc-2ffe-4308-970b-92dca1b32593,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-35ddda98-5428-4782-8849-fbb1c0c5ffba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 27 out of 50
result: false positive !!!
Total execution time in seconds : 5609
