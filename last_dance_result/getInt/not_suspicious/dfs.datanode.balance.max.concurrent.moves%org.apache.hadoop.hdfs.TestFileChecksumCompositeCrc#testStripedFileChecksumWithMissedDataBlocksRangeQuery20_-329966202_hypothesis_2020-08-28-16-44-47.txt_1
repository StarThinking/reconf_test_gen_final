reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646864846-172.17.0.9-1598633395385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-9ee6542f-bd70-46cd-9c52-456852668104,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f7f2576b-4748-4ead-b8b4-3e7408bffe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-626be228-3a7f-4d58-8ac7-6bcd53dcbd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-273df0c2-fc88-4b7b-82d5-2d7dcf89827d,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-4d34e9c7-b7cc-44fc-96a3-f6e83f0d069c,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f57d8187-a34b-4e3c-813a-5da1da5447f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-b154c26f-cdc4-4030-873f-0dac7d12688a,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-8bca7bdf-75fb-40df-baf4-fe2e59020390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646864846-172.17.0.9-1598633395385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-9ee6542f-bd70-46cd-9c52-456852668104,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-f7f2576b-4748-4ead-b8b4-3e7408bffe83,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-626be228-3a7f-4d58-8ac7-6bcd53dcbd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-273df0c2-fc88-4b7b-82d5-2d7dcf89827d,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-4d34e9c7-b7cc-44fc-96a3-f6e83f0d069c,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f57d8187-a34b-4e3c-813a-5da1da5447f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-b154c26f-cdc4-4030-873f-0dac7d12688a,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-8bca7bdf-75fb-40df-baf4-fe2e59020390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117486102-172.17.0.9-1598633737683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-16d60f26-def3-4653-830f-209cac147ead,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-264dc919-0e1f-44ac-bfce-14d9dbd1ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-2bdac2ac-4541-448a-a220-f760615a0084,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-eb325e90-bccf-4b76-8ab2-570111a1c372,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-228bf664-c4ab-4c21-a749-b43f0ec9e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-3e236307-12ce-4d07-ad00-d5d1b9553723,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-e5bc5fce-5b61-4cbc-9a9b-e9a99671c441,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-69c4ac80-9acd-493a-9173-9442045af81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117486102-172.17.0.9-1598633737683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-16d60f26-def3-4653-830f-209cac147ead,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-264dc919-0e1f-44ac-bfce-14d9dbd1ec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-2bdac2ac-4541-448a-a220-f760615a0084,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-eb325e90-bccf-4b76-8ab2-570111a1c372,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-228bf664-c4ab-4c21-a749-b43f0ec9e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-3e236307-12ce-4d07-ad00-d5d1b9553723,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-e5bc5fce-5b61-4cbc-9a9b-e9a99671c441,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-69c4ac80-9acd-493a-9173-9442045af81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708339640-172.17.0.9-1598633934945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-eafbefdb-704b-46a6-a36e-f71e5df9b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a8a900ec-2bbd-4a42-aaa0-b19b5a590f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-85c20a32-696f-4538-bfe9-5b066373192b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-70758bdf-74b1-4adc-9e96-bde0af30dede,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-0da90c67-9285-4692-b3c2-5407f2921e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-34fbf2fe-12af-4d31-a44e-29994b739f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-a7f78804-b89d-4ccd-b01c-03d2a732b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-a87f2666-fa4d-4c30-9400-4f0e0386b43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708339640-172.17.0.9-1598633934945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-eafbefdb-704b-46a6-a36e-f71e5df9b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-a8a900ec-2bbd-4a42-aaa0-b19b5a590f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-85c20a32-696f-4538-bfe9-5b066373192b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-70758bdf-74b1-4adc-9e96-bde0af30dede,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-0da90c67-9285-4692-b3c2-5407f2921e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-34fbf2fe-12af-4d31-a44e-29994b739f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-a7f78804-b89d-4ccd-b01c-03d2a732b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-a87f2666-fa4d-4c30-9400-4f0e0386b43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756018326-172.17.0.9-1598634244789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36475,DS-d6693288-1dee-4204-a778-4260a6810e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-eef9eebe-3b82-4f54-8cd9-196113306b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1b6d511a-82b0-4403-adb0-840bac147a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8a093a7a-f66e-4287-880f-6386d1f42e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-16ea6815-caea-4d72-9df9-3fa84bc5a836,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-9cfb2a3f-de2a-4d5c-a82f-f305c1728e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-74f44e2b-bade-42d9-95ef-d08c0888d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-34b895c3-6169-4109-816b-939bd3c4e4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756018326-172.17.0.9-1598634244789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36475,DS-d6693288-1dee-4204-a778-4260a6810e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-eef9eebe-3b82-4f54-8cd9-196113306b78,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-1b6d511a-82b0-4403-adb0-840bac147a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8a093a7a-f66e-4287-880f-6386d1f42e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-16ea6815-caea-4d72-9df9-3fa84bc5a836,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-9cfb2a3f-de2a-4d5c-a82f-f305c1728e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-74f44e2b-bade-42d9-95ef-d08c0888d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-34b895c3-6169-4109-816b-939bd3c4e4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025874287-172.17.0.9-1598636273730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-52e09f04-841a-4231-8166-5310c2a5fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-6baefe14-b6df-4ab8-9e24-68de13f99f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-bb2fc9d1-89b3-44b3-a2f5-bcaf9a7b320d,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-5d484149-b87e-4254-bbeb-9413d8390ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-8d347777-bba1-479c-b995-97932718c547,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-fa4f7196-c6f2-4706-ade7-a84c2fc570e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-97826687-a97c-4807-a04e-2bb11ea202e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-dfe3d5e8-4a84-4d33-9672-91bbcdaed40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025874287-172.17.0.9-1598636273730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35375,DS-52e09f04-841a-4231-8166-5310c2a5fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-6baefe14-b6df-4ab8-9e24-68de13f99f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-bb2fc9d1-89b3-44b3-a2f5-bcaf9a7b320d,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-5d484149-b87e-4254-bbeb-9413d8390ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-8d347777-bba1-479c-b995-97932718c547,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-fa4f7196-c6f2-4706-ade7-a84c2fc570e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-97826687-a97c-4807-a04e-2bb11ea202e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-dfe3d5e8-4a84-4d33-9672-91bbcdaed40a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385449752-172.17.0.9-1598636334864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-f417c14c-ba9e-4d5c-8c39-d775290bf570,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-2b080492-a7d8-458f-bf42-ede62e467132,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-e8f36d5d-00d6-45b9-a964-e9e0de72fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-5fea00d3-b1d9-40a3-a271-7d0687e81166,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-48d41de9-636f-45a6-96a1-b205a3f867e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-062b23c3-bf62-4396-b5f8-c7c8b54cc72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-84e2cdb7-0e53-49a5-8bf6-bd94497fb3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-3bf79145-42bc-47d3-bc41-80f06175531b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385449752-172.17.0.9-1598636334864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-f417c14c-ba9e-4d5c-8c39-d775290bf570,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-2b080492-a7d8-458f-bf42-ede62e467132,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-e8f36d5d-00d6-45b9-a964-e9e0de72fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-5fea00d3-b1d9-40a3-a271-7d0687e81166,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-48d41de9-636f-45a6-96a1-b205a3f867e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-062b23c3-bf62-4396-b5f8-c7c8b54cc72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-84e2cdb7-0e53-49a5-8bf6-bd94497fb3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-3bf79145-42bc-47d3-bc41-80f06175531b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129194864-172.17.0.9-1598636441855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-cdc6f79b-cc9a-41f1-9748-8d3e857a3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-472f1e35-24da-4013-9b2a-3206c740770b,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-87fb8985-4ae3-4f25-95db-937c64a268e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-3ef14cbd-4e74-4b71-b435-92c67bfad037,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-754594b7-d3ed-4479-b83c-844a3f430b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-4cd26ee7-89eb-4e32-9967-803ac3bb61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-14c1834f-0763-4f22-b53b-c261b6df633f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-a3d4542b-6459-4385-9ab8-b9f24006c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129194864-172.17.0.9-1598636441855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-cdc6f79b-cc9a-41f1-9748-8d3e857a3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-472f1e35-24da-4013-9b2a-3206c740770b,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-87fb8985-4ae3-4f25-95db-937c64a268e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-3ef14cbd-4e74-4b71-b435-92c67bfad037,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-754594b7-d3ed-4479-b83c-844a3f430b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-4cd26ee7-89eb-4e32-9967-803ac3bb61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-14c1834f-0763-4f22-b53b-c261b6df633f,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-a3d4542b-6459-4385-9ab8-b9f24006c9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850581144-172.17.0.9-1598636760542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-a19d7915-dc69-4506-ba80-c0477341d375,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-331eef00-0d57-48ae-ab11-512ae9284cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-76a1a5e5-28f8-4d48-a9b5-9dab81f763d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-f7ef829f-24af-4d80-bb69-870d82f5742d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-afe40de1-6b1e-4c23-af42-7aa45d652b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-25ceb7de-de99-4467-b40d-987ee21bc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-cc53a0b1-a420-4a11-888e-ca18bfbab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-1abe5f1b-01e3-4ea2-903a-8c23a79ccb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850581144-172.17.0.9-1598636760542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-a19d7915-dc69-4506-ba80-c0477341d375,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-331eef00-0d57-48ae-ab11-512ae9284cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-76a1a5e5-28f8-4d48-a9b5-9dab81f763d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-f7ef829f-24af-4d80-bb69-870d82f5742d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-afe40de1-6b1e-4c23-af42-7aa45d652b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-25ceb7de-de99-4467-b40d-987ee21bc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-cc53a0b1-a420-4a11-888e-ca18bfbab6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-1abe5f1b-01e3-4ea2-903a-8c23a79ccb4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999661457-172.17.0.9-1598636872759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-db983ea4-e268-45c2-88f7-126183e09ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-11c46cb5-890c-4c95-b86f-c3e47f8930af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-4e065895-b00f-4285-b553-5eb09f909115,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-f0ae162d-11ce-44ab-bb7a-2b1dacfa5b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2f680966-6e3b-443a-926d-7d8d47ffee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-a7f47425-8eb2-49ab-8394-c56f9ffd0861,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-1c3c5acf-50af-484e-bf88-e73195cd1437,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-acd5a2fc-37c7-40ee-abba-fefff1f43358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999661457-172.17.0.9-1598636872759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-db983ea4-e268-45c2-88f7-126183e09ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-11c46cb5-890c-4c95-b86f-c3e47f8930af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-4e065895-b00f-4285-b553-5eb09f909115,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-f0ae162d-11ce-44ab-bb7a-2b1dacfa5b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-2f680966-6e3b-443a-926d-7d8d47ffee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-a7f47425-8eb2-49ab-8394-c56f9ffd0861,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-1c3c5acf-50af-484e-bf88-e73195cd1437,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-acd5a2fc-37c7-40ee-abba-fefff1f43358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368555886-172.17.0.9-1598637006679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-c64fe0b1-3b28-4217-817d-5d0e260e1b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-06f5b8de-1b3f-4487-b50c-f6f91ad62b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-ae3c2242-0147-424f-a740-132e3b2714fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-fcdf0c84-19bc-4819-bedc-1a53bd43ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f35f8e15-bbac-4718-9d89-0635ca7caa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-f1e0c1c8-3923-4956-bf59-e0cf280acb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-a406ae99-1441-4615-8c88-af14da90abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-5e5cf106-8982-4e88-80b7-6e7c4cac7578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368555886-172.17.0.9-1598637006679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-c64fe0b1-3b28-4217-817d-5d0e260e1b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-06f5b8de-1b3f-4487-b50c-f6f91ad62b87,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-ae3c2242-0147-424f-a740-132e3b2714fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-fcdf0c84-19bc-4819-bedc-1a53bd43ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-f35f8e15-bbac-4718-9d89-0635ca7caa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-f1e0c1c8-3923-4956-bf59-e0cf280acb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-a406ae99-1441-4615-8c88-af14da90abee,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-5e5cf106-8982-4e88-80b7-6e7c4cac7578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65320788-172.17.0.9-1598637365045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-f442bb2a-df44-433e-8bc8-2c1f1172bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-e80ae38e-b186-468b-af9c-fed3c52356d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-f2a5b894-0973-46a2-87a6-394e039d39c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-7dfa571d-c57b-4cab-a78d-cf5f6da22828,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-c56beb0c-5914-44a4-b2c1-e92bf8c88864,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c2ac4f51-6f5d-4e68-922c-ed54a27c97ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-6ea360d7-ea46-4367-bfe9-75be55cc1b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f51fab4-9ae7-4880-af1c-505423db38b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65320788-172.17.0.9-1598637365045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-f442bb2a-df44-433e-8bc8-2c1f1172bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-e80ae38e-b186-468b-af9c-fed3c52356d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-f2a5b894-0973-46a2-87a6-394e039d39c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-7dfa571d-c57b-4cab-a78d-cf5f6da22828,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-c56beb0c-5914-44a4-b2c1-e92bf8c88864,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c2ac4f51-6f5d-4e68-922c-ed54a27c97ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-6ea360d7-ea46-4367-bfe9-75be55cc1b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f51fab4-9ae7-4880-af1c-505423db38b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544470822-172.17.0.9-1598637679169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-18a41dba-9877-42fd-96cd-b13aace3dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-abd3386e-cf46-40bd-9e79-fa2294f25905,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-df76ea45-d0e2-40d3-9b35-eda2d3ccd456,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-3537b927-b490-4334-b320-1b15fa5acaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-edc16168-529c-4da0-b468-eade957c3691,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-1105a68d-5c4d-4963-a42c-f5999a69644c,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-7a9a7446-f25c-400b-bec0-dbea4f64844d,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-11e4363a-db3f-4019-89ab-85cc9850accb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544470822-172.17.0.9-1598637679169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-18a41dba-9877-42fd-96cd-b13aace3dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-abd3386e-cf46-40bd-9e79-fa2294f25905,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-df76ea45-d0e2-40d3-9b35-eda2d3ccd456,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-3537b927-b490-4334-b320-1b15fa5acaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-edc16168-529c-4da0-b468-eade957c3691,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-1105a68d-5c4d-4963-a42c-f5999a69644c,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-7a9a7446-f25c-400b-bec0-dbea4f64844d,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-11e4363a-db3f-4019-89ab-85cc9850accb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707655958-172.17.0.9-1598637757133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36227,DS-86ece97a-d741-4759-9bb2-5bfda492101f,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-05b1f951-b68a-4f34-b16a-95342132cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-56385766-02f0-4a43-a1b5-82ca1755b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-45bb6440-d820-494e-a180-2a84385fc6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-5c649950-732f-41ca-8c2e-5276a8c08ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-9624c490-19d5-4641-9cb5-d08693493f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-352dd184-de27-43a7-8b0d-8bc73a4722cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-b6b4195a-7b8a-47c2-ab5a-d1decdd6bdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707655958-172.17.0.9-1598637757133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36227,DS-86ece97a-d741-4759-9bb2-5bfda492101f,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-05b1f951-b68a-4f34-b16a-95342132cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-56385766-02f0-4a43-a1b5-82ca1755b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-45bb6440-d820-494e-a180-2a84385fc6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-5c649950-732f-41ca-8c2e-5276a8c08ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-9624c490-19d5-4641-9cb5-d08693493f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-352dd184-de27-43a7-8b0d-8bc73a4722cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-b6b4195a-7b8a-47c2-ab5a-d1decdd6bdca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513448385-172.17.0.9-1598638248782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-3c1eabe2-7ce7-421f-a63b-c941ade19e66,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-82ee43ce-072b-4dfd-b836-295f48cb928c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-095f4eed-995d-4f2c-bd60-ea418ea66f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-61d386da-2b5b-4e35-b565-23d57d51f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-ebfa8a14-7009-4ea2-bdcd-270959dda075,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e66553f1-c8e6-46d6-9fce-d18ce20fd327,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-f1edde32-3b65-4de3-aa7b-b56c29675d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-da8fd6f9-b2cf-43e2-b52e-5de11a729f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513448385-172.17.0.9-1598638248782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-3c1eabe2-7ce7-421f-a63b-c941ade19e66,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-82ee43ce-072b-4dfd-b836-295f48cb928c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-095f4eed-995d-4f2c-bd60-ea418ea66f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-61d386da-2b5b-4e35-b565-23d57d51f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-ebfa8a14-7009-4ea2-bdcd-270959dda075,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e66553f1-c8e6-46d6-9fce-d18ce20fd327,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-f1edde32-3b65-4de3-aa7b-b56c29675d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-da8fd6f9-b2cf-43e2-b52e-5de11a729f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601957216-172.17.0.9-1598638466483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-c8372a34-591b-4206-bff5-ddc3aa3ca343,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-a972f43b-8414-44b6-8339-aab1e7d33190,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a93d735-f238-4529-b24a-621525afea31,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-4e442460-bed2-42b5-87e8-7626f2abf68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-8c1ef1ff-2f74-46d2-8d2e-aed9df0d46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-28d18b6b-80b2-4441-87ac-5d1c366c356e,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-db43810a-9837-43ab-81e8-107f4ccc6d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-df613eed-8260-43a0-b98e-b50150f58deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601957216-172.17.0.9-1598638466483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-c8372a34-591b-4206-bff5-ddc3aa3ca343,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-a972f43b-8414-44b6-8339-aab1e7d33190,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a93d735-f238-4529-b24a-621525afea31,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-4e442460-bed2-42b5-87e8-7626f2abf68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-8c1ef1ff-2f74-46d2-8d2e-aed9df0d46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-28d18b6b-80b2-4441-87ac-5d1c366c356e,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-db43810a-9837-43ab-81e8-107f4ccc6d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-df613eed-8260-43a0-b98e-b50150f58deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5508
