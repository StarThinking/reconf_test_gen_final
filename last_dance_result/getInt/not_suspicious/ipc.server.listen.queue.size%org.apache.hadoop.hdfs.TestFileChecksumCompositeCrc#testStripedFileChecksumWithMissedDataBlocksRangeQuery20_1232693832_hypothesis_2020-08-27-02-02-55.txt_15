reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17892062-172.17.0.21-1598494459564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-78ea56d3-0a80-4472-a494-d30e9b0d085b,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-17ccaa4f-72eb-4318-829a-399032d988cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-1fb53c8d-6bd0-446e-92f0-ac6044f97863,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-b2800879-f4d1-4643-afd8-255c4798395e,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6c6c45c0-b6c7-4ed0-b0df-b2384f99f788,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-460e8e67-c523-43ad-b6b4-9120ddde188b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-852769b1-fed6-483e-a950-2dcb8e1842c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-464f3579-3203-4425-b214-72dd3791416a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17892062-172.17.0.21-1598494459564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-78ea56d3-0a80-4472-a494-d30e9b0d085b,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-17ccaa4f-72eb-4318-829a-399032d988cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-1fb53c8d-6bd0-446e-92f0-ac6044f97863,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-b2800879-f4d1-4643-afd8-255c4798395e,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6c6c45c0-b6c7-4ed0-b0df-b2384f99f788,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-460e8e67-c523-43ad-b6b4-9120ddde188b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-852769b1-fed6-483e-a950-2dcb8e1842c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-464f3579-3203-4425-b214-72dd3791416a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895025391-172.17.0.21-1598494755721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-8e6062e1-99ab-4ef2-9bd4-ccfde6c0cfac,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ecd67622-246a-42ab-a4ad-a19a18b58e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-380f0ac2-6c98-4596-a50e-81adedfbf174,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-65581200-39a4-4446-8916-44bb8c6ee3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-0053ee10-db79-4dd5-8a00-2b843b5598cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-2f728945-37f5-4fee-81d8-c38aafcbec68,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-942e6bd5-fbd8-4102-b262-39d0694a177b,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-4ae100bd-a601-4af2-b546-3c9b17628f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895025391-172.17.0.21-1598494755721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-8e6062e1-99ab-4ef2-9bd4-ccfde6c0cfac,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-ecd67622-246a-42ab-a4ad-a19a18b58e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-380f0ac2-6c98-4596-a50e-81adedfbf174,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-65581200-39a4-4446-8916-44bb8c6ee3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-0053ee10-db79-4dd5-8a00-2b843b5598cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-2f728945-37f5-4fee-81d8-c38aafcbec68,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-942e6bd5-fbd8-4102-b262-39d0694a177b,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-4ae100bd-a601-4af2-b546-3c9b17628f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762728717-172.17.0.21-1598494885121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-9d544932-e41e-4643-87a6-e27076d7362b,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-7858b53d-accc-4d26-9ebe-4e5af56ecd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-36f7d0f6-76f3-47c6-be5c-8cce659360f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-a2ee89f3-ebc7-4932-8396-f94318ffbc31,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-80a077a8-285f-4ce8-ac1b-15d9517fe835,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-e3a2e2c2-c36c-4217-8a34-fd395d51e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3759dcb7-cbc7-4176-bd3a-1e1b6b325fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-851664f8-37d9-475f-a142-6e3f5cbf1ec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762728717-172.17.0.21-1598494885121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34006,DS-9d544932-e41e-4643-87a6-e27076d7362b,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-7858b53d-accc-4d26-9ebe-4e5af56ecd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-36f7d0f6-76f3-47c6-be5c-8cce659360f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-a2ee89f3-ebc7-4932-8396-f94318ffbc31,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-80a077a8-285f-4ce8-ac1b-15d9517fe835,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-e3a2e2c2-c36c-4217-8a34-fd395d51e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-3759dcb7-cbc7-4176-bd3a-1e1b6b325fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-851664f8-37d9-475f-a142-6e3f5cbf1ec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664078299-172.17.0.21-1598495531210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32954,DS-7c2face8-24a2-438e-ba06-f0f407cea164,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-c62bb28b-7458-4e4c-a76d-5d50fc564c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-54453d91-2bcc-4bad-b84d-37849974ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-a6a64c98-5234-4cdb-b976-2d1581435877,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-eba794fe-62a4-419e-9e35-aeafe6113773,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-8180d609-7971-420d-bf1a-28b4b9c2fe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-6a10c934-95e0-4f20-82f3-25c12bf20ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-05d9ef1e-0b70-409e-971f-ce5211a17012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664078299-172.17.0.21-1598495531210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32954,DS-7c2face8-24a2-438e-ba06-f0f407cea164,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-c62bb28b-7458-4e4c-a76d-5d50fc564c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-54453d91-2bcc-4bad-b84d-37849974ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-a6a64c98-5234-4cdb-b976-2d1581435877,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-eba794fe-62a4-419e-9e35-aeafe6113773,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-8180d609-7971-420d-bf1a-28b4b9c2fe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-6a10c934-95e0-4f20-82f3-25c12bf20ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-05d9ef1e-0b70-409e-971f-ce5211a17012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126908705-172.17.0.21-1598495637933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-eba8ad31-766b-4aa9-8a05-3790f56e4499,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-df95b2d3-50d9-4a2b-9b02-6c2581758977,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-058348c9-7c3b-4c4c-91ea-f5b7ad2fa817,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-02bce833-2ed8-4635-a203-31e16d886822,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a43bf651-5418-4064-b933-c655727aeeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-14338e31-c3b9-49fd-9a29-b4fb31c62ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-1c4a2028-8f37-4488-a4f7-6883935b439e,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-89e15a1e-8111-4cc1-b754-20607771d2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126908705-172.17.0.21-1598495637933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-eba8ad31-766b-4aa9-8a05-3790f56e4499,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-df95b2d3-50d9-4a2b-9b02-6c2581758977,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-058348c9-7c3b-4c4c-91ea-f5b7ad2fa817,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-02bce833-2ed8-4635-a203-31e16d886822,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-a43bf651-5418-4064-b933-c655727aeeab,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-14338e31-c3b9-49fd-9a29-b4fb31c62ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-1c4a2028-8f37-4488-a4f7-6883935b439e,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-89e15a1e-8111-4cc1-b754-20607771d2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936879540-172.17.0.21-1598495763776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-bc097586-5153-4d0a-97ca-f49d4b29e27a,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-8d52c36a-87d2-4faf-a82e-83d52c8e07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-079c846d-91b9-4ef8-96ed-4a22de057c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7d73dd71-a83e-44c7-87ae-4fc5de9c3ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-7b8a52f5-df39-470c-bd17-6757d74da577,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-7452cb48-25e5-4399-be59-d1b06dd218a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-6a228421-f534-44de-802d-e2c4454141f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-26bef0e8-fc82-4adb-a969-47b2d57ce537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-936879540-172.17.0.21-1598495763776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-bc097586-5153-4d0a-97ca-f49d4b29e27a,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-8d52c36a-87d2-4faf-a82e-83d52c8e07fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-079c846d-91b9-4ef8-96ed-4a22de057c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7d73dd71-a83e-44c7-87ae-4fc5de9c3ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-7b8a52f5-df39-470c-bd17-6757d74da577,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-7452cb48-25e5-4399-be59-d1b06dd218a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-6a228421-f534-44de-802d-e2c4454141f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-26bef0e8-fc82-4adb-a969-47b2d57ce537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145752261-172.17.0.21-1598495989859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-01f43ad9-b795-4952-b90d-a7d903740ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-b86e628e-07bd-4790-be21-e6a0a2a36db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-7d90437e-6bd7-423e-b6d4-78b646ce0081,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-2fc6f457-e273-43b7-b0a2-736a3bc0784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-f0d2c3ad-9769-4c12-9cca-9d66c32f26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-e3db416e-150b-4b52-8968-cd90df24e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-3de585a4-4409-432d-992c-c0905ce2a940,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-4418334b-eaa5-46ae-a322-614d7103c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145752261-172.17.0.21-1598495989859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-01f43ad9-b795-4952-b90d-a7d903740ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-b86e628e-07bd-4790-be21-e6a0a2a36db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-7d90437e-6bd7-423e-b6d4-78b646ce0081,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-2fc6f457-e273-43b7-b0a2-736a3bc0784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-f0d2c3ad-9769-4c12-9cca-9d66c32f26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-e3db416e-150b-4b52-8968-cd90df24e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-3de585a4-4409-432d-992c-c0905ce2a940,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-4418334b-eaa5-46ae-a322-614d7103c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493701342-172.17.0.21-1598496707583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-ad380178-3686-4c03-9550-6b732b505878,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a17ec269-3690-4ae4-9ae6-568d7d5874bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fd50e47d-4d58-4bb4-ab0a-e44bd6637939,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-40e3ea95-f214-4959-9dca-4cfa16764c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-3fdd3906-295e-45bd-b938-d740fa5aa117,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-7621ee26-3d0d-423d-9ed5-0143771ba6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-5e9633a3-d236-4726-bc36-d0ff9f7ebd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-52b6620a-be3d-4a97-b30c-a2c2f35b2727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493701342-172.17.0.21-1598496707583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-ad380178-3686-4c03-9550-6b732b505878,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-a17ec269-3690-4ae4-9ae6-568d7d5874bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fd50e47d-4d58-4bb4-ab0a-e44bd6637939,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-40e3ea95-f214-4959-9dca-4cfa16764c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-3fdd3906-295e-45bd-b938-d740fa5aa117,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-7621ee26-3d0d-423d-9ed5-0143771ba6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-5e9633a3-d236-4726-bc36-d0ff9f7ebd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-52b6620a-be3d-4a97-b30c-a2c2f35b2727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731746074-172.17.0.21-1598496785268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-cacd35cb-1e7b-4336-b3b0-516beb5dbf19,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-72ff1e7a-644b-4165-9418-fe6d27048b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-2cecc256-2bcd-40a4-b611-905b7e486eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d1b24d44-3f63-41c7-a386-a4ddcdc27e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-dbcff88d-d266-41a0-b4a2-a385370d91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-5d723007-df95-492a-b12c-91fa9ea92e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-fa691a4b-a3ba-4067-bcb5-79f054b37340,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-55cec551-af29-4e9d-951b-141de3124c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731746074-172.17.0.21-1598496785268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-cacd35cb-1e7b-4336-b3b0-516beb5dbf19,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-72ff1e7a-644b-4165-9418-fe6d27048b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-2cecc256-2bcd-40a4-b611-905b7e486eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d1b24d44-3f63-41c7-a386-a4ddcdc27e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-dbcff88d-d266-41a0-b4a2-a385370d91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-5d723007-df95-492a-b12c-91fa9ea92e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-fa691a4b-a3ba-4067-bcb5-79f054b37340,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-55cec551-af29-4e9d-951b-141de3124c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582937618-172.17.0.21-1598496835799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-ef0e6ba4-78c1-48e1-9bbf-8833eab6d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-7ee72433-5a10-4bd7-8fec-23d22d4340fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-1a6d98c5-bce4-4125-8efc-90b5b7b08c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-27d869a9-298f-45c9-8abd-5d96e21fcebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-00624af1-932a-4673-8ddf-9104293a0b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-746698eb-9cd4-46bb-bf2f-a434bac9b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-bc4e8615-94ae-4a74-9386-b52afeedbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-847f093b-222a-4402-880b-ecf7a53a20a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582937618-172.17.0.21-1598496835799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-ef0e6ba4-78c1-48e1-9bbf-8833eab6d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-7ee72433-5a10-4bd7-8fec-23d22d4340fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-1a6d98c5-bce4-4125-8efc-90b5b7b08c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-27d869a9-298f-45c9-8abd-5d96e21fcebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-00624af1-932a-4673-8ddf-9104293a0b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-746698eb-9cd4-46bb-bf2f-a434bac9b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-bc4e8615-94ae-4a74-9386-b52afeedbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-847f093b-222a-4402-880b-ecf7a53a20a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421873797-172.17.0.21-1598496963415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43025,DS-03104943-32cd-4dd1-b880-e1ebf8e7be46,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-7dc949a7-f9be-4d84-8546-121c8e555fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-93f64828-1245-460b-aa1a-95c3843e818f,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-171fe40a-eae7-46cd-a7bc-6e335d6f54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-8d40ff82-7f42-438f-8908-b0018390ecce,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-dd0b18b2-62d5-487f-bf7b-b568fb624956,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-d68e2ddc-8205-40fa-8135-d7253ce158d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-117b9f02-8787-45a1-a802-9eb11245cc59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421873797-172.17.0.21-1598496963415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43025,DS-03104943-32cd-4dd1-b880-e1ebf8e7be46,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-7dc949a7-f9be-4d84-8546-121c8e555fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-93f64828-1245-460b-aa1a-95c3843e818f,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-171fe40a-eae7-46cd-a7bc-6e335d6f54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-8d40ff82-7f42-438f-8908-b0018390ecce,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-dd0b18b2-62d5-487f-bf7b-b568fb624956,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-d68e2ddc-8205-40fa-8135-d7253ce158d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-117b9f02-8787-45a1-a802-9eb11245cc59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140092809-172.17.0.21-1598497136610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-b2a2b179-73af-4c4a-aa2a-9fdb4b250d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-29857594-49a0-4ea1-a9bb-fe613a671982,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-2c5fc934-f0e0-4948-b2c0-73529184a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ac937cf9-c45b-43c8-a629-35f08ad2cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-cd0553ad-7e11-4207-be7e-7ef11dec1c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-630b1b67-a15a-43c5-81aa-f308ad36c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-372ba3dc-b401-4ad1-9388-f0a8ad342ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-ad7b3ff5-a996-4ff7-a366-cc9b8d9e9970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140092809-172.17.0.21-1598497136610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-b2a2b179-73af-4c4a-aa2a-9fdb4b250d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-29857594-49a0-4ea1-a9bb-fe613a671982,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-2c5fc934-f0e0-4948-b2c0-73529184a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ac937cf9-c45b-43c8-a629-35f08ad2cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-cd0553ad-7e11-4207-be7e-7ef11dec1c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-630b1b67-a15a-43c5-81aa-f308ad36c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-372ba3dc-b401-4ad1-9388-f0a8ad342ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-ad7b3ff5-a996-4ff7-a366-cc9b8d9e9970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42686249-172.17.0.21-1598497307902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-ada22f77-d0bf-435b-a8c5-7c69809cb466,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-e049cc14-ca02-4480-a946-bc97c046e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-6e9e119f-b6f3-4f2d-a333-f9065379d042,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6d86f090-f590-4687-82cf-1afe6ce71c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-bab873a2-ed60-402c-ad72-5781f3459373,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-d9b0798b-9828-41f7-a1e4-ef2f1dabed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-bea585f4-1b85-44a1-aea6-b1a01899c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-818356f7-86eb-4e61-8c1f-3e7dad24fc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42686249-172.17.0.21-1598497307902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-ada22f77-d0bf-435b-a8c5-7c69809cb466,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-e049cc14-ca02-4480-a946-bc97c046e9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-6e9e119f-b6f3-4f2d-a333-f9065379d042,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6d86f090-f590-4687-82cf-1afe6ce71c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-bab873a2-ed60-402c-ad72-5781f3459373,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-d9b0798b-9828-41f7-a1e4-ef2f1dabed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-bea585f4-1b85-44a1-aea6-b1a01899c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-818356f7-86eb-4e61-8c1f-3e7dad24fc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075140674-172.17.0.21-1598497402932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37312,DS-eb57d795-62ff-42b4-b6ab-eb1065d0436b,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-d8dc994f-6a01-4c09-85f3-85d0ef991ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-bfd6362f-1177-4896-8d12-6932e6d0ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-38a66634-3962-46cd-b62a-1dae6fb287a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-53822084-f542-40b0-bf99-f004f1f91122,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-f5e5fc28-2f10-4ede-b05c-63c7d6a19152,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-2c8c88d3-7c6c-43fa-9219-faf579d2c292,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-9900b6b7-abc3-4de5-a66d-2261bc1ce8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075140674-172.17.0.21-1598497402932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37312,DS-eb57d795-62ff-42b4-b6ab-eb1065d0436b,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-d8dc994f-6a01-4c09-85f3-85d0ef991ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-bfd6362f-1177-4896-8d12-6932e6d0ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-38a66634-3962-46cd-b62a-1dae6fb287a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-53822084-f542-40b0-bf99-f004f1f91122,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-f5e5fc28-2f10-4ede-b05c-63c7d6a19152,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-2c8c88d3-7c6c-43fa-9219-faf579d2c292,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-9900b6b7-abc3-4de5-a66d-2261bc1ce8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36722640-172.17.0.21-1598498055287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-efcf4a50-84e7-45e7-a16e-b54fe7f34484,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-8b642ea1-9586-4cb5-bdb3-c9fbf6e4f924,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-86230306-4d95-40d8-85cb-e9fe8fe5249f,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4c93d5e2-c03e-4932-98d3-93354beba2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-83eb1165-418d-41dd-9f73-75b7656ab723,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-65915649-4720-4119-8eae-410871da43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-87f7ec56-77cd-46c3-9f48-5093aa478f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-dbbdc1cd-e568-435b-8684-f0b30aec8a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36722640-172.17.0.21-1598498055287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35314,DS-efcf4a50-84e7-45e7-a16e-b54fe7f34484,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-8b642ea1-9586-4cb5-bdb3-c9fbf6e4f924,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-86230306-4d95-40d8-85cb-e9fe8fe5249f,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-4c93d5e2-c03e-4932-98d3-93354beba2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-83eb1165-418d-41dd-9f73-75b7656ab723,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-65915649-4720-4119-8eae-410871da43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-87f7ec56-77cd-46c3-9f48-5093aa478f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-dbbdc1cd-e568-435b-8684-f0b30aec8a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312626994-172.17.0.21-1598498086197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-a459c028-bff1-4a7f-a94a-76f9182ce6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-0acbe188-7e56-4ac3-b59a-75b120499d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-617f6885-2ce7-4e65-bc12-52d0315e123f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0ff0d48d-2185-4153-b54e-44d8893f6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-aeda4b5a-e487-458a-96bb-d029b36d204b,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-16046382-eb7e-402d-a869-ba6fca854d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-58e7cf3b-f3a2-4e22-bb56-192f848434c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-4250f3a6-b0d6-4778-994f-da4bb039dea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312626994-172.17.0.21-1598498086197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35744,DS-a459c028-bff1-4a7f-a94a-76f9182ce6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-0acbe188-7e56-4ac3-b59a-75b120499d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-617f6885-2ce7-4e65-bc12-52d0315e123f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-0ff0d48d-2185-4153-b54e-44d8893f6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-aeda4b5a-e487-458a-96bb-d029b36d204b,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-16046382-eb7e-402d-a869-ba6fca854d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-58e7cf3b-f3a2-4e22-bb56-192f848434c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-4250f3a6-b0d6-4778-994f-da4bb039dea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267133038-172.17.0.21-1598498243589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33630,DS-cae63ffd-5c57-476d-b117-85dad00e4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-55940893-045e-4307-a923-b903f1ba875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-46d202f5-bc67-4285-8e87-ffaab1d89aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-89de5fca-2cf7-4791-b91b-cffe741ecf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-16820f8a-10b1-4d27-9c05-3834d0284166,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-f935afc5-434a-4aa6-a238-af86f59a0097,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-ca4a389c-e364-4419-af09-b44147cc1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-87f8f8a6-ea58-4e48-9205-6651d4875d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267133038-172.17.0.21-1598498243589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33630,DS-cae63ffd-5c57-476d-b117-85dad00e4e82,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-55940893-045e-4307-a923-b903f1ba875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-46d202f5-bc67-4285-8e87-ffaab1d89aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-89de5fca-2cf7-4791-b91b-cffe741ecf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-16820f8a-10b1-4d27-9c05-3834d0284166,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-f935afc5-434a-4aa6-a238-af86f59a0097,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-ca4a389c-e364-4419-af09-b44147cc1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-87f8f8a6-ea58-4e48-9205-6651d4875d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706219166-172.17.0.21-1598498301743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-cd4989e1-4981-4c73-8962-f521753b56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-c26b64d0-1cca-4dff-9787-a6f15f2b9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1e25668a-067a-43fa-b277-a733fcb8c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-883a1867-1180-4537-af97-af0e1b3de717,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-c46c11cd-e880-4905-a45e-23e7030b9593,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-66faa5b5-0ff5-4a13-b955-fb1e32211675,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-d598cae2-9caa-4435-a297-156f24fcb822,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-0f93d111-1dc5-41c7-90f2-ff64f7933915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706219166-172.17.0.21-1598498301743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-cd4989e1-4981-4c73-8962-f521753b56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-c26b64d0-1cca-4dff-9787-a6f15f2b9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1e25668a-067a-43fa-b277-a733fcb8c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-883a1867-1180-4537-af97-af0e1b3de717,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-c46c11cd-e880-4905-a45e-23e7030b9593,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-66faa5b5-0ff5-4a13-b955-fb1e32211675,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-d598cae2-9caa-4435-a297-156f24fcb822,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-0f93d111-1dc5-41c7-90f2-ff64f7933915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4731
