reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177914852-172.17.0.19-1598534049621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-b1662bc0-3ae6-43e6-9d22-d56daaf77789,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-7d07deb6-d186-4737-8802-dd5d3718bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-faac911f-1e4f-4847-ab64-069732df251a,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-554cda44-f32f-45dd-9323-67ddea0e6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-4f862325-344d-4d14-9024-5a41814de888,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-7e3ea531-860f-4977-98d6-6e6d8c529f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-207e5bf6-3dbd-4465-85ea-117f2f9c7d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-3b9733ab-8b0d-49d6-afe2-99aced69bd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177914852-172.17.0.19-1598534049621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-b1662bc0-3ae6-43e6-9d22-d56daaf77789,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-7d07deb6-d186-4737-8802-dd5d3718bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-faac911f-1e4f-4847-ab64-069732df251a,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-554cda44-f32f-45dd-9323-67ddea0e6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-4f862325-344d-4d14-9024-5a41814de888,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-7e3ea531-860f-4977-98d6-6e6d8c529f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-207e5bf6-3dbd-4465-85ea-117f2f9c7d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-3b9733ab-8b0d-49d6-afe2-99aced69bd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844235044-172.17.0.19-1598534121095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-b939b05c-98bb-472b-be2d-de3f559cc51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-65e0310b-23aa-4cb2-bbe9-d2c078e1861e,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-e2c24ec0-c457-44f7-9044-1fe0e99d7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-7b80e877-3ff7-4261-9fdb-3db7b73dd575,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-26d187f9-2ce9-4672-bbfd-b9c400a615b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-0d6e49b5-0c9c-4343-819b-5d2628561d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-855a54ae-050a-4bd6-9a38-1849cfdabaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-2548bdd4-75d2-4656-af65-8afe26bc2949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844235044-172.17.0.19-1598534121095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-b939b05c-98bb-472b-be2d-de3f559cc51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-65e0310b-23aa-4cb2-bbe9-d2c078e1861e,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-e2c24ec0-c457-44f7-9044-1fe0e99d7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-7b80e877-3ff7-4261-9fdb-3db7b73dd575,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-26d187f9-2ce9-4672-bbfd-b9c400a615b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-0d6e49b5-0c9c-4343-819b-5d2628561d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-855a54ae-050a-4bd6-9a38-1849cfdabaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-2548bdd4-75d2-4656-af65-8afe26bc2949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016558396-172.17.0.19-1598534373118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-a3fc2caa-4a0a-4f84-954d-9f187d68057b,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-158caabb-9d71-4053-bed8-bdde36e0fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-9ce0eb3b-fbbe-4bfc-8b7a-6d1e63136d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-52d23807-97e4-44f7-bc94-a40b05f68427,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-b26527f9-d79b-4a62-a7fd-525b93ac7372,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-04bdd181-67a5-41f8-b750-ca3e60fea913,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-3b7369c8-c738-409e-8623-d920e734a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b536a565-274e-4236-9b65-e4793ca45024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016558396-172.17.0.19-1598534373118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-a3fc2caa-4a0a-4f84-954d-9f187d68057b,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-158caabb-9d71-4053-bed8-bdde36e0fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-9ce0eb3b-fbbe-4bfc-8b7a-6d1e63136d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-52d23807-97e4-44f7-bc94-a40b05f68427,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-b26527f9-d79b-4a62-a7fd-525b93ac7372,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-04bdd181-67a5-41f8-b750-ca3e60fea913,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-3b7369c8-c738-409e-8623-d920e734a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b536a565-274e-4236-9b65-e4793ca45024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587453887-172.17.0.19-1598535428505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-7b1f7f49-d22a-4889-9a24-37327f6bf474,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d0373223-5b3f-42de-aa41-c9e8ab95d34d,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3401f24f-9748-4bd3-b182-8dae91c926e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-343db323-4d2e-4f82-aa1a-49aa54c8eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-78f8e95a-0ee9-48bf-af7e-ecd28e120cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-985fc224-d7b3-4c45-adac-c8b32e919cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-5a6dd151-cc90-4991-a486-1d28eeac91e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-0628db75-fc94-4e81-b01c-c6cd19687c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587453887-172.17.0.19-1598535428505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-7b1f7f49-d22a-4889-9a24-37327f6bf474,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d0373223-5b3f-42de-aa41-c9e8ab95d34d,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-3401f24f-9748-4bd3-b182-8dae91c926e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-343db323-4d2e-4f82-aa1a-49aa54c8eb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-78f8e95a-0ee9-48bf-af7e-ecd28e120cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-985fc224-d7b3-4c45-adac-c8b32e919cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-5a6dd151-cc90-4991-a486-1d28eeac91e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-0628db75-fc94-4e81-b01c-c6cd19687c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708558471-172.17.0.19-1598535463838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-e82f5104-677d-4df5-8beb-5403e9bcc1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-2df0aedd-f1f4-4825-954f-2e6359c23419,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fd75dafc-0aad-4c49-af25-bad55fdcd551,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b41355c-e9b3-49e3-ae44-c1bbca646bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-d188ac32-70a6-42e0-b06e-40aeb31b8283,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-645fbbc0-37a2-4798-aa9e-41867bc95f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-af98a41f-6587-4da5-9ccf-82750c0a58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-ae464838-43b2-41e0-a0bb-67df4a4f0361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708558471-172.17.0.19-1598535463838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-e82f5104-677d-4df5-8beb-5403e9bcc1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-2df0aedd-f1f4-4825-954f-2e6359c23419,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fd75dafc-0aad-4c49-af25-bad55fdcd551,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-5b41355c-e9b3-49e3-ae44-c1bbca646bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-d188ac32-70a6-42e0-b06e-40aeb31b8283,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-645fbbc0-37a2-4798-aa9e-41867bc95f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-af98a41f-6587-4da5-9ccf-82750c0a58ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-ae464838-43b2-41e0-a0bb-67df4a4f0361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594721929-172.17.0.19-1598535815387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c1ae6d5a-c9d4-453a-aabe-e1cc555b8988,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-4f7c21cd-cac3-41ea-9011-7fd2761f1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-34abdc74-e021-4bf8-bdee-5f55245733e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-25753a6d-55a8-481f-b8ce-45d927ae4553,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-a43a20d2-af4e-46ac-80c1-2a3ce8c1672a,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-26026920-747c-46e6-bbe8-9ab54c558ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-dca998b8-a583-4307-8a79-0bbb6f8e5454,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-d5318aab-b014-4f54-b985-6a2bb3920742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594721929-172.17.0.19-1598535815387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-c1ae6d5a-c9d4-453a-aabe-e1cc555b8988,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-4f7c21cd-cac3-41ea-9011-7fd2761f1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-34abdc74-e021-4bf8-bdee-5f55245733e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-25753a6d-55a8-481f-b8ce-45d927ae4553,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-a43a20d2-af4e-46ac-80c1-2a3ce8c1672a,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-26026920-747c-46e6-bbe8-9ab54c558ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-dca998b8-a583-4307-8a79-0bbb6f8e5454,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-d5318aab-b014-4f54-b985-6a2bb3920742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644470725-172.17.0.19-1598536145683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43942,DS-e4aad783-d242-4a54-b84a-f4cc17bae6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-49bbdd5c-bfac-40fd-80bf-b2204bceb090,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-d4d13dd4-3533-4570-bd5b-bda8ece96c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-209ada04-adf2-4fb2-9a06-fa9b841cbea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-7542e709-3eac-4383-ae55-ed28190d64fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-32775beb-d67d-40ff-a700-229f3a2b668d,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-410bbcb5-a603-48eb-a665-6be8470e2872,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-54d39cea-41a3-442b-a0f7-6b9875e715e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644470725-172.17.0.19-1598536145683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43942,DS-e4aad783-d242-4a54-b84a-f4cc17bae6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-49bbdd5c-bfac-40fd-80bf-b2204bceb090,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-d4d13dd4-3533-4570-bd5b-bda8ece96c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-209ada04-adf2-4fb2-9a06-fa9b841cbea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-7542e709-3eac-4383-ae55-ed28190d64fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-32775beb-d67d-40ff-a700-229f3a2b668d,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-410bbcb5-a603-48eb-a665-6be8470e2872,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-54d39cea-41a3-442b-a0f7-6b9875e715e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246279323-172.17.0.19-1598536245292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44263,DS-330cd0f0-77d3-48d1-bf69-a3baac4b81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-e7ee46ac-fbf5-4aad-b89e-cbe44563d09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-cd5e2190-13bd-4e6a-b700-a71c6cb09c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-d8c7d453-82b3-411b-b2de-4bd5264a71af,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-5ff9cda4-b083-4678-8b76-af080fd775f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-dccb2d75-fdfe-4c94-a192-3f95aecf2952,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-79812738-7ea6-4ea2-bc1d-29034ca76033,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-73daf6c2-a882-4398-be35-7df79faf286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246279323-172.17.0.19-1598536245292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44263,DS-330cd0f0-77d3-48d1-bf69-a3baac4b81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-e7ee46ac-fbf5-4aad-b89e-cbe44563d09e,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-cd5e2190-13bd-4e6a-b700-a71c6cb09c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-d8c7d453-82b3-411b-b2de-4bd5264a71af,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-5ff9cda4-b083-4678-8b76-af080fd775f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-dccb2d75-fdfe-4c94-a192-3f95aecf2952,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-79812738-7ea6-4ea2-bc1d-29034ca76033,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-73daf6c2-a882-4398-be35-7df79faf286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930844642-172.17.0.19-1598536567918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-585871d4-2ac9-4b9a-9ce0-d35b9aa32bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-46c8e0fd-1e35-4be8-8775-31e96a136aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-df64f8d0-3277-49fe-aeac-c1101eaa293b,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-300b2221-ff8c-4d3f-8e15-528f7ca57a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b8bd67e8-3b48-4b89-bf19-9870f7d4ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-2992707b-7e5c-4b7f-9073-698d6bc06ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6437e198-7616-49ab-9253-08d55da185b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-198360b6-1863-46dd-8bae-298cc8ccadca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930844642-172.17.0.19-1598536567918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-585871d4-2ac9-4b9a-9ce0-d35b9aa32bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-46c8e0fd-1e35-4be8-8775-31e96a136aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-df64f8d0-3277-49fe-aeac-c1101eaa293b,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-300b2221-ff8c-4d3f-8e15-528f7ca57a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b8bd67e8-3b48-4b89-bf19-9870f7d4ef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-2992707b-7e5c-4b7f-9073-698d6bc06ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6437e198-7616-49ab-9253-08d55da185b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-198360b6-1863-46dd-8bae-298cc8ccadca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502056099-172.17.0.19-1598536730691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-278607fc-afc2-4927-a1b3-e82361f118d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-4cf0fc63-eb54-45f5-8e9c-f4f4cf4cb238,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-12c56f62-09e5-4ea5-8dac-400b62b085eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-30ee322c-28ab-48db-9f33-796030307118,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-31e478ed-9283-4958-a0c8-d7c2ae72ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-0d5c5ac8-8007-488a-b2e1-2b247e46f360,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-dd404765-5ea8-465b-955b-24fecf5aa8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-f6328893-8f99-432b-ac0d-bf2965233c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502056099-172.17.0.19-1598536730691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-278607fc-afc2-4927-a1b3-e82361f118d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-4cf0fc63-eb54-45f5-8e9c-f4f4cf4cb238,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-12c56f62-09e5-4ea5-8dac-400b62b085eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-30ee322c-28ab-48db-9f33-796030307118,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-31e478ed-9283-4958-a0c8-d7c2ae72ed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-0d5c5ac8-8007-488a-b2e1-2b247e46f360,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-dd404765-5ea8-465b-955b-24fecf5aa8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-f6328893-8f99-432b-ac0d-bf2965233c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213345454-172.17.0.19-1598537149372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-37904bbc-7a78-481c-bb0b-eb978b9d2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-e39bd5b1-13a0-42c1-a1b1-77a4cbf33a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-1a08600a-9dbd-4d83-bb22-d0775e4cbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-22ea354a-3894-4d12-b35b-eec6acdbcd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-e6a5b8ae-0f88-4991-8095-4931a5c882f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-8c1e68b8-17ac-4601-8f12-3353e6f4ea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-23cb3d60-58e0-45f1-a4a0-e18a5213be57,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-b0a4f270-0cce-4b49-8315-cb9a8dbfac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213345454-172.17.0.19-1598537149372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-37904bbc-7a78-481c-bb0b-eb978b9d2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-e39bd5b1-13a0-42c1-a1b1-77a4cbf33a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-1a08600a-9dbd-4d83-bb22-d0775e4cbed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-22ea354a-3894-4d12-b35b-eec6acdbcd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-e6a5b8ae-0f88-4991-8095-4931a5c882f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-8c1e68b8-17ac-4601-8f12-3353e6f4ea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-23cb3d60-58e0-45f1-a4a0-e18a5213be57,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-b0a4f270-0cce-4b49-8315-cb9a8dbfac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343992248-172.17.0.19-1598537351271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-44baee9e-bad3-4b3d-a2b5-b027df57c608,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-5067017f-86af-45bd-be3f-ccee2275a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-b1a444fe-ae9b-4e15-8b4c-61663108edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-be17bcfc-3ec6-4055-8920-8137e9dac2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-73f560ed-bac8-430c-b7ed-6363ab91646b,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-fd40032f-b5bd-4842-af95-87f726e30614,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-1943ed2f-7c0b-4a36-b924-8cd1a551b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-fd49ba3a-95e3-43ff-92e1-ff142095b0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343992248-172.17.0.19-1598537351271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-44baee9e-bad3-4b3d-a2b5-b027df57c608,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-5067017f-86af-45bd-be3f-ccee2275a8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-b1a444fe-ae9b-4e15-8b4c-61663108edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-be17bcfc-3ec6-4055-8920-8137e9dac2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-73f560ed-bac8-430c-b7ed-6363ab91646b,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-fd40032f-b5bd-4842-af95-87f726e30614,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-1943ed2f-7c0b-4a36-b924-8cd1a551b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-fd49ba3a-95e3-43ff-92e1-ff142095b0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846436463-172.17.0.19-1598537655168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-c9facab5-2b6b-4024-8c01-fe42dea52cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-7a95a2da-f7ae-4f01-be84-84017c41911f,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-d006286c-f3af-4407-b8ce-d2e77577bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-c5f9d82e-e6b5-4d67-acee-d0bcedb97ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-e3a3f274-a99b-430b-bacd-7a829763f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-b1e5fbb9-2182-4092-be8e-96adc43efb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-9a71034b-68f0-46a6-8e9f-cb41822bf282,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-419d9312-d86d-4dfc-8be6-0aa1fe3f93ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846436463-172.17.0.19-1598537655168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-c9facab5-2b6b-4024-8c01-fe42dea52cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-7a95a2da-f7ae-4f01-be84-84017c41911f,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-d006286c-f3af-4407-b8ce-d2e77577bd48,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-c5f9d82e-e6b5-4d67-acee-d0bcedb97ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-e3a3f274-a99b-430b-bacd-7a829763f4df,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-b1e5fbb9-2182-4092-be8e-96adc43efb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-9a71034b-68f0-46a6-8e9f-cb41822bf282,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-419d9312-d86d-4dfc-8be6-0aa1fe3f93ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981606295-172.17.0.19-1598538071208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-ed65fac6-70f3-4d6a-8bbd-daae083d7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-a24156d3-bb8c-42a1-a223-5203da3f1dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e6c12d4e-e39d-43cd-9787-788f03fcb0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-03336c4e-b919-4d72-9681-1902665aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-6e1bf15e-25af-4809-a7fb-93f186048150,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-beee808f-bb90-4033-8b13-f40353a7222d,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b2a90d6c-20d6-4556-8a05-ea2c5e7f6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-40cf220f-deb3-49a2-80e6-ecb1b6fadcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981606295-172.17.0.19-1598538071208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-ed65fac6-70f3-4d6a-8bbd-daae083d7e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-a24156d3-bb8c-42a1-a223-5203da3f1dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e6c12d4e-e39d-43cd-9787-788f03fcb0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-03336c4e-b919-4d72-9681-1902665aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-6e1bf15e-25af-4809-a7fb-93f186048150,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-beee808f-bb90-4033-8b13-f40353a7222d,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-b2a90d6c-20d6-4556-8a05-ea2c5e7f6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-40cf220f-deb3-49a2-80e6-ecb1b6fadcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068060607-172.17.0.19-1598538403826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-f63d9af5-6927-401a-a592-3f771aa2da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-c4636a48-ba8a-4a48-aeae-fa8ef6987189,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-89699ecd-90bb-43e1-a662-5e76b96bad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-d3193757-b391-4608-874b-6046a0bbf323,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3faef51b-e937-4140-9b33-0b2f83815978,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-923fa73f-0047-4c33-8399-d143375cca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-f653235e-74db-4b23-a2ff-7a7071ea060a,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-dac57ebe-108d-4bd8-9ef3-2539649f4bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068060607-172.17.0.19-1598538403826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41908,DS-f63d9af5-6927-401a-a592-3f771aa2da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-c4636a48-ba8a-4a48-aeae-fa8ef6987189,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-89699ecd-90bb-43e1-a662-5e76b96bad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-d3193757-b391-4608-874b-6046a0bbf323,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3faef51b-e937-4140-9b33-0b2f83815978,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-923fa73f-0047-4c33-8399-d143375cca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-f653235e-74db-4b23-a2ff-7a7071ea060a,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-dac57ebe-108d-4bd8-9ef3-2539649f4bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228507480-172.17.0.19-1598538841901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44549,DS-5548ca65-7905-42fd-8b90-a9f6333ad4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-4970daf1-ea78-40e6-b249-0b20a08fc582,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-cc2d5440-2730-47b7-96b2-b79b4e9aa4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-1313fd6e-468c-4313-9970-3ef0709123e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-4edf0649-52c6-4f22-b0f9-705095e5f647,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-45b0be44-6a4e-4e18-97f5-3e9450399c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f13ac654-82a4-433f-9998-7e531b0413f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-2b15880c-f903-4a25-801d-6aa50f1a0308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228507480-172.17.0.19-1598538841901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44549,DS-5548ca65-7905-42fd-8b90-a9f6333ad4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-4970daf1-ea78-40e6-b249-0b20a08fc582,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-cc2d5440-2730-47b7-96b2-b79b4e9aa4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-1313fd6e-468c-4313-9970-3ef0709123e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-4edf0649-52c6-4f22-b0f9-705095e5f647,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-45b0be44-6a4e-4e18-97f5-3e9450399c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f13ac654-82a4-433f-9998-7e531b0413f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-2b15880c-f903-4a25-801d-6aa50f1a0308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859487583-172.17.0.19-1598539068413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-d8ac8880-17f8-428e-b507-61b6b81594ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-75ad69e1-6c01-4ada-a408-aba7cf0905a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-b1ed5edd-8535-4754-b20a-1d0e2dabf10e,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-570e5186-daa5-4c9c-b189-1221f1064fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-f2ad68d0-7cae-485e-a5c2-87148c5ec904,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-52f4cb20-aa0e-48d9-9af7-ed08300eebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-365fe0b0-151e-4f54-8a8f-4d48555011ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-746ab4cb-1c8e-469a-8006-fc7400cf5490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859487583-172.17.0.19-1598539068413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-d8ac8880-17f8-428e-b507-61b6b81594ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-75ad69e1-6c01-4ada-a408-aba7cf0905a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-b1ed5edd-8535-4754-b20a-1d0e2dabf10e,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-570e5186-daa5-4c9c-b189-1221f1064fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-f2ad68d0-7cae-485e-a5c2-87148c5ec904,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-52f4cb20-aa0e-48d9-9af7-ed08300eebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-365fe0b0-151e-4f54-8a8f-4d48555011ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-746ab4cb-1c8e-469a-8006-fc7400cf5490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5564
