reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239422641-172.17.0.7-1598667816055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-c7ef3045-8dbf-46af-b378-9cebaddfb382,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-88526675-b4dc-4e58-b31d-b0020aeb00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-c7a7f67f-4cdc-43cc-b58c-22e1a4674e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-98e5a6d7-c7ed-4a0d-8489-e0b01c4ed01d,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-d04d6362-efd2-405d-9283-dddb8f446e32,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-c8e6f803-b417-4f4f-b593-749efa9a0070,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c5f0d2e1-9086-4d76-a3c8-e047b5c501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-3d581981-e120-41f5-b6f7-fc68bfb53f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239422641-172.17.0.7-1598667816055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-c7ef3045-8dbf-46af-b378-9cebaddfb382,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-88526675-b4dc-4e58-b31d-b0020aeb00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-c7a7f67f-4cdc-43cc-b58c-22e1a4674e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-98e5a6d7-c7ed-4a0d-8489-e0b01c4ed01d,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-d04d6362-efd2-405d-9283-dddb8f446e32,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-c8e6f803-b417-4f4f-b593-749efa9a0070,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-c5f0d2e1-9086-4d76-a3c8-e047b5c501d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-3d581981-e120-41f5-b6f7-fc68bfb53f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145546048-172.17.0.7-1598668848126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-a4a245f9-2b5f-4b1e-b630-36b62601addc,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-5303f5b3-f8c9-4630-ba9c-47d24805169d,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-750ccab0-85cb-4fa0-ae1c-5fc066873eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-cdd2db67-39c7-4af3-8c01-64777286d085,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-f72a43ac-eb93-411e-b38d-3e81ce051c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-593a42fc-7577-4930-a7fe-df5e259eb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-2170bbb0-affa-4779-860d-f206de294635,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3855e8b3-063a-425f-96aa-00e61d0e4aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145546048-172.17.0.7-1598668848126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-a4a245f9-2b5f-4b1e-b630-36b62601addc,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-5303f5b3-f8c9-4630-ba9c-47d24805169d,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-750ccab0-85cb-4fa0-ae1c-5fc066873eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-cdd2db67-39c7-4af3-8c01-64777286d085,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-f72a43ac-eb93-411e-b38d-3e81ce051c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-593a42fc-7577-4930-a7fe-df5e259eb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-2170bbb0-affa-4779-860d-f206de294635,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3855e8b3-063a-425f-96aa-00e61d0e4aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908877539-172.17.0.7-1598669074153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-a0cb124e-eed6-414b-8fc3-9051ec0aaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5d00528b-b18c-43df-afdb-66769b7249de,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-175f275f-919f-4301-9315-59f9dda0e4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-749bd4f8-a6a6-4980-8e8e-bda3783e50f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-d5c82206-7fba-4d52-b796-4308576afb68,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-1c5d677f-444c-4401-a2ee-69c0cb60071e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-d8dee825-7f3f-4bf7-beb1-135c7c2a0677,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5d005721-b2d4-4923-91bb-77a3d8224937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908877539-172.17.0.7-1598669074153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-a0cb124e-eed6-414b-8fc3-9051ec0aaef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5d00528b-b18c-43df-afdb-66769b7249de,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-175f275f-919f-4301-9315-59f9dda0e4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-749bd4f8-a6a6-4980-8e8e-bda3783e50f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-d5c82206-7fba-4d52-b796-4308576afb68,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-1c5d677f-444c-4401-a2ee-69c0cb60071e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-d8dee825-7f3f-4bf7-beb1-135c7c2a0677,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5d005721-b2d4-4923-91bb-77a3d8224937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49677951-172.17.0.7-1598669606620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33965,DS-2b9ab989-86eb-4fdc-8d3a-b0844b32e318,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-e084bc5f-d5f1-40e0-ae68-dd6c8b33bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-99c8b718-d7dd-4e7a-93cc-3ee420185ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-193d3aa2-c58e-4719-ad4d-374ea12652bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-6d9ae33b-2a1a-4449-a674-0ac1e2fb903f,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-9bd0810f-3639-4d1d-9b75-08b247923c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-bef6a355-d5cb-4b83-8bf5-ee86ae6d504f,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-68497611-2733-4639-96b8-34ecfd681c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49677951-172.17.0.7-1598669606620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33965,DS-2b9ab989-86eb-4fdc-8d3a-b0844b32e318,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-e084bc5f-d5f1-40e0-ae68-dd6c8b33bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-99c8b718-d7dd-4e7a-93cc-3ee420185ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-193d3aa2-c58e-4719-ad4d-374ea12652bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-6d9ae33b-2a1a-4449-a674-0ac1e2fb903f,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-9bd0810f-3639-4d1d-9b75-08b247923c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-bef6a355-d5cb-4b83-8bf5-ee86ae6d504f,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-68497611-2733-4639-96b8-34ecfd681c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868216472-172.17.0.7-1598670094869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-f40eb973-7adb-433a-a8fc-019c8bca4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-d87b5549-c5d1-4130-9be0-12a0841e8205,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-2494dfbf-ef1e-4fc8-88ef-e766e7e76d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-69469b55-cedd-4f23-bcb0-0acf0740f6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-cde06496-f907-4151-b727-3633cd4d9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-c3bc48be-275d-493c-989c-570318afa323,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-51decd64-8ea2-41ae-8c9e-02a5128297f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-095cfda7-d02f-45eb-bb9d-6d42aff3e724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868216472-172.17.0.7-1598670094869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-f40eb973-7adb-433a-a8fc-019c8bca4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-d87b5549-c5d1-4130-9be0-12a0841e8205,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-2494dfbf-ef1e-4fc8-88ef-e766e7e76d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-69469b55-cedd-4f23-bcb0-0acf0740f6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-cde06496-f907-4151-b727-3633cd4d9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-c3bc48be-275d-493c-989c-570318afa323,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-51decd64-8ea2-41ae-8c9e-02a5128297f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-095cfda7-d02f-45eb-bb9d-6d42aff3e724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884222602-172.17.0.7-1598670360782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-39935ce5-4bd8-49c4-b730-2be10415439e,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-5ab2d4de-d94a-4d87-9255-de8d8aa1d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-735a358a-1040-409b-bf9c-44c6b5e19e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-dda57616-8508-43f8-b3a2-48db3c62f164,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-416c78cd-3db3-4f08-9a44-9424931f6828,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-73370501-67ab-4c55-b03c-68b1c95798cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-8a11dd92-419a-4f4c-909c-2105ee11d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-e5c8d335-bf09-41e4-b1ef-1a75b08ba0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884222602-172.17.0.7-1598670360782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-39935ce5-4bd8-49c4-b730-2be10415439e,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-5ab2d4de-d94a-4d87-9255-de8d8aa1d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-735a358a-1040-409b-bf9c-44c6b5e19e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-dda57616-8508-43f8-b3a2-48db3c62f164,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-416c78cd-3db3-4f08-9a44-9424931f6828,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-73370501-67ab-4c55-b03c-68b1c95798cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-8a11dd92-419a-4f4c-909c-2105ee11d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-e5c8d335-bf09-41e4-b1ef-1a75b08ba0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934166843-172.17.0.7-1598670746764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-27e6c48c-d9b1-4244-a52d-1b2342191a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-2255f814-7bd0-4875-a4b0-53d96d306b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ff74eedd-53a6-45d5-acba-3645357cd383,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-4559b7dc-b26d-4615-89ae-3a7bb717e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7a486f49-c418-4c7b-9da8-6c8cbb6b1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-3b4b8d7d-4683-41b5-95e3-c77da0a73038,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-94963edc-50de-4da4-9d3c-f4f0035acb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-f10fd0ef-7bd4-41a4-bc34-a16e04defb7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934166843-172.17.0.7-1598670746764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-27e6c48c-d9b1-4244-a52d-1b2342191a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-2255f814-7bd0-4875-a4b0-53d96d306b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-ff74eedd-53a6-45d5-acba-3645357cd383,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-4559b7dc-b26d-4615-89ae-3a7bb717e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7a486f49-c418-4c7b-9da8-6c8cbb6b1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-3b4b8d7d-4683-41b5-95e3-c77da0a73038,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-94963edc-50de-4da4-9d3c-f4f0035acb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-f10fd0ef-7bd4-41a4-bc34-a16e04defb7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425800384-172.17.0.7-1598670864322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-895be1ec-83ae-473b-acee-5e86651dd678,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-5aaeef30-d897-44a9-9b83-25292fa5a5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-ff7704ae-5190-4472-a0fe-114203a9eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a24d96b8-17f1-4a7f-915d-25f2f357d024,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-97d08984-acd0-4712-a86b-87a7c9b39a31,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-d21ec1cf-ca4c-4d58-9ffa-7136c6f6d1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-c99863fe-fe27-4cbf-8a79-11dd501991bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3a59fa7c-b0ed-4d42-8242-e2a726772330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425800384-172.17.0.7-1598670864322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37502,DS-895be1ec-83ae-473b-acee-5e86651dd678,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-5aaeef30-d897-44a9-9b83-25292fa5a5af,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-ff7704ae-5190-4472-a0fe-114203a9eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a24d96b8-17f1-4a7f-915d-25f2f357d024,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-97d08984-acd0-4712-a86b-87a7c9b39a31,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-d21ec1cf-ca4c-4d58-9ffa-7136c6f6d1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-c99863fe-fe27-4cbf-8a79-11dd501991bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3a59fa7c-b0ed-4d42-8242-e2a726772330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933863648-172.17.0.7-1598671027246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-7f9fae73-9064-4d19-954f-c353fd1c591c,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-74aeb3e0-b9fa-4104-8efb-549af9e7beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-56784bbc-829c-420a-bc36-4e7258b56034,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-53f2eec8-0596-4916-83b2-990ae57db24d,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-b428552c-167e-4db2-a156-f0a72b5307c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-60890a23-e160-4fad-9925-fbee5fb24c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-71a96fec-6d46-4702-8a4f-ea0d61581ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-94cf7814-f2da-4ffb-90ed-e53890b4825f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933863648-172.17.0.7-1598671027246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-7f9fae73-9064-4d19-954f-c353fd1c591c,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-74aeb3e0-b9fa-4104-8efb-549af9e7beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-56784bbc-829c-420a-bc36-4e7258b56034,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-53f2eec8-0596-4916-83b2-990ae57db24d,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-b428552c-167e-4db2-a156-f0a72b5307c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-60890a23-e160-4fad-9925-fbee5fb24c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-71a96fec-6d46-4702-8a4f-ea0d61581ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-94cf7814-f2da-4ffb-90ed-e53890b4825f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346167729-172.17.0.7-1598671856114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-0727bd68-b4b8-419d-8cea-225a4647eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-47659121-09b3-4e9c-9f31-4d3cb8a9fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-b28d7f9b-2c20-4d8e-b140-74bebaaa169d,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-0d833567-7033-49a3-a003-612a94c2e753,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-b693828f-c335-485d-acf8-c404a74bcfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-1172e320-59eb-47b2-82c6-4fc346b85958,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-6e9fb37e-51aa-4ba3-a6eb-e6ee8fe1b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c56d59a2-8be3-4d99-ad78-c113af80c035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346167729-172.17.0.7-1598671856114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-0727bd68-b4b8-419d-8cea-225a4647eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-47659121-09b3-4e9c-9f31-4d3cb8a9fc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-b28d7f9b-2c20-4d8e-b140-74bebaaa169d,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-0d833567-7033-49a3-a003-612a94c2e753,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-b693828f-c335-485d-acf8-c404a74bcfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-1172e320-59eb-47b2-82c6-4fc346b85958,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-6e9fb37e-51aa-4ba3-a6eb-e6ee8fe1b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c56d59a2-8be3-4d99-ad78-c113af80c035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612188573-172.17.0.7-1598672186073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-bf493366-d6ff-43c7-b9b5-e99656ba1240,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-2df8624c-2dd9-4923-b2e0-832ea73acdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-5ff8a888-5065-46f4-b8fb-30f6dfa6e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-a5a63778-b9e6-4e30-9185-d53e8b17521f,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-a4c5c68a-d70a-4a0e-a781-4de762eb33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-2e6de275-87c4-44ea-9127-a2f961fc7099,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-576e46cf-8546-41ed-acd1-44857ba5d62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-8c5a0b03-6a77-4c3e-92d6-88779847fb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612188573-172.17.0.7-1598672186073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41014,DS-bf493366-d6ff-43c7-b9b5-e99656ba1240,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-2df8624c-2dd9-4923-b2e0-832ea73acdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-5ff8a888-5065-46f4-b8fb-30f6dfa6e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-a5a63778-b9e6-4e30-9185-d53e8b17521f,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-a4c5c68a-d70a-4a0e-a781-4de762eb33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-2e6de275-87c4-44ea-9127-a2f961fc7099,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-576e46cf-8546-41ed-acd1-44857ba5d62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-8c5a0b03-6a77-4c3e-92d6-88779847fb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367726207-172.17.0.7-1598672625989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-3690825d-3f09-4120-b223-2ec2c91ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-daf2cdda-e078-4da5-91ce-6d53afab3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-3655b30d-dcee-499b-9324-65edeb5a4821,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-32639939-0c7a-4fea-a3ae-4a0409ed7526,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-932a15d3-ca23-47c7-b47a-14f65f45dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-6336bb27-ab2e-4754-9c4a-c92f470d237d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-1b3f7ca1-a495-479c-8727-15380710189c,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-0b60e43e-0657-4b74-bc77-21a99074f184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367726207-172.17.0.7-1598672625989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-3690825d-3f09-4120-b223-2ec2c91ac274,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-daf2cdda-e078-4da5-91ce-6d53afab3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-3655b30d-dcee-499b-9324-65edeb5a4821,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-32639939-0c7a-4fea-a3ae-4a0409ed7526,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-932a15d3-ca23-47c7-b47a-14f65f45dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-6336bb27-ab2e-4754-9c4a-c92f470d237d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-1b3f7ca1-a495-479c-8727-15380710189c,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-0b60e43e-0657-4b74-bc77-21a99074f184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638333545-172.17.0.7-1598672687119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-90d1a47c-0edb-49c1-999a-3f67c3d1d592,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0c745a49-f68a-4d1f-b835-164f480d3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-f9e84ae7-407b-473c-a8e3-8f4ec0c388be,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d50dc54e-e585-4fb7-885a-5b2155578c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-dd65703a-7d3d-47b6-9813-4b8405db04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-f8cbebc1-05bd-4db7-8714-bdeaa324981a,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-ff1bec21-389e-48f0-8e87-dcb3ef7d29ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-41a49ba4-49a4-4668-9213-9ddb25b89b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638333545-172.17.0.7-1598672687119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42709,DS-90d1a47c-0edb-49c1-999a-3f67c3d1d592,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0c745a49-f68a-4d1f-b835-164f480d3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-f9e84ae7-407b-473c-a8e3-8f4ec0c388be,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-d50dc54e-e585-4fb7-885a-5b2155578c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-dd65703a-7d3d-47b6-9813-4b8405db04d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-f8cbebc1-05bd-4db7-8714-bdeaa324981a,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-ff1bec21-389e-48f0-8e87-dcb3ef7d29ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-41a49ba4-49a4-4668-9213-9ddb25b89b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167054070-172.17.0.7-1598672849883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35269,DS-2b0c393f-82ab-457e-9914-c2463126a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-1a6bfead-239b-429e-9891-76625b8c0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-528351a9-b6e0-4281-ae4b-63b6051c7778,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-8523256d-010b-4a00-8de1-0e163327a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-388b733d-5905-424e-b8ff-43d968b07491,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0a23222b-5278-4677-b69b-499c58568265,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-0ffa7444-959e-488a-9c15-316d5ed1eb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-dbd3d7e0-bb53-4a6b-9f36-43d8b5d3ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167054070-172.17.0.7-1598672849883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35269,DS-2b0c393f-82ab-457e-9914-c2463126a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-1a6bfead-239b-429e-9891-76625b8c0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-528351a9-b6e0-4281-ae4b-63b6051c7778,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-8523256d-010b-4a00-8de1-0e163327a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-388b733d-5905-424e-b8ff-43d968b07491,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0a23222b-5278-4677-b69b-499c58568265,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-0ffa7444-959e-488a-9c15-316d5ed1eb41,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-dbd3d7e0-bb53-4a6b-9f36-43d8b5d3ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5308
