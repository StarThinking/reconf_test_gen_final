reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881093498-172.17.0.19-1598666196503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40041,DS-610d43ab-3876-4771-bac3-4dcb335bda4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-bb33b19c-96e2-4d0a-b130-bfc6716d8637,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-e976ff80-d152-4a7d-81cb-41c9c87fa7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-3226042c-8814-4e4c-9000-27efd75cf557,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-e1c53c2d-efda-4895-bd1a-fb206846e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-0f490c62-0e7e-4402-85db-771a99306f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-a5d1ae5e-ecb6-4179-9b7b-0062c3fe36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-29022db7-be28-452e-839f-aaf2c04d00af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881093498-172.17.0.19-1598666196503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40041,DS-610d43ab-3876-4771-bac3-4dcb335bda4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-bb33b19c-96e2-4d0a-b130-bfc6716d8637,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-e976ff80-d152-4a7d-81cb-41c9c87fa7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-3226042c-8814-4e4c-9000-27efd75cf557,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-e1c53c2d-efda-4895-bd1a-fb206846e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-0f490c62-0e7e-4402-85db-771a99306f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-a5d1ae5e-ecb6-4179-9b7b-0062c3fe36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-29022db7-be28-452e-839f-aaf2c04d00af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601963575-172.17.0.19-1598666326562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-81504002-4c26-4fce-8f01-8995b5af24a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-8a780819-67f8-48b2-a760-819869d6e422,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d4c02a02-ec9b-42ef-b726-1cd928bb910b,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7c9f86cf-91ed-401d-807f-a17a1f3a419d,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-ee3e62a0-8603-448f-a939-1e6e1e0fb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-9a9bbe2a-a731-409b-b6a1-37187f2cf125,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a0c2ab93-8af7-4ff6-8b32-6a2b12e6c235,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-33e53069-cc47-4c30-b6a5-64a93423f819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601963575-172.17.0.19-1598666326562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34036,DS-81504002-4c26-4fce-8f01-8995b5af24a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-8a780819-67f8-48b2-a760-819869d6e422,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d4c02a02-ec9b-42ef-b726-1cd928bb910b,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-7c9f86cf-91ed-401d-807f-a17a1f3a419d,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-ee3e62a0-8603-448f-a939-1e6e1e0fb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-9a9bbe2a-a731-409b-b6a1-37187f2cf125,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a0c2ab93-8af7-4ff6-8b32-6a2b12e6c235,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-33e53069-cc47-4c30-b6a5-64a93423f819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242725361-172.17.0.19-1598666469400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-0f895753-efac-4161-bf3b-eeaf7e3e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-7293e3e8-3555-4bb0-ab9a-ddf88ac3246e,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-deb48181-72a2-463d-8127-95ca8b115a14,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8e3e3446-7375-4518-a760-6976557f76a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-3934eb25-d454-4ca7-9c7c-3d597450979a,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-af219317-abc7-40e0-822a-3b0c82049630,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-6d48544b-f547-42aa-af3e-8e6a38d4be57,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-471f08d5-a815-4a1f-a8db-707e9cf24c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242725361-172.17.0.19-1598666469400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33923,DS-0f895753-efac-4161-bf3b-eeaf7e3e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-7293e3e8-3555-4bb0-ab9a-ddf88ac3246e,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-deb48181-72a2-463d-8127-95ca8b115a14,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-8e3e3446-7375-4518-a760-6976557f76a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-3934eb25-d454-4ca7-9c7c-3d597450979a,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-af219317-abc7-40e0-822a-3b0c82049630,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-6d48544b-f547-42aa-af3e-8e6a38d4be57,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-471f08d5-a815-4a1f-a8db-707e9cf24c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194797609-172.17.0.19-1598666766352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-12b07ee4-5c88-4213-b74c-f56edc147dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-33a1b322-20ab-4c00-97d4-f9fefcc3e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4a6e943e-ccfd-4d76-bfcc-0b7b4b516926,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-7163fd19-289c-4e26-b221-6abd06b8a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-a4ee5d73-9041-42bf-9e64-951ea1752d45,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-d54cd73f-ca88-4c67-bc30-b7b1e9f3e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-cfd997d8-bfd4-4ae5-a24a-d37842b35b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-3c2786ad-f28d-4a66-9792-d9b2863c97be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194797609-172.17.0.19-1598666766352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-12b07ee4-5c88-4213-b74c-f56edc147dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-33a1b322-20ab-4c00-97d4-f9fefcc3e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4a6e943e-ccfd-4d76-bfcc-0b7b4b516926,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-7163fd19-289c-4e26-b221-6abd06b8a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-a4ee5d73-9041-42bf-9e64-951ea1752d45,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-d54cd73f-ca88-4c67-bc30-b7b1e9f3e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-cfd997d8-bfd4-4ae5-a24a-d37842b35b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-3c2786ad-f28d-4a66-9792-d9b2863c97be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636902895-172.17.0.19-1598666940232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-dd14afc9-4acb-4323-b26a-80c21099a654,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-49275ba6-0747-44ca-a6f5-1cbe0107acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-490d7c64-6b72-4ae9-a9e5-961a8451df23,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-c60acb19-c5d6-4b59-b9eb-be1d48b7c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-1dc7f704-12c5-44f7-9f66-8aa540916f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-2b3c75f8-202e-4528-8d5d-fa571b96eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-cd2cf367-2ead-4d76-a5d9-0d18edf9b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-25866b85-9be8-4594-a607-7d5cfa393a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636902895-172.17.0.19-1598666940232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-dd14afc9-4acb-4323-b26a-80c21099a654,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-49275ba6-0747-44ca-a6f5-1cbe0107acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-490d7c64-6b72-4ae9-a9e5-961a8451df23,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-c60acb19-c5d6-4b59-b9eb-be1d48b7c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-1dc7f704-12c5-44f7-9f66-8aa540916f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-2b3c75f8-202e-4528-8d5d-fa571b96eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-cd2cf367-2ead-4d76-a5d9-0d18edf9b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-25866b85-9be8-4594-a607-7d5cfa393a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368520002-172.17.0.19-1598667807547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-2fa1d31a-6542-4101-bda3-ff92f8501800,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-662ee5f7-8b2a-4598-adc8-e466dd066d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-c4765463-f92f-4120-b188-74d7d4cd6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-2941fa7e-5fd7-4163-8a5b-0658f620709c,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a526515f-5590-4712-b8fe-ed60bfc40965,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-a5a887e5-984b-4f39-9fc9-7347a67f6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-72873903-b43e-40f9-ad66-4b12d5685c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-bb12c4f5-7c7b-46a6-8ffe-6c706b41e1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368520002-172.17.0.19-1598667807547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-2fa1d31a-6542-4101-bda3-ff92f8501800,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-662ee5f7-8b2a-4598-adc8-e466dd066d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-c4765463-f92f-4120-b188-74d7d4cd6f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-2941fa7e-5fd7-4163-8a5b-0658f620709c,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a526515f-5590-4712-b8fe-ed60bfc40965,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-a5a887e5-984b-4f39-9fc9-7347a67f6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-72873903-b43e-40f9-ad66-4b12d5685c05,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-bb12c4f5-7c7b-46a6-8ffe-6c706b41e1e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897328272-172.17.0.19-1598668544294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-5603be19-b675-4fef-a4ee-c25a691ba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-64ce7dc3-79bb-4318-8555-7e66100c8162,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-81e50681-ab65-447a-be55-109023d84bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-ef272df6-b72d-42c0-ba56-524a53957cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-68f0599e-e4f8-4111-b552-2c9efe4f34b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-94b27028-b76d-4b82-9178-39534ce0a644,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-32426268-4e9d-455b-9b24-d150b105c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-c9bc8d39-0034-4549-99a8-df214c89aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897328272-172.17.0.19-1598668544294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-5603be19-b675-4fef-a4ee-c25a691ba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-64ce7dc3-79bb-4318-8555-7e66100c8162,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-81e50681-ab65-447a-be55-109023d84bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-ef272df6-b72d-42c0-ba56-524a53957cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-68f0599e-e4f8-4111-b552-2c9efe4f34b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-94b27028-b76d-4b82-9178-39534ce0a644,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-32426268-4e9d-455b-9b24-d150b105c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-c9bc8d39-0034-4549-99a8-df214c89aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499196784-172.17.0.19-1598669042729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-e6358916-6a74-4f12-a941-8052e7d99642,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-d6660752-f6b8-4d73-b1da-a4f56517095a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-52d4e5c4-f98a-4935-8b6c-369a6f44b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-eba8e2de-3702-4cd7-a108-96f8153f2ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-f7b17128-2b0d-45e1-97a2-5889d9981714,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-15045eb5-172c-4ec5-badb-3de4afe68dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c118703c-cc55-43f2-8c55-344595f99697,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-3f59945c-93fd-42df-af9b-a78015ad1a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499196784-172.17.0.19-1598669042729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-e6358916-6a74-4f12-a941-8052e7d99642,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-d6660752-f6b8-4d73-b1da-a4f56517095a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-52d4e5c4-f98a-4935-8b6c-369a6f44b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-eba8e2de-3702-4cd7-a108-96f8153f2ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-f7b17128-2b0d-45e1-97a2-5889d9981714,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-15045eb5-172c-4ec5-badb-3de4afe68dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-c118703c-cc55-43f2-8c55-344595f99697,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-3f59945c-93fd-42df-af9b-a78015ad1a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717547253-172.17.0.19-1598670023834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-7ddd8d6c-d029-41a7-895c-457901b17fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-cfc755d6-2671-404d-a634-f2b33e1c9a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-6522d8a1-6eea-41f4-b36a-dadd95d208c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d726b0b1-723c-421a-b424-558ded5a1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-b0db2d45-4a14-4457-ba72-e9baaa868858,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-6d89391b-2d36-4599-bd9d-36a49aa0a765,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-00da6937-3ff2-4a4a-8484-29c5f6831926,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-cdad552f-9645-4d79-bee8-caf2339c31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717547253-172.17.0.19-1598670023834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43184,DS-7ddd8d6c-d029-41a7-895c-457901b17fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-cfc755d6-2671-404d-a634-f2b33e1c9a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-6522d8a1-6eea-41f4-b36a-dadd95d208c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d726b0b1-723c-421a-b424-558ded5a1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-b0db2d45-4a14-4457-ba72-e9baaa868858,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-6d89391b-2d36-4599-bd9d-36a49aa0a765,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-00da6937-3ff2-4a4a-8484-29c5f6831926,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-cdad552f-9645-4d79-bee8-caf2339c31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878638200-172.17.0.19-1598670369985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-8db9aa7d-0d99-40ed-9d10-56ac85cf5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-935c0f99-4e0f-401e-a9f4-4bd9ff5ed24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-5e0d93a8-559f-4ee2-81d1-013fbfe02baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-20d44f60-31a8-4d84-bcdc-c048e5d5fa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-4e85fd02-9850-49ed-8133-b1ad41cc663a,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-20d66ab2-33f6-4d37-9dce-cf46b909ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-b4c551c2-e6ee-48ee-92dc-fa67107ac028,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6b78585d-27b2-4a51-b64d-358248531278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878638200-172.17.0.19-1598670369985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34988,DS-8db9aa7d-0d99-40ed-9d10-56ac85cf5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-935c0f99-4e0f-401e-a9f4-4bd9ff5ed24b,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-5e0d93a8-559f-4ee2-81d1-013fbfe02baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-20d44f60-31a8-4d84-bcdc-c048e5d5fa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-4e85fd02-9850-49ed-8133-b1ad41cc663a,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-20d66ab2-33f6-4d37-9dce-cf46b909ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-b4c551c2-e6ee-48ee-92dc-fa67107ac028,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-6b78585d-27b2-4a51-b64d-358248531278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624377864-172.17.0.19-1598670406335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-551d9fbf-73d1-43c2-a35e-591641f88fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0cf3d4e2-0d51-4ccf-8912-e0d818e310fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5e21f9c6-78c8-4f26-b3c2-f059106841c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-86ae46d8-c776-418d-8dce-e36aa66d6adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-4c90e7c4-ff62-4800-aa56-8ae87a3de011,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-8183ab26-3037-4a2c-8c94-59aef649f754,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-f1c332b3-0325-41ce-b560-1d77e4134468,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-bcf471b9-2dac-4981-bc5e-31f267c0e264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624377864-172.17.0.19-1598670406335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-551d9fbf-73d1-43c2-a35e-591641f88fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0cf3d4e2-0d51-4ccf-8912-e0d818e310fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-5e21f9c6-78c8-4f26-b3c2-f059106841c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-86ae46d8-c776-418d-8dce-e36aa66d6adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-4c90e7c4-ff62-4800-aa56-8ae87a3de011,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-8183ab26-3037-4a2c-8c94-59aef649f754,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-f1c332b3-0325-41ce-b560-1d77e4134468,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-bcf471b9-2dac-4981-bc5e-31f267c0e264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031081082-172.17.0.19-1598670450349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-3dfdef89-e74d-46d9-b8c0-5020dd7c4b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a5abb311-e686-4585-819f-309ecc281c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-6b735847-9784-4cdb-8b8d-9f54fd7697a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-de6f03e7-d9e2-4c71-a3c6-52aaad171419,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-f6bc9cc3-b160-4b2b-b425-9d47ba64ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-9267c2f8-5dc1-4f36-bfcf-7e7c09dc23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-552bd7dc-a2ad-4b05-adc0-51352a90f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-33057aa4-228a-40cd-b246-58a4d7683b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031081082-172.17.0.19-1598670450349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-3dfdef89-e74d-46d9-b8c0-5020dd7c4b41,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a5abb311-e686-4585-819f-309ecc281c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-6b735847-9784-4cdb-8b8d-9f54fd7697a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-de6f03e7-d9e2-4c71-a3c6-52aaad171419,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-f6bc9cc3-b160-4b2b-b425-9d47ba64ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-9267c2f8-5dc1-4f36-bfcf-7e7c09dc23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-552bd7dc-a2ad-4b05-adc0-51352a90f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-33057aa4-228a-40cd-b246-58a4d7683b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513410844-172.17.0.19-1598670485438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-a9fc1b26-34fd-4147-a574-18d5032cb645,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-cd7b01cf-b149-4e08-8257-216593ad1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-1587b11d-1125-4d4f-bcf2-108b0e950d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-9192630f-c1d0-4ee0-bca7-8e3916db2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-0e11ee0a-609d-4ebe-9436-21c1e45d0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-927191c6-e958-49fc-9f7b-12b2a7b0e859,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-0b33ac9d-df92-46fe-b3c2-6530ceba815b,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-2a80a604-fc15-4107-ab43-84c110b4201a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513410844-172.17.0.19-1598670485438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-a9fc1b26-34fd-4147-a574-18d5032cb645,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-cd7b01cf-b149-4e08-8257-216593ad1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-1587b11d-1125-4d4f-bcf2-108b0e950d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-9192630f-c1d0-4ee0-bca7-8e3916db2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-0e11ee0a-609d-4ebe-9436-21c1e45d0c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-927191c6-e958-49fc-9f7b-12b2a7b0e859,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-0b33ac9d-df92-46fe-b3c2-6530ceba815b,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-2a80a604-fc15-4107-ab43-84c110b4201a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 64
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951512211-172.17.0.19-1598671325737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-f8ae5dd7-3e67-4396-9b8a-7c99ae15c003,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-eb3d7a37-bd4d-431d-b487-53fd5ce023b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-42fdcf50-4b95-45c6-90f9-89630d4b27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-d1799f21-9bb5-4edc-8a55-9586ac3972cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-682f7eb4-ad32-423b-ad42-de468ba683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-d47f840d-c770-4f8d-ae2c-f842f572c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-a8949fb0-9f40-4bd5-af8c-408ec49ba332,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8635ed6a-450a-4ec2-8ba0-39cb31165f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951512211-172.17.0.19-1598671325737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-f8ae5dd7-3e67-4396-9b8a-7c99ae15c003,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-eb3d7a37-bd4d-431d-b487-53fd5ce023b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-42fdcf50-4b95-45c6-90f9-89630d4b27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-d1799f21-9bb5-4edc-8a55-9586ac3972cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-682f7eb4-ad32-423b-ad42-de468ba683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-d47f840d-c770-4f8d-ae2c-f842f572c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-a8949fb0-9f40-4bd5-af8c-408ec49ba332,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8635ed6a-450a-4ec2-8ba0-39cb31165f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5205
