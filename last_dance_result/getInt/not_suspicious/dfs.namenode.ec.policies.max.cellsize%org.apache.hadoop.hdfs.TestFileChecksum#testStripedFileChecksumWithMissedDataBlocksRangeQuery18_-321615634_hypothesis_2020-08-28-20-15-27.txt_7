reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263673549-172.17.0.2-1598646109248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-fc5309fb-f5d6-42a6-ad21-38545560171b,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-1220b0ff-9f87-4d90-b561-802b1f95184d,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-eb4389b4-a507-4853-b344-b12e7763bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-2138f2f8-1f77-452e-ad8b-13f10001b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ad62fa94-2891-4014-beb4-7ab3340ee5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-b6d24d22-0f22-4fc8-9431-c33ad799d9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-4a6a0501-debc-4f2a-a4c6-5ded9568bf25,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-b949f060-12e5-42f4-934b-f23b8fe21aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1263673549-172.17.0.2-1598646109248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-fc5309fb-f5d6-42a6-ad21-38545560171b,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-1220b0ff-9f87-4d90-b561-802b1f95184d,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-eb4389b4-a507-4853-b344-b12e7763bd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-2138f2f8-1f77-452e-ad8b-13f10001b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-ad62fa94-2891-4014-beb4-7ab3340ee5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-b6d24d22-0f22-4fc8-9431-c33ad799d9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-4a6a0501-debc-4f2a-a4c6-5ded9568bf25,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-b949f060-12e5-42f4-934b-f23b8fe21aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151570522-172.17.0.2-1598646352653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-8fc13f9d-0964-447c-8524-7d018e9b2090,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-fe513c37-82a6-4af9-bdd4-80b29ac62917,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-917c33c9-c9ff-45f9-ad1c-a27163805bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-5196b960-7ff5-4326-916c-59a715522806,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-53a6ffa8-07bf-41e2-b020-ab54714c8277,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-b4d53922-5f0d-49fb-bfc1-17f49ad86612,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-51783fe4-484b-4d00-a92f-cf262180f6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-0526a0a7-a414-45f1-9329-1578824d4210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151570522-172.17.0.2-1598646352653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-8fc13f9d-0964-447c-8524-7d018e9b2090,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-fe513c37-82a6-4af9-bdd4-80b29ac62917,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-917c33c9-c9ff-45f9-ad1c-a27163805bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-5196b960-7ff5-4326-916c-59a715522806,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-53a6ffa8-07bf-41e2-b020-ab54714c8277,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-b4d53922-5f0d-49fb-bfc1-17f49ad86612,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-51783fe4-484b-4d00-a92f-cf262180f6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-0526a0a7-a414-45f1-9329-1578824d4210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234240997-172.17.0.2-1598646557009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-f1fb7451-1559-4651-a3e7-baf433e22716,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-16dbe2e1-69b7-4d38-aae2-a936b945fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-d23e15b6-ef05-492c-b340-2d4d92df459e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-cf14c2bd-593f-45ad-8526-35d1de99e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-da8d6d5b-1864-49a5-bcc5-fd5cc755a5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-ab23f0c5-6da4-46b4-b7d2-6f6b7af42b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-7644401a-fcf9-4605-94ac-d2383f0e3a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-47f7a477-d03c-4873-9499-658dfbf3b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234240997-172.17.0.2-1598646557009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-f1fb7451-1559-4651-a3e7-baf433e22716,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-16dbe2e1-69b7-4d38-aae2-a936b945fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-d23e15b6-ef05-492c-b340-2d4d92df459e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-cf14c2bd-593f-45ad-8526-35d1de99e4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-da8d6d5b-1864-49a5-bcc5-fd5cc755a5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-ab23f0c5-6da4-46b4-b7d2-6f6b7af42b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-7644401a-fcf9-4605-94ac-d2383f0e3a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-47f7a477-d03c-4873-9499-658dfbf3b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477930545-172.17.0.2-1598647031888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-cb3d1597-344e-4209-9e1a-3df778598b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-e157cf07-4fe1-4a07-b11b-d15bf760cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-d1c1c827-4bbe-45b2-b693-4cc5e36c7f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-f2d8332c-95e9-4281-80d2-512b5c62d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f8cbd8c8-8a0c-48c7-8c82-421bf70b4aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-1695186d-b09f-4e7c-ace6-1bf05aebb88f,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-43105566-5275-48b9-bef7-3ce6cc920450,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-dc62b46e-eec7-4c62-b049-a2d055dc72e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477930545-172.17.0.2-1598647031888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40432,DS-cb3d1597-344e-4209-9e1a-3df778598b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-e157cf07-4fe1-4a07-b11b-d15bf760cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-d1c1c827-4bbe-45b2-b693-4cc5e36c7f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-f2d8332c-95e9-4281-80d2-512b5c62d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f8cbd8c8-8a0c-48c7-8c82-421bf70b4aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-1695186d-b09f-4e7c-ace6-1bf05aebb88f,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-43105566-5275-48b9-bef7-3ce6cc920450,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-dc62b46e-eec7-4c62-b049-a2d055dc72e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618034544-172.17.0.2-1598647168970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-95207dd4-1839-4c96-9c7b-c37d3b080d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-1800f210-d7fb-4e47-97fa-eb856bf2ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fa9d6571-9ff9-4d0b-a207-40f0d417ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a72bad43-3a86-4af0-8b4c-6c85503a2e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-01eb7e7b-71ea-437b-842c-0e8b7a0e3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-548e7017-112e-47ba-9ac2-7a9143b0ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-df072078-43e2-4612-8781-a72d023dabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-90e62587-4def-48d3-9b60-9fc1c52b37f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618034544-172.17.0.2-1598647168970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-95207dd4-1839-4c96-9c7b-c37d3b080d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-1800f210-d7fb-4e47-97fa-eb856bf2ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fa9d6571-9ff9-4d0b-a207-40f0d417ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a72bad43-3a86-4af0-8b4c-6c85503a2e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-01eb7e7b-71ea-437b-842c-0e8b7a0e3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-548e7017-112e-47ba-9ac2-7a9143b0ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-df072078-43e2-4612-8781-a72d023dabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-90e62587-4def-48d3-9b60-9fc1c52b37f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057417248-172.17.0.2-1598647389304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-1d4ed849-511c-4a8a-ac0a-0ceb04124961,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5f95a51b-4a0f-4af3-a86a-d219eb96de82,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-1911011a-20b3-4630-9cc3-f7e09f0621bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-4c14b489-761a-440c-9eab-4f8bdf27e474,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-af9e1155-1421-4918-a5cc-c2a7c3a6ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-bb7e0228-f9e9-4891-8c99-ebefc929cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-27a2a362-f0ef-456c-b588-652bfb91af13,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-2c83e923-b3b2-4970-a97e-b431e2b003f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057417248-172.17.0.2-1598647389304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-1d4ed849-511c-4a8a-ac0a-0ceb04124961,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5f95a51b-4a0f-4af3-a86a-d219eb96de82,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-1911011a-20b3-4630-9cc3-f7e09f0621bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-4c14b489-761a-440c-9eab-4f8bdf27e474,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-af9e1155-1421-4918-a5cc-c2a7c3a6ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-bb7e0228-f9e9-4891-8c99-ebefc929cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-27a2a362-f0ef-456c-b588-652bfb91af13,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-2c83e923-b3b2-4970-a97e-b431e2b003f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476502259-172.17.0.2-1598647451447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-7a8ae108-9960-4f60-897b-78151f1ea517,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-a88b85b8-d69d-42e7-9a90-ca7db3c20e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-71bc2f04-3ace-4729-98c3-c0d17c00caf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-2e50b60c-cfa1-40cb-88aa-1196f3fd8766,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-82fb1ee0-fbf2-4e18-a3b8-bd46dd14501f,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-3935b16b-2a0c-4d6e-a69a-61a0bb5a674f,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-96eb6716-ebd7-4a0b-9798-39be9a24df38,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-2011b407-dab1-4a8e-a1ac-c4dcf3a0c583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476502259-172.17.0.2-1598647451447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-7a8ae108-9960-4f60-897b-78151f1ea517,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-a88b85b8-d69d-42e7-9a90-ca7db3c20e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-71bc2f04-3ace-4729-98c3-c0d17c00caf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-2e50b60c-cfa1-40cb-88aa-1196f3fd8766,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-82fb1ee0-fbf2-4e18-a3b8-bd46dd14501f,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-3935b16b-2a0c-4d6e-a69a-61a0bb5a674f,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-96eb6716-ebd7-4a0b-9798-39be9a24df38,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-2011b407-dab1-4a8e-a1ac-c4dcf3a0c583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073145013-172.17.0.2-1598648059239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-fe29ae66-39f7-45ce-80ca-590e86cd96ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-edc9cf0d-4bb7-42a4-be73-9f2ff5760151,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-6eb36040-c7dd-4a29-9173-9612b4a0e00d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-f0a25f6e-cc54-4575-bc69-ef491b7d5080,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-9a2f658e-3e7a-4380-a569-aad1fa37060a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-e1504b98-34e0-4b7a-be82-26cdac0739f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-fbdfa353-f5fd-4e77-9218-d322f8f5f697,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-285dc503-edc5-4565-8796-5bc57836f513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073145013-172.17.0.2-1598648059239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-fe29ae66-39f7-45ce-80ca-590e86cd96ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-edc9cf0d-4bb7-42a4-be73-9f2ff5760151,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-6eb36040-c7dd-4a29-9173-9612b4a0e00d,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-f0a25f6e-cc54-4575-bc69-ef491b7d5080,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-9a2f658e-3e7a-4380-a569-aad1fa37060a,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-e1504b98-34e0-4b7a-be82-26cdac0739f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-fbdfa353-f5fd-4e77-9218-d322f8f5f697,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-285dc503-edc5-4565-8796-5bc57836f513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466487937-172.17.0.2-1598648158564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33142,DS-367616c2-ba79-4cee-8a35-c5bdd734d193,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-0d6f6b41-feef-48c3-b773-3676842f3112,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-759326b6-8122-4dca-81ad-30e6e0236dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-687f1f3c-1f10-41d5-981b-2082d5268d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-2f36ffc3-d3bc-4e74-a777-38191905ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-56150006-a385-4da9-a764-2788bb3779b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7d417244-1ec8-49a9-98b4-cfdd5a2df1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a170e42b-5af6-46b3-9621-04fe70ad628a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466487937-172.17.0.2-1598648158564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33142,DS-367616c2-ba79-4cee-8a35-c5bdd734d193,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-0d6f6b41-feef-48c3-b773-3676842f3112,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-759326b6-8122-4dca-81ad-30e6e0236dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-687f1f3c-1f10-41d5-981b-2082d5268d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-2f36ffc3-d3bc-4e74-a777-38191905ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-56150006-a385-4da9-a764-2788bb3779b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7d417244-1ec8-49a9-98b4-cfdd5a2df1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a170e42b-5af6-46b3-9621-04fe70ad628a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689623698-172.17.0.2-1598648893519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36071,DS-7dbd675e-d1ca-4366-870e-bcf0bfd4d772,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-d99a421b-e5b0-49a7-b9f8-f07cb2b98227,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-ec782276-9c9b-4559-8d25-586949cf349f,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-0415f381-d38f-48eb-a9d1-f2580c5666b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-b99044a8-1d1a-4b7a-bf57-3ead9e61fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-a30719d7-b35b-47fe-a010-7a9db34e9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-b62766e8-51da-47f0-805b-5898aa91ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c0729f47-f084-407c-8c98-5721dced17b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689623698-172.17.0.2-1598648893519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36071,DS-7dbd675e-d1ca-4366-870e-bcf0bfd4d772,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-d99a421b-e5b0-49a7-b9f8-f07cb2b98227,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-ec782276-9c9b-4559-8d25-586949cf349f,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-0415f381-d38f-48eb-a9d1-f2580c5666b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-b99044a8-1d1a-4b7a-bf57-3ead9e61fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-a30719d7-b35b-47fe-a010-7a9db34e9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-b62766e8-51da-47f0-805b-5898aa91ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-c0729f47-f084-407c-8c98-5721dced17b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789114449-172.17.0.2-1598649230334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-66d385ed-1f7a-47e0-8251-c77401dcc393,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8e78d30e-92ff-4a9b-a939-4c0805ef6ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-cfc9734b-b474-49e3-b04f-8c889aa437b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-5b39006b-310d-4a07-8d33-3530a3d1b268,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-5bb0db55-fba0-46db-b918-db47efe1f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-47762a27-0537-4d1f-89b6-c508d1f62ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-53daed16-ed1a-40a0-a86b-d3cca98f4f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-6faea439-4c1f-4361-97f3-32a62f7ba4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789114449-172.17.0.2-1598649230334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-66d385ed-1f7a-47e0-8251-c77401dcc393,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8e78d30e-92ff-4a9b-a939-4c0805ef6ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-cfc9734b-b474-49e3-b04f-8c889aa437b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-5b39006b-310d-4a07-8d33-3530a3d1b268,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-5bb0db55-fba0-46db-b918-db47efe1f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-47762a27-0537-4d1f-89b6-c508d1f62ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-53daed16-ed1a-40a0-a86b-d3cca98f4f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-6faea439-4c1f-4361-97f3-32a62f7ba4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836013095-172.17.0.2-1598649490312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-72776a50-d480-4adc-9ec1-3eeb5dc0d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-51be9ce4-4e9b-4219-b9b8-ae43a162b321,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-798d8796-34b4-429a-a8e9-df0d94259474,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-c378c37b-546d-4382-8c8b-31fa0a5acfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-7106cec8-38c1-432d-91a1-2c3c462fa929,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-a21ee413-9956-4686-a059-a6c72c8ade85,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-7965d47d-6b51-44fc-acbf-8fdded6fc6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-3e9c192c-4769-4ac0-94a4-55ddfbdc0757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836013095-172.17.0.2-1598649490312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-72776a50-d480-4adc-9ec1-3eeb5dc0d7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-51be9ce4-4e9b-4219-b9b8-ae43a162b321,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-798d8796-34b4-429a-a8e9-df0d94259474,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-c378c37b-546d-4382-8c8b-31fa0a5acfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-7106cec8-38c1-432d-91a1-2c3c462fa929,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-a21ee413-9956-4686-a059-a6c72c8ade85,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-7965d47d-6b51-44fc-acbf-8fdded6fc6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-3e9c192c-4769-4ac0-94a4-55ddfbdc0757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21485776-172.17.0.2-1598649584274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-9903f9c7-94a5-4681-81f5-f5ccd134cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aea58b49-0cdf-4a76-a58a-a5ac2a1f3787,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-ab2d0691-4391-4cca-b689-d75d64668553,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2689194c-8a67-4d5e-a5a6-38eb3d8cf697,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-4b6308c7-3034-4cb4-85e2-3732fced39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-334503c1-5b51-4d6f-88b0-d0de6779ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-f8c03f23-5860-439d-a2eb-edec8151f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-da5b6a40-250f-4dcd-92a9-d52cb07eca2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21485776-172.17.0.2-1598649584274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35965,DS-9903f9c7-94a5-4681-81f5-f5ccd134cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aea58b49-0cdf-4a76-a58a-a5ac2a1f3787,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-ab2d0691-4391-4cca-b689-d75d64668553,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2689194c-8a67-4d5e-a5a6-38eb3d8cf697,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-4b6308c7-3034-4cb4-85e2-3732fced39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-334503c1-5b51-4d6f-88b0-d0de6779ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-f8c03f23-5860-439d-a2eb-edec8151f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-da5b6a40-250f-4dcd-92a9-d52cb07eca2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870213906-172.17.0.2-1598649712274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-7f4ac696-4616-4380-b1f2-4619d7aa9d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0836eb8f-4f93-4c7f-bada-0905473ba9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-c64d87e6-0b58-431b-9f81-16045a005bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-7d63f26c-c098-40af-92d3-f8c9df601778,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-d738919e-4546-46ba-987b-b6ff5b049d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-2cff1b1b-b66d-416b-aec9-3721ee800a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-0cd6f4b4-981d-4e76-ba65-2b77fd8d75ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-f59cb1ce-f57b-4008-a132-ba1acaeaae0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870213906-172.17.0.2-1598649712274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-7f4ac696-4616-4380-b1f2-4619d7aa9d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-0836eb8f-4f93-4c7f-bada-0905473ba9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-c64d87e6-0b58-431b-9f81-16045a005bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-7d63f26c-c098-40af-92d3-f8c9df601778,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-d738919e-4546-46ba-987b-b6ff5b049d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-2cff1b1b-b66d-416b-aec9-3721ee800a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-0cd6f4b4-981d-4e76-ba65-2b77fd8d75ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-f59cb1ce-f57b-4008-a132-ba1acaeaae0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341828466-172.17.0.2-1598649784327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-cf843d16-4e98-489e-9555-f9486dcf1508,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-4b809e04-b19c-429d-89ab-1cfe744678da,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-65fea9d6-5ec9-4872-add5-3f943451f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-dfec65af-cfc6-46c8-8b3a-c43f408387c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-3b8d8abb-5d0c-4430-953c-ef21847ac56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-4990fe02-cc8d-4d39-bdfc-e5a0d8bb4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-5f847035-74c5-4a1f-940b-dd350f734a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-c7b9932e-ac5c-4a8a-9939-75be98978326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341828466-172.17.0.2-1598649784327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-cf843d16-4e98-489e-9555-f9486dcf1508,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-4b809e04-b19c-429d-89ab-1cfe744678da,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-65fea9d6-5ec9-4872-add5-3f943451f7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-dfec65af-cfc6-46c8-8b3a-c43f408387c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-3b8d8abb-5d0c-4430-953c-ef21847ac56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-4990fe02-cc8d-4d39-bdfc-e5a0d8bb4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-5f847035-74c5-4a1f-940b-dd350f734a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-c7b9932e-ac5c-4a8a-9939-75be98978326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262826101-172.17.0.2-1598649820912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-6b34dae3-f2d9-459d-927a-ef3ad86a4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-23fad354-1c3e-4cd2-a8d6-a21b7fc87c90,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-667117c1-f775-452f-81e5-27b3845507c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-3aac30d7-9bc8-4f73-8af7-4df1002dd8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-deba929b-2ad2-41b2-aefa-d787c181b410,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-8e66a1c7-4f41-4c8b-86d1-1cd67f5c03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-b44158d7-8c3e-4c05-b829-fd477974069a,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-931b00f2-b0a1-42ea-854c-d1174cc83034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262826101-172.17.0.2-1598649820912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-6b34dae3-f2d9-459d-927a-ef3ad86a4f45,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-23fad354-1c3e-4cd2-a8d6-a21b7fc87c90,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-667117c1-f775-452f-81e5-27b3845507c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-3aac30d7-9bc8-4f73-8af7-4df1002dd8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-deba929b-2ad2-41b2-aefa-d787c181b410,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-8e66a1c7-4f41-4c8b-86d1-1cd67f5c03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-b44158d7-8c3e-4c05-b829-fd477974069a,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-931b00f2-b0a1-42ea-854c-d1174cc83034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303751273-172.17.0.2-1598649887485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-3967e1a2-ac39-4c2a-84c7-12b8ca2d4c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-aacbe73f-678d-4251-973d-db1b7bdcb560,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-2f36c474-488e-4586-b1cc-11cea838d434,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-76140bd9-91b1-4c38-ae85-658e4bc756be,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5cfeeb06-6aab-4f7c-8b55-d87adf63ed34,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4795bd8b-f0ad-4517-9ab5-1fa36706f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-a1aa7a76-3142-406a-89f5-eed0f71f60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-778803e8-a953-4f20-81bf-f70b0a43bd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303751273-172.17.0.2-1598649887485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-3967e1a2-ac39-4c2a-84c7-12b8ca2d4c77,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-aacbe73f-678d-4251-973d-db1b7bdcb560,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-2f36c474-488e-4586-b1cc-11cea838d434,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-76140bd9-91b1-4c38-ae85-658e4bc756be,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-5cfeeb06-6aab-4f7c-8b55-d87adf63ed34,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-4795bd8b-f0ad-4517-9ab5-1fa36706f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-a1aa7a76-3142-406a-89f5-eed0f71f60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-778803e8-a953-4f20-81bf-f70b0a43bd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.ec.policies.max.cellsize
component: hdfs:NameNode
v1: 8388608
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765626741-172.17.0.2-1598649925566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-bbc3aac8-3efd-4432-a58c-7a91e315f862,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-8d5e6c71-f9d3-4aff-85df-38f5b75f2abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-26bf61b0-31a4-49d9-9f84-522dc4cc540f,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-d3aa184f-b215-4bc9-b1ee-630ff4159427,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-0f2a5eee-a799-4301-a565-194e9dae0905,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-f59788e4-ddb2-4115-adaa-398232b67981,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-cbd9c2d5-c0c2-4869-9088-9d440b90becd,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-7704457e-e2ef-4251-bfe5-08d92211d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765626741-172.17.0.2-1598649925566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-bbc3aac8-3efd-4432-a58c-7a91e315f862,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-8d5e6c71-f9d3-4aff-85df-38f5b75f2abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-26bf61b0-31a4-49d9-9f84-522dc4cc540f,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-d3aa184f-b215-4bc9-b1ee-630ff4159427,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-0f2a5eee-a799-4301-a565-194e9dae0905,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-f59788e4-ddb2-4115-adaa-398232b67981,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-cbd9c2d5-c0c2-4869-9088-9d440b90becd,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-7704457e-e2ef-4251-bfe5-08d92211d9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5132
