reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251321090-172.17.0.7-1598559109104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-2e857016-7e98-4e67-bb8c-f29f2956d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-23123527-3aaf-4dc9-bf51-a9de7b7dbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-4b935283-1eda-4fff-912c-32740b1bd618,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-8eca41f4-aacc-48ca-b180-4f74bc8b5635,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-878a2661-8f81-4b0a-b93a-9e8e435bbbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-e98fc8d0-1d37-4c97-8f75-77458fe7d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-12f110b6-2311-4f4a-8e15-877f01eda88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-8fbdb183-54d2-4647-8d29-cf7f9e46ca10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251321090-172.17.0.7-1598559109104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-2e857016-7e98-4e67-bb8c-f29f2956d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-23123527-3aaf-4dc9-bf51-a9de7b7dbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-4b935283-1eda-4fff-912c-32740b1bd618,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-8eca41f4-aacc-48ca-b180-4f74bc8b5635,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-878a2661-8f81-4b0a-b93a-9e8e435bbbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-e98fc8d0-1d37-4c97-8f75-77458fe7d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-12f110b6-2311-4f4a-8e15-877f01eda88c,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-8fbdb183-54d2-4647-8d29-cf7f9e46ca10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512831744-172.17.0.7-1598559139074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-7d8d37c2-3ffc-434b-bcc2-876cce371dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-6615e837-c9f9-4c3b-988b-50f01a758088,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-faf41458-4a5a-4e4b-8026-13e63adc6813,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2a0eba9f-3069-4e60-b846-40319fdf422c,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-b2ed6af1-5036-4d73-874a-c9fc80cc307a,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-87b2f992-289c-4820-b626-cd149b93416e,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-99de51cb-3349-418f-84f0-2bfbe37dde44,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d50b7c7-9677-4bda-8345-687b731926cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512831744-172.17.0.7-1598559139074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-7d8d37c2-3ffc-434b-bcc2-876cce371dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-6615e837-c9f9-4c3b-988b-50f01a758088,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-faf41458-4a5a-4e4b-8026-13e63adc6813,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-2a0eba9f-3069-4e60-b846-40319fdf422c,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-b2ed6af1-5036-4d73-874a-c9fc80cc307a,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-87b2f992-289c-4820-b626-cd149b93416e,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-99de51cb-3349-418f-84f0-2bfbe37dde44,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d50b7c7-9677-4bda-8345-687b731926cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44816628-172.17.0.7-1598559176195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-8245b809-7995-44a3-ad3e-21728bc3a70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8b04ba47-a6c6-4697-b588-b225148deebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-b76d3aee-73eb-45dc-9258-e58e67f25f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ebfc4c19-a867-489c-9b0e-a951e754722c,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-3d2b8e1e-6f7f-4f2b-ba4d-a610ce59fbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-83290e14-d2f2-4549-954a-a6dd55789154,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-1c693b6e-eb18-4ee3-acc1-02ae644bc3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-7f13337e-2a41-4ff9-84eb-0f13949f497f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44816628-172.17.0.7-1598559176195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-8245b809-7995-44a3-ad3e-21728bc3a70b,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-8b04ba47-a6c6-4697-b588-b225148deebb,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-b76d3aee-73eb-45dc-9258-e58e67f25f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ebfc4c19-a867-489c-9b0e-a951e754722c,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-3d2b8e1e-6f7f-4f2b-ba4d-a610ce59fbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-83290e14-d2f2-4549-954a-a6dd55789154,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-1c693b6e-eb18-4ee3-acc1-02ae644bc3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-7f13337e-2a41-4ff9-84eb-0f13949f497f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344268159-172.17.0.7-1598559393239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-b73f0ebd-b922-40b9-8206-f9025b105e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4158af97-5738-4b5b-a3d3-50998c46357f,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ac5249b0-44be-4005-bf8f-150fc4477398,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-2cb51720-7957-4d9c-aff2-2accf3c94e30,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-aa22d3d4-62fa-4920-8e58-9a405296db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-80468254-2ee1-4115-addd-f0280b0d6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-4a75da7d-16ae-421f-ab37-a757e95d0320,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-4fbf9347-41b9-47a2-be7d-5dc13fae30de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344268159-172.17.0.7-1598559393239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-b73f0ebd-b922-40b9-8206-f9025b105e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4158af97-5738-4b5b-a3d3-50998c46357f,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-ac5249b0-44be-4005-bf8f-150fc4477398,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-2cb51720-7957-4d9c-aff2-2accf3c94e30,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-aa22d3d4-62fa-4920-8e58-9a405296db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-80468254-2ee1-4115-addd-f0280b0d6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-4a75da7d-16ae-421f-ab37-a757e95d0320,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-4fbf9347-41b9-47a2-be7d-5dc13fae30de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676383878-172.17.0.7-1598559857762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-c2ba9b8a-3180-43e7-a397-0006138ed412,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-316f6912-3b02-4dea-ab98-456f32427dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-81973ef2-0f04-4ca1-a5a4-fcf758b163c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-b1606e37-c539-4f42-a84e-d5a4ed3a5133,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-dd29c81f-66d0-4469-b64b-d832819f714f,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-4e9afaf6-e4a7-48fb-a70c-94c2a36b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-eec32d1e-a608-4177-ae00-0671b7e20ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-9be47b34-3b9f-44b1-b34e-e712e096a5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676383878-172.17.0.7-1598559857762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-c2ba9b8a-3180-43e7-a397-0006138ed412,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-316f6912-3b02-4dea-ab98-456f32427dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-81973ef2-0f04-4ca1-a5a4-fcf758b163c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-b1606e37-c539-4f42-a84e-d5a4ed3a5133,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-dd29c81f-66d0-4469-b64b-d832819f714f,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-4e9afaf6-e4a7-48fb-a70c-94c2a36b3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-eec32d1e-a608-4177-ae00-0671b7e20ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-9be47b34-3b9f-44b1-b34e-e712e096a5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049544176-172.17.0.7-1598560200767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-1a99f91f-6514-419a-b913-000b8970f281,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-03403c7d-06af-4419-8e4b-a9076191f491,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-e9d10cc4-3457-461f-9562-9c92a4a15876,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-bcad6665-cafd-4ae4-81b7-4a6f02c38a23,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-0264a088-da39-46e3-85fc-c45a4d26acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d11c7f73-72ac-4e6d-a0c2-b7d0df9e0b51,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3b99b55f-bc98-4b79-9345-7efd5061070f,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-40a3be38-3f08-4d07-a7ba-1c4d33de1b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049544176-172.17.0.7-1598560200767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-1a99f91f-6514-419a-b913-000b8970f281,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-03403c7d-06af-4419-8e4b-a9076191f491,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-e9d10cc4-3457-461f-9562-9c92a4a15876,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-bcad6665-cafd-4ae4-81b7-4a6f02c38a23,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-0264a088-da39-46e3-85fc-c45a4d26acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-d11c7f73-72ac-4e6d-a0c2-b7d0df9e0b51,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-3b99b55f-bc98-4b79-9345-7efd5061070f,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-40a3be38-3f08-4d07-a7ba-1c4d33de1b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875118267-172.17.0.7-1598560787210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39691,DS-5c6fff39-1350-4a8f-88c4-4e0739123462,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-14f16d5d-2a02-41ed-9fd0-750cee717f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-f746f224-19c3-4153-88c2-49cb61690faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-8fb521cb-1f47-49f4-939a-b2a76e45d758,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0f183af2-7c98-43b9-81e6-e9e5a3b3bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-5685af81-32aa-47a2-ad2b-0d203dfb0105,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1820d4bf-c171-4dbd-ab11-5c813931160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-354513a0-f226-41d3-8f70-a9a84f7d967c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875118267-172.17.0.7-1598560787210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39691,DS-5c6fff39-1350-4a8f-88c4-4e0739123462,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-14f16d5d-2a02-41ed-9fd0-750cee717f44,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-f746f224-19c3-4153-88c2-49cb61690faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-8fb521cb-1f47-49f4-939a-b2a76e45d758,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0f183af2-7c98-43b9-81e6-e9e5a3b3bab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-5685af81-32aa-47a2-ad2b-0d203dfb0105,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1820d4bf-c171-4dbd-ab11-5c813931160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-354513a0-f226-41d3-8f70-a9a84f7d967c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512342729-172.17.0.7-1598560925267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-84df1fa2-d709-478c-baa4-59e5bf24a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-8d6fc733-ab59-4533-93fd-05b2437f7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-666ecfc5-b6d0-4845-a768-5ab67f51e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-315f2c48-b85d-4b5b-8527-d173bee352c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d1fbd57b-704d-439f-9b37-9a87c293fbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-318d4ccb-7347-485b-be02-d04aebf519c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-dc1f2712-c41d-4e2b-bb97-706b2d0ebbab,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-785c0511-18a9-4795-b542-ca5791109378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512342729-172.17.0.7-1598560925267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-84df1fa2-d709-478c-baa4-59e5bf24a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-8d6fc733-ab59-4533-93fd-05b2437f7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-666ecfc5-b6d0-4845-a768-5ab67f51e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-315f2c48-b85d-4b5b-8527-d173bee352c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d1fbd57b-704d-439f-9b37-9a87c293fbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-318d4ccb-7347-485b-be02-d04aebf519c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-dc1f2712-c41d-4e2b-bb97-706b2d0ebbab,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-785c0511-18a9-4795-b542-ca5791109378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148724773-172.17.0.7-1598561000703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-81d8bdc4-f4b5-457d-8174-a25d4e6f3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-be1a0733-5d53-4ebb-aecd-3841ccff504e,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-ee1a4f8b-5d02-424f-b9b9-dd5b1721c9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-25fa1ca6-4f09-4775-84a2-98ad4c51b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-64994b14-316e-4a14-a50b-40583598ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-75d992ae-594c-4a3f-960d-7de6fcd75302,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-68cac409-c8e8-4bb3-8292-7d98312c368e,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-904c970f-8724-4c31-824c-77c5c7bfbbc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148724773-172.17.0.7-1598561000703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-81d8bdc4-f4b5-457d-8174-a25d4e6f3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-be1a0733-5d53-4ebb-aecd-3841ccff504e,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-ee1a4f8b-5d02-424f-b9b9-dd5b1721c9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-25fa1ca6-4f09-4775-84a2-98ad4c51b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-64994b14-316e-4a14-a50b-40583598ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-75d992ae-594c-4a3f-960d-7de6fcd75302,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-68cac409-c8e8-4bb3-8292-7d98312c368e,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-904c970f-8724-4c31-824c-77c5c7bfbbc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180858294-172.17.0.7-1598561113714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-50179eac-5233-482c-a947-5087479fe6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-c314fdf6-0a48-40ec-a9f4-f4a3b97e8816,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-10f856c3-0f44-4d89-8da6-230aa811c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-318eded7-035e-4a40-a177-271dcbe24861,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-a1c3b315-7bf2-4769-bd66-f050d5175761,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-0c9091d3-83eb-4bc5-843d-c0e46c4e6c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-47441722-a279-4863-9eed-471e84339781,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-bbdeb32b-61dd-4606-8ae6-f547222899a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180858294-172.17.0.7-1598561113714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-50179eac-5233-482c-a947-5087479fe6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-c314fdf6-0a48-40ec-a9f4-f4a3b97e8816,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-10f856c3-0f44-4d89-8da6-230aa811c82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-318eded7-035e-4a40-a177-271dcbe24861,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-a1c3b315-7bf2-4769-bd66-f050d5175761,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-0c9091d3-83eb-4bc5-843d-c0e46c4e6c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-47441722-a279-4863-9eed-471e84339781,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-bbdeb32b-61dd-4606-8ae6-f547222899a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110928371-172.17.0.7-1598561609315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-b69bf157-bd23-4532-9414-fd4d99d9eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-a5785855-9f6e-42e4-b7d8-62921726bca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-68ee83af-8815-437e-917f-eca9e39cb6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-13c0788c-6788-4985-b498-24b055dc13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-dda94030-7283-4bb8-874c-8f6d0365b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-5cf30733-731b-4036-a843-b760e09b4961,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-8048920a-7a1b-49f4-9cec-44a83325b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-2260180e-1366-484b-8f24-df21241e6423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110928371-172.17.0.7-1598561609315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-b69bf157-bd23-4532-9414-fd4d99d9eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-a5785855-9f6e-42e4-b7d8-62921726bca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-68ee83af-8815-437e-917f-eca9e39cb6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-13c0788c-6788-4985-b498-24b055dc13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-dda94030-7283-4bb8-874c-8f6d0365b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-5cf30733-731b-4036-a843-b760e09b4961,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-8048920a-7a1b-49f4-9cec-44a83325b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-2260180e-1366-484b-8f24-df21241e6423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192426112-172.17.0.7-1598561859456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-60427d35-3787-4448-94c7-d9ed575a1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7638ea32-adcd-4691-88da-c7e329258728,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-ed982125-a598-4aed-a879-12b02a5bd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-9fa72223-bac3-4521-9b41-3dd1ab2487dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-95cb5f5e-3456-43d0-9395-9e87d53655d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-abe22e92-e33e-40b0-a12a-0733fe8eaa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-8d77b912-b4fb-4581-aa02-e2708e79e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-368cc307-187e-4197-b133-02e43e362876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192426112-172.17.0.7-1598561859456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-60427d35-3787-4448-94c7-d9ed575a1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7638ea32-adcd-4691-88da-c7e329258728,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-ed982125-a598-4aed-a879-12b02a5bd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-9fa72223-bac3-4521-9b41-3dd1ab2487dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-95cb5f5e-3456-43d0-9395-9e87d53655d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-abe22e92-e33e-40b0-a12a-0733fe8eaa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-8d77b912-b4fb-4581-aa02-e2708e79e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-368cc307-187e-4197-b133-02e43e362876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503920211-172.17.0.7-1598561956613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-afc306fa-28d4-4297-b6de-9649cd8e91f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-dce43c00-c72e-42b3-8dc2-92d7e2daf838,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b6c1f6bd-0c0f-4bde-809a-b5c614b3c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-73efaba7-08eb-4509-9c96-f562e5b1af66,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-b8d1afe9-0989-4684-9073-c72dd55e3c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-d5727776-14a2-4e01-9619-83d684d18d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-94568dcb-cf65-4da3-8498-6e5bbdbd37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-ec915434-c323-4315-b963-f4cb574b289b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503920211-172.17.0.7-1598561956613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-afc306fa-28d4-4297-b6de-9649cd8e91f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-dce43c00-c72e-42b3-8dc2-92d7e2daf838,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b6c1f6bd-0c0f-4bde-809a-b5c614b3c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-73efaba7-08eb-4509-9c96-f562e5b1af66,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-b8d1afe9-0989-4684-9073-c72dd55e3c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-d5727776-14a2-4e01-9619-83d684d18d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-94568dcb-cf65-4da3-8498-6e5bbdbd37d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-ec915434-c323-4315-b963-f4cb574b289b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077834330-172.17.0.7-1598562053166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-003da8bb-950f-4fd3-ba8c-17ce40faba93,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-38afb612-7f74-4478-a849-c1c1d433657b,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-ebe6b5b1-f1e6-4310-a23b-6392d6402267,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-571fc3ef-513a-4528-b3ba-8ed04a4ee6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-5ff93bb3-78e6-473a-82e4-987e66e032af,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-6e255519-33a2-4753-b4f4-3096beca2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-a919ec26-a3cf-45b4-8f17-7d961dbf6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-35b13b6f-f072-4d9a-bce8-cac999de8a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077834330-172.17.0.7-1598562053166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-003da8bb-950f-4fd3-ba8c-17ce40faba93,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-38afb612-7f74-4478-a849-c1c1d433657b,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-ebe6b5b1-f1e6-4310-a23b-6392d6402267,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-571fc3ef-513a-4528-b3ba-8ed04a4ee6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-5ff93bb3-78e6-473a-82e4-987e66e032af,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-6e255519-33a2-4753-b4f4-3096beca2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-a919ec26-a3cf-45b4-8f17-7d961dbf6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-35b13b6f-f072-4d9a-bce8-cac999de8a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381428158-172.17.0.7-1598562091848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-70713f89-ef34-48a4-8c82-86e944cb384b,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-f8e5e3e5-8d4d-4359-8360-68789a24abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fbd2ab4b-2d3d-4e7c-9915-d56f33b2ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c2b56000-d6da-429b-bbff-12c7b3b09e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-65740929-32fc-4c3d-ae18-3d66679b6389,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-9813cd40-7a30-4995-9ae7-c0ae09ab2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-c943b656-4cf7-498e-a456-65674aa33ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-b4fe31f6-9818-4bdf-afee-6e83fe93a07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381428158-172.17.0.7-1598562091848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-70713f89-ef34-48a4-8c82-86e944cb384b,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-f8e5e3e5-8d4d-4359-8360-68789a24abe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fbd2ab4b-2d3d-4e7c-9915-d56f33b2ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-c2b56000-d6da-429b-bbff-12c7b3b09e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-65740929-32fc-4c3d-ae18-3d66679b6389,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-9813cd40-7a30-4995-9ae7-c0ae09ab2be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-c943b656-4cf7-498e-a456-65674aa33ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-b4fe31f6-9818-4bdf-afee-6e83fe93a07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755981999-172.17.0.7-1598563058838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39156,DS-097348d5-960f-4f6f-a7e3-7fd246d7e049,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f4a4455b-a468-43e8-8746-456cc8962d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-e0db97dd-b9a7-4c43-9827-3db8eb94bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-4a71a0ed-f954-43f9-a2c8-295bb91036c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-26429492-80fa-4901-aafb-7d1d3654f905,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ad80e3ff-0770-47ab-a4b0-fefc9e059656,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-86765754-f5bb-448a-954d-d3d491106950,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-07efdcab-f575-48ca-8e6f-67edbcc8f663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755981999-172.17.0.7-1598563058838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39156,DS-097348d5-960f-4f6f-a7e3-7fd246d7e049,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f4a4455b-a468-43e8-8746-456cc8962d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-e0db97dd-b9a7-4c43-9827-3db8eb94bf17,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-4a71a0ed-f954-43f9-a2c8-295bb91036c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-26429492-80fa-4901-aafb-7d1d3654f905,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-ad80e3ff-0770-47ab-a4b0-fefc9e059656,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-86765754-f5bb-448a-954d-d3d491106950,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-07efdcab-f575-48ca-8e6f-67edbcc8f663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539039740-172.17.0.7-1598563474347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-9f327e86-270d-4995-878a-f9a4054fe39f,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-8cf05f79-c1dc-4ce7-8f70-2c68dd0db291,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-383ca9bc-f800-4afb-bbac-8613b2166692,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-b5da9865-cefb-4d18-b2ee-126300c3979b,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-b9122793-6515-4c9e-993d-54cada23d3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-0888b0b9-a2d5-4209-934d-c4a4a8703d19,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-779a5c80-331a-43f7-a5cd-d0e14d891870,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-81b532ee-87e9-49ed-982d-79586335c8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539039740-172.17.0.7-1598563474347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-9f327e86-270d-4995-878a-f9a4054fe39f,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-8cf05f79-c1dc-4ce7-8f70-2c68dd0db291,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-383ca9bc-f800-4afb-bbac-8613b2166692,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-b5da9865-cefb-4d18-b2ee-126300c3979b,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-b9122793-6515-4c9e-993d-54cada23d3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-0888b0b9-a2d5-4209-934d-c4a4a8703d19,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-779a5c80-331a-43f7-a5cd-d0e14d891870,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-81b532ee-87e9-49ed-982d-79586335c8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5358
