reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632898276-172.17.0.20-1598510840178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-766df58d-74c2-4d9a-9b76-8257fff03def,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-3fd22f75-c476-46ec-ad17-466ed265d432,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-00210edd-7c34-4430-890c-021482f02989,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-d1caef47-dd26-492e-9193-94679afb3326,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-93ac0706-f8e9-4499-9088-7df6f5cfabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-33584dfd-5ddb-4fe3-b4b4-e412af06a659,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-b0ed4be2-4a97-48f9-932b-22e1ada13dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-6fcb5448-3c08-42e6-ab47-aa06d981f3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632898276-172.17.0.20-1598510840178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-766df58d-74c2-4d9a-9b76-8257fff03def,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-3fd22f75-c476-46ec-ad17-466ed265d432,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-00210edd-7c34-4430-890c-021482f02989,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-d1caef47-dd26-492e-9193-94679afb3326,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-93ac0706-f8e9-4499-9088-7df6f5cfabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-33584dfd-5ddb-4fe3-b4b4-e412af06a659,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-b0ed4be2-4a97-48f9-932b-22e1ada13dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-6fcb5448-3c08-42e6-ab47-aa06d981f3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393075545-172.17.0.20-1598511634516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-fb40c673-04bc-4ec5-b694-2d9e13c62e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-24a82ac0-8f4a-405e-a357-960f07ffbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-c547c318-ae24-432c-92fb-c0c83f995e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-880a47fe-40c5-4cce-a093-528795b683e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-df687704-227e-4303-99b6-7e39b3c9d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c937fbd3-eda4-4e77-9986-ccfed92d9715,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-771e6243-df5f-4e3e-8eba-d2e1b01b6cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d4bfe04f-5063-438a-bc7f-8f3226292088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393075545-172.17.0.20-1598511634516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-fb40c673-04bc-4ec5-b694-2d9e13c62e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-24a82ac0-8f4a-405e-a357-960f07ffbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-c547c318-ae24-432c-92fb-c0c83f995e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-880a47fe-40c5-4cce-a093-528795b683e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-df687704-227e-4303-99b6-7e39b3c9d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c937fbd3-eda4-4e77-9986-ccfed92d9715,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-771e6243-df5f-4e3e-8eba-d2e1b01b6cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d4bfe04f-5063-438a-bc7f-8f3226292088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287923710-172.17.0.20-1598511741522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-e284ca7e-3da8-4f6a-941b-ba609a946641,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-2b1ed188-d396-412f-8906-826f5de4d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-82ccc87d-8d90-48b8-8cd0-a357d62d3cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-fb96b2af-1b62-4df1-bdf7-6a4ad1b14cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-bcfcd5a1-1a94-4821-885b-6358d610b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-15cf0a04-a39b-4c76-9266-b1e339208ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-bc910787-f6df-4fce-85ec-8d30ae4fb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-b3c7df2a-4a08-4c1f-85eb-e439334eb3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287923710-172.17.0.20-1598511741522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-e284ca7e-3da8-4f6a-941b-ba609a946641,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-2b1ed188-d396-412f-8906-826f5de4d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-82ccc87d-8d90-48b8-8cd0-a357d62d3cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-fb96b2af-1b62-4df1-bdf7-6a4ad1b14cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-bcfcd5a1-1a94-4821-885b-6358d610b8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-15cf0a04-a39b-4c76-9266-b1e339208ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-bc910787-f6df-4fce-85ec-8d30ae4fb55c,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-b3c7df2a-4a08-4c1f-85eb-e439334eb3a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721330984-172.17.0.20-1598512070249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-64831a7d-c2a2-46bb-892d-9195433467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d17f6966-a0a3-4046-aa6c-a56909b7aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-2a03642e-9f33-419f-871e-07042577372d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8c9204da-5bce-43d8-a530-a84e2773e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-7fddb080-1ddb-4b02-9686-4f769c964eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-8ed9c29b-e0b8-4250-b6ae-35745a03abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-1926f986-c5e1-4fad-ba0f-30e52e9ef288,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-51d96796-52e9-4761-86ff-1daaa3c21562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721330984-172.17.0.20-1598512070249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-64831a7d-c2a2-46bb-892d-9195433467a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-d17f6966-a0a3-4046-aa6c-a56909b7aa46,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-2a03642e-9f33-419f-871e-07042577372d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8c9204da-5bce-43d8-a530-a84e2773e83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-7fddb080-1ddb-4b02-9686-4f769c964eae,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-8ed9c29b-e0b8-4250-b6ae-35745a03abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-1926f986-c5e1-4fad-ba0f-30e52e9ef288,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-51d96796-52e9-4761-86ff-1daaa3c21562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89954083-172.17.0.20-1598512285399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-ef18bce6-68e5-403b-9e6b-52284cb1cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-cdfec314-5552-4c45-8f9a-e76dbf8abd87,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-c50a7b4a-891f-4404-ace0-a051d172d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-9173b1fe-c048-48dc-9006-caea1f33c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b79e5498-b028-4cf3-84ec-24caf582921f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-3f500fa8-2561-4df2-8baf-86326de0aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-e4cc6430-341e-4236-8614-29fa8c6d2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-9978ff29-39fc-47f9-88c1-3ba3d339a157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89954083-172.17.0.20-1598512285399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-ef18bce6-68e5-403b-9e6b-52284cb1cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-cdfec314-5552-4c45-8f9a-e76dbf8abd87,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-c50a7b4a-891f-4404-ace0-a051d172d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-9173b1fe-c048-48dc-9006-caea1f33c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b79e5498-b028-4cf3-84ec-24caf582921f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-3f500fa8-2561-4df2-8baf-86326de0aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-e4cc6430-341e-4236-8614-29fa8c6d2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-9978ff29-39fc-47f9-88c1-3ba3d339a157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170610211-172.17.0.20-1598512319903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-27cf90db-b5ba-4f2e-ac59-3fd71a28518d,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-c505d39a-929b-401b-848b-ae381d1de147,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-25a75e09-b156-4ead-9918-2f60fca89935,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-9a3bf049-ec38-42e6-8434-08a4e1ff494a,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-53a2dde2-a962-4343-86a4-ff7f39cde6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-90151318-e4b6-4a25-90a4-6ba479b7b112,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-4a5c668d-6c2b-4ac3-9330-bc044c87ef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1e7894ed-5b84-48a9-808d-1ebfece7440b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170610211-172.17.0.20-1598512319903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-27cf90db-b5ba-4f2e-ac59-3fd71a28518d,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-c505d39a-929b-401b-848b-ae381d1de147,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-25a75e09-b156-4ead-9918-2f60fca89935,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-9a3bf049-ec38-42e6-8434-08a4e1ff494a,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-53a2dde2-a962-4343-86a4-ff7f39cde6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-90151318-e4b6-4a25-90a4-6ba479b7b112,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-4a5c668d-6c2b-4ac3-9330-bc044c87ef2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1e7894ed-5b84-48a9-808d-1ebfece7440b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676076690-172.17.0.20-1598512521539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36515,DS-de92af57-b78f-4d51-9ca0-ac5c839369df,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-70705b8e-1101-4794-b5c4-11ebfde6c964,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-a2f10ccd-c2a3-471f-8e29-3944ea120b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-042d71aa-482f-44f5-9f31-bb2bbb394e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-fcb87938-3a6f-4b42-ac71-b8ec13401801,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-fba0d98d-2804-43dc-b46e-2747de91151f,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-dd4b8428-2fdd-4933-a83d-c1591a94d6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-dccde4c1-d34c-4936-a736-58568cb4e71f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676076690-172.17.0.20-1598512521539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36515,DS-de92af57-b78f-4d51-9ca0-ac5c839369df,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-70705b8e-1101-4794-b5c4-11ebfde6c964,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-a2f10ccd-c2a3-471f-8e29-3944ea120b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-042d71aa-482f-44f5-9f31-bb2bbb394e19,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-fcb87938-3a6f-4b42-ac71-b8ec13401801,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-fba0d98d-2804-43dc-b46e-2747de91151f,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-dd4b8428-2fdd-4933-a83d-c1591a94d6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-dccde4c1-d34c-4936-a736-58568cb4e71f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793992696-172.17.0.20-1598513004918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-aa47a9de-d502-435a-9ca7-f6bfc9467e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-0ee48ac5-5225-4779-b2c4-64d8670e717e,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-4ef9fe99-8767-485e-86ff-6a0f2174e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d4e36e5f-2dcd-4250-8650-034b621be2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-9bb0ac18-56e4-434c-84bc-73eaea6cc38f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-90f913b9-9b3e-49a5-9f0e-0b03eae0c438,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-83afcad0-0a34-4239-9eea-203d5fa2cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-4ac30974-7c8b-4fe3-9c81-e527b92db538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793992696-172.17.0.20-1598513004918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-aa47a9de-d502-435a-9ca7-f6bfc9467e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-0ee48ac5-5225-4779-b2c4-64d8670e717e,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-4ef9fe99-8767-485e-86ff-6a0f2174e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-d4e36e5f-2dcd-4250-8650-034b621be2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-9bb0ac18-56e4-434c-84bc-73eaea6cc38f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-90f913b9-9b3e-49a5-9f0e-0b03eae0c438,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-83afcad0-0a34-4239-9eea-203d5fa2cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-4ac30974-7c8b-4fe3-9c81-e527b92db538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186413283-172.17.0.20-1598513043492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40767,DS-1db4929d-bd4b-4ab5-8528-24680b6cc85f,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-50903158-fa87-4c79-a862-ae1248888653,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-c9d64e56-3baf-46e9-9708-491359cc87f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-1e8ba792-1b6e-47e4-bacd-3c017be1745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-de6cfb07-b9ae-43c5-9224-700da35f488d,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1e5a3ab6-ee7e-4b73-a6bc-f4ccccc96505,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-375cf570-dd39-478c-b60e-b46fe7f11106,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-36494f2b-7801-4bc0-a679-f47f42bf0ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186413283-172.17.0.20-1598513043492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40767,DS-1db4929d-bd4b-4ab5-8528-24680b6cc85f,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-50903158-fa87-4c79-a862-ae1248888653,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-c9d64e56-3baf-46e9-9708-491359cc87f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-1e8ba792-1b6e-47e4-bacd-3c017be1745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-de6cfb07-b9ae-43c5-9224-700da35f488d,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1e5a3ab6-ee7e-4b73-a6bc-f4ccccc96505,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-375cf570-dd39-478c-b60e-b46fe7f11106,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-36494f2b-7801-4bc0-a679-f47f42bf0ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474957718-172.17.0.20-1598513219249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-f579381b-d3d3-4aec-b47b-004a352bf1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-92c7a4c3-ffe4-4fcf-934a-c8865ccf8556,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-aa167764-a390-4735-9ca6-27db5a3467a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-882bd308-ddfc-4bde-8096-c2c72b8c339c,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-eb74d7f8-7247-4724-b492-f4c7421b3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-8f9622b1-092d-4500-9597-e1e0a40178ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-52f7ed29-991f-479c-b5f4-badb8c626d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-1d599b03-f3d8-4a4a-ab23-5b9a7bbb5db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474957718-172.17.0.20-1598513219249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40301,DS-f579381b-d3d3-4aec-b47b-004a352bf1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-92c7a4c3-ffe4-4fcf-934a-c8865ccf8556,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-aa167764-a390-4735-9ca6-27db5a3467a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-882bd308-ddfc-4bde-8096-c2c72b8c339c,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-eb74d7f8-7247-4724-b492-f4c7421b3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-8f9622b1-092d-4500-9597-e1e0a40178ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-52f7ed29-991f-479c-b5f4-badb8c626d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-1d599b03-f3d8-4a4a-ab23-5b9a7bbb5db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254401598-172.17.0.20-1598513772556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-936398d9-c86a-4adf-aaa5-ed8c19f880f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9c62aef6-fa25-4e0a-bc0e-a2fbca4a619f,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-a41e27ff-a4d4-4f20-ac6f-36301ad4f106,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-078273b3-6d7d-4b53-8a06-922a624110e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-61c1eccd-f3c7-4983-941d-b2805bde666b,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-75ac3ac1-5475-466e-98f0-af9b7df0ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d7efcd06-bdca-4a6d-b12c-21b46660d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-e0820075-8d81-4aab-8922-af7299c05a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254401598-172.17.0.20-1598513772556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-936398d9-c86a-4adf-aaa5-ed8c19f880f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9c62aef6-fa25-4e0a-bc0e-a2fbca4a619f,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-a41e27ff-a4d4-4f20-ac6f-36301ad4f106,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-078273b3-6d7d-4b53-8a06-922a624110e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-61c1eccd-f3c7-4983-941d-b2805bde666b,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-75ac3ac1-5475-466e-98f0-af9b7df0ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d7efcd06-bdca-4a6d-b12c-21b46660d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-e0820075-8d81-4aab-8922-af7299c05a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897197905-172.17.0.20-1598514163491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-5b5a5184-f5fd-4c62-ae1b-34baa48453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-34f09b95-a16a-4238-9289-bb0ea07ff92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-2c71d8a4-abf7-4f0f-8432-ad3e8daeb186,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-c3158c2f-7b94-49f6-b1ed-66995c9a53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-45b8a73c-0953-4782-abef-ab2e343b8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-773c2588-8668-4aa4-b43b-125c2e0cbeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-dc38f563-f4bd-45d4-9477-8c75161dea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8c642631-4c24-4fe1-88d4-ec8fdf4435cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897197905-172.17.0.20-1598514163491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-5b5a5184-f5fd-4c62-ae1b-34baa48453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-34f09b95-a16a-4238-9289-bb0ea07ff92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-2c71d8a4-abf7-4f0f-8432-ad3e8daeb186,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-c3158c2f-7b94-49f6-b1ed-66995c9a53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-45b8a73c-0953-4782-abef-ab2e343b8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-773c2588-8668-4aa4-b43b-125c2e0cbeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-dc38f563-f4bd-45d4-9477-8c75161dea65,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-8c642631-4c24-4fe1-88d4-ec8fdf4435cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494537055-172.17.0.20-1598514583002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-86f52a03-3eca-4aa2-ab02-271a12f1f043,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-73286f28-67a9-48c3-be0c-161d97c8eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-b916d33e-ffb5-48fb-a0cb-10f057a57bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5aaf487e-810e-4432-844f-97a596061e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-e813811f-1ac6-4ac6-bd8f-07e13504bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-d0516425-2714-43d4-92d3-51703e9d8bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-8cf88d60-aa96-4a8a-9dc1-2a9a29804c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-80f0620d-927d-45d1-99ad-9eaf609f124e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494537055-172.17.0.20-1598514583002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36567,DS-86f52a03-3eca-4aa2-ab02-271a12f1f043,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-73286f28-67a9-48c3-be0c-161d97c8eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-b916d33e-ffb5-48fb-a0cb-10f057a57bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-5aaf487e-810e-4432-844f-97a596061e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-e813811f-1ac6-4ac6-bd8f-07e13504bb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-d0516425-2714-43d4-92d3-51703e9d8bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-8cf88d60-aa96-4a8a-9dc1-2a9a29804c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-80f0620d-927d-45d1-99ad-9eaf609f124e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007215450-172.17.0.20-1598514789173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b5dad43f-3378-4092-b266-7ffd6bd0ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-f36bc9f0-ab08-42cb-9a73-8e4c5ceffaad,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-ca432cf3-94a4-400b-8c21-ed94c7d32703,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-5e72818e-ec79-489a-aed7-902d5fdad4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-2c527d3a-aaaa-455f-9b06-1b4680cc56cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-088f7f1c-b8ed-4cec-bd1a-5163df3c7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-d0e377fc-c27b-43c5-a36f-de0231b7547c,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-8da7154a-9d2f-4d0b-90e6-f37e5b118db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007215450-172.17.0.20-1598514789173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b5dad43f-3378-4092-b266-7ffd6bd0ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-f36bc9f0-ab08-42cb-9a73-8e4c5ceffaad,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-ca432cf3-94a4-400b-8c21-ed94c7d32703,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-5e72818e-ec79-489a-aed7-902d5fdad4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-2c527d3a-aaaa-455f-9b06-1b4680cc56cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-088f7f1c-b8ed-4cec-bd1a-5163df3c7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-d0e377fc-c27b-43c5-a36f-de0231b7547c,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-8da7154a-9d2f-4d0b-90e6-f37e5b118db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242233874-172.17.0.20-1598515713734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-46cfe335-4b9e-4ee2-9f7e-b5eb01687151,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-e2bdfd5b-a64c-472a-8de6-29650161a01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-076e3d55-e7e0-46ff-9c5d-a1e3c5e24894,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-88255a68-e15b-4601-bc57-4396bbe508e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-849c110a-b3c3-443f-a8b0-a2aa69a6d45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-67fe5e81-88a9-4f3f-8503-b2c3770670e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-cd2ce87d-09e0-4850-858a-e535ccebe366,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-f1860494-8679-4bef-8754-3835be621f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242233874-172.17.0.20-1598515713734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-46cfe335-4b9e-4ee2-9f7e-b5eb01687151,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-e2bdfd5b-a64c-472a-8de6-29650161a01d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-076e3d55-e7e0-46ff-9c5d-a1e3c5e24894,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-88255a68-e15b-4601-bc57-4396bbe508e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-849c110a-b3c3-443f-a8b0-a2aa69a6d45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-67fe5e81-88a9-4f3f-8503-b2c3770670e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-cd2ce87d-09e0-4850-858a-e535ccebe366,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-f1860494-8679-4bef-8754-3835be621f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5250
