reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395261827-172.17.0.17-1598522782804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-5b1ee862-9c39-4a96-9016-9fbe9172fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-4da34a02-1cdc-4e25-99af-00370f74121f,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-1d7292b8-add0-4e58-a54c-81665955a856,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-e8b9de06-047b-4efd-8e13-f25d43cd6fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-6f599f67-aa57-4338-a0bc-1fc07146f502,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-c2dab6bd-e940-4cdb-857c-1dbdc55f2496,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-a5af0bcd-a9cb-4a79-8cbd-b3a11ace96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-5dd66ec5-3265-45f6-a91d-6a12db7e5013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395261827-172.17.0.17-1598522782804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-5b1ee862-9c39-4a96-9016-9fbe9172fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-4da34a02-1cdc-4e25-99af-00370f74121f,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-1d7292b8-add0-4e58-a54c-81665955a856,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-e8b9de06-047b-4efd-8e13-f25d43cd6fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-6f599f67-aa57-4338-a0bc-1fc07146f502,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-c2dab6bd-e940-4cdb-857c-1dbdc55f2496,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-a5af0bcd-a9cb-4a79-8cbd-b3a11ace96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-5dd66ec5-3265-45f6-a91d-6a12db7e5013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687325166-172.17.0.17-1598523220162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-c7228cd7-0f3f-4ea6-88be-fe670e36e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-0fc205bf-a341-400c-aebd-98e6e1b0d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-c3604cb4-9a0d-4ff8-9dbe-3176c3174875,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-a802bc88-ba2b-4aea-a69f-d0a62e11f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-be04a6c1-2ff2-46db-ad1c-659721857a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-ba47f2e5-59d0-42ec-a7b6-8851c7f7bf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-2b09d0e8-40b4-43c3-ae65-1514273c45ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-50916dfd-3cc9-4cf8-b4ba-34be8f3791dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687325166-172.17.0.17-1598523220162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-c7228cd7-0f3f-4ea6-88be-fe670e36e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-0fc205bf-a341-400c-aebd-98e6e1b0d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-c3604cb4-9a0d-4ff8-9dbe-3176c3174875,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-a802bc88-ba2b-4aea-a69f-d0a62e11f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-be04a6c1-2ff2-46db-ad1c-659721857a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-ba47f2e5-59d0-42ec-a7b6-8851c7f7bf79,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-2b09d0e8-40b4-43c3-ae65-1514273c45ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-50916dfd-3cc9-4cf8-b4ba-34be8f3791dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720066840-172.17.0.17-1598523469469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-ad9f0508-5d4a-422c-a5a8-dc784cd9f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-6f9ae5b7-9345-431e-9abf-deadb2a857b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-d7bff8e8-bc6c-481c-bb97-446848d52b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-21bc2a4a-2960-47d5-9f3e-a159db758a07,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f98911af-b5cb-426c-9145-9b873b668214,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-16e39e77-af1d-435e-b49c-49e6e2b05e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-95caf371-3d3b-4f8b-9ee8-8c0d0aa5ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-6333bcbf-c534-414d-955e-ac077e568817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720066840-172.17.0.17-1598523469469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-ad9f0508-5d4a-422c-a5a8-dc784cd9f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-6f9ae5b7-9345-431e-9abf-deadb2a857b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-d7bff8e8-bc6c-481c-bb97-446848d52b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-21bc2a4a-2960-47d5-9f3e-a159db758a07,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-f98911af-b5cb-426c-9145-9b873b668214,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-16e39e77-af1d-435e-b49c-49e6e2b05e82,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-95caf371-3d3b-4f8b-9ee8-8c0d0aa5ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-6333bcbf-c534-414d-955e-ac077e568817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961819445-172.17.0.17-1598523508646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-d3241d28-15e1-4824-ad07-3ff511e83ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fdc21248-a9a8-4192-93f8-1f2aefbfe5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-2408f7a6-12fd-4686-9afd-214e88d2d318,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-16fb3fd4-1d3b-44b5-a8e0-232ab4d39466,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-33699853-3664-4b7f-8dd7-02d2153ac69a,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-7fd37198-4601-42a2-b9b3-ac350acce72a,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-3db227f5-9061-483b-b687-509f5b988f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-ef785af1-a572-4865-82ed-7ec19064fed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961819445-172.17.0.17-1598523508646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-d3241d28-15e1-4824-ad07-3ff511e83ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fdc21248-a9a8-4192-93f8-1f2aefbfe5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-2408f7a6-12fd-4686-9afd-214e88d2d318,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-16fb3fd4-1d3b-44b5-a8e0-232ab4d39466,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-33699853-3664-4b7f-8dd7-02d2153ac69a,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-7fd37198-4601-42a2-b9b3-ac350acce72a,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-3db227f5-9061-483b-b687-509f5b988f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-ef785af1-a572-4865-82ed-7ec19064fed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162675632-172.17.0.17-1598523648685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40098,DS-818f5e32-0f81-4f03-a3d6-4e0b961f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-c9d92a05-0d8c-48c6-9be9-44dd3bbb1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-baa9546a-b667-4468-8153-ed8a36f541ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-b7da51c4-4793-43cb-a577-b72ce7bd122f,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-0fd823d5-6cdc-40b8-ab4f-0f15f6af5818,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-95dfcb3b-c882-4aad-9907-83b1fa17c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-b325aa26-f3f2-4486-b813-fd0aba29b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-04cefce1-9b04-4df3-b6e5-595287c122ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162675632-172.17.0.17-1598523648685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40098,DS-818f5e32-0f81-4f03-a3d6-4e0b961f1591,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-c9d92a05-0d8c-48c6-9be9-44dd3bbb1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-baa9546a-b667-4468-8153-ed8a36f541ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-b7da51c4-4793-43cb-a577-b72ce7bd122f,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-0fd823d5-6cdc-40b8-ab4f-0f15f6af5818,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-95dfcb3b-c882-4aad-9907-83b1fa17c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-b325aa26-f3f2-4486-b813-fd0aba29b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-04cefce1-9b04-4df3-b6e5-595287c122ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733815699-172.17.0.17-1598524435031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-711685b5-ee18-4177-ac61-4362ba85469c,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-80add4ee-509a-4b4f-b213-b9186987adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-39d5dd18-e33a-4d55-98cb-d5b2b4021731,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-8cd26889-db93-4f4c-a3d8-c021f88793ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-0ed9abe0-82e6-4154-a339-5f9b1c7f4fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9dd92613-97ec-4d27-a815-4edf5f3db37d,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-9c0b8335-1d8f-4144-aefd-85284a3f24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-6c04005a-24ba-4e67-98a1-9c4af5143319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733815699-172.17.0.17-1598524435031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-711685b5-ee18-4177-ac61-4362ba85469c,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-80add4ee-509a-4b4f-b213-b9186987adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-39d5dd18-e33a-4d55-98cb-d5b2b4021731,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-8cd26889-db93-4f4c-a3d8-c021f88793ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-0ed9abe0-82e6-4154-a339-5f9b1c7f4fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9dd92613-97ec-4d27-a815-4edf5f3db37d,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-9c0b8335-1d8f-4144-aefd-85284a3f24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-6c04005a-24ba-4e67-98a1-9c4af5143319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427954224-172.17.0.17-1598524550277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-d0f82e52-653e-457d-b149-d09d418dcc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-ee1e5dfd-6bd5-403e-9082-30b3eb821625,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-9db8e807-843d-47a2-b9d5-30690fa284d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-b6b21ce0-694e-49ce-9653-9a3bc9e9226e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3a40fb74-a96c-4724-a38a-b759bba8e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-f910f7c2-8c01-41a0-834a-63633f385626,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-a1b8f4c0-3c23-4a9b-84aa-d1e6cb86d452,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-c4bc1136-741c-4f85-a45c-6d971632ddec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427954224-172.17.0.17-1598524550277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39083,DS-d0f82e52-653e-457d-b149-d09d418dcc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-ee1e5dfd-6bd5-403e-9082-30b3eb821625,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-9db8e807-843d-47a2-b9d5-30690fa284d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-b6b21ce0-694e-49ce-9653-9a3bc9e9226e,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-3a40fb74-a96c-4724-a38a-b759bba8e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-f910f7c2-8c01-41a0-834a-63633f385626,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-a1b8f4c0-3c23-4a9b-84aa-d1e6cb86d452,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-c4bc1136-741c-4f85-a45c-6d971632ddec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377162992-172.17.0.17-1598524885297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-f7825c27-e18c-4446-9e8e-2644ba5a7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4e017406-2fae-4867-b5b0-6e8713152362,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-d00b9998-df67-498b-a572-a7a49f08f217,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-3c1833df-c77f-410a-ac9c-eb05d59ab3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-f7182f9c-cb31-4b6f-a94c-0240f5b80fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-f3e5b013-3f80-4908-8aa2-e6cc34231c11,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-af53f1f2-36e6-4d33-8abf-747339cbf75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-b031cb8e-b842-4cb3-a2e2-06027a93e847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377162992-172.17.0.17-1598524885297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34464,DS-f7825c27-e18c-4446-9e8e-2644ba5a7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4e017406-2fae-4867-b5b0-6e8713152362,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-d00b9998-df67-498b-a572-a7a49f08f217,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-3c1833df-c77f-410a-ac9c-eb05d59ab3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-f7182f9c-cb31-4b6f-a94c-0240f5b80fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-f3e5b013-3f80-4908-8aa2-e6cc34231c11,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-af53f1f2-36e6-4d33-8abf-747339cbf75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-b031cb8e-b842-4cb3-a2e2-06027a93e847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870642917-172.17.0.17-1598525257855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-c04579ed-f9a9-4c91-807b-c283440d19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-08b8687f-271e-4c7a-8d9c-9dccdc0b6e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-753380fe-6f7f-404d-a19a-ee43867d4494,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-a0129d1b-39e1-48a4-8d68-94cad22a5872,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-90e8afd8-c06c-41dc-9b2b-b6f8ea015513,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-cd0f014d-e358-425c-a81f-f4aded689861,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-a4ac5c18-9080-483c-96ac-61d123c96269,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-7fd3def3-debf-4e55-803f-bcd3693dc00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870642917-172.17.0.17-1598525257855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-c04579ed-f9a9-4c91-807b-c283440d19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-08b8687f-271e-4c7a-8d9c-9dccdc0b6e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-753380fe-6f7f-404d-a19a-ee43867d4494,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-a0129d1b-39e1-48a4-8d68-94cad22a5872,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-90e8afd8-c06c-41dc-9b2b-b6f8ea015513,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-cd0f014d-e358-425c-a81f-f4aded689861,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-a4ac5c18-9080-483c-96ac-61d123c96269,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-7fd3def3-debf-4e55-803f-bcd3693dc00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122799278-172.17.0.17-1598526149298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-44d32b1f-20e6-4b4d-b84f-c5e10e88687c,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-640c755e-38bb-4455-98b3-767975026353,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-c003db1e-2009-4158-8b1a-07663a0e981b,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-71f401aa-c9ab-4c38-ba3b-1de146304081,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-7c947f4a-03ce-478a-9dad-ee624e2e76e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-3e21cafa-01c4-46c9-9ac3-05891006b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-221a80b6-7688-4ed0-bfe4-8748067eaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-01db1dd0-4456-4db9-9881-9c47c18dc1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122799278-172.17.0.17-1598526149298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-44d32b1f-20e6-4b4d-b84f-c5e10e88687c,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-640c755e-38bb-4455-98b3-767975026353,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-c003db1e-2009-4158-8b1a-07663a0e981b,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-71f401aa-c9ab-4c38-ba3b-1de146304081,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-7c947f4a-03ce-478a-9dad-ee624e2e76e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-3e21cafa-01c4-46c9-9ac3-05891006b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-221a80b6-7688-4ed0-bfe4-8748067eaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-01db1dd0-4456-4db9-9881-9c47c18dc1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548385397-172.17.0.17-1598526364261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-25a7bcec-4bf6-4cd4-8ec7-070d3e101ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-42107e20-d307-485e-b0f6-8709c819b23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-4aaaf6f1-8ff5-43d5-aab6-a034abd77c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-e5f53c68-f132-4a80-8a37-0ef9b9e7e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-b61b0d59-9506-4b61-82f3-4d129ce7a109,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-5ae1e54a-8087-4a5d-9024-bed89e9e0c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-16192656-67aa-43a6-9436-65ee1ea8d766,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-36196454-2b9a-4ab7-b1c9-57c7a85f36c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548385397-172.17.0.17-1598526364261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-25a7bcec-4bf6-4cd4-8ec7-070d3e101ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-42107e20-d307-485e-b0f6-8709c819b23c,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-4aaaf6f1-8ff5-43d5-aab6-a034abd77c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-e5f53c68-f132-4a80-8a37-0ef9b9e7e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-b61b0d59-9506-4b61-82f3-4d129ce7a109,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-5ae1e54a-8087-4a5d-9024-bed89e9e0c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-16192656-67aa-43a6-9436-65ee1ea8d766,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-36196454-2b9a-4ab7-b1c9-57c7a85f36c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337142839-172.17.0.17-1598527184947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-8477b94d-1ea6-40c6-8254-f5ba67be1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-5eb271d3-67da-4f26-b0fe-b64ed6c115cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-4132070a-8f3e-4b5d-84ee-075c89dd634c,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-d6ab3bb7-f67b-46c7-bad0-df1e16363a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-fc26f364-6f82-4489-a610-1b39afba4039,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-4d7fdfba-fe69-4885-a566-d6ac00f08dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-31a5df53-a2a9-4d28-b7f2-fd07241eeb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-b50499b4-4731-4256-82c5-4390a6944183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337142839-172.17.0.17-1598527184947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33934,DS-8477b94d-1ea6-40c6-8254-f5ba67be1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-5eb271d3-67da-4f26-b0fe-b64ed6c115cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-4132070a-8f3e-4b5d-84ee-075c89dd634c,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-d6ab3bb7-f67b-46c7-bad0-df1e16363a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-fc26f364-6f82-4489-a610-1b39afba4039,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-4d7fdfba-fe69-4885-a566-d6ac00f08dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-31a5df53-a2a9-4d28-b7f2-fd07241eeb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-b50499b4-4731-4256-82c5-4390a6944183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673483881-172.17.0.17-1598527255723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-91a246a3-87b6-4c59-aab4-fe38dc988f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-a57191f6-a017-4d6b-bf21-65323f22ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-84cbe699-b1c6-40b0-994b-e348244f0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-19d01841-d6dc-46f8-a076-2d7bf4bb7956,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-18a83666-1aa6-4f79-a609-e664c4264576,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-894b3e69-e3f0-47b8-a954-f22ca56b8f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-f7c5558c-b6cc-4e7a-ac6b-4b05085ffeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-cabd8400-48d0-4655-8893-6279c2b655cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673483881-172.17.0.17-1598527255723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36927,DS-91a246a3-87b6-4c59-aab4-fe38dc988f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-a57191f6-a017-4d6b-bf21-65323f22ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-84cbe699-b1c6-40b0-994b-e348244f0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-19d01841-d6dc-46f8-a076-2d7bf4bb7956,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-18a83666-1aa6-4f79-a609-e664c4264576,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-894b3e69-e3f0-47b8-a954-f22ca56b8f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-f7c5558c-b6cc-4e7a-ac6b-4b05085ffeff,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-cabd8400-48d0-4655-8893-6279c2b655cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348395005-172.17.0.17-1598527523633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-823276a4-4cae-46d0-ac88-65f540067bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-d83edd25-8027-4faa-b4cf-d3d58e2b9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-9af56d0c-3425-4999-a4cc-dde89b66b8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-daf56d9f-d7e9-4dd8-8fde-518e10920863,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-837f9ea8-f06c-4e53-8e05-23cbbf89118a,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-6d71affc-3b5e-4177-b4ca-5bfd4cf1df87,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-f2d4d949-1c5f-4514-b24f-bd212246d177,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-24122e87-614d-4cae-9232-003683e64db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348395005-172.17.0.17-1598527523633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-823276a4-4cae-46d0-ac88-65f540067bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-d83edd25-8027-4faa-b4cf-d3d58e2b9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-9af56d0c-3425-4999-a4cc-dde89b66b8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-daf56d9f-d7e9-4dd8-8fde-518e10920863,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-837f9ea8-f06c-4e53-8e05-23cbbf89118a,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-6d71affc-3b5e-4177-b4ca-5bfd4cf1df87,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-f2d4d949-1c5f-4514-b24f-bd212246d177,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-24122e87-614d-4cae-9232-003683e64db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980401814-172.17.0.17-1598527876851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37121,DS-815fb1af-387d-43f6-ab4d-97710fd3d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-c843916f-52b2-4308-ad0a-6a639ab70649,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-df3bda92-f13c-4011-9f30-a39138d4017c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-8db4ab34-0dad-4c0f-857d-e957cc8c30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-bf80daca-69fb-4bf0-9172-6a60b4756a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-29f30193-7797-4a27-b4c9-6b93017259ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-d6494018-179e-4f33-910e-8a1e5f3c8499,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-e73ba545-3cb6-45af-b96d-d97ce052ee03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980401814-172.17.0.17-1598527876851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37121,DS-815fb1af-387d-43f6-ab4d-97710fd3d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-c843916f-52b2-4308-ad0a-6a639ab70649,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-df3bda92-f13c-4011-9f30-a39138d4017c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-8db4ab34-0dad-4c0f-857d-e957cc8c30c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-bf80daca-69fb-4bf0-9172-6a60b4756a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-29f30193-7797-4a27-b4c9-6b93017259ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-d6494018-179e-4f33-910e-8a1e5f3c8499,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-e73ba545-3cb6-45af-b96d-d97ce052ee03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5529
