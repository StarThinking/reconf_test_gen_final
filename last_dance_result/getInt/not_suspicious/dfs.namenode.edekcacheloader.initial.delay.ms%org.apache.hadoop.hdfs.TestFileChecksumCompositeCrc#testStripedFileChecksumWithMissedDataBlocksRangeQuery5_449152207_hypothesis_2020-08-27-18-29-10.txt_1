reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135942039-172.17.0.14-1598553051501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-9baf8862-c01f-4427-9ff1-59124b4211d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-fd25692e-78d8-479b-b2e8-f9b54e71ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-fe1ab36f-48f4-47ac-8bd9-20296641ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-b834d102-c5ad-41f2-8581-ce4d72be34ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-e79d8791-8183-499b-b450-affeacf31d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-d173eaa2-344c-4751-94d0-31b510549388,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-cb575731-f409-4f09-a134-32be24e5611a,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-c1fa66b8-b076-4df0-8b77-e3a71b8ebe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135942039-172.17.0.14-1598553051501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-9baf8862-c01f-4427-9ff1-59124b4211d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-fd25692e-78d8-479b-b2e8-f9b54e71ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-fe1ab36f-48f4-47ac-8bd9-20296641ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-b834d102-c5ad-41f2-8581-ce4d72be34ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-e79d8791-8183-499b-b450-affeacf31d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-d173eaa2-344c-4751-94d0-31b510549388,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-cb575731-f409-4f09-a134-32be24e5611a,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-c1fa66b8-b076-4df0-8b77-e3a71b8ebe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267944040-172.17.0.14-1598553262558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-49681765-f94d-4529-a7aa-94b93387dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-08ce7251-0a64-4e71-a06d-91fd74a0de88,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-37ac070a-71d4-4164-90ea-5bc4bed41244,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-33908dfa-fd08-4be3-9dd8-4b5cbd26bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-b00f4d96-1e02-4fa8-907a-5cfd30c71038,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-0c39eb2e-02a0-4f4a-b327-82297f12027b,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-75e757cf-1278-434e-a069-c2a8b48fa9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-231fbf94-0e01-4dd7-be1c-309f25823e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267944040-172.17.0.14-1598553262558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38267,DS-49681765-f94d-4529-a7aa-94b93387dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-08ce7251-0a64-4e71-a06d-91fd74a0de88,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-37ac070a-71d4-4164-90ea-5bc4bed41244,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-33908dfa-fd08-4be3-9dd8-4b5cbd26bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-b00f4d96-1e02-4fa8-907a-5cfd30c71038,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-0c39eb2e-02a0-4f4a-b327-82297f12027b,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-75e757cf-1278-434e-a069-c2a8b48fa9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-231fbf94-0e01-4dd7-be1c-309f25823e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303812563-172.17.0.14-1598553746478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2d169fa-bc42-4080-8b3b-249cefdcf887,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-3400e1a4-96e4-4aec-a8bd-53782632f456,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-17db40d6-427d-4258-b2ad-a4f4f646c295,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-1fa56013-1b74-455f-a6b5-3aa5a040c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-25a76682-0fdb-43d4-9ead-7eba0ee44b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-e88e37c5-10ea-4091-81f6-cbe068fd1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-39556c17-0652-4a55-8847-c5b6391c5428,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-7d9c8746-1fa6-49b3-bba9-076529391650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303812563-172.17.0.14-1598553746478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36734,DS-d2d169fa-bc42-4080-8b3b-249cefdcf887,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-3400e1a4-96e4-4aec-a8bd-53782632f456,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-17db40d6-427d-4258-b2ad-a4f4f646c295,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-1fa56013-1b74-455f-a6b5-3aa5a040c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-25a76682-0fdb-43d4-9ead-7eba0ee44b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-e88e37c5-10ea-4091-81f6-cbe068fd1bef,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-39556c17-0652-4a55-8847-c5b6391c5428,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-7d9c8746-1fa6-49b3-bba9-076529391650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112787600-172.17.0.14-1598554303394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-abf3b422-a12f-4c05-9d99-a66885792a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-8b253356-001e-4404-b2dd-191c5bda881a,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-7a819056-d7c7-4ccb-b31a-60df4b57e862,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-40b8f878-6888-4061-ae3a-30b8f76c44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-85678dea-6b9b-45ae-b8d3-97aea9afaaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-fe08bc3b-4d2f-4f0e-aa00-61614a7e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-2ef81eb3-7edf-4e3e-99e4-c73bd9f82019,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-57d58ae8-8ccb-4e2d-9207-38d138badea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112787600-172.17.0.14-1598554303394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-abf3b422-a12f-4c05-9d99-a66885792a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-8b253356-001e-4404-b2dd-191c5bda881a,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-7a819056-d7c7-4ccb-b31a-60df4b57e862,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-40b8f878-6888-4061-ae3a-30b8f76c44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-85678dea-6b9b-45ae-b8d3-97aea9afaaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-fe08bc3b-4d2f-4f0e-aa00-61614a7e19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-2ef81eb3-7edf-4e3e-99e4-c73bd9f82019,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-57d58ae8-8ccb-4e2d-9207-38d138badea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969710120-172.17.0.14-1598554666784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-0a807aff-690a-4291-9599-1196dbee4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-05355cd5-c05a-4743-8dca-4c11333cafda,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-d2205fde-ac60-4ede-a7e9-95103635c5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-b7e962d5-2f4e-4816-8128-d7817d29588d,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-c36c0fea-63dd-4302-b456-821477657db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8f17dafa-0835-4e6c-bc00-9c771d7de968,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-aef318c5-ce05-472e-b66d-674798b9271f,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-fa05daf8-7be3-45a6-a9f9-36ef0da99f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969710120-172.17.0.14-1598554666784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-0a807aff-690a-4291-9599-1196dbee4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-05355cd5-c05a-4743-8dca-4c11333cafda,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-d2205fde-ac60-4ede-a7e9-95103635c5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-b7e962d5-2f4e-4816-8128-d7817d29588d,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-c36c0fea-63dd-4302-b456-821477657db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-8f17dafa-0835-4e6c-bc00-9c771d7de968,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-aef318c5-ce05-472e-b66d-674798b9271f,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-fa05daf8-7be3-45a6-a9f9-36ef0da99f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717421012-172.17.0.14-1598555943920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-0a0bcc76-7140-4b00-80ed-3261ac92c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b0dcb7f4-9017-4ce2-8fe7-ba69f8a16ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-9bf92d51-a755-4638-83ea-80b21d9d6965,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-ff0ed127-d3b1-422a-9199-89f2b61614a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-94678700-d127-4ff8-bbc3-a8d612aab6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-81105c5a-0c76-4bf8-a964-dff23d7b9246,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3bf819c7-ab34-46f7-bee8-824b2d6ec98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-459d436e-27cc-4c78-9e45-15380ebde870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717421012-172.17.0.14-1598555943920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-0a0bcc76-7140-4b00-80ed-3261ac92c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b0dcb7f4-9017-4ce2-8fe7-ba69f8a16ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-9bf92d51-a755-4638-83ea-80b21d9d6965,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-ff0ed127-d3b1-422a-9199-89f2b61614a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-94678700-d127-4ff8-bbc3-a8d612aab6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-81105c5a-0c76-4bf8-a964-dff23d7b9246,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3bf819c7-ab34-46f7-bee8-824b2d6ec98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-459d436e-27cc-4c78-9e45-15380ebde870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326106577-172.17.0.14-1598556302033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-0d8f6ca0-3e5c-414c-8af2-e94d7b359165,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-3e6d7549-9875-465d-9505-2777460d79c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-22acde2d-9007-4431-bc6e-47ca698efa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e503d350-ad7c-4373-9c09-664ce1387697,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-68a43a52-930e-4ce8-912e-9386fbf15ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-67139c2f-96e1-4bd6-95f7-02ff09453c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-f29eeab2-45eb-49a4-9908-7f3947e48dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-0856b4af-7726-43be-bd3d-a211c8e86b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326106577-172.17.0.14-1598556302033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-0d8f6ca0-3e5c-414c-8af2-e94d7b359165,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-3e6d7549-9875-465d-9505-2777460d79c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-22acde2d-9007-4431-bc6e-47ca698efa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e503d350-ad7c-4373-9c09-664ce1387697,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-68a43a52-930e-4ce8-912e-9386fbf15ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-67139c2f-96e1-4bd6-95f7-02ff09453c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-f29eeab2-45eb-49a4-9908-7f3947e48dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-0856b4af-7726-43be-bd3d-a211c8e86b9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047653253-172.17.0.14-1598556559424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-bc30662c-cfcf-40f8-8200-bb43e3b9b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c0d05c3f-5ff4-4595-99f0-20cdbc64792c,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-895ac044-2f87-490e-829f-a65697890125,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-0ee6544b-3843-46ed-976a-f5dc89a1faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-34d8c542-dc89-4f84-82d4-19eb2222ee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6b7e74c6-5ea7-44a1-aa69-a74b19298819,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-36f059b1-a731-4e0a-978b-db54b1e2f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1981006e-dc41-40e2-936a-96d9e7d6f8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047653253-172.17.0.14-1598556559424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-bc30662c-cfcf-40f8-8200-bb43e3b9b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-c0d05c3f-5ff4-4595-99f0-20cdbc64792c,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-895ac044-2f87-490e-829f-a65697890125,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-0ee6544b-3843-46ed-976a-f5dc89a1faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-34d8c542-dc89-4f84-82d4-19eb2222ee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6b7e74c6-5ea7-44a1-aa69-a74b19298819,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-36f059b1-a731-4e0a-978b-db54b1e2f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1981006e-dc41-40e2-936a-96d9e7d6f8d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439524943-172.17.0.14-1598556588060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-2848b601-8492-478c-96a4-a7a3092fb182,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-db045636-04e6-4774-a57f-016418d99776,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-ebb3242a-e6b7-4dbe-949f-f421551bc00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-70ffc791-5fd9-4aba-9457-2f938e8fe590,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e8c79e70-d84a-47dd-8b6d-b436aba52add,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-df897762-cd80-4b09-92d9-1ff4d72554e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3afdce97-f5a7-47ba-a0ad-fb04e070386c,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-6fd58f74-41b7-4147-9ad7-587da64e1c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439524943-172.17.0.14-1598556588060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-2848b601-8492-478c-96a4-a7a3092fb182,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-db045636-04e6-4774-a57f-016418d99776,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-ebb3242a-e6b7-4dbe-949f-f421551bc00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-70ffc791-5fd9-4aba-9457-2f938e8fe590,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e8c79e70-d84a-47dd-8b6d-b436aba52add,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-df897762-cd80-4b09-92d9-1ff4d72554e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3afdce97-f5a7-47ba-a0ad-fb04e070386c,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-6fd58f74-41b7-4147-9ad7-587da64e1c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992227589-172.17.0.14-1598556615845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45812,DS-112bdd98-fe3e-4a97-8107-6bccbff53c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0bad6320-987c-4e35-a1f0-ab9ba0972b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-a85bc07c-74fd-430b-ac5c-d4bd40ae494c,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8d837bbd-de27-40ca-96a6-e8581ae5a0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-06836464-08a2-4a3e-b841-7bcf80758df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-71c5efaf-ec23-4c0a-bfbd-c9867731dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-57bb4cbe-23b6-41e6-99f9-ba0603c8c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a4f01286-f35d-4aab-8739-353d764b26a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992227589-172.17.0.14-1598556615845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45812,DS-112bdd98-fe3e-4a97-8107-6bccbff53c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0bad6320-987c-4e35-a1f0-ab9ba0972b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-a85bc07c-74fd-430b-ac5c-d4bd40ae494c,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-8d837bbd-de27-40ca-96a6-e8581ae5a0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-06836464-08a2-4a3e-b841-7bcf80758df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-71c5efaf-ec23-4c0a-bfbd-c9867731dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-57bb4cbe-23b6-41e6-99f9-ba0603c8c9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a4f01286-f35d-4aab-8739-353d764b26a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265908833-172.17.0.14-1598556872714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-69133f2d-08d1-479c-907d-2608f2b52f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-61906a5e-b0aa-42c7-ac9f-9eba4ce3f411,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-bd3fc96a-4e42-462e-907f-007997821bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-fb4df8d4-2f29-4684-9198-83b12afddfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-1745e9bb-c209-4177-a961-cb1cbddacea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-62f924cf-477e-4f4a-a4ac-24604ca86943,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-7babf320-187d-41e2-8e70-26985c37c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-6fb4d62e-8b2c-436b-9305-12291f49d4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265908833-172.17.0.14-1598556872714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-69133f2d-08d1-479c-907d-2608f2b52f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-61906a5e-b0aa-42c7-ac9f-9eba4ce3f411,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-bd3fc96a-4e42-462e-907f-007997821bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-fb4df8d4-2f29-4684-9198-83b12afddfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-1745e9bb-c209-4177-a961-cb1cbddacea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-62f924cf-477e-4f4a-a4ac-24604ca86943,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-7babf320-187d-41e2-8e70-26985c37c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-6fb4d62e-8b2c-436b-9305-12291f49d4b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313003146-172.17.0.14-1598556957552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-54dde3ce-8cc8-418f-ae97-3b130515b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-1e6acdd5-2a00-43e1-9fbe-194790e42178,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-9cf492be-b999-4e9d-b1b2-6d010d4f44cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-e53524d6-dcf9-4445-92f2-6af6634338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-69670f98-eb61-4260-ad29-f471507f2835,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-970f1893-0ee3-414f-8270-0e251d0cecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-707a2332-41b9-4bc3-b81f-83ca08800545,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0572ae7d-02de-44f6-91e6-3ca36e711136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313003146-172.17.0.14-1598556957552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-54dde3ce-8cc8-418f-ae97-3b130515b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-1e6acdd5-2a00-43e1-9fbe-194790e42178,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-9cf492be-b999-4e9d-b1b2-6d010d4f44cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-e53524d6-dcf9-4445-92f2-6af6634338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-69670f98-eb61-4260-ad29-f471507f2835,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-970f1893-0ee3-414f-8270-0e251d0cecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-707a2332-41b9-4bc3-b81f-83ca08800545,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0572ae7d-02de-44f6-91e6-3ca36e711136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313775498-172.17.0.14-1598557071457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-02b88eaa-719e-44a6-aa71-b8dd8be2ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-7ef9a61c-15e8-433d-a6d7-2ec1dd27d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-d52e17fb-4585-4eb5-8c38-f6ea5e3a28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b9b50d61-10dd-4acb-a967-090ca7c906a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-9994c16a-7e7a-4aa1-ba3d-a4057f54662a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-9c40897e-2cd3-4ec7-b5ca-3c870458af52,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-38fa00ad-2e9c-4b66-b5e6-77343f906c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-034c5a83-387c-4d10-9a7b-4c4464c05596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313775498-172.17.0.14-1598557071457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-02b88eaa-719e-44a6-aa71-b8dd8be2ab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-7ef9a61c-15e8-433d-a6d7-2ec1dd27d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-d52e17fb-4585-4eb5-8c38-f6ea5e3a28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b9b50d61-10dd-4acb-a967-090ca7c906a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-9994c16a-7e7a-4aa1-ba3d-a4057f54662a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-9c40897e-2cd3-4ec7-b5ca-3c870458af52,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-38fa00ad-2e9c-4b66-b5e6-77343f906c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-034c5a83-387c-4d10-9a7b-4c4464c05596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5310
