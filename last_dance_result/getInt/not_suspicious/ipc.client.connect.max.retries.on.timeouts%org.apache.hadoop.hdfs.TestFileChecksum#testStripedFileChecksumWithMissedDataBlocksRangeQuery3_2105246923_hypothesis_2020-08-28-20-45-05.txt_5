reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358914142-172.17.0.20-1598647994252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-f9baf1d8-b6dd-4726-a2d2-284e2ec1fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-a46f94be-ced6-4451-992e-e393b9fff77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-16bb25f5-76f1-48b6-b4f0-fdf019b9e3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-f40d2676-a546-4d31-8f18-9ea5ea08e458,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-36cc95b0-86e7-4d1d-b3ef-cb3370a262b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-b2e5a886-def9-4779-b583-d7d43fb85c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-d2240273-5a8f-4efc-bae7-543030a47a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-b841e8ad-bd4e-457e-8a06-8c7388cafdd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358914142-172.17.0.20-1598647994252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-f9baf1d8-b6dd-4726-a2d2-284e2ec1fad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-a46f94be-ced6-4451-992e-e393b9fff77b,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-16bb25f5-76f1-48b6-b4f0-fdf019b9e3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-f40d2676-a546-4d31-8f18-9ea5ea08e458,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-36cc95b0-86e7-4d1d-b3ef-cb3370a262b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-b2e5a886-def9-4779-b583-d7d43fb85c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-d2240273-5a8f-4efc-bae7-543030a47a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-b841e8ad-bd4e-457e-8a06-8c7388cafdd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109649466-172.17.0.20-1598648381390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-67af01c2-6635-4d76-93f1-207e1f078cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-8cf955e8-068e-4ea0-bf61-9da108fdc58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-0abe2a69-5f44-4891-8446-97d139ab95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-ce9465f8-b7f5-41db-9f65-d93c8fcfe2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-d98becf0-24e6-43eb-8616-7be164b09003,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-9d391d3f-0257-47b2-a607-e5a4598c9ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-0d821b3b-9d46-447f-9f09-22e7cb802a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-47936a54-a71b-4cf8-94de-67639299482b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109649466-172.17.0.20-1598648381390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-67af01c2-6635-4d76-93f1-207e1f078cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-8cf955e8-068e-4ea0-bf61-9da108fdc58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-0abe2a69-5f44-4891-8446-97d139ab95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-ce9465f8-b7f5-41db-9f65-d93c8fcfe2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-d98becf0-24e6-43eb-8616-7be164b09003,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-9d391d3f-0257-47b2-a607-e5a4598c9ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-0d821b3b-9d46-447f-9f09-22e7cb802a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-47936a54-a71b-4cf8-94de-67639299482b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922788763-172.17.0.20-1598648448764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44110,DS-47e39a77-c5bb-4802-8b8a-37124233a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-758d2528-d275-418f-988a-9289b96a9ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-e4ec0aa9-af90-47de-9d9b-c00967c6276a,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-126ac88c-0544-4ae8-a029-81154912acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4fc3c475-f2c8-45ba-90a0-7ca3f0d088ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-6f39a15a-dbb6-41f5-80aa-57bc4336dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b857a04f-d24a-4cce-93c0-97116e300e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-7fc02fef-2acb-4ec2-a9b2-2b01ca2f6763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922788763-172.17.0.20-1598648448764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44110,DS-47e39a77-c5bb-4802-8b8a-37124233a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-758d2528-d275-418f-988a-9289b96a9ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-e4ec0aa9-af90-47de-9d9b-c00967c6276a,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-126ac88c-0544-4ae8-a029-81154912acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-4fc3c475-f2c8-45ba-90a0-7ca3f0d088ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-6f39a15a-dbb6-41f5-80aa-57bc4336dc03,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b857a04f-d24a-4cce-93c0-97116e300e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-7fc02fef-2acb-4ec2-a9b2-2b01ca2f6763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546988302-172.17.0.20-1598648521246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-7c61c964-b082-4830-b5d6-e66e396a3596,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5df2ef42-f27a-461f-8bd9-83f71f3247ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-bc5109a6-92f2-4ab2-b244-0308e4073155,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-e516bc6f-8d24-4a78-b6c0-2c0a72a9ce82,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-fed863bb-0d83-4d87-bb85-b961061f7d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-58aa3142-3153-4c43-94a0-4b20c9008c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-14baa42b-e536-497b-a050-4427c1c8efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-d157510e-774a-4486-81fc-7e704654b3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546988302-172.17.0.20-1598648521246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-7c61c964-b082-4830-b5d6-e66e396a3596,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5df2ef42-f27a-461f-8bd9-83f71f3247ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-bc5109a6-92f2-4ab2-b244-0308e4073155,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-e516bc6f-8d24-4a78-b6c0-2c0a72a9ce82,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-fed863bb-0d83-4d87-bb85-b961061f7d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-58aa3142-3153-4c43-94a0-4b20c9008c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-14baa42b-e536-497b-a050-4427c1c8efb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-d157510e-774a-4486-81fc-7e704654b3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934787101-172.17.0.20-1598648565107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-1c14b9ba-d3a0-43f5-a7d4-4d77cb18290c,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-bc7d046d-3d82-46a8-9c0e-5fdef0df022c,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-67186f6e-f318-4900-8c26-fa50d04bd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e8d2e36b-989d-4543-b9cd-49d6323ffcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-1becbb9c-4829-4771-8460-7c84987f98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-a041d2cd-fc04-469a-84be-cb782c36d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-80f04b14-3c1c-4162-8361-52cf646ef7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-ed468272-f00d-484a-a9bf-b2785d447007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934787101-172.17.0.20-1598648565107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-1c14b9ba-d3a0-43f5-a7d4-4d77cb18290c,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-bc7d046d-3d82-46a8-9c0e-5fdef0df022c,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-67186f6e-f318-4900-8c26-fa50d04bd2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e8d2e36b-989d-4543-b9cd-49d6323ffcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-1becbb9c-4829-4771-8460-7c84987f98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-a041d2cd-fc04-469a-84be-cb782c36d15f,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-80f04b14-3c1c-4162-8361-52cf646ef7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-ed468272-f00d-484a-a9bf-b2785d447007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498442230-172.17.0.20-1598648673157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-a792650d-7a34-48e7-b404-37f69f2a2184,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f8a49c49-0667-4745-9349-b0bdb2cadd72,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-b590054d-6919-4f84-9237-4bf437a0d174,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-3b6df8ee-60a3-4633-a3eb-74cab70aaf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-cbdbea9a-210d-4757-a2d4-a55b1bfd2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-7aa5986b-0db6-48b4-8512-781002c11d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-bcbf485e-50ef-414e-870f-a13ae5745c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-fbbd6f52-db63-4c0e-8246-99c9d99343c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498442230-172.17.0.20-1598648673157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33981,DS-a792650d-7a34-48e7-b404-37f69f2a2184,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f8a49c49-0667-4745-9349-b0bdb2cadd72,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-b590054d-6919-4f84-9237-4bf437a0d174,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-3b6df8ee-60a3-4633-a3eb-74cab70aaf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-cbdbea9a-210d-4757-a2d4-a55b1bfd2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-7aa5986b-0db6-48b4-8512-781002c11d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-bcbf485e-50ef-414e-870f-a13ae5745c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-fbbd6f52-db63-4c0e-8246-99c9d99343c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521739334-172.17.0.20-1598648712236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-0c687a8f-720d-41bc-9d46-bb50bdf388a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-293031d7-06cb-4938-bc0e-90252bec8213,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-7ab4ecd0-57bc-4ecd-b554-071313034006,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-16e741b8-8344-42cb-99dc-4526daae0cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-6fa67f04-70cb-47aa-953e-de0bece11308,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-6bff4961-e437-445a-ab59-21edff1fcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-f5b62eb3-f9ba-42d1-be36-49dc6e7b6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-5dadd535-9bb1-4ca4-92b5-5bdc709ba5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521739334-172.17.0.20-1598648712236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-0c687a8f-720d-41bc-9d46-bb50bdf388a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-293031d7-06cb-4938-bc0e-90252bec8213,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-7ab4ecd0-57bc-4ecd-b554-071313034006,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-16e741b8-8344-42cb-99dc-4526daae0cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-6fa67f04-70cb-47aa-953e-de0bece11308,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-6bff4961-e437-445a-ab59-21edff1fcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-f5b62eb3-f9ba-42d1-be36-49dc6e7b6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-5dadd535-9bb1-4ca4-92b5-5bdc709ba5d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386696241-172.17.0.20-1598648847672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-b7e0bc78-e42d-4d6a-bccd-844fa03ef65a,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-b0d6a626-8839-43f9-9735-a9593240f67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-c47e05d7-d9cc-444c-afd3-7093f4f4f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-5a636490-7074-44b8-a4fe-0933eeaa92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-eff5c421-0e27-4781-aa50-55789949c962,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-8422727c-e881-4901-9654-1627aeefa25a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-640e5bdb-c0b1-411f-84ea-682cc0f56a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-d40d666f-eae4-4cbc-b236-2ebc506e0c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386696241-172.17.0.20-1598648847672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-b7e0bc78-e42d-4d6a-bccd-844fa03ef65a,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-b0d6a626-8839-43f9-9735-a9593240f67c,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-c47e05d7-d9cc-444c-afd3-7093f4f4f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-5a636490-7074-44b8-a4fe-0933eeaa92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-eff5c421-0e27-4781-aa50-55789949c962,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-8422727c-e881-4901-9654-1627aeefa25a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-640e5bdb-c0b1-411f-84ea-682cc0f56a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-d40d666f-eae4-4cbc-b236-2ebc506e0c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2908927-172.17.0.20-1598648911944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-ade72d1b-3e06-4b7c-a4ce-a92c40695fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-1264377b-beef-4e3d-824f-c9d0ec8ea211,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-2411a718-0346-4966-8c31-0c5bea39797e,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-45f04643-42c5-4e22-acd0-e44523f0183c,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-4c14dc18-5e1a-438d-8d9d-cb3921cea2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4b59e738-d87d-42b2-9dc6-edf09886b132,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-fa3f2d11-c104-497a-a3c6-bdfc69c2e336,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-3d14a892-5b59-4d1e-bde5-babeb5cf8331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2908927-172.17.0.20-1598648911944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-ade72d1b-3e06-4b7c-a4ce-a92c40695fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-1264377b-beef-4e3d-824f-c9d0ec8ea211,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-2411a718-0346-4966-8c31-0c5bea39797e,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-45f04643-42c5-4e22-acd0-e44523f0183c,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-4c14dc18-5e1a-438d-8d9d-cb3921cea2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4b59e738-d87d-42b2-9dc6-edf09886b132,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-fa3f2d11-c104-497a-a3c6-bdfc69c2e336,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-3d14a892-5b59-4d1e-bde5-babeb5cf8331,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169802341-172.17.0.20-1598649308247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34800,DS-2c7297e6-805a-4ca4-a040-5b56a9b9b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-54e2b70a-530b-4a63-ac78-8c91ebe1e546,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1f8c24db-501f-4901-b744-2f29ea07d56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-621b2958-2976-48a0-a69e-ee704abdf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-c06dbb43-36f9-49ac-a142-a6248f6fbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-127f93b6-a548-41f5-9117-ada29b63194c,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-72671642-06ea-436c-8736-f6478300e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-33115e14-d8c9-4971-8a54-8d4452d787d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169802341-172.17.0.20-1598649308247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34800,DS-2c7297e6-805a-4ca4-a040-5b56a9b9b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-54e2b70a-530b-4a63-ac78-8c91ebe1e546,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1f8c24db-501f-4901-b744-2f29ea07d56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-621b2958-2976-48a0-a69e-ee704abdf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-c06dbb43-36f9-49ac-a142-a6248f6fbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-127f93b6-a548-41f5-9117-ada29b63194c,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-72671642-06ea-436c-8736-f6478300e1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-33115e14-d8c9-4971-8a54-8d4452d787d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916777637-172.17.0.20-1598649421763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-f444c722-628a-4cc8-98dc-3dcb906c6d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-410937f5-bb52-4ee2-8820-5e5de2bd818a,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b4d36afa-bf44-4a27-8bc9-e7e138eccdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-521ebf5b-e44c-4424-bb49-f8ed5e6b7fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-363af67f-48b7-41cd-9371-424b187ecae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dfa04aa2-5927-45c4-8698-3064453f06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-db4e40e6-c10b-43aa-a8db-94160bb759ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-e263803c-bbdb-4776-889f-49621a2ab591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916777637-172.17.0.20-1598649421763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-f444c722-628a-4cc8-98dc-3dcb906c6d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-410937f5-bb52-4ee2-8820-5e5de2bd818a,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-b4d36afa-bf44-4a27-8bc9-e7e138eccdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-521ebf5b-e44c-4424-bb49-f8ed5e6b7fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-363af67f-48b7-41cd-9371-424b187ecae7,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dfa04aa2-5927-45c4-8698-3064453f06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-db4e40e6-c10b-43aa-a8db-94160bb759ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-e263803c-bbdb-4776-889f-49621a2ab591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578652175-172.17.0.20-1598649576178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f60ffe15-5728-4c90-9a18-3f9acd5ae71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-3c502e9e-f07b-4488-be51-edc12d47ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-7b1f17a9-2804-42d5-bba4-14ea53daafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-c670b113-f9ae-4a59-a549-a7889b634bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-9380accf-1dec-42fd-9868-a91ab065d15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-21b4961d-d983-418c-bca7-577d00662b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-dda44ccd-fd49-4ef6-8914-54a825d5bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-ec3cd7a8-857f-4d37-8980-78d390e7c3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578652175-172.17.0.20-1598649576178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-f60ffe15-5728-4c90-9a18-3f9acd5ae71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-3c502e9e-f07b-4488-be51-edc12d47ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-7b1f17a9-2804-42d5-bba4-14ea53daafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-c670b113-f9ae-4a59-a549-a7889b634bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-9380accf-1dec-42fd-9868-a91ab065d15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-21b4961d-d983-418c-bca7-577d00662b52,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-dda44ccd-fd49-4ef6-8914-54a825d5bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-ec3cd7a8-857f-4d37-8980-78d390e7c3b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959096713-172.17.0.20-1598649887570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-2b6cfe44-e733-40f4-9527-b2a24468c4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-89702480-e5e2-4cac-9b52-0582f5a4f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-904aef81-881f-48c5-89b7-b1d48e250d44,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-205519ed-efa9-4c69-b88d-c8cf166d792a,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-592d347e-91e8-4061-9104-cddac98d2911,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-6ab24419-9736-4bce-86a7-c31e7ab14f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-0ddb6293-3926-4b1f-acc8-013e1152ffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-c35600c8-3553-433f-b228-c8b0cfcb6098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959096713-172.17.0.20-1598649887570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33344,DS-2b6cfe44-e733-40f4-9527-b2a24468c4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-89702480-e5e2-4cac-9b52-0582f5a4f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-904aef81-881f-48c5-89b7-b1d48e250d44,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-205519ed-efa9-4c69-b88d-c8cf166d792a,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-592d347e-91e8-4061-9104-cddac98d2911,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-6ab24419-9736-4bce-86a7-c31e7ab14f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-0ddb6293-3926-4b1f-acc8-013e1152ffb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-c35600c8-3553-433f-b228-c8b0cfcb6098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358355670-172.17.0.20-1598650011896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-d8dbc551-f5fb-4343-8594-40bf52fa41a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-03c0108d-3529-4968-a0aa-ca4151d540ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-efae4d64-66a9-45a4-9a49-ef840cec3dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-dbc075df-96d8-4e02-aee0-6e3098a5a654,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-01a7f03e-cfbd-431c-a954-afeb483a25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-8ce51617-9702-47ce-98e3-12ed7f846cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-8640b6ac-5881-4869-96c9-d4408cef044b,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-d1ae273d-539c-4720-8736-50f4d3735cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358355670-172.17.0.20-1598650011896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-d8dbc551-f5fb-4343-8594-40bf52fa41a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-03c0108d-3529-4968-a0aa-ca4151d540ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-efae4d64-66a9-45a4-9a49-ef840cec3dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-dbc075df-96d8-4e02-aee0-6e3098a5a654,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-01a7f03e-cfbd-431c-a954-afeb483a25ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-8ce51617-9702-47ce-98e3-12ed7f846cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-8640b6ac-5881-4869-96c9-d4408cef044b,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-d1ae273d-539c-4720-8736-50f4d3735cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478549223-172.17.0.20-1598650305330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-f19b4006-e5b9-4811-a942-57f81be7ac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-43712d5b-fb3e-4f25-a232-bd33fa164099,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-06a17187-77db-42f5-a29a-9fb6a068c323,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-aac43103-ac4a-49bf-bd1a-3c97f4c46abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-1d8e2e4c-8677-4a37-921e-bfb8176e42c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-420b04f6-07eb-427d-84aa-2031a3f97666,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-4dee1dc3-7378-4aa2-9d5f-d7bee580686c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-be73de50-6beb-4146-9c98-091fc6e8ed4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478549223-172.17.0.20-1598650305330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-f19b4006-e5b9-4811-a942-57f81be7ac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-43712d5b-fb3e-4f25-a232-bd33fa164099,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-06a17187-77db-42f5-a29a-9fb6a068c323,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-aac43103-ac4a-49bf-bd1a-3c97f4c46abf,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-1d8e2e4c-8677-4a37-921e-bfb8176e42c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-420b04f6-07eb-427d-84aa-2031a3f97666,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-4dee1dc3-7378-4aa2-9d5f-d7bee580686c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-be73de50-6beb-4146-9c98-091fc6e8ed4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302052984-172.17.0.20-1598650414311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-6afb847e-3b36-4855-8716-6cca6bbb02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-b3821167-a15c-4209-b426-9ef032a3662a,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-44c98bed-2cf2-4481-8887-ec1f2fe16322,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-ee669831-3af1-426b-a4a9-916d20ac3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-577be01c-a028-452e-9890-566ea5144089,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-31d0cc11-d68d-4207-8132-11f6e2ea89d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-ab89dd6e-8b7d-4127-909d-905900ed5221,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4fa09c43-0d7a-4824-b32d-efb4a94c2af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302052984-172.17.0.20-1598650414311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-6afb847e-3b36-4855-8716-6cca6bbb02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-b3821167-a15c-4209-b426-9ef032a3662a,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-44c98bed-2cf2-4481-8887-ec1f2fe16322,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-ee669831-3af1-426b-a4a9-916d20ac3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-577be01c-a028-452e-9890-566ea5144089,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-31d0cc11-d68d-4207-8132-11f6e2ea89d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-ab89dd6e-8b7d-4127-909d-905900ed5221,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4fa09c43-0d7a-4824-b32d-efb4a94c2af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727077394-172.17.0.20-1598650602653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-0af3bc86-54bc-461a-9b03-a9535af0543b,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-680c2129-5f51-4b24-87cc-cbfa737b7e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-9ef10440-be6f-49e8-9441-4c07a193a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-7e94b5ed-bfb0-440d-96e2-010eb84e8dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-c6f6a68e-8f60-49bb-ad31-276bdb1deabb,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-f66a9a76-0f8b-420f-a975-f0e6c07bf560,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-be1666a4-98af-42e7-8a2a-661d499d1a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4bea27b4-cd44-4104-ac0a-071944e1bacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727077394-172.17.0.20-1598650602653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-0af3bc86-54bc-461a-9b03-a9535af0543b,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-680c2129-5f51-4b24-87cc-cbfa737b7e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-9ef10440-be6f-49e8-9441-4c07a193a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-7e94b5ed-bfb0-440d-96e2-010eb84e8dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-c6f6a68e-8f60-49bb-ad31-276bdb1deabb,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-f66a9a76-0f8b-420f-a975-f0e6c07bf560,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-be1666a4-98af-42e7-8a2a-661d499d1a45,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4bea27b4-cd44-4104-ac0a-071944e1bacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888689713-172.17.0.20-1598650898697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-8d652cf5-72f7-43eb-a600-ab06093f40cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a1c4238b-196e-4dca-9fd8-be1ca4166cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-99102c6b-a703-4194-92b5-50c5248164d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-698a39a0-7aa9-42b1-bfb0-991316feface,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6ddcc8ab-0244-470d-926f-56fa30f12ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e0f0128e-627b-4f30-89ea-ffe431ceafe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-e6d7a16d-ad0d-4e99-b39a-4dff474d628c,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-0393b842-08f1-49e6-aec2-6e1c2c03888f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888689713-172.17.0.20-1598650898697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-8d652cf5-72f7-43eb-a600-ab06093f40cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a1c4238b-196e-4dca-9fd8-be1ca4166cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-99102c6b-a703-4194-92b5-50c5248164d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-698a39a0-7aa9-42b1-bfb0-991316feface,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6ddcc8ab-0244-470d-926f-56fa30f12ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e0f0128e-627b-4f30-89ea-ffe431ceafe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-e6d7a16d-ad0d-4e99-b39a-4dff474d628c,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-0393b842-08f1-49e6-aec2-6e1c2c03888f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906425013-172.17.0.20-1598651237948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-1f14a916-157c-4cb9-b30a-22002295033b,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-c3fa081f-2774-4a68-b59a-d5d55ee1d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4f9dba88-e723-443e-a361-701cb583ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-817601b2-39a7-4eca-9f67-b94c072762df,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-388c7f1d-1ed8-44b4-87f9-56e631443bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-39e6ea3e-6b6a-4ac5-8582-00ee48618e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-621dbfd6-57a3-4da9-9100-3be55b699529,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f90fc5f7-35c9-41c5-b9aa-e342c744d32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906425013-172.17.0.20-1598651237948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-1f14a916-157c-4cb9-b30a-22002295033b,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-c3fa081f-2774-4a68-b59a-d5d55ee1d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4f9dba88-e723-443e-a361-701cb583ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-817601b2-39a7-4eca-9f67-b94c072762df,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-388c7f1d-1ed8-44b4-87f9-56e631443bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-39e6ea3e-6b6a-4ac5-8582-00ee48618e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-621dbfd6-57a3-4da9-9100-3be55b699529,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f90fc5f7-35c9-41c5-b9aa-e342c744d32d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337808080-172.17.0.20-1598651284838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-95cd7c4e-a46c-4ccf-8d37-d5967596acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-8fb19caa-7d3c-4ba1-90a2-c37cfebe71ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-f92a3b85-272e-4c19-8c37-525aa50e911c,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-d4da24ff-bb9f-453d-a33d-b7b2fb4d2097,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-48a097b4-be9e-451f-8620-4cb3bc3a70e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-55073397-6eb6-485d-a7bc-7b7fc9af9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-de5f489e-4c4f-4d1b-b774-7d3e61a99748,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-64c4624d-3ff4-4126-9697-45486c42d999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337808080-172.17.0.20-1598651284838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41547,DS-95cd7c4e-a46c-4ccf-8d37-d5967596acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-8fb19caa-7d3c-4ba1-90a2-c37cfebe71ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-f92a3b85-272e-4c19-8c37-525aa50e911c,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-d4da24ff-bb9f-453d-a33d-b7b2fb4d2097,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-48a097b4-be9e-451f-8620-4cb3bc3a70e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-55073397-6eb6-485d-a7bc-7b7fc9af9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-de5f489e-4c4f-4d1b-b774-7d3e61a99748,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-64c4624d-3ff4-4126-9697-45486c42d999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281681915-172.17.0.20-1598651425961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-6af493bd-9983-4de2-b466-ec60d68a40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-05aaecfa-92ef-4b3e-ba6d-1260f5409589,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-155984bf-383a-42b3-b6f8-e80fff187e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-4985f190-0744-4f34-96f2-b437273b5fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-500ac9b2-aa44-4d0d-a7be-6043a37c8b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-b931e4f5-52e6-4d2c-8ea4-c210dff56ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cbff2921-df65-416e-a3da-f5c964c29bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-7ae3ac9e-619a-4088-a970-45320e2df46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281681915-172.17.0.20-1598651425961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-6af493bd-9983-4de2-b466-ec60d68a40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-05aaecfa-92ef-4b3e-ba6d-1260f5409589,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-155984bf-383a-42b3-b6f8-e80fff187e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-4985f190-0744-4f34-96f2-b437273b5fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-500ac9b2-aa44-4d0d-a7be-6043a37c8b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-b931e4f5-52e6-4d2c-8ea4-c210dff56ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cbff2921-df65-416e-a3da-f5c964c29bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-7ae3ac9e-619a-4088-a970-45320e2df46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7028972-172.17.0.20-1598651521312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-dfaab3d4-5c01-4861-9c12-2347e8e52088,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4ea971de-95b7-43f2-9d83-7688a5c6cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-dee254e9-2638-44f5-8ec1-f437e4e513ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-07d4066c-0685-4a8d-87ab-967438a0ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-9d9a6795-8bc1-4056-94ac-429ac3b826a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-353d19a6-ecd0-4a17-959e-ff07cefdf03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-1fb3d302-2a97-4985-8549-b0f72e159b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-e2cdf036-7900-4488-b5f6-38cd1f0cf2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7028972-172.17.0.20-1598651521312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-dfaab3d4-5c01-4861-9c12-2347e8e52088,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-4ea971de-95b7-43f2-9d83-7688a5c6cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-dee254e9-2638-44f5-8ec1-f437e4e513ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-07d4066c-0685-4a8d-87ab-967438a0ec88,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-9d9a6795-8bc1-4056-94ac-429ac3b826a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-353d19a6-ecd0-4a17-959e-ff07cefdf03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-1fb3d302-2a97-4985-8549-b0f72e159b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-e2cdf036-7900-4488-b5f6-38cd1f0cf2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102685404-172.17.0.20-1598651812378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-de2afcbf-e320-4e93-a40d-3bcfd202b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d04e484b-25ea-4269-ad99-a8aaf3406e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-657ce7a7-7321-4ceb-a563-c9a0d86711bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-8d311f21-b5b0-4607-8c61-0f130b65697e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-d9f5f589-a7ac-4f82-9c24-0c5684cfcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-4f4f4157-b0bd-4338-8404-7ac29c615a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-0c8e3401-fe70-44fd-9713-a2c51629aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-f3668fc6-92af-4fd9-8d69-3a10d15a2a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102685404-172.17.0.20-1598651812378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-de2afcbf-e320-4e93-a40d-3bcfd202b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d04e484b-25ea-4269-ad99-a8aaf3406e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-657ce7a7-7321-4ceb-a563-c9a0d86711bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-8d311f21-b5b0-4607-8c61-0f130b65697e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-d9f5f589-a7ac-4f82-9c24-0c5684cfcf48,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-4f4f4157-b0bd-4338-8404-7ac29c615a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-0c8e3401-fe70-44fd-9713-a2c51629aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-f3668fc6-92af-4fd9-8d69-3a10d15a2a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432100617-172.17.0.20-1598652039327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-81ae5829-a735-4bf8-afdf-4307b937fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-bded765e-66af-4492-abc2-24027ff5dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-257d8924-4d2a-4ea6-b743-74749ed38a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-441e23e2-874c-4883-ab82-fa0fb37b3a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a150755e-1497-4056-bb0a-a5013b22e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-34097e7c-4668-4c24-b464-93e796f5b99a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-70bb7d5a-5359-49e2-a355-eff1234bd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-11e71fb9-ec04-4d52-bd20-dcb47028ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432100617-172.17.0.20-1598652039327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-81ae5829-a735-4bf8-afdf-4307b937fe44,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-bded765e-66af-4492-abc2-24027ff5dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-257d8924-4d2a-4ea6-b743-74749ed38a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-441e23e2-874c-4883-ab82-fa0fb37b3a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a150755e-1497-4056-bb0a-a5013b22e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-34097e7c-4668-4c24-b464-93e796f5b99a,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-70bb7d5a-5359-49e2-a355-eff1234bd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-11e71fb9-ec04-4d52-bd20-dcb47028ad5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771789271-172.17.0.20-1598652102562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-d2af4909-5e80-4e18-b918-f5f866cecc98,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-72c14460-cdee-4ddd-886c-1ac59640c575,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-6ce0a743-7b89-4b3c-b83f-16a0c654c072,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-20cf4c87-7442-4418-941a-59c5479afb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-06177e08-ba91-4d6b-ad9f-00f4ba29c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-34e8f083-723f-4ada-83a6-ebac0e8168e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-d5337746-20ec-48b5-8bbd-cf5596b42ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-68fb6a7b-2636-46dc-8e3b-d118dc1c5df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771789271-172.17.0.20-1598652102562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-d2af4909-5e80-4e18-b918-f5f866cecc98,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-72c14460-cdee-4ddd-886c-1ac59640c575,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-6ce0a743-7b89-4b3c-b83f-16a0c654c072,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-20cf4c87-7442-4418-941a-59c5479afb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-06177e08-ba91-4d6b-ad9f-00f4ba29c77a,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-34e8f083-723f-4ada-83a6-ebac0e8168e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-d5337746-20ec-48b5-8bbd-cf5596b42ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-68fb6a7b-2636-46dc-8e3b-d118dc1c5df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759644844-172.17.0.20-1598652496979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37860,DS-995581ad-f9f8-4463-a9c8-b919424eca80,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-a5331217-7564-41ee-a31b-d67a860de126,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-a77cf560-be1a-444d-a3c1-f7da05d0014c,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-8d3f6061-780e-443f-b5bb-6fe77d33239b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-f7cc9f83-c9b1-4dc9-8e7e-87308983929a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ba5c4c7b-285f-4d68-9a6f-ef31db4a8497,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-bc69ddea-7a20-425c-b112-c75ae51dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-4f50e058-da82-4e3f-a2e3-1c7abb0bc69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759644844-172.17.0.20-1598652496979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37860,DS-995581ad-f9f8-4463-a9c8-b919424eca80,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-a5331217-7564-41ee-a31b-d67a860de126,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-a77cf560-be1a-444d-a3c1-f7da05d0014c,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-8d3f6061-780e-443f-b5bb-6fe77d33239b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-f7cc9f83-c9b1-4dc9-8e7e-87308983929a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ba5c4c7b-285f-4d68-9a6f-ef31db4a8497,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-bc69ddea-7a20-425c-b112-c75ae51dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-4f50e058-da82-4e3f-a2e3-1c7abb0bc69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151582011-172.17.0.20-1598652531659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-ab06d285-8795-445c-8008-124a1eeca949,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-8fe5e068-1953-48da-8abd-d59b81f75285,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-a6ac4fea-cd99-4749-a0d0-141c20a80dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-1621f648-1174-4b8b-b25f-aaf60a370303,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-03117c60-55e8-45c3-98ef-d55c37858e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-64abe4c4-761c-476a-89ef-c101ae88aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-674e2ef2-9bf6-4428-9981-cacb6b84e223,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-5fd1ab97-ebbe-4883-8fd4-03cf0c795f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151582011-172.17.0.20-1598652531659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-ab06d285-8795-445c-8008-124a1eeca949,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-8fe5e068-1953-48da-8abd-d59b81f75285,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-a6ac4fea-cd99-4749-a0d0-141c20a80dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-1621f648-1174-4b8b-b25f-aaf60a370303,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-03117c60-55e8-45c3-98ef-d55c37858e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-64abe4c4-761c-476a-89ef-c101ae88aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-674e2ef2-9bf6-4428-9981-cacb6b84e223,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-5fd1ab97-ebbe-4883-8fd4-03cf0c795f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 1
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7115806-172.17.0.20-1598652860533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-db41814c-8f37-4ff1-8375-188af8707eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-e350f958-e67c-4427-84a8-e52cc3e96d25,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d1ef2443-86e3-42f9-9887-5c9a39b2c366,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-22f045ce-efae-4856-aab8-89e47ba6bdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-22daadfa-2a09-40d0-8c72-c996073d5440,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-09cca0c8-8771-4de8-b613-b9af1c6518b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0ad061d1-eef9-49d9-806d-85baed25dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-09238682-1be7-4833-b780-c75490baddc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7115806-172.17.0.20-1598652860533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-db41814c-8f37-4ff1-8375-188af8707eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-e350f958-e67c-4427-84a8-e52cc3e96d25,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-d1ef2443-86e3-42f9-9887-5c9a39b2c366,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-22f045ce-efae-4856-aab8-89e47ba6bdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-22daadfa-2a09-40d0-8c72-c996073d5440,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-09cca0c8-8771-4de8-b613-b9af1c6518b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0ad061d1-eef9-49d9-806d-85baed25dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-09238682-1be7-4833-b780-c75490baddc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5377
