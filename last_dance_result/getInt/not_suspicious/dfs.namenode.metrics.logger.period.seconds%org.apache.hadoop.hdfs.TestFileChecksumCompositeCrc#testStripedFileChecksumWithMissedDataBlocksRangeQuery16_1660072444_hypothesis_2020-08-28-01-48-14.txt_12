reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42788663-172.17.0.8-1598579446745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-f5bf8076-cddc-474d-9e5d-7c1760792c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-14bf6910-179a-4f25-9e18-2cc60ee7e742,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-2376fc87-7174-4e22-a0a9-1c09b19d4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-db3e7d42-4c44-4709-8a60-741e1ccaddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-7e6fb8e6-2aff-44d0-a0e8-c7a0f47e1959,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-2eda5bb6-cf4a-48ec-89e6-0f39845039c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-8c3d4146-6954-41ea-8ea3-fb41ba7b5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-086a7d1a-e8a3-4f2f-bb84-7f46896b0184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42788663-172.17.0.8-1598579446745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42111,DS-f5bf8076-cddc-474d-9e5d-7c1760792c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-14bf6910-179a-4f25-9e18-2cc60ee7e742,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-2376fc87-7174-4e22-a0a9-1c09b19d4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-db3e7d42-4c44-4709-8a60-741e1ccaddc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-7e6fb8e6-2aff-44d0-a0e8-c7a0f47e1959,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-2eda5bb6-cf4a-48ec-89e6-0f39845039c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-8c3d4146-6954-41ea-8ea3-fb41ba7b5ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-086a7d1a-e8a3-4f2f-bb84-7f46896b0184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526329712-172.17.0.8-1598579520897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-e1d009b6-405c-4346-a4a5-78604af1da27,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-d0fb9948-5f6f-4065-82af-149f352166ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-4ccf0253-b330-4986-b9a7-d9fc6b275c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-56b8522f-a88e-42ba-a23e-895fc3da0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-42eb315f-00af-4be0-89ac-f9927f86fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-84de2092-efa1-4189-a248-1ea7ca7aa752,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-ffd57999-a472-45ee-83db-d31bd713a393,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-5f8283c6-aee3-44bd-a9af-4fb88af40b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526329712-172.17.0.8-1598579520897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-e1d009b6-405c-4346-a4a5-78604af1da27,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-d0fb9948-5f6f-4065-82af-149f352166ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-4ccf0253-b330-4986-b9a7-d9fc6b275c87,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-56b8522f-a88e-42ba-a23e-895fc3da0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-42eb315f-00af-4be0-89ac-f9927f86fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-84de2092-efa1-4189-a248-1ea7ca7aa752,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-ffd57999-a472-45ee-83db-d31bd713a393,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-5f8283c6-aee3-44bd-a9af-4fb88af40b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074325724-172.17.0.8-1598580179173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-79bcbcf3-57fb-4799-b2bf-b382efdaf5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-359aebed-a7bf-43cc-8465-83359ac45497,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-03ec626c-48e2-4d21-a80c-d93dccb19044,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7febabec-dd35-479d-97bb-7f8c30a80362,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-7e1cbd1c-860f-4870-9214-f8791df26ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-22d2fa47-dcf2-4a5a-ba23-70b3dbdc6fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-545efa82-b647-4197-ad38-f3e194f0b425,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-42027d6d-7094-4dec-be5c-bc71dbce08e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074325724-172.17.0.8-1598580179173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-79bcbcf3-57fb-4799-b2bf-b382efdaf5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-359aebed-a7bf-43cc-8465-83359ac45497,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-03ec626c-48e2-4d21-a80c-d93dccb19044,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7febabec-dd35-479d-97bb-7f8c30a80362,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-7e1cbd1c-860f-4870-9214-f8791df26ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-22d2fa47-dcf2-4a5a-ba23-70b3dbdc6fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-545efa82-b647-4197-ad38-f3e194f0b425,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-42027d6d-7094-4dec-be5c-bc71dbce08e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578786631-172.17.0.8-1598581087587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-0cbf11dd-767f-4efa-8eba-13f0440a3ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c155969c-3d14-42a3-93b7-c9f962a52166,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6e7ff5f1-39bf-4d4d-a05b-0af99ae46bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-1217e97a-489b-4402-a3e0-fe2e78df3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-c2190a69-12d2-4401-8178-3529d13ad84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-1ae916b5-2bac-46b6-8702-070cb0725cee,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-2fc09bc2-6db7-4d2b-a5d6-4f37fd0e1e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3d994f6b-85fd-4ddf-9d45-ce9ccbca5c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578786631-172.17.0.8-1598581087587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-0cbf11dd-767f-4efa-8eba-13f0440a3ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c155969c-3d14-42a3-93b7-c9f962a52166,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-6e7ff5f1-39bf-4d4d-a05b-0af99ae46bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-1217e97a-489b-4402-a3e0-fe2e78df3fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-c2190a69-12d2-4401-8178-3529d13ad84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-1ae916b5-2bac-46b6-8702-070cb0725cee,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-2fc09bc2-6db7-4d2b-a5d6-4f37fd0e1e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3d994f6b-85fd-4ddf-9d45-ce9ccbca5c66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811125775-172.17.0.8-1598581131577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-d3965bfc-355a-4c37-89d3-8994cb825119,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-d6bef398-d1e8-441b-832c-befa4f2afc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-3315348f-c8e3-47af-8300-702fb88be8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a72bebf1-ea64-4431-ac63-2769c20ba58f,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-da1f7c6c-379e-4d16-a489-de2d5b438b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-ea3f5752-6b45-4a26-9991-7dea65fa8b11,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-3d1c3621-52d5-46c3-bacf-a6bcaeb414cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-8ed86b48-8182-4f79-8f3f-3275f1463ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811125775-172.17.0.8-1598581131577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-d3965bfc-355a-4c37-89d3-8994cb825119,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-d6bef398-d1e8-441b-832c-befa4f2afc23,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-3315348f-c8e3-47af-8300-702fb88be8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a72bebf1-ea64-4431-ac63-2769c20ba58f,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-da1f7c6c-379e-4d16-a489-de2d5b438b80,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-ea3f5752-6b45-4a26-9991-7dea65fa8b11,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-3d1c3621-52d5-46c3-bacf-a6bcaeb414cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-8ed86b48-8182-4f79-8f3f-3275f1463ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16858047-172.17.0.8-1598581175036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-0c273684-9efa-4059-9ddd-90d510c87f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-afd4df6c-0042-4274-ba81-bef037c067a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c3494425-e5ae-4f76-b5cd-42c875fef672,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-3070a581-99dd-46d5-b59b-d5306f5084c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-5125dd72-b309-42e3-9102-70db3ff162bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-d06b71e8-f799-4f41-a473-a37fbb12e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-57568062-73ed-40bf-be32-f29318e7d7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-e2300f8f-c0ef-4117-969b-272583b37dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16858047-172.17.0.8-1598581175036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-0c273684-9efa-4059-9ddd-90d510c87f08,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-afd4df6c-0042-4274-ba81-bef037c067a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c3494425-e5ae-4f76-b5cd-42c875fef672,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-3070a581-99dd-46d5-b59b-d5306f5084c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-5125dd72-b309-42e3-9102-70db3ff162bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-d06b71e8-f799-4f41-a473-a37fbb12e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-57568062-73ed-40bf-be32-f29318e7d7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-e2300f8f-c0ef-4117-969b-272583b37dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771333482-172.17.0.8-1598581281100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-87fba6f1-353c-4de6-84f2-bd60a4c49c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-5760a473-0296-4302-9b23-7d8aea4cbbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-9da04696-b610-4367-9390-23c04266df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-5c937580-0516-4f84-90f7-6a419c88cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-1526ac47-7875-44f0-adb4-b108ff4c32b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-006852f6-06e0-4aae-84a0-9390eac1f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-3208e7db-3502-45c0-843a-167133bf8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-e8e1fa5c-db0a-4858-8b43-6d4294b94b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771333482-172.17.0.8-1598581281100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37374,DS-87fba6f1-353c-4de6-84f2-bd60a4c49c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-5760a473-0296-4302-9b23-7d8aea4cbbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-9da04696-b610-4367-9390-23c04266df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-5c937580-0516-4f84-90f7-6a419c88cf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-1526ac47-7875-44f0-adb4-b108ff4c32b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-006852f6-06e0-4aae-84a0-9390eac1f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-3208e7db-3502-45c0-843a-167133bf8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-e8e1fa5c-db0a-4858-8b43-6d4294b94b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454885073-172.17.0.8-1598581659916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-79671d83-235f-42a3-9cd6-42c7e584ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-00dae659-1729-4c8b-aa3f-09df79ec8b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9a7f6448-47a4-46da-9bd6-33d235961b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-fd9e9d2a-e611-4ec5-95d1-05f0930fef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-0f87193b-a8c1-418f-825e-2bb2dc546a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-dc71f6b2-f089-457f-b2fb-c11081f674ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-14573a4c-73ac-4190-a45e-f3e359b93792,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-658e8826-c1fa-4fd2-883f-76b3ced9fd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454885073-172.17.0.8-1598581659916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-79671d83-235f-42a3-9cd6-42c7e584ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-00dae659-1729-4c8b-aa3f-09df79ec8b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-9a7f6448-47a4-46da-9bd6-33d235961b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-fd9e9d2a-e611-4ec5-95d1-05f0930fef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-0f87193b-a8c1-418f-825e-2bb2dc546a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-dc71f6b2-f089-457f-b2fb-c11081f674ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-14573a4c-73ac-4190-a45e-f3e359b93792,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-658e8826-c1fa-4fd2-883f-76b3ced9fd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164060150-172.17.0.8-1598581965320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-a715950a-670f-4c33-9646-6351d8232445,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-81861a97-edbd-4408-a5ed-6e3a20d658e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-b1cc257d-86cb-4fc1-9c05-7d32039b6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-fd9476e4-a473-4a75-932a-54d54c610432,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-feb7f0c7-ff53-41d4-97fe-e6ebf54ee288,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-b6b4ff16-2df6-4a09-87ac-66d0ec39f145,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-16b43a11-2632-4bab-aa9b-102ad27c1197,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2f3bc1b5-e02f-451a-bcb3-f3cd9e0e15f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164060150-172.17.0.8-1598581965320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-a715950a-670f-4c33-9646-6351d8232445,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-81861a97-edbd-4408-a5ed-6e3a20d658e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-b1cc257d-86cb-4fc1-9c05-7d32039b6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-fd9476e4-a473-4a75-932a-54d54c610432,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-feb7f0c7-ff53-41d4-97fe-e6ebf54ee288,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-b6b4ff16-2df6-4a09-87ac-66d0ec39f145,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-16b43a11-2632-4bab-aa9b-102ad27c1197,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-2f3bc1b5-e02f-451a-bcb3-f3cd9e0e15f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853055052-172.17.0.8-1598582003723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-f0bb1fb7-957a-419b-9bd1-dcec14be6f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-06588173-fff9-4c0c-8445-946db4db09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-7ea2048a-e02c-4890-bf6a-8f119312ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-7060e2c6-d218-48af-bea2-62a4699820c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-9d1d51b2-e287-4cba-a460-44b79f069a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-4f290c7d-ed57-4cfd-bdd7-14ef9dd989bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-6eba2a64-7943-4f22-a161-3498e47b97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-e099867d-a5f9-406c-a72b-3cc71c0cd2d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853055052-172.17.0.8-1598582003723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-f0bb1fb7-957a-419b-9bd1-dcec14be6f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-06588173-fff9-4c0c-8445-946db4db09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-7ea2048a-e02c-4890-bf6a-8f119312ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-7060e2c6-d218-48af-bea2-62a4699820c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-9d1d51b2-e287-4cba-a460-44b79f069a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-4f290c7d-ed57-4cfd-bdd7-14ef9dd989bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-6eba2a64-7943-4f22-a161-3498e47b97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-e099867d-a5f9-406c-a72b-3cc71c0cd2d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571336251-172.17.0.8-1598582082019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42342,DS-c6aa3b49-9ed6-44db-b75c-05c4f8f2f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-4e53b15e-f226-4227-8e2a-e63ef03e2cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a27f211d-0713-4b84-83d9-b50838236023,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-d24f38e2-53bb-49a7-b9f9-3707f82d85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-329997de-d407-41ce-a34a-d60ce0a008cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-a03db4b5-d929-4260-8b71-82f3d9ef3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-5a651b12-6297-41d5-8ed8-97b45cc5ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-a1ecdafd-726d-46cc-9f79-90253e77fca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571336251-172.17.0.8-1598582082019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42342,DS-c6aa3b49-9ed6-44db-b75c-05c4f8f2f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-4e53b15e-f226-4227-8e2a-e63ef03e2cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a27f211d-0713-4b84-83d9-b50838236023,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-d24f38e2-53bb-49a7-b9f9-3707f82d85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-329997de-d407-41ce-a34a-d60ce0a008cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-a03db4b5-d929-4260-8b71-82f3d9ef3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-5a651b12-6297-41d5-8ed8-97b45cc5ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-a1ecdafd-726d-46cc-9f79-90253e77fca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915660564-172.17.0.8-1598582199348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-ef8c3de4-382c-45e7-8a73-59d4b094bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0942845f-12e6-4adb-bfd5-6f289ca8d256,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-6eca4ef4-ff39-4fae-86c0-b57643507665,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-e128d2b5-633e-4882-a1d2-35a792a9428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-3fdf9f7b-92f0-404e-b3e4-0b5e27876ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e0e19e2e-3b19-49d7-88a9-9728a66b2c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-49c41ac6-40b9-4ee9-8d90-be0b66359e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-1ae6260f-018e-4ced-82ab-c42d0d4d8f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915660564-172.17.0.8-1598582199348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-ef8c3de4-382c-45e7-8a73-59d4b094bfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0942845f-12e6-4adb-bfd5-6f289ca8d256,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-6eca4ef4-ff39-4fae-86c0-b57643507665,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-e128d2b5-633e-4882-a1d2-35a792a9428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-3fdf9f7b-92f0-404e-b3e4-0b5e27876ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e0e19e2e-3b19-49d7-88a9-9728a66b2c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-49c41ac6-40b9-4ee9-8d90-be0b66359e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-1ae6260f-018e-4ced-82ab-c42d0d4d8f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760442986-172.17.0.8-1598582282352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-38b7678f-d745-4f2c-a4d6-0cfdb9cab31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-52c3b2af-5d51-4d71-9012-6a762ddcfee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-10781537-e182-420a-bba1-2758659b0669,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-1b8d3146-abe7-4b15-ae0f-225dd21a2f46,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-1ff60153-aade-4eeb-8aea-d9644018d079,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7f195e95-488e-417e-bfe1-37ee6a0a4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-09ea30a9-0824-4187-b3b0-b70c806d07aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-a7c5cb36-5783-43e2-ae8d-1faff43505ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760442986-172.17.0.8-1598582282352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-38b7678f-d745-4f2c-a4d6-0cfdb9cab31c,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-52c3b2af-5d51-4d71-9012-6a762ddcfee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-10781537-e182-420a-bba1-2758659b0669,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-1b8d3146-abe7-4b15-ae0f-225dd21a2f46,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-1ff60153-aade-4eeb-8aea-d9644018d079,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7f195e95-488e-417e-bfe1-37ee6a0a4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-09ea30a9-0824-4187-b3b0-b70c806d07aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-a7c5cb36-5783-43e2-ae8d-1faff43505ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325933315-172.17.0.8-1598582438678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35103,DS-c6dacd27-28f2-46d0-8373-d7add9e29279,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-68c1fd7a-6327-46b4-824f-8da9fb453472,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c31b0cf8-a608-46c2-8b4d-ac97ae74e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-bf1979bd-49ab-4c63-9482-d800e849a080,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-b946875c-96db-4d75-84fe-91fb1586e830,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1eadaa76-0ebe-4687-a1a1-1ddb2c131b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-f55ac775-e2ce-4d8b-bb00-ebe2a26c44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-2e8414a3-aa69-4fb6-ab35-04cb87453c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325933315-172.17.0.8-1598582438678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35103,DS-c6dacd27-28f2-46d0-8373-d7add9e29279,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-68c1fd7a-6327-46b4-824f-8da9fb453472,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c31b0cf8-a608-46c2-8b4d-ac97ae74e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-bf1979bd-49ab-4c63-9482-d800e849a080,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-b946875c-96db-4d75-84fe-91fb1586e830,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-1eadaa76-0ebe-4687-a1a1-1ddb2c131b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-f55ac775-e2ce-4d8b-bb00-ebe2a26c44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-2e8414a3-aa69-4fb6-ab35-04cb87453c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417372420-172.17.0.8-1598583177308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-00b47f33-9a08-471c-aae5-02944af80034,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0de5f013-fa9a-4c79-a6dc-765140f39d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4de75d27-c1ea-4c7b-a261-b52c25705b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-020d2cc5-925b-4b59-89e3-0d947da3fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-56cc086c-3d1c-4048-bef1-b8c4ea2f251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-cb44b47a-32b3-4ad8-9b43-bca334bb1181,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-59a37d48-e089-4345-b0ab-ed6906efb459,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-3e0bcd45-bab2-41cc-a7f8-1fc3329d7254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417372420-172.17.0.8-1598583177308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-00b47f33-9a08-471c-aae5-02944af80034,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0de5f013-fa9a-4c79-a6dc-765140f39d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4de75d27-c1ea-4c7b-a261-b52c25705b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-020d2cc5-925b-4b59-89e3-0d947da3fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-56cc086c-3d1c-4048-bef1-b8c4ea2f251a,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-cb44b47a-32b3-4ad8-9b43-bca334bb1181,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-59a37d48-e089-4345-b0ab-ed6906efb459,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-3e0bcd45-bab2-41cc-a7f8-1fc3329d7254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687858148-172.17.0.8-1598583514457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-7304234a-977b-4253-aeef-09a0b5de7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-4d12bf3f-bc80-4631-91f6-41de8641959a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-b7e874f1-c0a6-4eab-b632-27a152b93785,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-edb3e245-ecdf-45a7-b222-3cbd1f2671e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-314c2b82-d66c-4d63-beb5-dd795036493a,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-f4df41c1-ef67-477e-b66c-91a1f15b50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-62f26f74-1e2a-4c45-adcd-10eca57532ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-0bf3590b-ef42-4245-9856-31ed376f7811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687858148-172.17.0.8-1598583514457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-7304234a-977b-4253-aeef-09a0b5de7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-4d12bf3f-bc80-4631-91f6-41de8641959a,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-b7e874f1-c0a6-4eab-b632-27a152b93785,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-edb3e245-ecdf-45a7-b222-3cbd1f2671e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-314c2b82-d66c-4d63-beb5-dd795036493a,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-f4df41c1-ef67-477e-b66c-91a1f15b50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-62f26f74-1e2a-4c45-adcd-10eca57532ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-0bf3590b-ef42-4245-9856-31ed376f7811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400659372-172.17.0.8-1598583934409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-fb43fc04-5980-497c-a768-0ff37b768931,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-071958c7-1b7d-4e95-bf46-81499a8c4e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-837ab9fc-cc08-4556-9751-c58987df4c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-dccad538-b0f2-4f52-a835-6b812d65f6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-8c1a7d23-f50f-45c3-907f-fe5b31a549b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-1bc589ef-948f-4f3d-bce7-6de38fa5cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-86994b45-cd2d-4ec6-b305-229bd37bd91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-73a2f1d1-fe26-465f-9c01-68ed0d59878a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400659372-172.17.0.8-1598583934409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46016,DS-fb43fc04-5980-497c-a768-0ff37b768931,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-071958c7-1b7d-4e95-bf46-81499a8c4e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-837ab9fc-cc08-4556-9751-c58987df4c27,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-dccad538-b0f2-4f52-a835-6b812d65f6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-8c1a7d23-f50f-45c3-907f-fe5b31a549b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-1bc589ef-948f-4f3d-bce7-6de38fa5cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-86994b45-cd2d-4ec6-b305-229bd37bd91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-73a2f1d1-fe26-465f-9c01-68ed0d59878a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76347516-172.17.0.8-1598584426116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-21784463-c7c4-467e-8f75-3f6a3cece198,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e5d79a49-a36a-4175-a09a-8101e0fbe596,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-c96ddbc5-be67-4479-aa58-056783f22504,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-ab130760-e08f-4752-96d0-d522a912f378,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-65e4a2af-d0c9-4361-b093-3ae6f85cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-ba7ceded-6857-49fb-8429-2ee636c99ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-fbcce160-b331-4e87-83bf-2bbb33c5bfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-12c1b8d2-a09b-4df9-8150-58c9c5165e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76347516-172.17.0.8-1598584426116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-21784463-c7c4-467e-8f75-3f6a3cece198,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-e5d79a49-a36a-4175-a09a-8101e0fbe596,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-c96ddbc5-be67-4479-aa58-056783f22504,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-ab130760-e08f-4752-96d0-d522a912f378,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-65e4a2af-d0c9-4361-b093-3ae6f85cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-ba7ceded-6857-49fb-8429-2ee636c99ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-fbcce160-b331-4e87-83bf-2bbb33c5bfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-12c1b8d2-a09b-4df9-8150-58c9c5165e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5537
