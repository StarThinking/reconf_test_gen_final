reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171887599-172.17.0.11-1598675428397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44571,DS-e259b002-ebb7-498c-bd60-5b1f834d81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b0fcfd3f-3ea5-4d4a-b81a-f64c0d9519f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-5ae5b54a-2d42-42d7-ae75-56d4d7c2643b,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-de9d6313-2169-4072-848b-afcfa8328358,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-e4c8a7fd-6845-4e62-a4f4-390a25f4ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-9213eb66-2e4c-4570-bcae-92cf0a8a9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-3e7acafd-ab46-4f12-bfb0-dfb6f5666951,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-dc1b8681-d664-4c51-a91f-27af986ba3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171887599-172.17.0.11-1598675428397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44571,DS-e259b002-ebb7-498c-bd60-5b1f834d81ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-b0fcfd3f-3ea5-4d4a-b81a-f64c0d9519f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-5ae5b54a-2d42-42d7-ae75-56d4d7c2643b,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-de9d6313-2169-4072-848b-afcfa8328358,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-e4c8a7fd-6845-4e62-a4f4-390a25f4ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-9213eb66-2e4c-4570-bcae-92cf0a8a9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-3e7acafd-ab46-4f12-bfb0-dfb6f5666951,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-dc1b8681-d664-4c51-a91f-27af986ba3a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248780700-172.17.0.11-1598675469695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-5b37eb61-15f4-4811-b738-ea31bb55c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-c4e26798-634c-4984-94ba-5b5146b3d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-020d0ad0-79a6-471b-ba6b-83790fc3a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-d37a7dae-6531-4062-9245-e8aa80090a05,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-484e0b94-da97-4500-ab2b-ff33ee283175,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c2e42086-bb55-4d9a-b1c1-87c32d037de8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-b477f4ad-9060-471c-9567-8ff44520e1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-d1e56155-5b91-4576-8219-872dd696e5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248780700-172.17.0.11-1598675469695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-5b37eb61-15f4-4811-b738-ea31bb55c27c,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-c4e26798-634c-4984-94ba-5b5146b3d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-020d0ad0-79a6-471b-ba6b-83790fc3a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-d37a7dae-6531-4062-9245-e8aa80090a05,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-484e0b94-da97-4500-ab2b-ff33ee283175,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-c2e42086-bb55-4d9a-b1c1-87c32d037de8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-b477f4ad-9060-471c-9567-8ff44520e1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-d1e56155-5b91-4576-8219-872dd696e5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239620254-172.17.0.11-1598675649381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-47d8a130-3d6f-428a-8149-80dc2ead7191,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-d78c3ddc-586d-4de8-b678-34405fe34fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c07f8e18-5720-4caa-9608-0363fba987d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-a1d45b19-ade0-4168-96c8-f2e6256079ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-666f5a91-e9cb-44c7-bc49-8423d3751718,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-2caf84b6-af67-403f-a893-1a5ef126a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-5d24aa59-8ec0-44c1-9d28-3b5ad850ca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-bf61a242-c91d-430d-b295-896964f8c6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239620254-172.17.0.11-1598675649381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-47d8a130-3d6f-428a-8149-80dc2ead7191,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-d78c3ddc-586d-4de8-b678-34405fe34fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c07f8e18-5720-4caa-9608-0363fba987d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-a1d45b19-ade0-4168-96c8-f2e6256079ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-666f5a91-e9cb-44c7-bc49-8423d3751718,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-2caf84b6-af67-403f-a893-1a5ef126a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-5d24aa59-8ec0-44c1-9d28-3b5ad850ca4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-bf61a242-c91d-430d-b295-896964f8c6c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648658700-172.17.0.11-1598675823618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-b903a4b5-a518-4a0c-a572-4d5375dc2476,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-f5a7beb6-0ad3-4be7-a07f-4b8cf913f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c42ab4ed-5e4f-4727-954f-9bf8bf270fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-4ae823f8-38fe-4482-ad23-33bf43f05b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-5e10cbc8-7692-4f6c-9219-65b9eb547b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-2f61a4e9-a8e2-4e5e-b084-c147963a902f,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-aabb3f8c-4f29-4c42-bba8-573e38cec497,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-7ad491dd-eeed-4943-b6c1-2b07dd7fe9b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648658700-172.17.0.11-1598675823618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-b903a4b5-a518-4a0c-a572-4d5375dc2476,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-f5a7beb6-0ad3-4be7-a07f-4b8cf913f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c42ab4ed-5e4f-4727-954f-9bf8bf270fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-4ae823f8-38fe-4482-ad23-33bf43f05b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-5e10cbc8-7692-4f6c-9219-65b9eb547b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-2f61a4e9-a8e2-4e5e-b084-c147963a902f,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-aabb3f8c-4f29-4c42-bba8-573e38cec497,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-7ad491dd-eeed-4943-b6c1-2b07dd7fe9b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297497970-172.17.0.11-1598676183599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-17baf469-c41a-4920-a731-cf9cda6e1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-fd474955-3cb2-40a5-8b85-79f837b496d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-10765119-9ad8-43f3-a1a2-3e5c0a5a6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-b7528d04-29a5-4176-9e0d-76504bf470ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5d4329b5-f3eb-426e-aed5-174b7e3e1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a77aa8d3-e754-4f1a-862f-afb4dbfc8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-fcc164a3-7349-4ebf-bd70-442276a793c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-469ece83-5792-49e2-b141-1b1b3ea08349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297497970-172.17.0.11-1598676183599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33602,DS-17baf469-c41a-4920-a731-cf9cda6e1f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-fd474955-3cb2-40a5-8b85-79f837b496d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-10765119-9ad8-43f3-a1a2-3e5c0a5a6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-b7528d04-29a5-4176-9e0d-76504bf470ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5d4329b5-f3eb-426e-aed5-174b7e3e1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-a77aa8d3-e754-4f1a-862f-afb4dbfc8a03,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-fcc164a3-7349-4ebf-bd70-442276a793c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-469ece83-5792-49e2-b141-1b1b3ea08349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666594122-172.17.0.11-1598676875993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33141,DS-c04f112f-3423-4304-854b-c6394faf63d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-6d64bf2e-5b67-4601-a919-51db46ad5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2174bb48-3480-4614-abc1-36d19bbfe39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ee6a96da-8985-4d88-a92d-4cf7272dde60,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-a7013263-45dc-493b-a664-5660fb49f18a,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-8e511ed1-2f3f-4805-899b-94b94610c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-a368351d-0f73-4319-ac1b-3cc121b2f413,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-cf8bd2e4-7cc7-4c53-b54b-77546e09068e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666594122-172.17.0.11-1598676875993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33141,DS-c04f112f-3423-4304-854b-c6394faf63d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-6d64bf2e-5b67-4601-a919-51db46ad5b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-2174bb48-3480-4614-abc1-36d19bbfe39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ee6a96da-8985-4d88-a92d-4cf7272dde60,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-a7013263-45dc-493b-a664-5660fb49f18a,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-8e511ed1-2f3f-4805-899b-94b94610c4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-a368351d-0f73-4319-ac1b-3cc121b2f413,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-cf8bd2e4-7cc7-4c53-b54b-77546e09068e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452202154-172.17.0.11-1598676944477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42799,DS-337b8bd9-37de-4488-a655-bd980e45e415,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-dcf04119-25db-45f5-b619-6c5a8e7d0eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-ab18ad7d-9569-407b-bddb-498329a43acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-86e442a0-bcc3-4ad8-81c1-b48b33b87932,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-6834549b-d28a-4d03-9346-8932cea483fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-a33c5b53-c318-4d3b-b3f5-055964be28e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d554911b-c9c0-42b2-b7c6-7aecd3972af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-dd0abf3a-b722-4008-8e31-c33cbb8ab4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452202154-172.17.0.11-1598676944477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42799,DS-337b8bd9-37de-4488-a655-bd980e45e415,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-dcf04119-25db-45f5-b619-6c5a8e7d0eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-ab18ad7d-9569-407b-bddb-498329a43acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-86e442a0-bcc3-4ad8-81c1-b48b33b87932,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-6834549b-d28a-4d03-9346-8932cea483fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-a33c5b53-c318-4d3b-b3f5-055964be28e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-d554911b-c9c0-42b2-b7c6-7aecd3972af2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-dd0abf3a-b722-4008-8e31-c33cbb8ab4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578957278-172.17.0.11-1598677602399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-1e0bcb75-7492-4d4c-9a94-1fd26e7b5aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-eaa5639f-33dd-4418-99c1-4e6819f1ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-0904131b-8837-423a-93a7-2f6fc2dc0258,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-f6ce5a9d-eb3b-4294-b15b-587fc7190d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-da90150d-48c2-49c2-a1eb-0ddb30ca6340,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-b3b5ff3e-6ec0-4b9c-a346-d1a606c2278d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-044d90e4-e0de-4360-a687-978c6206b883,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-3b2ddecb-9321-4a5d-bcc6-20d468b9e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578957278-172.17.0.11-1598677602399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-1e0bcb75-7492-4d4c-9a94-1fd26e7b5aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-eaa5639f-33dd-4418-99c1-4e6819f1ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-0904131b-8837-423a-93a7-2f6fc2dc0258,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-f6ce5a9d-eb3b-4294-b15b-587fc7190d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-da90150d-48c2-49c2-a1eb-0ddb30ca6340,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-b3b5ff3e-6ec0-4b9c-a346-d1a606c2278d,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-044d90e4-e0de-4360-a687-978c6206b883,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-3b2ddecb-9321-4a5d-bcc6-20d468b9e5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785130728-172.17.0.11-1598677635107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-26eb840f-8a70-4463-ad5f-bb20a6228d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-8cc1129a-099e-4e5d-af7c-d60742b509a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-53c1d758-b608-46f6-973a-88a7c7f123c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-febc727b-1401-468d-9fb9-904873ae38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-24449032-9bc5-47e2-b94e-73412a920c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5635d0f1-ad16-48e3-b39e-9c9c44ca19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-812ec0ea-c045-4b4c-8ac8-26f45c2d5080,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-b8308889-34de-4688-99be-3a66b12b98b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785130728-172.17.0.11-1598677635107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37628,DS-26eb840f-8a70-4463-ad5f-bb20a6228d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-8cc1129a-099e-4e5d-af7c-d60742b509a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-53c1d758-b608-46f6-973a-88a7c7f123c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-febc727b-1401-468d-9fb9-904873ae38e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-24449032-9bc5-47e2-b94e-73412a920c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5635d0f1-ad16-48e3-b39e-9c9c44ca19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-812ec0ea-c045-4b4c-8ac8-26f45c2d5080,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-b8308889-34de-4688-99be-3a66b12b98b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415019630-172.17.0.11-1598677888759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-2f5ea430-5df8-465c-bfe1-15769cbd91df,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-ea3bb6a5-95b9-4f79-8d78-c0ffa123b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-0b08bfca-576d-4799-9f37-e4abbff6a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-9172a911-eae1-4939-89d3-1d184af3d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-84c1f23f-ddd0-43c1-9608-2fa84f8f4fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-c641472e-d3c1-4867-a0cb-277030f70a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-58ab1ffe-01e8-4771-a04e-4a4dbaffac61,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-56e8f596-1eb1-435a-ba57-21e9a93f4b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415019630-172.17.0.11-1598677888759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-2f5ea430-5df8-465c-bfe1-15769cbd91df,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-ea3bb6a5-95b9-4f79-8d78-c0ffa123b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-0b08bfca-576d-4799-9f37-e4abbff6a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-9172a911-eae1-4939-89d3-1d184af3d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-84c1f23f-ddd0-43c1-9608-2fa84f8f4fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-c641472e-d3c1-4867-a0cb-277030f70a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-58ab1ffe-01e8-4771-a04e-4a4dbaffac61,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-56e8f596-1eb1-435a-ba57-21e9a93f4b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642037256-172.17.0.11-1598678023316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46593,DS-257dde82-4030-4a45-a0ae-731d3b9d3c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-0d06d6e1-84d2-4ea4-9dce-7c6ea30591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-5c9be213-0f38-4025-a703-60197fabea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-68f91d03-679f-4380-b527-f5cb7eeff1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-aa2c891f-e4e5-4721-b797-9ed29bf68cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-f2a3bb59-9b4d-41a4-8401-3fae4bd9c324,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-778b42cd-e963-4545-a1f3-1926bb93d06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-abbffe0d-dea5-4a0a-a6c9-9988e5656fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642037256-172.17.0.11-1598678023316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46593,DS-257dde82-4030-4a45-a0ae-731d3b9d3c14,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-0d06d6e1-84d2-4ea4-9dce-7c6ea30591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-5c9be213-0f38-4025-a703-60197fabea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-68f91d03-679f-4380-b527-f5cb7eeff1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-aa2c891f-e4e5-4721-b797-9ed29bf68cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-f2a3bb59-9b4d-41a4-8401-3fae4bd9c324,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-778b42cd-e963-4545-a1f3-1926bb93d06d,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-abbffe0d-dea5-4a0a-a6c9-9988e5656fb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529999006-172.17.0.11-1598678137851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-47f30884-350d-4393-90d8-0eb244261770,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-55147a74-c629-4936-b581-13f3c90c98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-f4c1f81d-7a35-4f2d-bc45-730c0a128fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-109221fd-1f24-4063-95d1-e18f7d26331e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-93d7eb7a-6589-4570-9d25-4662716b6ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-43fc8e62-9c3e-4764-9d20-06841115e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-8ca11d17-a516-4045-879a-f551321c14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-0ca252b9-149e-489b-8a8f-52c05b9f5e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529999006-172.17.0.11-1598678137851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-47f30884-350d-4393-90d8-0eb244261770,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-55147a74-c629-4936-b581-13f3c90c98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-f4c1f81d-7a35-4f2d-bc45-730c0a128fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-109221fd-1f24-4063-95d1-e18f7d26331e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-93d7eb7a-6589-4570-9d25-4662716b6ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-43fc8e62-9c3e-4764-9d20-06841115e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-8ca11d17-a516-4045-879a-f551321c14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-0ca252b9-149e-489b-8a8f-52c05b9f5e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169723755-172.17.0.11-1598678209466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-9794d037-7d51-4adc-bdf2-70037b7a1010,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-6f1d6146-706a-45c0-950b-8d20ea7f6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7d4063d3-f842-4f02-b95c-e37eef0b2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-730fc823-55ea-4209-9838-8312c17af07f,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-18e43bdd-2a1a-4bb1-a154-74501534e581,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-42a82569-91be-4601-97e3-e764ede8080e,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-b3498e17-6ba9-4dc2-b9fa-7606d9c9e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-4980f8e6-b09f-490e-b5c5-3adf647a599e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169723755-172.17.0.11-1598678209466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-9794d037-7d51-4adc-bdf2-70037b7a1010,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-6f1d6146-706a-45c0-950b-8d20ea7f6d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-7d4063d3-f842-4f02-b95c-e37eef0b2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-730fc823-55ea-4209-9838-8312c17af07f,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-18e43bdd-2a1a-4bb1-a154-74501534e581,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-42a82569-91be-4601-97e3-e764ede8080e,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-b3498e17-6ba9-4dc2-b9fa-7606d9c9e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-4980f8e6-b09f-490e-b5c5-3adf647a599e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821728114-172.17.0.11-1598678252247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-69ce802e-c951-450f-888b-d57f33bd1015,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-a28b7255-b1b6-483e-8124-a9d5d330ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-92cec3ff-3d7f-4067-8822-e7898623c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-fe661762-95d1-47e6-8be8-4427d890c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-0672c86e-c5f7-4d80-b7b4-891372cc1dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-1caed882-0e4c-4ba1-b80d-1369fa309b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-fd009f68-9a20-4462-be1d-e54f0f19d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e7de3d90-a118-4d76-937d-d281b75892b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821728114-172.17.0.11-1598678252247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-69ce802e-c951-450f-888b-d57f33bd1015,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-a28b7255-b1b6-483e-8124-a9d5d330ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-92cec3ff-3d7f-4067-8822-e7898623c03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-fe661762-95d1-47e6-8be8-4427d890c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-0672c86e-c5f7-4d80-b7b4-891372cc1dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-1caed882-0e4c-4ba1-b80d-1369fa309b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-fd009f68-9a20-4462-be1d-e54f0f19d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e7de3d90-a118-4d76-937d-d281b75892b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404161728-172.17.0.11-1598678663025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-90e39552-a4fb-4617-9a90-fadda7ec85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-499d5c90-11c2-49c2-b691-483f55ec9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-2a36c3c4-4fc9-4938-855d-19481cef7716,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-e7109083-9ba0-4241-b96d-5b89d85a7b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-daeb6849-5855-47d9-b426-0bd5ed464ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-1bcd395f-bce9-4fe3-b420-0a5ea9a71c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-0e45d554-2c83-477c-9c4e-6eb57538d163,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1d36c481-bb7d-421b-966f-f76cfdc74477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404161728-172.17.0.11-1598678663025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-90e39552-a4fb-4617-9a90-fadda7ec85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-499d5c90-11c2-49c2-b691-483f55ec9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-2a36c3c4-4fc9-4938-855d-19481cef7716,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-e7109083-9ba0-4241-b96d-5b89d85a7b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-daeb6849-5855-47d9-b426-0bd5ed464ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-1bcd395f-bce9-4fe3-b420-0a5ea9a71c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-0e45d554-2c83-477c-9c4e-6eb57538d163,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-1d36c481-bb7d-421b-966f-f76cfdc74477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730315084-172.17.0.11-1598679155345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-18601ad4-6616-419f-bce6-44c58fa52b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-168eec1a-24b6-4e03-92e1-71da8e876abf,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4ea148eb-2794-4473-adbd-4b1748ee3da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-69ac26dd-59c9-4cac-bc7e-bab0fbdba600,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-155a16a6-c661-4d6b-91c1-9767ddcf476a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-780773a4-009d-4590-8979-060a5662a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-229fd0cb-a59f-4539-b76a-c45bb8223961,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-ac802668-860c-4066-aae9-738434c6c958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730315084-172.17.0.11-1598679155345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-18601ad4-6616-419f-bce6-44c58fa52b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-168eec1a-24b6-4e03-92e1-71da8e876abf,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4ea148eb-2794-4473-adbd-4b1748ee3da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-69ac26dd-59c9-4cac-bc7e-bab0fbdba600,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-155a16a6-c661-4d6b-91c1-9767ddcf476a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-780773a4-009d-4590-8979-060a5662a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-229fd0cb-a59f-4539-b76a-c45bb8223961,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-ac802668-860c-4066-aae9-738434c6c958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443713788-172.17.0.11-1598679330973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-3fab565f-2bb1-4882-bee4-2a26dc71622d,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-90382b2f-0d73-4287-80e1-b4a38bed16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-79b589ae-d399-4f93-a1ba-afdb62952795,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-6b4969ed-291d-4727-8f08-8d250c3e4001,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-8ff716cf-83db-43e7-9268-16024c550771,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ee7dffd5-bee6-4cea-8beb-e3f3ed31aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-bb54486b-7361-4858-9a5c-0820947bbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-615f4769-14be-4718-a8cc-48bda648c77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443713788-172.17.0.11-1598679330973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-3fab565f-2bb1-4882-bee4-2a26dc71622d,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-90382b2f-0d73-4287-80e1-b4a38bed16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-79b589ae-d399-4f93-a1ba-afdb62952795,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-6b4969ed-291d-4727-8f08-8d250c3e4001,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-8ff716cf-83db-43e7-9268-16024c550771,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ee7dffd5-bee6-4cea-8beb-e3f3ed31aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-bb54486b-7361-4858-9a5c-0820947bbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-615f4769-14be-4718-a8cc-48bda648c77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59596129-172.17.0.11-1598679366353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44090,DS-349b6f60-a5b3-4328-9b9c-f2f2c1e5fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4a290d42-cb3d-4ca1-bf62-7225b5f4ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-3a6a974c-2584-4911-8361-4d483c72d035,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-48485e9f-c3e2-4697-86de-66ba2e63c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-e582a542-95c2-412a-8c00-c64600e47212,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-9529dfdd-c4a0-4411-b9f7-9ef4960c7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-38aa0ac4-72c1-4d92-a73e-4619efd1f8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-28e8adf3-b434-4523-bc14-755db7528837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59596129-172.17.0.11-1598679366353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44090,DS-349b6f60-a5b3-4328-9b9c-f2f2c1e5fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4a290d42-cb3d-4ca1-bf62-7225b5f4ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-3a6a974c-2584-4911-8361-4d483c72d035,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-48485e9f-c3e2-4697-86de-66ba2e63c0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-e582a542-95c2-412a-8c00-c64600e47212,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-9529dfdd-c4a0-4411-b9f7-9ef4960c7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-38aa0ac4-72c1-4d92-a73e-4619efd1f8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-28e8adf3-b434-4523-bc14-755db7528837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618692405-172.17.0.11-1598680285742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-120400e7-f6e1-4bd8-8d29-5798ff8965f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-554232ac-14e6-4d4f-8130-6a5681a5be8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-caf24756-ebe7-4602-ac80-9ce219645880,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-43d08071-4b5f-4372-89b1-6df3ac207328,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-0e7531db-1bd0-458f-af78-59fa5e88823e,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-6e0a2a97-54f6-47e5-ab23-fac46989b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-7d48a2be-0f58-40bf-9eb1-bbac9838b760,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-b5a62dd4-baa8-4398-91a0-00d5330c76b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618692405-172.17.0.11-1598680285742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35064,DS-120400e7-f6e1-4bd8-8d29-5798ff8965f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-554232ac-14e6-4d4f-8130-6a5681a5be8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-caf24756-ebe7-4602-ac80-9ce219645880,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-43d08071-4b5f-4372-89b1-6df3ac207328,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-0e7531db-1bd0-458f-af78-59fa5e88823e,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-6e0a2a97-54f6-47e5-ab23-fac46989b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-7d48a2be-0f58-40bf-9eb1-bbac9838b760,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-b5a62dd4-baa8-4398-91a0-00d5330c76b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5287
