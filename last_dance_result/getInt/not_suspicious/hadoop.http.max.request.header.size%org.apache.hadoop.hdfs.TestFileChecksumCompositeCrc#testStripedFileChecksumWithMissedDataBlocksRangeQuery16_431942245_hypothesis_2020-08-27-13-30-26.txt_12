reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536434016-172.17.0.20-1598535356172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-818e20d7-88da-49a6-9845-cd238219236a,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-151dffd5-0ae2-4648-b915-291832581f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-672a0cd3-1f6e-40d6-8eaf-d534427786e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-2ba0101e-18cc-4992-b297-1980e2fcb710,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-99a2a9b7-4c9a-4d8a-aa29-9aca3bf3bd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-5b70d8e8-56d3-4e93-9cc6-dae46c7ebe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-7a9fad57-a188-44b5-89c6-c70536eb690c,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-faa743ae-0dd9-4fe8-83e3-798ebec47384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536434016-172.17.0.20-1598535356172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38262,DS-818e20d7-88da-49a6-9845-cd238219236a,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-151dffd5-0ae2-4648-b915-291832581f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-672a0cd3-1f6e-40d6-8eaf-d534427786e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-2ba0101e-18cc-4992-b297-1980e2fcb710,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-99a2a9b7-4c9a-4d8a-aa29-9aca3bf3bd49,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-5b70d8e8-56d3-4e93-9cc6-dae46c7ebe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-7a9fad57-a188-44b5-89c6-c70536eb690c,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-faa743ae-0dd9-4fe8-83e3-798ebec47384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723307629-172.17.0.20-1598535660179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-a4d749f0-68c3-4567-84e7-7fead09186a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-cb43fafe-9914-492b-a0fc-6fc90ff717c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-7270284b-234b-416f-ab75-d5a01eb2c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-12f44f9d-ec52-4c06-8aee-277a055c119b,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ac21303f-d4a7-4162-a7a9-c3792ba5549b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-fed8c5d1-8ad7-4baf-8ec3-e13a2166e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-6e602b86-1034-4737-ad02-2acd65938590,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-c6b8028e-05fd-4d8f-9e95-f85e001621c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723307629-172.17.0.20-1598535660179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-a4d749f0-68c3-4567-84e7-7fead09186a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-cb43fafe-9914-492b-a0fc-6fc90ff717c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-7270284b-234b-416f-ab75-d5a01eb2c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-12f44f9d-ec52-4c06-8aee-277a055c119b,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ac21303f-d4a7-4162-a7a9-c3792ba5549b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-fed8c5d1-8ad7-4baf-8ec3-e13a2166e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-6e602b86-1034-4737-ad02-2acd65938590,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-c6b8028e-05fd-4d8f-9e95-f85e001621c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760822795-172.17.0.20-1598536399728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-d36d6143-86d5-4d39-adb4-55294bf3fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ba5d2567-ce51-441b-91ae-2edf4cb3f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-75551270-2ac2-467d-9cd4-deb4a924e175,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-aa95a839-092c-4487-91b8-c38e39383f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-5e2a3619-d83b-434a-969b-1640c5b91902,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-09e988c9-e25c-4b8c-9eb8-a3ef848fefac,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-801877ea-fbfa-44f4-a1cb-ab3b22399c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-1400f8b5-aa6f-465c-8277-6fe934a25504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760822795-172.17.0.20-1598536399728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-d36d6143-86d5-4d39-adb4-55294bf3fe8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-ba5d2567-ce51-441b-91ae-2edf4cb3f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-75551270-2ac2-467d-9cd4-deb4a924e175,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-aa95a839-092c-4487-91b8-c38e39383f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-5e2a3619-d83b-434a-969b-1640c5b91902,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-09e988c9-e25c-4b8c-9eb8-a3ef848fefac,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-801877ea-fbfa-44f4-a1cb-ab3b22399c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-1400f8b5-aa6f-465c-8277-6fe934a25504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649597834-172.17.0.20-1598536871849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-e0ba5575-a82d-49b9-b69a-9bf757e1d593,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-384b5144-e527-45cc-b265-fe2c542d6559,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-52fc7dad-e126-4b4a-a1df-b3ad9c5078f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-6d93ba36-f791-4a46-9e17-e5a57ca6d475,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-fffb0966-8b3e-42b1-b224-ed067fdd21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-4e0271c0-c3a7-4a06-b99b-e5e60310b422,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-7abe9890-06f4-4922-abbe-f2a32e002a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-257ab830-de4e-4d87-b2a0-1a15450a5c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649597834-172.17.0.20-1598536871849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-e0ba5575-a82d-49b9-b69a-9bf757e1d593,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-384b5144-e527-45cc-b265-fe2c542d6559,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-52fc7dad-e126-4b4a-a1df-b3ad9c5078f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-6d93ba36-f791-4a46-9e17-e5a57ca6d475,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-fffb0966-8b3e-42b1-b224-ed067fdd21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-4e0271c0-c3a7-4a06-b99b-e5e60310b422,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-7abe9890-06f4-4922-abbe-f2a32e002a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-257ab830-de4e-4d87-b2a0-1a15450a5c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282329587-172.17.0.20-1598537159420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-7de1fe39-97ca-405d-901a-7a7aa49ae210,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-b97427ec-f080-4a9a-9bad-7410d088e329,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-095af807-d7f3-4ccc-aa8a-115a3dbda355,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-87fffa2a-2239-42e1-902b-ad9cf375b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d2803e85-3274-4616-8c62-29ff23568404,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-c69bf09e-08fe-4da7-8fbb-0b4320eb3365,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aebcec7a-7598-477d-aab0-385103cc15b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d200ba51-6921-4f3c-95e8-7eff3f4125ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282329587-172.17.0.20-1598537159420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-7de1fe39-97ca-405d-901a-7a7aa49ae210,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-b97427ec-f080-4a9a-9bad-7410d088e329,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-095af807-d7f3-4ccc-aa8a-115a3dbda355,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-87fffa2a-2239-42e1-902b-ad9cf375b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d2803e85-3274-4616-8c62-29ff23568404,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-c69bf09e-08fe-4da7-8fbb-0b4320eb3365,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-aebcec7a-7598-477d-aab0-385103cc15b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d200ba51-6921-4f3c-95e8-7eff3f4125ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327125774-172.17.0.20-1598537266943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-145ffba0-6d5c-4c7e-8cd8-40b037034279,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-c12b1a0f-61b4-4653-8381-67fdffe0abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8d681fe0-026f-4a46-8950-92bfd571af33,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-3ccff446-cef7-4391-940a-9753ba8ab757,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-d8e0fa75-1950-481a-9890-4aa0f4784f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ca37270e-0d40-479e-a9bd-edf6c4590100,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-46e2aea0-375f-4f6a-8bcf-efe5b0e38a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-e8fdfbdf-fb67-4abd-8fb3-87a024826363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327125774-172.17.0.20-1598537266943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-145ffba0-6d5c-4c7e-8cd8-40b037034279,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-c12b1a0f-61b4-4653-8381-67fdffe0abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-8d681fe0-026f-4a46-8950-92bfd571af33,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-3ccff446-cef7-4391-940a-9753ba8ab757,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-d8e0fa75-1950-481a-9890-4aa0f4784f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ca37270e-0d40-479e-a9bd-edf6c4590100,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-46e2aea0-375f-4f6a-8bcf-efe5b0e38a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-e8fdfbdf-fb67-4abd-8fb3-87a024826363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025929233-172.17.0.20-1598537441804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-61454bed-247c-475c-8beb-4c4da681b512,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-cea4e8ae-8f4a-4d75-908d-8bc987d6d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-45381013-382e-442c-921e-05abb323e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-c88ec59b-5c65-4ada-a63b-538275313253,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-60817f6c-2042-407a-8e30-e6d1e708785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2275aad5-5d7d-428b-a984-e23090682ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-27eee6ce-b9b8-49ea-98d2-bbf5babcdf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ab6c8853-9e59-4371-92ba-e90946f399e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025929233-172.17.0.20-1598537441804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-61454bed-247c-475c-8beb-4c4da681b512,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-cea4e8ae-8f4a-4d75-908d-8bc987d6d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-45381013-382e-442c-921e-05abb323e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-c88ec59b-5c65-4ada-a63b-538275313253,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-60817f6c-2042-407a-8e30-e6d1e708785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-2275aad5-5d7d-428b-a984-e23090682ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-27eee6ce-b9b8-49ea-98d2-bbf5babcdf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ab6c8853-9e59-4371-92ba-e90946f399e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907107203-172.17.0.20-1598538851572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-80f0c9b3-b6c3-4d9c-a267-e4cc007b0fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9df1fa3f-6609-45c8-af9f-c9b6e28420c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-bccf8236-72e7-40b1-9ceb-13e88570a611,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-96a59c2a-c631-48f8-9b21-37ebb359a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-1fa2a4b8-6090-4d4a-83f1-60e58e908e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-9f3d8f35-fb27-454d-9098-71fde3d8d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-09a12024-c307-4a59-9aeb-01986df74fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-50a862ef-55f9-4d40-b567-90c775405628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907107203-172.17.0.20-1598538851572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-80f0c9b3-b6c3-4d9c-a267-e4cc007b0fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9df1fa3f-6609-45c8-af9f-c9b6e28420c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-bccf8236-72e7-40b1-9ceb-13e88570a611,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-96a59c2a-c631-48f8-9b21-37ebb359a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-1fa2a4b8-6090-4d4a-83f1-60e58e908e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-9f3d8f35-fb27-454d-9098-71fde3d8d14c,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-09a12024-c307-4a59-9aeb-01986df74fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-50a862ef-55f9-4d40-b567-90c775405628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81936629-172.17.0.20-1598538996105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-d506ee5b-c4b1-4308-b9ce-797bbe53b445,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-05fd4cbf-15ef-476d-b647-15bbaaf5efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-4adc9639-8459-4b2d-ad8f-398cf51a1d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-bdcb62c9-0214-4a6f-8543-67de15f31aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-15152755-a61f-4d34-98fc-1f7a6b51055d,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-cce6c86e-ce54-4776-8a4e-44b3700ec99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-d37a8ab8-6a88-48c3-a863-f76e7001fdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-a3bf9b61-5020-4db7-adae-a502a3c1fb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81936629-172.17.0.20-1598538996105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-d506ee5b-c4b1-4308-b9ce-797bbe53b445,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-05fd4cbf-15ef-476d-b647-15bbaaf5efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-4adc9639-8459-4b2d-ad8f-398cf51a1d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-bdcb62c9-0214-4a6f-8543-67de15f31aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-15152755-a61f-4d34-98fc-1f7a6b51055d,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-cce6c86e-ce54-4776-8a4e-44b3700ec99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-d37a8ab8-6a88-48c3-a863-f76e7001fdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-a3bf9b61-5020-4db7-adae-a502a3c1fb28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908586326-172.17.0.20-1598539125622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-313b4893-3d19-4f4c-86b8-32e2b4564c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-e0ef2cc9-c42d-4a51-b3be-15c041b09fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-fa0d8184-fd24-44c1-a4bf-5078fa9cd114,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e425c1db-c8ff-4b6e-8b33-aa251cf87bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-77917cd3-f14e-473e-971b-471202bff62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-8f18a8a8-6734-4372-9d59-6bc579bf8383,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-2a19635f-96ac-4bbc-a583-609c621742ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-d85de02f-fdd9-4a63-a643-f07deda37dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908586326-172.17.0.20-1598539125622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-313b4893-3d19-4f4c-86b8-32e2b4564c02,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-e0ef2cc9-c42d-4a51-b3be-15c041b09fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-fa0d8184-fd24-44c1-a4bf-5078fa9cd114,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e425c1db-c8ff-4b6e-8b33-aa251cf87bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-77917cd3-f14e-473e-971b-471202bff62d,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-8f18a8a8-6734-4372-9d59-6bc579bf8383,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-2a19635f-96ac-4bbc-a583-609c621742ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-d85de02f-fdd9-4a63-a643-f07deda37dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267282784-172.17.0.20-1598539384801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-b117c1f8-e6a1-44cf-a968-fb3e8564deb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-77c4bdc6-2c9b-473d-b1c0-0318c2a44059,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-b9fbfe79-c455-45fc-9fef-019c0832bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-320f7cf2-8eeb-47a8-b0bf-312315634344,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-76dc2cc7-9de0-46e5-953b-99370f40efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-3030be37-82e3-42e3-b7ec-0baf25f50606,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-806578a5-2a1e-40dc-9f2e-03228ea71d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-2f0c2fdc-cafb-489b-84b3-2fb2a5a944b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267282784-172.17.0.20-1598539384801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-b117c1f8-e6a1-44cf-a968-fb3e8564deb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-77c4bdc6-2c9b-473d-b1c0-0318c2a44059,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-b9fbfe79-c455-45fc-9fef-019c0832bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-320f7cf2-8eeb-47a8-b0bf-312315634344,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-76dc2cc7-9de0-46e5-953b-99370f40efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-3030be37-82e3-42e3-b7ec-0baf25f50606,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-806578a5-2a1e-40dc-9f2e-03228ea71d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-2f0c2fdc-cafb-489b-84b3-2fb2a5a944b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128635191-172.17.0.20-1598539414713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-2f0b8790-bf67-4fd9-8a1f-c3311886cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-2198e91b-dee9-4d19-982d-bb33e308c749,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-ec043458-1831-4374-b497-a7ddf176d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-509c744c-017d-49bc-b4ab-3ceab5dd09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-629c686c-bebc-4221-8edd-715dd706274d,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-878a599f-145f-41ae-9967-77f4d1f7b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-2af4c008-9a69-4195-8c75-2b9eba44fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-49982860-5045-4db6-8ddf-1ffbf2412820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128635191-172.17.0.20-1598539414713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33743,DS-2f0b8790-bf67-4fd9-8a1f-c3311886cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-2198e91b-dee9-4d19-982d-bb33e308c749,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-ec043458-1831-4374-b497-a7ddf176d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-509c744c-017d-49bc-b4ab-3ceab5dd09f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-629c686c-bebc-4221-8edd-715dd706274d,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-878a599f-145f-41ae-9967-77f4d1f7b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-2af4c008-9a69-4195-8c75-2b9eba44fe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-49982860-5045-4db6-8ddf-1ffbf2412820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5104
