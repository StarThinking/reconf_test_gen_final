reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369251000-172.17.0.9-1598508754764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-37d97f6c-72b9-4202-b146-87ad06b9ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-24ca3c7b-1756-4d4a-a73d-214321e7f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-d7feee0c-c7ad-4763-a9a7-935afb2cbbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-9b4f94e9-ba52-4534-93b3-a856e3dc53ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-5c3982b0-3ded-4986-948e-951806c412cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-c2d02491-c12e-4264-8ccf-d937517f49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-678bfb9f-f779-4797-9bc0-c80e469fe946,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-660d2bf5-0df0-4333-bdac-53815280c2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369251000-172.17.0.9-1598508754764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-37d97f6c-72b9-4202-b146-87ad06b9ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-24ca3c7b-1756-4d4a-a73d-214321e7f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-d7feee0c-c7ad-4763-a9a7-935afb2cbbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-9b4f94e9-ba52-4534-93b3-a856e3dc53ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-5c3982b0-3ded-4986-948e-951806c412cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-c2d02491-c12e-4264-8ccf-d937517f49ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-678bfb9f-f779-4797-9bc0-c80e469fe946,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-660d2bf5-0df0-4333-bdac-53815280c2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60654546-172.17.0.9-1598508947097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-c4d78a6c-4c1a-4d9a-8f97-d229098f805b,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-db4fb3b9-4787-4bc6-b164-6ea9b0e3b12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-5a9706b2-b826-46a0-8325-d2fbe24883b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6a42ce6b-de94-4722-aec1-6d98b1bdde9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-5c43c1a8-3e13-4282-a455-ce7f0d2e53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-35beecce-ba63-4ba2-82c1-637e04949d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-63ae5de8-486f-47eb-bac7-bfa10dfa54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-690f5341-3a61-4b8d-b3bf-ed3e4f7b18fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60654546-172.17.0.9-1598508947097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-c4d78a6c-4c1a-4d9a-8f97-d229098f805b,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-db4fb3b9-4787-4bc6-b164-6ea9b0e3b12a,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-5a9706b2-b826-46a0-8325-d2fbe24883b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6a42ce6b-de94-4722-aec1-6d98b1bdde9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-5c43c1a8-3e13-4282-a455-ce7f0d2e53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-35beecce-ba63-4ba2-82c1-637e04949d22,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-63ae5de8-486f-47eb-bac7-bfa10dfa54c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-690f5341-3a61-4b8d-b3bf-ed3e4f7b18fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757547599-172.17.0.9-1598509068748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-1f00ecd6-3480-4b0f-98cf-251e8fbc8684,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-c3cf7c0c-acd2-4d4b-9bdf-4d0171767f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-f1cbbfa2-90c0-4599-b639-b9ba4df7895e,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-5d1dbfc4-ae31-481c-9836-fc37bbd30eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4e4751fa-9723-48f4-87ca-9b9bdec1eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-6ab5ca5b-ef15-4c4e-9834-bd44267092ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-4519e67d-b14c-4183-a15b-ed878a8abc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-875bc576-f428-4138-81a0-783ae4acd961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757547599-172.17.0.9-1598509068748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-1f00ecd6-3480-4b0f-98cf-251e8fbc8684,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-c3cf7c0c-acd2-4d4b-9bdf-4d0171767f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-f1cbbfa2-90c0-4599-b639-b9ba4df7895e,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-5d1dbfc4-ae31-481c-9836-fc37bbd30eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4e4751fa-9723-48f4-87ca-9b9bdec1eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-6ab5ca5b-ef15-4c4e-9834-bd44267092ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-4519e67d-b14c-4183-a15b-ed878a8abc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-875bc576-f428-4138-81a0-783ae4acd961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254066438-172.17.0.9-1598509137568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-d3bc1e3d-44d6-4e10-b44b-eea760a9fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-f36b58aa-27bc-47d2-b595-6d0c207084e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-7b1e1237-f6a2-4489-bcfe-c99d89f11585,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-5723cb14-e509-4c96-b024-dae7465bd80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-b66edd3a-f96a-4d85-a697-13546e9167dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-cb36f057-e316-4466-be3d-ac726e523ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-feb6af8c-94d0-492d-81be-711af0f71665,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d26e58bb-fcf4-47c4-9158-24b42a34f1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254066438-172.17.0.9-1598509137568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-d3bc1e3d-44d6-4e10-b44b-eea760a9fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-f36b58aa-27bc-47d2-b595-6d0c207084e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-7b1e1237-f6a2-4489-bcfe-c99d89f11585,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-5723cb14-e509-4c96-b024-dae7465bd80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-b66edd3a-f96a-4d85-a697-13546e9167dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-cb36f057-e316-4466-be3d-ac726e523ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-feb6af8c-94d0-492d-81be-711af0f71665,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d26e58bb-fcf4-47c4-9158-24b42a34f1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145608779-172.17.0.9-1598509176804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-007f6858-e4ad-43fc-8996-52765af9b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a9bd0f4e-c1b9-4d9d-9c7e-325c28f5c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-38a8eeb8-c623-4396-b2d5-4f33c314d070,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-72369851-6eda-407b-9945-9f81bfa8997f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-a608e24a-72c1-4c57-b65f-d874fbf56697,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-d527c57d-1412-42ca-aeb5-eaf494d3f606,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-ef3263c0-547d-4ff1-a5b7-5f6632233211,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-0dd7c8e0-42d1-4fe6-af9e-c8fe5b554d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145608779-172.17.0.9-1598509176804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-007f6858-e4ad-43fc-8996-52765af9b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a9bd0f4e-c1b9-4d9d-9c7e-325c28f5c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-38a8eeb8-c623-4396-b2d5-4f33c314d070,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-72369851-6eda-407b-9945-9f81bfa8997f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-a608e24a-72c1-4c57-b65f-d874fbf56697,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-d527c57d-1412-42ca-aeb5-eaf494d3f606,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-ef3263c0-547d-4ff1-a5b7-5f6632233211,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-0dd7c8e0-42d1-4fe6-af9e-c8fe5b554d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691868335-172.17.0.9-1598510428933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46549,DS-26f066f1-1f9a-406c-b493-126b125b3200,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-4303627c-b812-43fa-a5ca-4cd353a55afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-8bfddc6b-1fe0-4b40-abcf-f319168d7029,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-f95b18cc-e0b8-4b44-b19e-3499eb9147df,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-509cb1a5-4595-4d23-9dfa-50060bd73dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-f9cc2b7d-0059-4ebd-92cd-f50ca4cb3115,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-9e8de7ea-391b-4df6-bb61-5c966f8e4a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-496cc9c4-5ec8-44da-aefe-10a7c1d69450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691868335-172.17.0.9-1598510428933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46549,DS-26f066f1-1f9a-406c-b493-126b125b3200,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-4303627c-b812-43fa-a5ca-4cd353a55afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-8bfddc6b-1fe0-4b40-abcf-f319168d7029,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-f95b18cc-e0b8-4b44-b19e-3499eb9147df,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-509cb1a5-4595-4d23-9dfa-50060bd73dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-f9cc2b7d-0059-4ebd-92cd-f50ca4cb3115,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-9e8de7ea-391b-4df6-bb61-5c966f8e4a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-496cc9c4-5ec8-44da-aefe-10a7c1d69450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457522613-172.17.0.9-1598510732113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-dc9e569a-0855-4592-8ee9-27f61bc5d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-a2e71c8b-a1c4-419c-b294-8756885abe23,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d520ea37-c751-4ea0-81b0-68516e853ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-98caa7e5-bf93-4a98-89c1-b7c127048c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-0ff655ce-e533-40b7-ba2f-0e1b505603c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-081e97a4-6d9b-4cbe-b02f-a0bb87f6a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-a2c01e82-e451-46e5-a05e-20c9338ec2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-21338e93-96cb-40a3-962a-ebbffd2312cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457522613-172.17.0.9-1598510732113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-dc9e569a-0855-4592-8ee9-27f61bc5d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-a2e71c8b-a1c4-419c-b294-8756885abe23,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-d520ea37-c751-4ea0-81b0-68516e853ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-98caa7e5-bf93-4a98-89c1-b7c127048c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-0ff655ce-e533-40b7-ba2f-0e1b505603c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-081e97a4-6d9b-4cbe-b02f-a0bb87f6a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-a2c01e82-e451-46e5-a05e-20c9338ec2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-21338e93-96cb-40a3-962a-ebbffd2312cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883833279-172.17.0.9-1598511226322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-ff3b7e5b-9681-4a7d-b0f8-a586a190bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-c98aeb9e-8b94-4af1-a922-1c0491d87829,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-b95b42f3-56d7-439f-bfa0-280faaefdc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-ea6e599b-8ce3-453a-9a20-86efc09b631f,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-1ec815b6-54f1-4692-a835-6e4fee2f2ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-70ccb875-5599-4457-a4f8-cda2ab0fab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-62d4ae8f-2e20-4eb8-b08b-da46df2de0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-2f909ecd-d476-4ae3-bd65-64ec56322ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883833279-172.17.0.9-1598511226322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-ff3b7e5b-9681-4a7d-b0f8-a586a190bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-c98aeb9e-8b94-4af1-a922-1c0491d87829,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-b95b42f3-56d7-439f-bfa0-280faaefdc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-ea6e599b-8ce3-453a-9a20-86efc09b631f,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-1ec815b6-54f1-4692-a835-6e4fee2f2ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-70ccb875-5599-4457-a4f8-cda2ab0fab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-62d4ae8f-2e20-4eb8-b08b-da46df2de0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-2f909ecd-d476-4ae3-bd65-64ec56322ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39695176-172.17.0.9-1598511478488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-9c458af7-979f-4718-b960-8a3b0d94082c,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-bdd0b0ad-c570-4bff-bda1-7595cb5a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2097449a-1658-4bd9-b06b-880ec24ab38d,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-bb67556d-5f0c-4352-b02e-cf2c656f6295,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ee10abc5-8f04-4565-b380-925f61156d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-7b8c36f6-0a8d-4a4e-a995-8392271b1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-c53d8ba6-5f00-4165-b633-41a7a1ef09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-022da9f2-f4cf-433b-a312-a587a260d545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39695176-172.17.0.9-1598511478488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-9c458af7-979f-4718-b960-8a3b0d94082c,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-bdd0b0ad-c570-4bff-bda1-7595cb5a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2097449a-1658-4bd9-b06b-880ec24ab38d,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-bb67556d-5f0c-4352-b02e-cf2c656f6295,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ee10abc5-8f04-4565-b380-925f61156d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-7b8c36f6-0a8d-4a4e-a995-8392271b1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-c53d8ba6-5f00-4165-b633-41a7a1ef09ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-022da9f2-f4cf-433b-a312-a587a260d545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290222155-172.17.0.9-1598511806143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46395,DS-5b6b27b5-6191-4ec2-961e-1a49af7039e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-fe019938-13c0-4c2e-8c2a-1b3a9c7efc87,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-1b1e0959-e94c-4c97-88dc-9b243289beae,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-0e8589a8-5595-40d3-8af9-6674c7b3f839,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-826dd246-531b-4ada-94c1-095f2807c676,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-654f93e5-dd74-432e-bbc9-aea0b07b5148,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-158d835c-65d7-4640-aaa4-0e95c8b27202,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-789b7551-3d84-4355-bdad-782f45d96107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290222155-172.17.0.9-1598511806143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46395,DS-5b6b27b5-6191-4ec2-961e-1a49af7039e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-fe019938-13c0-4c2e-8c2a-1b3a9c7efc87,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-1b1e0959-e94c-4c97-88dc-9b243289beae,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-0e8589a8-5595-40d3-8af9-6674c7b3f839,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-826dd246-531b-4ada-94c1-095f2807c676,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-654f93e5-dd74-432e-bbc9-aea0b07b5148,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-158d835c-65d7-4640-aaa4-0e95c8b27202,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-789b7551-3d84-4355-bdad-782f45d96107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440464392-172.17.0.9-1598512322026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-771b7cab-5d70-4582-8819-7db6def0ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-ac39715e-3d02-433c-8a6c-c12cae71c79f,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0e7e1ce0-1e29-4b7b-a8e0-cf9d750234b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-a590e5e0-314b-424f-a7e5-eadf7a767dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c9854651-1f54-47c4-97cf-d09725926e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-5c19c6a8-f81f-4a52-bc7b-22034f6e796b,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-7bc1c6b8-37d3-4601-9a3b-edb12e758db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-07966d8c-782b-40ed-9f89-b07ed67164ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440464392-172.17.0.9-1598512322026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-771b7cab-5d70-4582-8819-7db6def0ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-ac39715e-3d02-433c-8a6c-c12cae71c79f,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-0e7e1ce0-1e29-4b7b-a8e0-cf9d750234b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-a590e5e0-314b-424f-a7e5-eadf7a767dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c9854651-1f54-47c4-97cf-d09725926e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-5c19c6a8-f81f-4a52-bc7b-22034f6e796b,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-7bc1c6b8-37d3-4601-9a3b-edb12e758db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-07966d8c-782b-40ed-9f89-b07ed67164ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141178505-172.17.0.9-1598512489123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-9cf58af0-f588-4282-9305-36beb71f4853,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-2ce93abb-87d3-47ab-ba0d-33ba5ae2ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-75fd7024-613a-4d50-b1af-f304d665764d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f1fd143c-5a1e-46fe-bf08-78acc6b64c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-ee1f356b-ad51-4da8-b6fe-4d886951b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-68ee1570-685b-4bec-b07c-e19bf5ceefd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-ba3349b1-c712-4541-9451-d781e8267b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-545d55db-eb55-457d-be0b-1e418c107701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141178505-172.17.0.9-1598512489123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36289,DS-9cf58af0-f588-4282-9305-36beb71f4853,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-2ce93abb-87d3-47ab-ba0d-33ba5ae2ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-75fd7024-613a-4d50-b1af-f304d665764d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f1fd143c-5a1e-46fe-bf08-78acc6b64c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-ee1f356b-ad51-4da8-b6fe-4d886951b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-68ee1570-685b-4bec-b07c-e19bf5ceefd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-ba3349b1-c712-4541-9451-d781e8267b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-545d55db-eb55-457d-be0b-1e418c107701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328167445-172.17.0.9-1598513082004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-2573dca2-0f5f-450d-bac0-aa78be460cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-02f35957-51c8-496b-a442-246f67577e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-361799e3-fe2d-4324-bac0-d7adefce145b,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-7bf4e19a-e7e8-4f67-b1f5-6ab37e6e158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-ce17d95b-a3af-4b98-b6b8-dbd50f927f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-9e2447ec-9a2e-4a09-96f8-0c1987cce613,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-2589b718-91ac-4ec4-8b5a-ff5b9d870751,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-950a77ce-c4ec-4068-9370-a97ae8c30193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328167445-172.17.0.9-1598513082004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-2573dca2-0f5f-450d-bac0-aa78be460cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-02f35957-51c8-496b-a442-246f67577e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-361799e3-fe2d-4324-bac0-d7adefce145b,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-7bf4e19a-e7e8-4f67-b1f5-6ab37e6e158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-ce17d95b-a3af-4b98-b6b8-dbd50f927f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-9e2447ec-9a2e-4a09-96f8-0c1987cce613,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-2589b718-91ac-4ec4-8b5a-ff5b9d870751,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-950a77ce-c4ec-4068-9370-a97ae8c30193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 134217728
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86403379-172.17.0.9-1598513222871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-5828f600-6404-435d-844d-789eb2b50d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-4992fa86-96d7-49cb-b67f-cb686f822d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-71399578-a46b-4f2a-8efd-832cddf88d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-a4e26f52-c6c5-41c0-86cb-d69047a5960c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-e7339fc7-0921-4daf-acde-d601b1fd80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-77f27290-b0d2-4238-ad86-7d83ea732eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-d353e36c-8759-40a7-b8cb-7e4d90bf6151,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-52170ac1-c6b1-48df-ba6b-67fdd90f87c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86403379-172.17.0.9-1598513222871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-5828f600-6404-435d-844d-789eb2b50d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-4992fa86-96d7-49cb-b67f-cb686f822d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-71399578-a46b-4f2a-8efd-832cddf88d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-a4e26f52-c6c5-41c0-86cb-d69047a5960c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-e7339fc7-0921-4daf-acde-d601b1fd80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-77f27290-b0d2-4238-ad86-7d83ea732eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-d353e36c-8759-40a7-b8cb-7e4d90bf6151,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-52170ac1-c6b1-48df-ba6b-67fdd90f87c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5539
