reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588894181-172.17.0.13-1598495747439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-ffc81c2b-d94f-497b-9193-65c505fac524,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-38327d5c-e107-4440-acaf-68c86d05f851,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-32d8963a-7ba4-496d-be73-ac99ae8e618c,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8d1e734d-8a33-4094-a36e-c2c12b9fe5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-5fd2ed0e-116d-4c79-8967-6742bcaf0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1a767fbf-3352-4a67-a71f-640b8c465d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-e5fb4f78-006d-4c12-8413-3689e36f7c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-9a5427df-e196-4c53-b5a1-66db235ffddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588894181-172.17.0.13-1598495747439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-ffc81c2b-d94f-497b-9193-65c505fac524,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-38327d5c-e107-4440-acaf-68c86d05f851,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-32d8963a-7ba4-496d-be73-ac99ae8e618c,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8d1e734d-8a33-4094-a36e-c2c12b9fe5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-5fd2ed0e-116d-4c79-8967-6742bcaf0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1a767fbf-3352-4a67-a71f-640b8c465d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-e5fb4f78-006d-4c12-8413-3689e36f7c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-9a5427df-e196-4c53-b5a1-66db235ffddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867914709-172.17.0.13-1598496099008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-4a081703-5220-4c05-b89a-5b28aa3627f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-87c5e5ea-ff6d-43ec-bc30-2c4b3b911e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-02b710f8-b833-41ab-951d-29e91d58ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-56cefa3f-309e-48a8-a9e8-bd7c5326a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-4f75e1d0-dbf4-4d82-827c-7a1b40bd65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-86c55ec0-c851-42b0-a7f5-478e038d653e,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b3397ff0-caab-4e6d-9ed6-7d74136947fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-16535c1d-e3e2-407a-a365-d7458749b07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867914709-172.17.0.13-1598496099008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-4a081703-5220-4c05-b89a-5b28aa3627f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-87c5e5ea-ff6d-43ec-bc30-2c4b3b911e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-02b710f8-b833-41ab-951d-29e91d58ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-56cefa3f-309e-48a8-a9e8-bd7c5326a0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-4f75e1d0-dbf4-4d82-827c-7a1b40bd65ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-86c55ec0-c851-42b0-a7f5-478e038d653e,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-b3397ff0-caab-4e6d-9ed6-7d74136947fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-16535c1d-e3e2-407a-a365-d7458749b07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549331446-172.17.0.13-1598496243433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-cfc8a80d-8cb6-4ff5-82c1-49d816323539,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-be3a2b8b-72d1-4d79-9bcd-66395b7b0ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5c500516-0b98-4120-9bbe-12b7af78aa34,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-6017f32c-ba0c-4fac-be82-ab62877f66c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-ef1ccc87-a6e5-4478-8941-db0a1e1ff049,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-d53423f2-0591-49c7-9d1c-ec35989c05f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-4b430f0e-b6a6-4928-8ed4-7439eabfa664,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9c82827c-11f1-4b22-8920-aee8d88263c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549331446-172.17.0.13-1598496243433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-cfc8a80d-8cb6-4ff5-82c1-49d816323539,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-be3a2b8b-72d1-4d79-9bcd-66395b7b0ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5c500516-0b98-4120-9bbe-12b7af78aa34,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-6017f32c-ba0c-4fac-be82-ab62877f66c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-ef1ccc87-a6e5-4478-8941-db0a1e1ff049,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-d53423f2-0591-49c7-9d1c-ec35989c05f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-4b430f0e-b6a6-4928-8ed4-7439eabfa664,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9c82827c-11f1-4b22-8920-aee8d88263c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694722583-172.17.0.13-1598496511448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-ea2a3cab-2daa-4aeb-a141-8e691381cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-386c0985-f262-4bf5-86ec-d77a17e026e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-c47afc34-d20c-4d2a-bd3c-0a6b753bf278,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-69f7e82e-188b-432c-b630-3ea6ecb9b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-134c270e-3c5a-4acc-8261-b81e98c6ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-f29ca47d-9bce-4b7a-8b1a-af8ee91272f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-6fe106dc-73dd-4006-8727-969f848745d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-177f3cab-b7d3-4507-b152-f72bde192968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694722583-172.17.0.13-1598496511448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-ea2a3cab-2daa-4aeb-a141-8e691381cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-386c0985-f262-4bf5-86ec-d77a17e026e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-c47afc34-d20c-4d2a-bd3c-0a6b753bf278,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-69f7e82e-188b-432c-b630-3ea6ecb9b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-134c270e-3c5a-4acc-8261-b81e98c6ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-f29ca47d-9bce-4b7a-8b1a-af8ee91272f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-6fe106dc-73dd-4006-8727-969f848745d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-177f3cab-b7d3-4507-b152-f72bde192968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904550630-172.17.0.13-1598496819423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-9f027e27-9488-4e69-936c-b71d95dc5730,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-61c657e5-8921-427e-8b8a-3dea79e0955a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-6d7e6e32-b5b2-4d26-a7b1-e38d5f1bda76,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-7b2b14c3-0b79-4941-b65e-5d76347e3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-a48a295b-9b3f-4a2b-b3d7-cb82b72b989a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-d60da200-bc01-46e0-8e8f-c3acea929480,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-d78b1951-5ad4-403a-ad44-238c8a82344c,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-0ce4bd97-d716-4ce9-8695-ea3ee516cbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904550630-172.17.0.13-1598496819423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-9f027e27-9488-4e69-936c-b71d95dc5730,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-61c657e5-8921-427e-8b8a-3dea79e0955a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-6d7e6e32-b5b2-4d26-a7b1-e38d5f1bda76,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-7b2b14c3-0b79-4941-b65e-5d76347e3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-a48a295b-9b3f-4a2b-b3d7-cb82b72b989a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-d60da200-bc01-46e0-8e8f-c3acea929480,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-d78b1951-5ad4-403a-ad44-238c8a82344c,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-0ce4bd97-d716-4ce9-8695-ea3ee516cbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804845687-172.17.0.13-1598496851220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-e83f4e0c-b24b-4807-aff1-16fa58e95338,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-5d6d029d-c554-4cec-8e99-1b1c4c1d5960,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-f0182a82-26df-472c-80eb-7ffd07233be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-322da0e3-a111-40c4-b8d0-e44c047789c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-28d0543b-e625-432c-8b1f-50a48fa99e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-d41c0d76-42c9-4adf-a068-e201c4e68575,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-3a3f08fd-7637-4308-9e6d-53baa85a0001,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-6b6e762d-b8ff-44ad-8943-705300cb903d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-804845687-172.17.0.13-1598496851220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-e83f4e0c-b24b-4807-aff1-16fa58e95338,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-5d6d029d-c554-4cec-8e99-1b1c4c1d5960,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-f0182a82-26df-472c-80eb-7ffd07233be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-322da0e3-a111-40c4-b8d0-e44c047789c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-28d0543b-e625-432c-8b1f-50a48fa99e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-d41c0d76-42c9-4adf-a068-e201c4e68575,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-3a3f08fd-7637-4308-9e6d-53baa85a0001,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-6b6e762d-b8ff-44ad-8943-705300cb903d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007543360-172.17.0.13-1598497196948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-4cc44014-5e49-420a-881e-9d2640427001,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-51a6deb8-47f9-43b2-8905-75170fbeb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-06e693c7-d6c9-4498-bf45-bd056ae4054b,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ddcca816-3f9d-494c-91f1-35f1d21cd808,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-42e14e20-e0ce-4b58-95db-b60c2afc8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-3ed4bf3d-11e9-49f1-87cc-1fb101c8e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-965ee23e-81c2-4c6a-89d9-74e94ae75818,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-c062a902-f9d4-4f55-b181-3aabe90c52d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007543360-172.17.0.13-1598497196948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-4cc44014-5e49-420a-881e-9d2640427001,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-51a6deb8-47f9-43b2-8905-75170fbeb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-06e693c7-d6c9-4498-bf45-bd056ae4054b,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ddcca816-3f9d-494c-91f1-35f1d21cd808,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-42e14e20-e0ce-4b58-95db-b60c2afc8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-3ed4bf3d-11e9-49f1-87cc-1fb101c8e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-965ee23e-81c2-4c6a-89d9-74e94ae75818,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-c062a902-f9d4-4f55-b181-3aabe90c52d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118266470-172.17.0.13-1598497528496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-b9280ff3-06a2-4a7f-8961-b61205a62623,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-4ea1aebf-12e2-4d26-8273-e18f239b232b,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-8ac83756-4961-470c-93a4-0850336138a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-f14ee04e-28e3-4a07-944e-d81c95a1161e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-494fa198-fc1d-45c7-97db-a6118da4da97,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-004eb368-0e58-4dd5-9fc0-64fe16813b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-c146c245-3541-4081-8d45-918c947eb235,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-3a6f7aa9-fa58-4bcd-ae68-01cd1941d607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118266470-172.17.0.13-1598497528496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-b9280ff3-06a2-4a7f-8961-b61205a62623,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-4ea1aebf-12e2-4d26-8273-e18f239b232b,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-8ac83756-4961-470c-93a4-0850336138a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-f14ee04e-28e3-4a07-944e-d81c95a1161e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-494fa198-fc1d-45c7-97db-a6118da4da97,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-004eb368-0e58-4dd5-9fc0-64fe16813b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-c146c245-3541-4081-8d45-918c947eb235,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-3a6f7aa9-fa58-4bcd-ae68-01cd1941d607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478796358-172.17.0.13-1598497685685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41525,DS-e68acf1f-5665-4fc9-aa21-385c1eda3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-df78d00b-ebb4-4e32-8968-79663faae7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-715dcfc1-3f6e-4aac-a70a-beb086a11da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d04b2b52-c741-46a2-a6a3-a30d0058e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-9b72dbdd-9746-4bbe-920b-f0150c9cd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6dc1873c-8d6f-44b6-b95f-cdddf49321fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-ff561022-36af-4921-9366-0e87eb4515ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-25134de4-0c9b-4efa-bbf4-7b1bb7a0fae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478796358-172.17.0.13-1598497685685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41525,DS-e68acf1f-5665-4fc9-aa21-385c1eda3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-df78d00b-ebb4-4e32-8968-79663faae7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-715dcfc1-3f6e-4aac-a70a-beb086a11da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d04b2b52-c741-46a2-a6a3-a30d0058e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-9b72dbdd-9746-4bbe-920b-f0150c9cd1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6dc1873c-8d6f-44b6-b95f-cdddf49321fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-ff561022-36af-4921-9366-0e87eb4515ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-25134de4-0c9b-4efa-bbf4-7b1bb7a0fae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563087670-172.17.0.13-1598497999155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-6193eaf3-9ea7-4729-a3d8-75e0f2625a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-5ce995d1-6724-4949-9489-685e9cf2e51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-a63cfb4f-f36a-4609-bc09-876c6800e426,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-1a127bdc-0dfe-4899-9b7d-c69aee3a60e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-b3c37365-3444-439b-ad18-1bc190d9d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-c0c8d94d-d309-4793-bc3c-91090ecf30b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-097df893-226a-43e0-892e-530223b58c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-acfe5ae1-3d6f-41ca-bfbe-899f9e0ea02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563087670-172.17.0.13-1598497999155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-6193eaf3-9ea7-4729-a3d8-75e0f2625a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-5ce995d1-6724-4949-9489-685e9cf2e51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-a63cfb4f-f36a-4609-bc09-876c6800e426,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-1a127bdc-0dfe-4899-9b7d-c69aee3a60e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-b3c37365-3444-439b-ad18-1bc190d9d0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-c0c8d94d-d309-4793-bc3c-91090ecf30b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-097df893-226a-43e0-892e-530223b58c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-acfe5ae1-3d6f-41ca-bfbe-899f9e0ea02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535144329-172.17.0.13-1598498601090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-93614452-038d-4ff9-a5b2-d15f7b9e287f,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-5a0ddbd3-083c-47e5-b4b1-a14a5398f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-8da500c5-91dc-4306-8301-c5757da2b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-a93d14bb-bb5c-4ccd-8ff7-c0a6510087c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-7070320b-d8fc-4b4e-b241-30383135b017,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-969c5aa1-47e8-4ab1-8c86-3b1589bd6120,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-a61e4a9c-7682-4163-8047-27fbf1b76f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-9ae7029c-adec-4a2a-be24-29f339a4cfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535144329-172.17.0.13-1598498601090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-93614452-038d-4ff9-a5b2-d15f7b9e287f,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-5a0ddbd3-083c-47e5-b4b1-a14a5398f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-8da500c5-91dc-4306-8301-c5757da2b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-a93d14bb-bb5c-4ccd-8ff7-c0a6510087c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-7070320b-d8fc-4b4e-b241-30383135b017,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-969c5aa1-47e8-4ab1-8c86-3b1589bd6120,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-a61e4a9c-7682-4163-8047-27fbf1b76f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-9ae7029c-adec-4a2a-be24-29f339a4cfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950844387-172.17.0.13-1598498972524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-1b65c58c-b22b-4a08-ba50-49689c886729,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6961a141-3eaf-4f00-9f71-1544610df558,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-04feff99-52e6-4ff1-b48b-1a2889427c03,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-8b9d1f6b-fc04-472e-a268-3410d1b8d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-0fcffd78-52ac-487e-acd0-995cb495adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5fc53909-fdfa-45ba-92a6-8e5ffb882dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-8d804f31-b451-49f4-b93c-a2f2bbb952ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-3947ca22-cf9e-4333-a3ff-eade9084f471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950844387-172.17.0.13-1598498972524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-1b65c58c-b22b-4a08-ba50-49689c886729,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6961a141-3eaf-4f00-9f71-1544610df558,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-04feff99-52e6-4ff1-b48b-1a2889427c03,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-8b9d1f6b-fc04-472e-a268-3410d1b8d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-0fcffd78-52ac-487e-acd0-995cb495adcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-5fc53909-fdfa-45ba-92a6-8e5ffb882dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-8d804f31-b451-49f4-b93c-a2f2bbb952ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-3947ca22-cf9e-4333-a3ff-eade9084f471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285678918-172.17.0.13-1598499752989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-7a30fb93-0b9e-4217-b504-01344f0383ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-b1905a14-b5f4-430e-a3e3-5b4f2e55742d,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-adbbeb3d-95a2-48fa-b059-1c2fa209586e,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-f1ff98fb-f314-42b1-9796-e1b0c3870f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-7a7adb0e-ec33-472f-ba08-1f2333fe83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d75ed8b7-6ee9-44b3-92da-cd0370a3c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-1c0c8fa7-1fc1-4e8d-b580-162a4297dd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-341e8bf3-6e97-4a9f-a915-3d6ffc2f8357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285678918-172.17.0.13-1598499752989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36311,DS-7a30fb93-0b9e-4217-b504-01344f0383ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-b1905a14-b5f4-430e-a3e3-5b4f2e55742d,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-adbbeb3d-95a2-48fa-b059-1c2fa209586e,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-f1ff98fb-f314-42b1-9796-e1b0c3870f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-7a7adb0e-ec33-472f-ba08-1f2333fe83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-d75ed8b7-6ee9-44b3-92da-cd0370a3c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-1c0c8fa7-1fc1-4e8d-b580-162a4297dd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-341e8bf3-6e97-4a9f-a915-3d6ffc2f8357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566954693-172.17.0.13-1598499792106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-d4ff5e55-9199-4194-99ce-08dd1bea8111,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-b9f5a435-414b-4953-9a43-5e11f2967b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-38ad51b2-956b-4e1b-a934-05f7c6649f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-ad607304-0145-48a1-895d-c958c1efdd65,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9f166477-94cc-475b-8a32-8f38597e1f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ca67f445-0d7b-456d-bf95-a651c243dade,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-e73928b8-9bcd-4a9c-a8ba-e7996b82a6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-4b9ae640-560f-4e80-bd7b-acd48643832e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566954693-172.17.0.13-1598499792106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36679,DS-d4ff5e55-9199-4194-99ce-08dd1bea8111,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-b9f5a435-414b-4953-9a43-5e11f2967b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-38ad51b2-956b-4e1b-a934-05f7c6649f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-ad607304-0145-48a1-895d-c958c1efdd65,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-9f166477-94cc-475b-8a32-8f38597e1f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ca67f445-0d7b-456d-bf95-a651c243dade,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-e73928b8-9bcd-4a9c-a8ba-e7996b82a6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-4b9ae640-560f-4e80-bd7b-acd48643832e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403467754-172.17.0.13-1598499926803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-d75a85f2-71ea-4264-96f3-fd7a12f468ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-15226abd-606f-4a02-b8f8-01de2c7dbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b757f2a9-752b-45bc-9127-994388575ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ea6b042c-0b1b-43d4-ad3a-31eaf9f2fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-4d2ba458-5d96-4435-a85b-9bbd49a0fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3963e6f0-d2f0-463f-92ea-a57344649644,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-30eb8c3f-9370-4db8-95ab-e9da5f4e1222,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-6c485306-d977-427a-91e4-458f43a7a263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403467754-172.17.0.13-1598499926803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-d75a85f2-71ea-4264-96f3-fd7a12f468ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-15226abd-606f-4a02-b8f8-01de2c7dbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b757f2a9-752b-45bc-9127-994388575ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ea6b042c-0b1b-43d4-ad3a-31eaf9f2fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-4d2ba458-5d96-4435-a85b-9bbd49a0fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3963e6f0-d2f0-463f-92ea-a57344649644,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-30eb8c3f-9370-4db8-95ab-e9da5f4e1222,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-6c485306-d977-427a-91e4-458f43a7a263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4981
