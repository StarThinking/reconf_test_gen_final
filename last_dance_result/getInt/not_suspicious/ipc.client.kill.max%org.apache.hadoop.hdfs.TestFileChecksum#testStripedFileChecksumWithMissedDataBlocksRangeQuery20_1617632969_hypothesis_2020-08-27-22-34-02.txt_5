reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795606734-172.17.0.17-1598567658572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-d3506ce2-8ec7-42aa-927d-1759446889e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-2cecdc6e-468d-432e-b582-e267420a64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-10a0384c-6308-413c-8ddc-73f971529d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-3692746c-790a-4253-89f4-268f5912fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-2b1798a6-aa4b-4a66-8b7c-c47c719a2560,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-19622876-8e68-45e1-8f78-074982e352a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-17c4aa38-64fc-4a65-b0bd-7de0208c31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-54b8af04-d95e-40f3-8256-e5ce9ad999d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795606734-172.17.0.17-1598567658572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-d3506ce2-8ec7-42aa-927d-1759446889e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-2cecdc6e-468d-432e-b582-e267420a64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-10a0384c-6308-413c-8ddc-73f971529d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-3692746c-790a-4253-89f4-268f5912fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-2b1798a6-aa4b-4a66-8b7c-c47c719a2560,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-19622876-8e68-45e1-8f78-074982e352a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-17c4aa38-64fc-4a65-b0bd-7de0208c31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-54b8af04-d95e-40f3-8256-e5ce9ad999d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487628634-172.17.0.17-1598567771338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35646,DS-b874bd7a-94ac-4965-b7cd-34a614c5b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-352ee11e-3692-4e4b-8dc3-949ba4c357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-edeb7321-8a52-4767-bcd0-7188f29632f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-92cee4ab-a3c6-46e6-bade-e9127f0df383,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-9e479f05-909c-436b-bdf3-ab5cbd753535,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-aae8f6fe-91c8-4ec4-a65f-85d4618676fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-f523ccc4-39d4-4bc4-b81e-2a22d1aa1464,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-2f8356a2-bb63-496d-9a65-f1b35712f7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487628634-172.17.0.17-1598567771338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35646,DS-b874bd7a-94ac-4965-b7cd-34a614c5b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-352ee11e-3692-4e4b-8dc3-949ba4c357f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-edeb7321-8a52-4767-bcd0-7188f29632f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-92cee4ab-a3c6-46e6-bade-e9127f0df383,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-9e479f05-909c-436b-bdf3-ab5cbd753535,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-aae8f6fe-91c8-4ec4-a65f-85d4618676fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-f523ccc4-39d4-4bc4-b81e-2a22d1aa1464,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-2f8356a2-bb63-496d-9a65-f1b35712f7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392210868-172.17.0.17-1598567903981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-3338e1ca-c1f6-4289-9f4d-bb48f220d631,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-d137c955-c752-4b65-9202-c05c0dbc01bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-76394a23-9ccd-40ac-b74a-9ad0e9d596cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-4734f2e9-ca3a-48fa-b1b9-ffad9eb20011,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-79ec6436-f563-4b81-86b0-ae7b3aa47e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-7df83d67-f0f0-48ce-8c38-6004043fae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-9af13016-2b8a-41e9-bc81-31607dca76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-4ea54c4c-967c-4494-b856-593d5f46e020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392210868-172.17.0.17-1598567903981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-3338e1ca-c1f6-4289-9f4d-bb48f220d631,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-d137c955-c752-4b65-9202-c05c0dbc01bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-76394a23-9ccd-40ac-b74a-9ad0e9d596cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-4734f2e9-ca3a-48fa-b1b9-ffad9eb20011,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-79ec6436-f563-4b81-86b0-ae7b3aa47e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-7df83d67-f0f0-48ce-8c38-6004043fae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-9af13016-2b8a-41e9-bc81-31607dca76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-4ea54c4c-967c-4494-b856-593d5f46e020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592201925-172.17.0.17-1598568181390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-6bfd001a-0494-4208-b895-549aee23edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-61cb25c4-6d70-4b65-9ec9-5300265f55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-8e644b24-c77c-44af-8c42-1254ad760bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-1b9133b7-d233-4b56-a0ce-89d0adc96554,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-1e275dd4-7948-4198-b540-5a356614cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-c37a5957-86d8-42b2-9352-a0b9412ff135,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-8742377c-c8b8-4851-aae8-6069548edeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-68a1720e-2a75-4a6e-8b7d-27b23e642fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592201925-172.17.0.17-1598568181390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35074,DS-6bfd001a-0494-4208-b895-549aee23edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-61cb25c4-6d70-4b65-9ec9-5300265f55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-8e644b24-c77c-44af-8c42-1254ad760bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-1b9133b7-d233-4b56-a0ce-89d0adc96554,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-1e275dd4-7948-4198-b540-5a356614cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-c37a5957-86d8-42b2-9352-a0b9412ff135,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-8742377c-c8b8-4851-aae8-6069548edeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-68a1720e-2a75-4a6e-8b7d-27b23e642fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854252949-172.17.0.17-1598568427046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-8d9bbef5-edca-4ae8-a8d7-7acd97aec7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-9cdb97e8-0868-4900-9a1e-22c83674ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-b38823b0-83d6-47a6-a462-3872458b6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-1f4f4f05-90f5-46d3-819a-05f96672b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-2c0d6a4d-6c33-4ce2-821f-2128e57cf2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-2cd2ae55-4c2d-495d-9854-ab00ccd330e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-4ae3f96b-7f2e-41f6-b054-c9d3c7844d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-18eb5080-d99b-4fb9-942e-f4d6d1fb7ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854252949-172.17.0.17-1598568427046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-8d9bbef5-edca-4ae8-a8d7-7acd97aec7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-9cdb97e8-0868-4900-9a1e-22c83674ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-b38823b0-83d6-47a6-a462-3872458b6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-1f4f4f05-90f5-46d3-819a-05f96672b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-2c0d6a4d-6c33-4ce2-821f-2128e57cf2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-2cd2ae55-4c2d-495d-9854-ab00ccd330e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-4ae3f96b-7f2e-41f6-b054-c9d3c7844d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-18eb5080-d99b-4fb9-942e-f4d6d1fb7ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156007498-172.17.0.17-1598568529928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-7e96a3ad-0530-4218-8829-d3eaddb89e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-7dc1425b-d6d1-42f4-87cb-8042e5abd5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-54b350d7-2b6a-49be-892b-54e00b973c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-0cabdaaa-c906-4c21-8358-19aa562af1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-85b4d14e-c354-455d-8ad2-8b4bdceb1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-092f6534-4f79-4860-8ad3-6ccdb5ff0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-f0229b29-fef8-459f-aa2d-848efb0687ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-61e31c1b-b0c7-4993-b0ea-01c570c868fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156007498-172.17.0.17-1598568529928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-7e96a3ad-0530-4218-8829-d3eaddb89e41,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-7dc1425b-d6d1-42f4-87cb-8042e5abd5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-54b350d7-2b6a-49be-892b-54e00b973c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-0cabdaaa-c906-4c21-8358-19aa562af1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-85b4d14e-c354-455d-8ad2-8b4bdceb1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-092f6534-4f79-4860-8ad3-6ccdb5ff0e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-f0229b29-fef8-459f-aa2d-848efb0687ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-61e31c1b-b0c7-4993-b0ea-01c570c868fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316310290-172.17.0.17-1598568597138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-4c851327-2da2-44fa-b90a-2fb4a589274d,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-ce74b281-3ee2-4268-9a20-5853d94173c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-fbc96d42-e497-483c-892d-5e911d2ae10d,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-933c9afd-d1d0-4df3-b8b9-d0e885c9113f,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-90e96967-eb23-4f84-9c11-835cf3226167,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-bac66fce-d637-4a0d-ae21-92d96559739b,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e6f0ea51-e6e7-41cb-87b0-23fc35696024,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a223df64-172a-4b5a-8759-ec09ebcbba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316310290-172.17.0.17-1598568597138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-4c851327-2da2-44fa-b90a-2fb4a589274d,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-ce74b281-3ee2-4268-9a20-5853d94173c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-fbc96d42-e497-483c-892d-5e911d2ae10d,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-933c9afd-d1d0-4df3-b8b9-d0e885c9113f,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-90e96967-eb23-4f84-9c11-835cf3226167,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-bac66fce-d637-4a0d-ae21-92d96559739b,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e6f0ea51-e6e7-41cb-87b0-23fc35696024,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a223df64-172a-4b5a-8759-ec09ebcbba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458613766-172.17.0.17-1598568710810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-2b0f808f-58e7-4530-8f2c-4782da4b559e,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-59e4c871-4284-45d4-8f60-16670cda53dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-3b8532b9-e949-4fe8-8b19-d4eff07bc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-70899ff3-91d7-4eaa-ba32-f2df76c3acec,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-f814a9a8-1d57-4a16-84ba-9dad9e439938,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-c95daaf4-afab-4398-873a-b438747b05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-7bf99040-bb35-44c9-9b7d-d600350a47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-3de9e740-564d-41bd-b3c8-419bb0b8b9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458613766-172.17.0.17-1598568710810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-2b0f808f-58e7-4530-8f2c-4782da4b559e,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-59e4c871-4284-45d4-8f60-16670cda53dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-3b8532b9-e949-4fe8-8b19-d4eff07bc5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-70899ff3-91d7-4eaa-ba32-f2df76c3acec,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-f814a9a8-1d57-4a16-84ba-9dad9e439938,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-c95daaf4-afab-4398-873a-b438747b05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-7bf99040-bb35-44c9-9b7d-d600350a47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-3de9e740-564d-41bd-b3c8-419bb0b8b9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683228526-172.17.0.17-1598568743998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-116bbebf-b2b5-4694-a848-2772ca744b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-25ddc4fc-1746-4a04-84d0-02c4c541d495,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-729487ab-5393-4b99-a1ca-f3a63f9e4510,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-2956fc85-0572-4fa5-aa7a-d275ace4491f,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-7a30901f-126a-473f-86da-005423dc174d,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-1d7885b9-d9f3-4adf-89c5-a6a9e9c1e927,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-24a628ea-9d31-4691-9468-dc37a0cc4a58,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-d724d2f9-832e-4e8e-9c8c-e0c0a9196e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683228526-172.17.0.17-1598568743998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-116bbebf-b2b5-4694-a848-2772ca744b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-25ddc4fc-1746-4a04-84d0-02c4c541d495,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-729487ab-5393-4b99-a1ca-f3a63f9e4510,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-2956fc85-0572-4fa5-aa7a-d275ace4491f,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-7a30901f-126a-473f-86da-005423dc174d,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-1d7885b9-d9f3-4adf-89c5-a6a9e9c1e927,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-24a628ea-9d31-4691-9468-dc37a0cc4a58,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-d724d2f9-832e-4e8e-9c8c-e0c0a9196e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918346398-172.17.0.17-1598568774395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-2e823992-0b45-450d-96c5-40677d658c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-5f8f4363-e6ed-4475-becd-f51db3a729db,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-89763e20-9287-48dd-a1ff-04f521eb417b,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-63bb2dc5-1de8-45b7-9387-bb00dc265c59,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-e9502971-2763-4fa4-9216-cc3900ea8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-87f14a74-ca77-4ff5-ae86-50e20f02c36b,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-ca8ed2b8-a370-4bc6-8dc6-0b77a75382be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-f664de01-5c3e-402b-82a6-b28882e5bc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918346398-172.17.0.17-1598568774395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-2e823992-0b45-450d-96c5-40677d658c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-5f8f4363-e6ed-4475-becd-f51db3a729db,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-89763e20-9287-48dd-a1ff-04f521eb417b,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-63bb2dc5-1de8-45b7-9387-bb00dc265c59,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-e9502971-2763-4fa4-9216-cc3900ea8d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-87f14a74-ca77-4ff5-ae86-50e20f02c36b,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-ca8ed2b8-a370-4bc6-8dc6-0b77a75382be,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-f664de01-5c3e-402b-82a6-b28882e5bc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712596487-172.17.0.17-1598569179050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-966c5ef9-6f02-4cbb-ad6a-9b59d4ee81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4ce11498-3444-47c9-b0de-d3154c2e3285,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-a5eac9ba-7a15-45b6-b125-e6e95a17f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-21227be4-cfa3-4d94-a227-cfb30b1994a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bf19a9ca-cb68-48a9-9efd-bdcfda164b02,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-cc76a318-df3a-4760-8fed-9e5e1ccd0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b4f70253-880e-4af3-bfe8-a65cbe81e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-dbdec255-1d4a-49c5-bfc7-a3c26f518ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712596487-172.17.0.17-1598569179050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-966c5ef9-6f02-4cbb-ad6a-9b59d4ee81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4ce11498-3444-47c9-b0de-d3154c2e3285,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-a5eac9ba-7a15-45b6-b125-e6e95a17f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-21227be4-cfa3-4d94-a227-cfb30b1994a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bf19a9ca-cb68-48a9-9efd-bdcfda164b02,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-cc76a318-df3a-4760-8fed-9e5e1ccd0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-b4f70253-880e-4af3-bfe8-a65cbe81e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-dbdec255-1d4a-49c5-bfc7-a3c26f518ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117309846-172.17.0.17-1598569210363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-3c27cb5f-cab0-46ac-9037-0bd3554dd86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-9baaffad-414b-456b-a8cc-ed98bbcfb612,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-86b09b21-8e51-4332-9c8b-db2803fd4641,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6944c449-417f-4231-99a1-7d07d44c0f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-de77f106-9483-45ee-8513-be760bf62fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-0df9d094-3e3b-44b6-9958-d9a4797bfd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-b5dd680a-38c6-4c43-a133-de08561d663c,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-555acf9a-d3b8-4cc2-8820-0a933435ea95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117309846-172.17.0.17-1598569210363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-3c27cb5f-cab0-46ac-9037-0bd3554dd86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-9baaffad-414b-456b-a8cc-ed98bbcfb612,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-86b09b21-8e51-4332-9c8b-db2803fd4641,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6944c449-417f-4231-99a1-7d07d44c0f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-de77f106-9483-45ee-8513-be760bf62fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-0df9d094-3e3b-44b6-9958-d9a4797bfd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-b5dd680a-38c6-4c43-a133-de08561d663c,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-555acf9a-d3b8-4cc2-8820-0a933435ea95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781305452-172.17.0.17-1598569417702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-422b65ad-4bc9-4209-a341-f57afbab8f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-223ae1b0-ddac-4116-8bae-4ea5c7876bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-39e57a74-270c-4b93-8819-6ace3ae6c8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6d074c40-4a58-4305-a4b7-fa104c928e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-888df40d-3c13-4a38-9d17-93f467571667,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-256b0290-fb74-4c9c-9230-a80a169f046d,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-94924a19-a0f4-448d-b885-12735e3084b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-c9491a80-8dde-4e08-8811-d48d8e1a9d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781305452-172.17.0.17-1598569417702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-422b65ad-4bc9-4209-a341-f57afbab8f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-223ae1b0-ddac-4116-8bae-4ea5c7876bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-39e57a74-270c-4b93-8819-6ace3ae6c8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-6d074c40-4a58-4305-a4b7-fa104c928e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-888df40d-3c13-4a38-9d17-93f467571667,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-256b0290-fb74-4c9c-9230-a80a169f046d,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-94924a19-a0f4-448d-b885-12735e3084b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-c9491a80-8dde-4e08-8811-d48d8e1a9d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347584172-172.17.0.17-1598569506301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-52aa233b-87b4-4048-b175-775b247263a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-2bf1c3e6-8faa-4aad-a357-e8996b4bf0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-7ce42a23-1d47-48a3-9802-ac7a8c09491c,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c2d196b8-e6e2-424a-896a-fc8f026a1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-bf99e432-683f-4ee3-b92c-12926b8ea4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-355b72b5-c79b-4df0-b067-0825142ad667,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-8d1fc901-222c-4b95-bd81-38f8ab21b864,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-671f5f59-64de-49dc-9f73-cb11a58e2d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347584172-172.17.0.17-1598569506301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-52aa233b-87b4-4048-b175-775b247263a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-2bf1c3e6-8faa-4aad-a357-e8996b4bf0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-7ce42a23-1d47-48a3-9802-ac7a8c09491c,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c2d196b8-e6e2-424a-896a-fc8f026a1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-bf99e432-683f-4ee3-b92c-12926b8ea4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-355b72b5-c79b-4df0-b067-0825142ad667,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-8d1fc901-222c-4b95-bd81-38f8ab21b864,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-671f5f59-64de-49dc-9f73-cb11a58e2d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944770425-172.17.0.17-1598569661146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-adecdbdc-28d9-4f22-b1fa-d5be6ad7c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-10fe59a7-c79d-499b-982c-0dc552038ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-6c06964f-658d-4d64-978f-59fe6f11e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0031c38f-2093-4b00-a624-e15a52da85d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-94d43a8f-ebc9-44e8-9744-bd9ce454e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-06256615-7896-40db-8bac-0bad37fc27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-aaf10ce3-3391-4461-86f3-862c34f3d779,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-916bf934-e9e3-433c-b47c-5ddab31650ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944770425-172.17.0.17-1598569661146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-adecdbdc-28d9-4f22-b1fa-d5be6ad7c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-10fe59a7-c79d-499b-982c-0dc552038ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-6c06964f-658d-4d64-978f-59fe6f11e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-0031c38f-2093-4b00-a624-e15a52da85d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-94d43a8f-ebc9-44e8-9744-bd9ce454e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-06256615-7896-40db-8bac-0bad37fc27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-aaf10ce3-3391-4461-86f3-862c34f3d779,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-916bf934-e9e3-433c-b47c-5ddab31650ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604451054-172.17.0.17-1598569689965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43750,DS-a0f88b6c-8d93-4249-8f20-66735b5c4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-e3c5b0f7-65cb-4419-8a7b-f6bc351b1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f4081190-8b47-4b9b-b2dd-68081e792ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-098f9b93-cb26-4657-b481-ebbed4506753,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-d0df043d-e9cb-4dc8-97b8-be2b07ac4bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-c055445e-e970-4d98-b8be-9c2911eea76a,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-8632edb1-53c1-4ba3-89f9-9b84a4dff6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d7ea302b-89a8-4923-b1b1-e8e431e1d6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604451054-172.17.0.17-1598569689965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43750,DS-a0f88b6c-8d93-4249-8f20-66735b5c4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-e3c5b0f7-65cb-4419-8a7b-f6bc351b1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-f4081190-8b47-4b9b-b2dd-68081e792ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-098f9b93-cb26-4657-b481-ebbed4506753,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-d0df043d-e9cb-4dc8-97b8-be2b07ac4bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-c055445e-e970-4d98-b8be-9c2911eea76a,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-8632edb1-53c1-4ba3-89f9-9b84a4dff6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d7ea302b-89a8-4923-b1b1-e8e431e1d6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738095777-172.17.0.17-1598569991335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-7df05ca0-7b77-49cb-bf82-47a34886767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-b58f5a57-2685-4acd-839f-b5cdb2c4b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-a0407c62-d0c5-4dca-94d9-502a34d6efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-cb042dbf-d083-40ef-a593-2bc485137fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-46075984-d271-4462-8ef2-8c7a256de3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-d26b1510-5042-490a-b61c-ca71e119f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-a579654d-dd0d-488f-9e2a-d08fea32382b,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-8ce11307-4512-49b4-b5ad-c65bb812aaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738095777-172.17.0.17-1598569991335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-7df05ca0-7b77-49cb-bf82-47a34886767d,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-b58f5a57-2685-4acd-839f-b5cdb2c4b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-a0407c62-d0c5-4dca-94d9-502a34d6efe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-cb042dbf-d083-40ef-a593-2bc485137fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-46075984-d271-4462-8ef2-8c7a256de3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-d26b1510-5042-490a-b61c-ca71e119f02b,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-a579654d-dd0d-488f-9e2a-d08fea32382b,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-8ce11307-4512-49b4-b5ad-c65bb812aaad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30293530-172.17.0.17-1598570023407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44507,DS-bb666a66-7618-44cf-bee1-fc4f4d6a130c,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-f1998ede-8066-4bbd-be7a-d5a5141348e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-4adf400e-e1d2-4179-8bf2-dd11298e9fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-50f3faa8-014e-466b-969a-998bf8d4568d,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9877866c-a8a3-4957-8340-318e6ad64a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7e790391-f918-4a43-9ed4-ccc88d47a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-55f5079e-0fa0-4ca2-808c-d096c7d4d271,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-f92d2353-3dd7-4f02-960b-f0e409c08a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30293530-172.17.0.17-1598570023407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44507,DS-bb666a66-7618-44cf-bee1-fc4f4d6a130c,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-f1998ede-8066-4bbd-be7a-d5a5141348e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-4adf400e-e1d2-4179-8bf2-dd11298e9fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-50f3faa8-014e-466b-969a-998bf8d4568d,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-9877866c-a8a3-4957-8340-318e6ad64a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-7e790391-f918-4a43-9ed4-ccc88d47a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-55f5079e-0fa0-4ca2-808c-d096c7d4d271,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-f92d2353-3dd7-4f02-960b-f0e409c08a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655204265-172.17.0.17-1598570055280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-20b6067d-416d-4904-8865-6048dddddf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-7d2a13b0-6bec-488a-abd5-dabda1f11090,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-13b82f21-7676-4def-a50a-48c8ea451ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-50e33093-3127-43a7-9750-7c5c5906a9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-74c0a04a-cb4f-4ed8-ae04-bb1bd378e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-669cc139-8306-4c70-abe7-39525ad96f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-c7cb4d44-c0c0-4dc2-a372-80f78fdf15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-d8881ae5-6e73-452f-9de4-c4149f7484e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655204265-172.17.0.17-1598570055280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-20b6067d-416d-4904-8865-6048dddddf70,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-7d2a13b0-6bec-488a-abd5-dabda1f11090,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-13b82f21-7676-4def-a50a-48c8ea451ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-50e33093-3127-43a7-9750-7c5c5906a9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-74c0a04a-cb4f-4ed8-ae04-bb1bd378e9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-669cc139-8306-4c70-abe7-39525ad96f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-c7cb4d44-c0c0-4dc2-a372-80f78fdf15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-d8881ae5-6e73-452f-9de4-c4149f7484e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950267622-172.17.0.17-1598570304768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-9488f1d8-ec76-45b6-b569-ddac2676908a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-fb503ef2-8088-4847-bddd-7d4e01b491cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-ebaa785b-1794-4ee7-822e-8a5f688fdf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-d2591982-9365-497a-993e-34dcbbafa898,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-acda370c-e655-4d66-9ae3-9ff5edac3807,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-8851dcd6-e634-463b-bc71-5da30e781297,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-6478d35c-f981-45ab-b99c-6642f7874ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-b18f36f9-4fb2-4982-bcd0-531d75e9cda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950267622-172.17.0.17-1598570304768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-9488f1d8-ec76-45b6-b569-ddac2676908a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-fb503ef2-8088-4847-bddd-7d4e01b491cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-ebaa785b-1794-4ee7-822e-8a5f688fdf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-d2591982-9365-497a-993e-34dcbbafa898,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-acda370c-e655-4d66-9ae3-9ff5edac3807,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-8851dcd6-e634-463b-bc71-5da30e781297,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-6478d35c-f981-45ab-b99c-6642f7874ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-b18f36f9-4fb2-4982-bcd0-531d75e9cda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244413979-172.17.0.17-1598570564444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-b89b82b2-c5a1-4d89-b0f3-e4f308f3f006,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-b0a81a61-6cd1-467b-b881-4bbd95aeb525,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-62f05718-8a3d-41c3-8b91-990cf0a62e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-3363af8d-25fe-4b20-8dcc-14501cb2a327,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-6aff42c8-5c07-480e-9e7b-899241c42249,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-56bb93c3-8e54-4962-9888-c9189f9dadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bfa79bd6-2842-4851-8710-e795675b4e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5d4092a1-6bdb-46a0-9e5b-54ff38193077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244413979-172.17.0.17-1598570564444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-b89b82b2-c5a1-4d89-b0f3-e4f308f3f006,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-b0a81a61-6cd1-467b-b881-4bbd95aeb525,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-62f05718-8a3d-41c3-8b91-990cf0a62e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-3363af8d-25fe-4b20-8dcc-14501cb2a327,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-6aff42c8-5c07-480e-9e7b-899241c42249,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-56bb93c3-8e54-4962-9888-c9189f9dadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bfa79bd6-2842-4851-8710-e795675b4e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-5d4092a1-6bdb-46a0-9e5b-54ff38193077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638788199-172.17.0.17-1598570623033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-b9b0221d-c3cb-4ded-948a-6be120ee6928,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-d00a0d84-0903-407f-9846-9fc409b69c91,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-60f43251-6e67-4523-8acb-4655297f953f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-0f2f8aa3-3c1f-4c72-8df9-9b0a08ea9630,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-b9b69d49-2935-4a7a-86eb-a60cf855f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-eb1aafed-6a93-47e3-893f-ebf33af675d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-914503e2-1087-41a4-8422-fc919a35d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b57e137d-64b5-4f8a-ae5d-cfe50d030339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638788199-172.17.0.17-1598570623033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-b9b0221d-c3cb-4ded-948a-6be120ee6928,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-d00a0d84-0903-407f-9846-9fc409b69c91,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-60f43251-6e67-4523-8acb-4655297f953f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-0f2f8aa3-3c1f-4c72-8df9-9b0a08ea9630,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-b9b69d49-2935-4a7a-86eb-a60cf855f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-eb1aafed-6a93-47e3-893f-ebf33af675d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-914503e2-1087-41a4-8422-fc919a35d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b57e137d-64b5-4f8a-ae5d-cfe50d030339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171480992-172.17.0.17-1598570842538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-00cb757c-8b4b-495f-b9e6-4a7583e0e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-f2a60cd1-dd10-4ec0-ac74-f7c8f118907a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-678b10ef-f712-4adf-bc92-7c9a026df2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d07def77-2c98-447a-a41e-b87e51c45b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-a5aced7e-95ba-4138-8bb5-f6083957f421,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9fe5659b-720b-47db-979a-c509f8d91607,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-6b36cf88-6f97-4587-bc68-2cbefa9c7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-1d09a785-7ce8-4901-ad8c-d9172f2ee99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171480992-172.17.0.17-1598570842538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-00cb757c-8b4b-495f-b9e6-4a7583e0e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-f2a60cd1-dd10-4ec0-ac74-f7c8f118907a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-678b10ef-f712-4adf-bc92-7c9a026df2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-d07def77-2c98-447a-a41e-b87e51c45b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-a5aced7e-95ba-4138-8bb5-f6083957f421,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9fe5659b-720b-47db-979a-c509f8d91607,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-6b36cf88-6f97-4587-bc68-2cbefa9c7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-1d09a785-7ce8-4901-ad8c-d9172f2ee99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350144238-172.17.0.17-1598570957562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-a0a0a5aa-a12d-47c5-a8aa-193e0796c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-4cb73250-aa46-4498-bc31-ea78b2b1dc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-9b21f5ae-267b-4ad4-9bf8-98ab5ee891ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-6c4cfbf2-763e-4a24-a229-bb4cb5337f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-15696c0a-9ba2-45a3-af9b-34bac2ef22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-67f6008b-72f4-480b-88a8-2d611681784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-c8414e56-1ea5-4e97-8ad4-2ae746042dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-4bb6d849-adb2-4fc5-a06a-0bc5fe5e598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350144238-172.17.0.17-1598570957562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-a0a0a5aa-a12d-47c5-a8aa-193e0796c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-4cb73250-aa46-4498-bc31-ea78b2b1dc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-9b21f5ae-267b-4ad4-9bf8-98ab5ee891ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-6c4cfbf2-763e-4a24-a229-bb4cb5337f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-15696c0a-9ba2-45a3-af9b-34bac2ef22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-67f6008b-72f4-480b-88a8-2d611681784f,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-c8414e56-1ea5-4e97-8ad4-2ae746042dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-4bb6d849-adb2-4fc5-a06a-0bc5fe5e598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154030060-172.17.0.17-1598570987923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-451c1668-48a6-4876-90d5-7427a8b8d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-250a4ef7-7386-4173-834a-75bb7e2434dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-b5f8022c-21c6-4520-bb7d-3ac3310b6e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-8e613e20-6683-49e0-aaf4-d5b591562725,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-99ba8a14-bbec-4e8e-a5a9-adaac18a56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-7bc81a28-8897-4106-a050-665ec3bf4237,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-de1faf45-d248-4212-8765-1c1f88959bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-40f6dbd4-e91f-4f5e-9443-f85ee26bfbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154030060-172.17.0.17-1598570987923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38392,DS-451c1668-48a6-4876-90d5-7427a8b8d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-250a4ef7-7386-4173-834a-75bb7e2434dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-b5f8022c-21c6-4520-bb7d-3ac3310b6e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-8e613e20-6683-49e0-aaf4-d5b591562725,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-99ba8a14-bbec-4e8e-a5a9-adaac18a56dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-7bc81a28-8897-4106-a050-665ec3bf4237,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-de1faf45-d248-4212-8765-1c1f88959bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-40f6dbd4-e91f-4f5e-9443-f85ee26bfbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036265389-172.17.0.17-1598571539852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-90b5db75-47ea-4f7c-aebc-83f8a49b7985,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-fc6fa028-8d1f-4541-bd29-77e9a0911931,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-9d86a7e4-711e-48df-802d-ea4dccd566ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-245e2ed9-fda2-4c14-8122-057e76a44fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-65d75d8e-30fe-4508-b61f-35f4513b5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-821ff456-c510-48d3-9577-c9bb5cccb624,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-cb89e997-f641-4fe9-bff7-9ed1e67fd9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-2a7d85ea-d97c-4b50-91a3-bf026c4b8be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036265389-172.17.0.17-1598571539852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-90b5db75-47ea-4f7c-aebc-83f8a49b7985,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-fc6fa028-8d1f-4541-bd29-77e9a0911931,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-9d86a7e4-711e-48df-802d-ea4dccd566ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-245e2ed9-fda2-4c14-8122-057e76a44fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-65d75d8e-30fe-4508-b61f-35f4513b5cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-821ff456-c510-48d3-9577-c9bb5cccb624,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-cb89e997-f641-4fe9-bff7-9ed1e67fd9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-2a7d85ea-d97c-4b50-91a3-bf026c4b8be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931004256-172.17.0.17-1598571668375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-3e0093b2-72fc-4706-a1c5-939c277a50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-90591527-4186-477a-ae08-9f61e15ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-cf599eac-4533-4110-bfe0-2a20dc14fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-fcbc836a-f914-44d5-a617-79f98e9413f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-737d67ee-1faf-46d8-91ec-61b5644cb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-3dbe2cf0-abdf-4173-87bd-e28f9fca85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-e3025da7-8e46-41de-97c3-056e522a7260,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-1ce7321b-a61b-4003-884a-4faec9b95089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931004256-172.17.0.17-1598571668375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-3e0093b2-72fc-4706-a1c5-939c277a50c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-90591527-4186-477a-ae08-9f61e15ee24b,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-cf599eac-4533-4110-bfe0-2a20dc14fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-fcbc836a-f914-44d5-a617-79f98e9413f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-737d67ee-1faf-46d8-91ec-61b5644cb5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-3dbe2cf0-abdf-4173-87bd-e28f9fca85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-e3025da7-8e46-41de-97c3-056e522a7260,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-1ce7321b-a61b-4003-884a-4faec9b95089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957653560-172.17.0.17-1598571700687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-426eebaa-f21f-4e6d-be80-9bc1d213ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e932112e-60a8-4612-afe0-6e4aae8ad5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-7f554322-53af-43fc-a0ee-97a88280687d,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-8cdece2a-eb9b-4300-a401-86d35506e288,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-37a0d3a0-95f4-4c91-972e-88bd14e92e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-7f149173-2621-41f4-a2d4-a26a2e583236,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-4d9ffed8-9acc-457f-8853-f86ff2d929d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-0dc14ed2-e39b-4195-b69f-8961750b856b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957653560-172.17.0.17-1598571700687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-426eebaa-f21f-4e6d-be80-9bc1d213ee90,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e932112e-60a8-4612-afe0-6e4aae8ad5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-7f554322-53af-43fc-a0ee-97a88280687d,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-8cdece2a-eb9b-4300-a401-86d35506e288,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-37a0d3a0-95f4-4c91-972e-88bd14e92e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-7f149173-2621-41f4-a2d4-a26a2e583236,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-4d9ffed8-9acc-457f-8853-f86ff2d929d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-0dc14ed2-e39b-4195-b69f-8961750b856b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126176105-172.17.0.17-1598571929682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-4eaae8d6-7346-4fef-9ab0-baef9e8c1b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-4465c431-f87b-4614-a411-a58f867ff325,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-c41e04ad-e0a9-46d5-899d-21f7d53a4792,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-bd74ca1d-4cfa-4d47-8d7e-ce8b3bb5707d,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-0f03fd46-55b6-498d-9ea1-41429170777b,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-a0241fc5-48aa-409b-85e3-8ba11d8798e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-31fa60a4-485a-44aa-89c1-9fdb89e17930,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-b3c4c469-c480-42a2-99fd-f5c0c6306646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126176105-172.17.0.17-1598571929682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-4eaae8d6-7346-4fef-9ab0-baef9e8c1b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-4465c431-f87b-4614-a411-a58f867ff325,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-c41e04ad-e0a9-46d5-899d-21f7d53a4792,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-bd74ca1d-4cfa-4d47-8d7e-ce8b3bb5707d,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-0f03fd46-55b6-498d-9ea1-41429170777b,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-a0241fc5-48aa-409b-85e3-8ba11d8798e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-31fa60a4-485a-44aa-89c1-9fdb89e17930,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-b3c4c469-c480-42a2-99fd-f5c0c6306646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 4851
