reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275285894-172.17.0.9-1598659342049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-6d9454a0-3984-47ec-aa7d-6501a9129c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-89e3f18a-af4c-4781-ad01-423a3c753e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-c6b74b2e-14c0-4e97-b5be-ddec041808ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-66ffe051-189c-41e7-aaee-e0e05b7b1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-319a90f1-755d-416c-8bfa-4dd5b0b8095e,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-53b6d46a-a6c4-4961-938d-4a9b2978da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-63932148-a6ef-4734-8a7c-a946303ac1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-468957db-9ec4-40b1-871a-a44584d986e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275285894-172.17.0.9-1598659342049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-6d9454a0-3984-47ec-aa7d-6501a9129c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-89e3f18a-af4c-4781-ad01-423a3c753e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-c6b74b2e-14c0-4e97-b5be-ddec041808ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-66ffe051-189c-41e7-aaee-e0e05b7b1f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-319a90f1-755d-416c-8bfa-4dd5b0b8095e,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-53b6d46a-a6c4-4961-938d-4a9b2978da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-63932148-a6ef-4734-8a7c-a946303ac1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-468957db-9ec4-40b1-871a-a44584d986e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237607233-172.17.0.9-1598659519487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-2f5ab6cd-08e0-491f-b7d7-f999bc78f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-44410d37-caec-4599-be1f-1fbe92bb755a,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-9652197a-738a-4bf7-bc49-ea58dc30e331,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d7cc7e62-6400-4896-9164-4efc9caaa26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-97976f53-133e-4663-9244-bd1e636b4910,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-6e057436-7571-4154-9c08-19c0a4f3aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b8d1cf11-1f43-4a01-82f1-e9007e50de09,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-820009fd-60f9-4d1f-a46b-117e3f180224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237607233-172.17.0.9-1598659519487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-2f5ab6cd-08e0-491f-b7d7-f999bc78f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-44410d37-caec-4599-be1f-1fbe92bb755a,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-9652197a-738a-4bf7-bc49-ea58dc30e331,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-d7cc7e62-6400-4896-9164-4efc9caaa26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-97976f53-133e-4663-9244-bd1e636b4910,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-6e057436-7571-4154-9c08-19c0a4f3aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b8d1cf11-1f43-4a01-82f1-e9007e50de09,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-820009fd-60f9-4d1f-a46b-117e3f180224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553306138-172.17.0.9-1598660019382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-7fda8976-a726-4ef4-a96a-757f87dd4dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-662a27bd-db33-448e-a046-fda6f0318073,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-d7714d8a-90ca-4e03-923e-bee4dc0af40f,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-f5095a28-9a82-473a-af27-4d4d2f727d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-ed559a24-c23a-4584-896e-b918093568c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-ce24b10d-f2fd-4961-9110-3d897c874421,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-291bfb6a-b475-4c7b-985a-3f1679a77227,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-492ff192-f5cf-4dd8-9a22-4bf45b628367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553306138-172.17.0.9-1598660019382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-7fda8976-a726-4ef4-a96a-757f87dd4dad,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-662a27bd-db33-448e-a046-fda6f0318073,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-d7714d8a-90ca-4e03-923e-bee4dc0af40f,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-f5095a28-9a82-473a-af27-4d4d2f727d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-ed559a24-c23a-4584-896e-b918093568c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-ce24b10d-f2fd-4961-9110-3d897c874421,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-291bfb6a-b475-4c7b-985a-3f1679a77227,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-492ff192-f5cf-4dd8-9a22-4bf45b628367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112245468-172.17.0.9-1598660087388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-602ace98-74aa-4eba-b6e6-0525c5d4c203,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-e5d09e7b-f07a-4fd2-bcfd-96b1a05e8f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-52928ba5-e2db-45f0-b791-c62e1de1a571,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-849f44ae-e77c-4061-8635-0d791fc0816b,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-127606f9-be42-439e-9a9b-f0f490765dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-8c4c981f-346b-467e-97ff-22c0be156bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-b22bfcf6-f311-40ce-9c11-2e1aafbd7178,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ea07afd0-9bfc-4c91-ad25-aa4b6d4d14b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112245468-172.17.0.9-1598660087388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-602ace98-74aa-4eba-b6e6-0525c5d4c203,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-e5d09e7b-f07a-4fd2-bcfd-96b1a05e8f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-52928ba5-e2db-45f0-b791-c62e1de1a571,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-849f44ae-e77c-4061-8635-0d791fc0816b,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-127606f9-be42-439e-9a9b-f0f490765dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-8c4c981f-346b-467e-97ff-22c0be156bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-b22bfcf6-f311-40ce-9c11-2e1aafbd7178,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ea07afd0-9bfc-4c91-ad25-aa4b6d4d14b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487884876-172.17.0.9-1598660550251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-57ff5b48-a3ac-42ff-ba37-b20c22d51ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-2af9f07f-71c6-4699-9cb1-14c6fff1359f,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-c25c7973-d6c1-4f0f-a254-d95fb36ffd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-47f1e010-1de0-4c40-b7ed-b63c2a9ade10,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-9f8163bb-fe4a-4eaa-a3d6-90db39c98649,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-47510025-4177-4b37-abdc-b4a7ecbe118b,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-a24e902d-9213-4572-8c96-3f0a26804d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-a1164c9a-25ed-4098-b2ff-e8eab86d7bd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487884876-172.17.0.9-1598660550251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-57ff5b48-a3ac-42ff-ba37-b20c22d51ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-2af9f07f-71c6-4699-9cb1-14c6fff1359f,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-c25c7973-d6c1-4f0f-a254-d95fb36ffd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-47f1e010-1de0-4c40-b7ed-b63c2a9ade10,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-9f8163bb-fe4a-4eaa-a3d6-90db39c98649,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-47510025-4177-4b37-abdc-b4a7ecbe118b,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-a24e902d-9213-4572-8c96-3f0a26804d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-a1164c9a-25ed-4098-b2ff-e8eab86d7bd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631316820-172.17.0.9-1598661462787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-58fd555d-0a78-4514-b3eb-b88b6191a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-a8eb498f-2710-4333-9f45-909fe1b42a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a27af543-3b84-4ab4-ac36-fb65db4ad2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-64cfa93a-2f84-4314-9a1a-082854d872bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-75a696c1-be3a-42c9-9eaa-2ae83f9b9d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-07d2c593-5fd7-4e9d-b80f-eac118ec86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-e351df09-7eb9-43fb-b190-7562d142ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-8615aea2-9705-47a4-9dec-ac6cb47f9d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631316820-172.17.0.9-1598661462787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-58fd555d-0a78-4514-b3eb-b88b6191a77f,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-a8eb498f-2710-4333-9f45-909fe1b42a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-a27af543-3b84-4ab4-ac36-fb65db4ad2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-64cfa93a-2f84-4314-9a1a-082854d872bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-75a696c1-be3a-42c9-9eaa-2ae83f9b9d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-07d2c593-5fd7-4e9d-b80f-eac118ec86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-e351df09-7eb9-43fb-b190-7562d142ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-8615aea2-9705-47a4-9dec-ac6cb47f9d33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504711425-172.17.0.9-1598662155966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-f8fe5a37-0432-4775-b22d-808f061c3218,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-307226f9-8751-4d2e-995d-49f0e3d5e961,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-2efb1286-dca7-4f9f-b562-8147036c4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-d55c07c2-1122-4a8d-97d4-5206a0001f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-2313afa0-661d-4917-8a7f-421e4c826cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-ee85ca7a-c150-485b-90e0-8f836ea508f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-085e4396-31ba-4dbe-8c33-af3b5e05e805,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-9192e514-3ee0-4b67-9375-e1a8a2db66fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504711425-172.17.0.9-1598662155966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-f8fe5a37-0432-4775-b22d-808f061c3218,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-307226f9-8751-4d2e-995d-49f0e3d5e961,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-2efb1286-dca7-4f9f-b562-8147036c4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-d55c07c2-1122-4a8d-97d4-5206a0001f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-2313afa0-661d-4917-8a7f-421e4c826cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-ee85ca7a-c150-485b-90e0-8f836ea508f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-085e4396-31ba-4dbe-8c33-af3b5e05e805,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-9192e514-3ee0-4b67-9375-e1a8a2db66fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266851331-172.17.0.9-1598662233437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-2c55d1fb-5e3a-4811-a974-da780f00c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-84f619f9-7ee4-4480-b025-9b15583586e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-a01b17aa-0d42-4496-8773-b3fb0df9ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-57512334-05ff-4e28-bf0c-9c27e82cdbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-84c8a69e-a010-4bb2-a758-37eae7508176,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e7b7538f-cebf-43e4-8f5d-6a72e852ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-c4e9ca53-b720-40b5-93b9-9758b13c980d,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-3ba83057-b7b9-4b87-a4c6-765cced77bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266851331-172.17.0.9-1598662233437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-2c55d1fb-5e3a-4811-a974-da780f00c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-84f619f9-7ee4-4480-b025-9b15583586e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-a01b17aa-0d42-4496-8773-b3fb0df9ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-57512334-05ff-4e28-bf0c-9c27e82cdbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-84c8a69e-a010-4bb2-a758-37eae7508176,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e7b7538f-cebf-43e4-8f5d-6a72e852ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-c4e9ca53-b720-40b5-93b9-9758b13c980d,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-3ba83057-b7b9-4b87-a4c6-765cced77bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875368665-172.17.0.9-1598662801145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-034914a8-7411-4de1-aaf8-31ee55604990,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a5b59837-1f47-4903-be50-4b0703e56477,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-2c22dcd6-e85d-4b4e-81cb-f4d816b39b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-973044df-0315-4f6f-bcab-187e30b123ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-cf0d76aa-2b73-423e-b342-1f65d2d99cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3fabde84-8736-4504-898d-8e46678d7d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-4f181eb6-28c8-41a7-9339-a7e69cccae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-df253e32-3813-4226-830c-009450ffd82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875368665-172.17.0.9-1598662801145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-034914a8-7411-4de1-aaf8-31ee55604990,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-a5b59837-1f47-4903-be50-4b0703e56477,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-2c22dcd6-e85d-4b4e-81cb-f4d816b39b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-973044df-0315-4f6f-bcab-187e30b123ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-cf0d76aa-2b73-423e-b342-1f65d2d99cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3fabde84-8736-4504-898d-8e46678d7d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-4f181eb6-28c8-41a7-9339-a7e69cccae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-df253e32-3813-4226-830c-009450ffd82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049499190-172.17.0.9-1598662943784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-87407475-bad5-45b1-8442-08350963c370,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-69f3a108-71cd-40d2-a9b0-4886eca61841,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a89d42cd-4b49-41ff-b3b4-a99f217be3df,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-e8429255-2ef0-4180-aeb3-aac96bf3e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-db440d91-8032-4b2c-9df6-609923378c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-4f803a74-eb1c-4a07-a79d-aa8fe0a92704,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-582a0db4-1c11-4ae6-b0ed-46d29456d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ae0b61e0-eaca-4584-bb37-0bd3f572ec0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049499190-172.17.0.9-1598662943784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-87407475-bad5-45b1-8442-08350963c370,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-69f3a108-71cd-40d2-a9b0-4886eca61841,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a89d42cd-4b49-41ff-b3b4-a99f217be3df,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-e8429255-2ef0-4180-aeb3-aac96bf3e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-db440d91-8032-4b2c-9df6-609923378c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-4f803a74-eb1c-4a07-a79d-aa8fe0a92704,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-582a0db4-1c11-4ae6-b0ed-46d29456d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ae0b61e0-eaca-4584-bb37-0bd3f572ec0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744536887-172.17.0.9-1598663067265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-dc7ee065-dec9-4336-b8a2-ff3a12361d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-7b5a37ed-48c6-45aa-8a75-699eb93e9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-4c6463e2-b6f4-4cfa-a7e5-d299a77884f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c66a0a1d-a54e-44da-a6f4-429b9891b859,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-cd19f022-88dd-464f-893f-6b3e1925e375,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a31ac578-2a3d-4871-940c-70dfd7269565,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-e8961289-91c9-49d1-9e8b-c943cd216a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ecb78d34-d28a-40b7-8d98-e523d7609634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744536887-172.17.0.9-1598663067265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-dc7ee065-dec9-4336-b8a2-ff3a12361d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-7b5a37ed-48c6-45aa-8a75-699eb93e9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-4c6463e2-b6f4-4cfa-a7e5-d299a77884f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c66a0a1d-a54e-44da-a6f4-429b9891b859,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-cd19f022-88dd-464f-893f-6b3e1925e375,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a31ac578-2a3d-4871-940c-70dfd7269565,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-e8961289-91c9-49d1-9e8b-c943cd216a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ecb78d34-d28a-40b7-8d98-e523d7609634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153348723-172.17.0.9-1598664080696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-f40c8598-b2c0-41b1-904a-ecd06d091a38,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-506a1fc1-ecf2-40a4-8cf0-732f01ea3682,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-14d6cbd4-0911-4b0f-9775-162ae2f10622,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-c2d1d36e-cfc9-447c-93bb-0f0e1bcf95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9f6bee2a-740d-4c5c-a6de-9acb70de1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-769e4f88-9afb-4bfb-8d0b-1abf7d778b84,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-fb1a3306-23d3-4564-8741-008511a40da9,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4356b824-a187-4553-b079-4f0d7a262983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153348723-172.17.0.9-1598664080696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-f40c8598-b2c0-41b1-904a-ecd06d091a38,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-506a1fc1-ecf2-40a4-8cf0-732f01ea3682,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-14d6cbd4-0911-4b0f-9775-162ae2f10622,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-c2d1d36e-cfc9-447c-93bb-0f0e1bcf95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9f6bee2a-740d-4c5c-a6de-9acb70de1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-769e4f88-9afb-4bfb-8d0b-1abf7d778b84,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-fb1a3306-23d3-4564-8741-008511a40da9,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4356b824-a187-4553-b079-4f0d7a262983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379164667-172.17.0.9-1598664316725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-cb25d10f-29c2-4ef5-9c25-2d0fe01e0074,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-7ff11bf1-462a-4d9d-9cff-587c73e2b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-cd6edd7d-d66e-4de9-ab50-94db1bd7b133,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-764a2a69-bc13-4619-b7bc-8127ae358cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-0f7cc68a-b73f-43fc-9896-d3cbfb9f166e,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-e8b1fb69-8130-46c6-b3b3-90edd7fb97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-b562617b-c9b5-4ebd-92e0-d7ec2f0fd6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-e5b4731a-1bc5-42ac-aef0-00aacad1654c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379164667-172.17.0.9-1598664316725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-cb25d10f-29c2-4ef5-9c25-2d0fe01e0074,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-7ff11bf1-462a-4d9d-9cff-587c73e2b88e,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-cd6edd7d-d66e-4de9-ab50-94db1bd7b133,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-764a2a69-bc13-4619-b7bc-8127ae358cde,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-0f7cc68a-b73f-43fc-9896-d3cbfb9f166e,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-e8b1fb69-8130-46c6-b3b3-90edd7fb97f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-b562617b-c9b5-4ebd-92e0-d7ec2f0fd6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-e5b4731a-1bc5-42ac-aef0-00aacad1654c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5642
