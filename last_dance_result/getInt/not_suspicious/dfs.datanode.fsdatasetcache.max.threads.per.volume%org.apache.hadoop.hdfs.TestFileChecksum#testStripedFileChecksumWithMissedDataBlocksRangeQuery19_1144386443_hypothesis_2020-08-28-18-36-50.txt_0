reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805193814-172.17.0.21-1598640069141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-f38a083a-c4b2-43dc-b0a9-42d1a7a663bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-dbcdfe30-4beb-43fe-9afb-e05536896c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-a8f628dc-1438-4cd3-bf91-8bb1cc9f60a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-d47b7f1f-3755-4d3a-9394-06b788b97817,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-31873230-4e14-42f0-9e11-9df632d2d26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-f3d5b9fb-f6a6-4608-89c6-6978ec88cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-88cd8b01-a623-4868-a77d-d1f5b0e44fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-d2034431-c025-4176-8047-98ddc0c2a238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805193814-172.17.0.21-1598640069141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-f38a083a-c4b2-43dc-b0a9-42d1a7a663bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-dbcdfe30-4beb-43fe-9afb-e05536896c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-a8f628dc-1438-4cd3-bf91-8bb1cc9f60a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-d47b7f1f-3755-4d3a-9394-06b788b97817,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-31873230-4e14-42f0-9e11-9df632d2d26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-f3d5b9fb-f6a6-4608-89c6-6978ec88cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-88cd8b01-a623-4868-a77d-d1f5b0e44fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-d2034431-c025-4176-8047-98ddc0c2a238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794831700-172.17.0.21-1598640105228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-a4815f64-a5c3-4e8d-a29a-3ef3fb73aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-a90fe451-ead2-431d-8e89-ceeedb72a400,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-82fd5a7e-7a73-4b40-a2ef-8a6c74f4eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-48bc4419-a2c9-48ce-93d7-380d560a48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c9519b91-77c7-4e19-8bda-d88ec9d24ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-4074dcd5-2e76-4d22-ab21-1f3c1bf967b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-64c7b36e-15a9-4c5f-a2f3-c53215b3713d,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-1383cffe-236f-43fc-a21c-d44808f56c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794831700-172.17.0.21-1598640105228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-a4815f64-a5c3-4e8d-a29a-3ef3fb73aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-a90fe451-ead2-431d-8e89-ceeedb72a400,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-82fd5a7e-7a73-4b40-a2ef-8a6c74f4eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-48bc4419-a2c9-48ce-93d7-380d560a48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c9519b91-77c7-4e19-8bda-d88ec9d24ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-4074dcd5-2e76-4d22-ab21-1f3c1bf967b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-64c7b36e-15a9-4c5f-a2f3-c53215b3713d,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-1383cffe-236f-43fc-a21c-d44808f56c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461389146-172.17.0.21-1598640739328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-a3a4c27b-bb50-4143-bcc9-40709e9825e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-343ba9ce-b736-4c9a-b4c4-92b22aa8b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-c3a0ebb3-d16f-459b-a7e3-27568d6aa6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3c39970b-945e-45dc-90c0-e5cb5937a2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-2fc17c42-63e8-49d7-9f75-1530ffbc3813,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-98c246b0-52f5-4f31-80dc-1db6c65f94ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-3db668da-a78a-4725-aa8c-a1ba9e7b7bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-cd67b4e8-5acf-4839-8b60-3dec44f94a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461389146-172.17.0.21-1598640739328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-a3a4c27b-bb50-4143-bcc9-40709e9825e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-343ba9ce-b736-4c9a-b4c4-92b22aa8b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-c3a0ebb3-d16f-459b-a7e3-27568d6aa6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-3c39970b-945e-45dc-90c0-e5cb5937a2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-2fc17c42-63e8-49d7-9f75-1530ffbc3813,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-98c246b0-52f5-4f31-80dc-1db6c65f94ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-3db668da-a78a-4725-aa8c-a1ba9e7b7bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-cd67b4e8-5acf-4839-8b60-3dec44f94a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650153110-172.17.0.21-1598641486141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-a30199a0-ae59-4190-8be8-e4e9e1135692,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-c182587c-66f1-4a15-bc03-1f866e23908e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-e5c4bee8-017a-406c-a0bd-866fcc3f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-e5d6187f-5559-47ee-a39c-19d6f2aa728f,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-7e61afeb-3425-48a5-a2db-9dfc42355dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-d7d52e4b-fc4b-4780-8373-637d61b75051,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-e72a6409-15fb-4f76-81e1-5ef8637372f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-cd379998-760d-4f43-9ebf-7502b29ebbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650153110-172.17.0.21-1598641486141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-a30199a0-ae59-4190-8be8-e4e9e1135692,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-c182587c-66f1-4a15-bc03-1f866e23908e,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-e5c4bee8-017a-406c-a0bd-866fcc3f683e,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-e5d6187f-5559-47ee-a39c-19d6f2aa728f,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-7e61afeb-3425-48a5-a2db-9dfc42355dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-d7d52e4b-fc4b-4780-8373-637d61b75051,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-e72a6409-15fb-4f76-81e1-5ef8637372f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-cd379998-760d-4f43-9ebf-7502b29ebbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599207994-172.17.0.21-1598641979898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-36389b16-0dda-4b8f-85ef-d7c360423060,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-12f9942f-23df-4078-895c-355f614639ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-e2758432-39ad-4e67-880a-b55b27ce699c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-fbcf0a4b-20d7-4360-935e-f5ddf75a7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-bf315140-c079-4791-b0a2-f02bd8330071,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-e37920c5-3c02-4a30-a25c-972f4576fc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-ef84f13f-61aa-4255-a978-8d085bff3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-912d02aa-2f21-4263-862a-dea0f5397f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599207994-172.17.0.21-1598641979898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-36389b16-0dda-4b8f-85ef-d7c360423060,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-12f9942f-23df-4078-895c-355f614639ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-e2758432-39ad-4e67-880a-b55b27ce699c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-fbcf0a4b-20d7-4360-935e-f5ddf75a7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-bf315140-c079-4791-b0a2-f02bd8330071,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-e37920c5-3c02-4a30-a25c-972f4576fc69,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-ef84f13f-61aa-4255-a978-8d085bff3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-912d02aa-2f21-4263-862a-dea0f5397f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216426605-172.17.0.21-1598642163038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-26b78d9f-72f7-4085-b011-580a3eec7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-e2cb4a96-c2d0-4d0a-8b2c-893b2214398c,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-22e00e56-516c-4bfd-9959-caaa22258012,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-fc3d71c7-9167-4157-a37c-93d0c55868bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-7a181ded-0668-46e1-8545-49176f8e8098,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-c90559a9-2563-4b94-864b-0c0660ae40b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-79ae4880-80a2-4d31-9d0c-823f1a9f5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-6d324acb-f9b0-4959-b384-ff228065ef52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216426605-172.17.0.21-1598642163038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-26b78d9f-72f7-4085-b011-580a3eec7e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-e2cb4a96-c2d0-4d0a-8b2c-893b2214398c,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-22e00e56-516c-4bfd-9959-caaa22258012,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-fc3d71c7-9167-4157-a37c-93d0c55868bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-7a181ded-0668-46e1-8545-49176f8e8098,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-c90559a9-2563-4b94-864b-0c0660ae40b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-79ae4880-80a2-4d31-9d0c-823f1a9f5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-6d324acb-f9b0-4959-b384-ff228065ef52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621876975-172.17.0.21-1598642489188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-d85e9250-92b1-4fa0-8188-7030710cedd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-5628709c-b87f-410c-b8eb-06ef96c745d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-7af4f318-0da1-4d17-b34d-d158fb943bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-fed15448-1daf-4800-8083-0594fe1f4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-3583fcce-7456-4b3e-b5fa-40c822f77339,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-31aa4299-55fb-459b-90b2-3dd74077cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-a607ec42-ff06-4fae-84fa-bdef453db2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-0b9d4637-b191-4e5e-afbc-a25fb9a08b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621876975-172.17.0.21-1598642489188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-d85e9250-92b1-4fa0-8188-7030710cedd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-5628709c-b87f-410c-b8eb-06ef96c745d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-7af4f318-0da1-4d17-b34d-d158fb943bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-fed15448-1daf-4800-8083-0594fe1f4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-3583fcce-7456-4b3e-b5fa-40c822f77339,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-31aa4299-55fb-459b-90b2-3dd74077cf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-a607ec42-ff06-4fae-84fa-bdef453db2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-0b9d4637-b191-4e5e-afbc-a25fb9a08b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717294709-172.17.0.21-1598642532612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-ec156197-77f7-4796-831e-9f73d5f57889,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e19a1161-e080-438f-a201-ba375eb8d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-8c2208a9-73a2-41f6-aa94-90eea018391b,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-882cab63-9dcb-49b6-b857-629acc9a4054,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-18ce5547-751e-48c5-9c49-8922f7f20122,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4117815d-b053-4434-9245-3a22145ba10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e951b6bf-58fa-4aeb-9fb4-95eefb56effd,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-c61beee4-0670-4699-81cb-fdbf5d91b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717294709-172.17.0.21-1598642532612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32929,DS-ec156197-77f7-4796-831e-9f73d5f57889,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-e19a1161-e080-438f-a201-ba375eb8d4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-8c2208a9-73a2-41f6-aa94-90eea018391b,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-882cab63-9dcb-49b6-b857-629acc9a4054,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-18ce5547-751e-48c5-9c49-8922f7f20122,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-4117815d-b053-4434-9245-3a22145ba10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e951b6bf-58fa-4aeb-9fb4-95eefb56effd,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-c61beee4-0670-4699-81cb-fdbf5d91b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654745216-172.17.0.21-1598642571350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-b4bc3e84-efc5-4d19-9e01-78c326b55a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-1aec4c34-5914-4dde-8668-ca142aedc24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-7c9174d3-ef58-4fa1-8b4c-91cc469b851c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-e417f3c3-efc3-4538-8a02-7277afacb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-270de662-9bb4-4864-972d-6255b50a85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-7a31e192-3e98-4e6b-b934-199c2321e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-952df320-2f60-47c9-bc12-5115163dbc72,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2a221754-1c79-48dd-8ac7-3f30cc833e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654745216-172.17.0.21-1598642571350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-b4bc3e84-efc5-4d19-9e01-78c326b55a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-1aec4c34-5914-4dde-8668-ca142aedc24c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-7c9174d3-ef58-4fa1-8b4c-91cc469b851c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-e417f3c3-efc3-4538-8a02-7277afacb6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-270de662-9bb4-4864-972d-6255b50a85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-7a31e192-3e98-4e6b-b934-199c2321e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-952df320-2f60-47c9-bc12-5115163dbc72,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-2a221754-1c79-48dd-8ac7-3f30cc833e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632275647-172.17.0.21-1598642719402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-e6ed5559-96dd-4e88-b0a8-efc07c490e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-e915c4ad-08f4-4e79-8746-3422d7419ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-54df721d-e608-4450-848a-2d3c3f43b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-74a9ba16-b771-448f-983b-b5f387e63319,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-fd0b7a3b-5472-41f7-ad83-ec1911901264,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1f8fa539-71a7-414d-af02-b3db029a3111,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-6d4b8518-de24-495c-80f4-ba9d9c9fe9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-3a2dc71d-cd31-454c-8c2b-802eb0d072b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632275647-172.17.0.21-1598642719402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40434,DS-e6ed5559-96dd-4e88-b0a8-efc07c490e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-e915c4ad-08f4-4e79-8746-3422d7419ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-54df721d-e608-4450-848a-2d3c3f43b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-74a9ba16-b771-448f-983b-b5f387e63319,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-fd0b7a3b-5472-41f7-ad83-ec1911901264,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1f8fa539-71a7-414d-af02-b3db029a3111,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-6d4b8518-de24-495c-80f4-ba9d9c9fe9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-3a2dc71d-cd31-454c-8c2b-802eb0d072b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348283378-172.17.0.21-1598642865379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35209,DS-7fa414bd-54d6-4c72-b116-24828bb1bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a72bb0c2-20b1-4cb3-a65f-fa39c97847d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-dd40b62e-8e86-4f68-b829-e60cdb43cc78,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-1f16dbda-4f20-4d07-a5d9-60b7c8311c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8dcae71c-6542-4341-8f68-37e701fc78c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-925e1656-95cb-4bee-9e77-480af21859c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-aecbfb17-b413-47c2-b169-8b27f9005219,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-e08969e2-616c-45c1-a51c-08cdaa6bc545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348283378-172.17.0.21-1598642865379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35209,DS-7fa414bd-54d6-4c72-b116-24828bb1bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a72bb0c2-20b1-4cb3-a65f-fa39c97847d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-dd40b62e-8e86-4f68-b829-e60cdb43cc78,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-1f16dbda-4f20-4d07-a5d9-60b7c8311c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-8dcae71c-6542-4341-8f68-37e701fc78c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-925e1656-95cb-4bee-9e77-480af21859c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-aecbfb17-b413-47c2-b169-8b27f9005219,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-e08969e2-616c-45c1-a51c-08cdaa6bc545,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167878372-172.17.0.21-1598643333196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-42b4118f-6520-4572-84ab-602cb099a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-71356c23-427a-4cad-9bbc-5d905919c22a,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-5e69d1bd-a024-41fe-9dba-815c478a4215,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-78e6aaf3-b5a4-4c7a-9145-2d8f8107768a,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-802d9e1d-a618-4bf7-8114-eb8d4a86a099,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-9ddda7bf-2885-44f0-ad27-51ed9d651379,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-d3bab042-dfc5-424c-9584-df8ea3637e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-3445d93b-2f30-4282-ada9-0c4afa0efda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167878372-172.17.0.21-1598643333196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-42b4118f-6520-4572-84ab-602cb099a0af,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-71356c23-427a-4cad-9bbc-5d905919c22a,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-5e69d1bd-a024-41fe-9dba-815c478a4215,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-78e6aaf3-b5a4-4c7a-9145-2d8f8107768a,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-802d9e1d-a618-4bf7-8114-eb8d4a86a099,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-9ddda7bf-2885-44f0-ad27-51ed9d651379,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-d3bab042-dfc5-424c-9584-df8ea3637e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-3445d93b-2f30-4282-ada9-0c4afa0efda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422725866-172.17.0.21-1598643366273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-3f26bd2d-2123-49ba-8274-845ca7f73960,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-84c8fa2c-ba38-4377-8ab7-2b90f3222e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-bd7bd232-a5a7-4c20-b534-791480190ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-9792d5f8-4856-4ff8-8914-cd6e73d3662f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-511d8197-2aff-4d66-8820-4f03fdbc42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-cfe04280-a1de-4a54-99a2-f09f6ef94538,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bf6be609-7c3e-4516-a275-c09273b9b558,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-121e5048-067f-43de-85f6-c19772168405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422725866-172.17.0.21-1598643366273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-3f26bd2d-2123-49ba-8274-845ca7f73960,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-84c8fa2c-ba38-4377-8ab7-2b90f3222e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-bd7bd232-a5a7-4c20-b534-791480190ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-9792d5f8-4856-4ff8-8914-cd6e73d3662f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-511d8197-2aff-4d66-8820-4f03fdbc42ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-cfe04280-a1de-4a54-99a2-f09f6ef94538,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bf6be609-7c3e-4516-a275-c09273b9b558,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-121e5048-067f-43de-85f6-c19772168405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607858855-172.17.0.21-1598643641649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-8a702718-e6e5-4698-8002-eedac946f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-29926933-09f6-4fc0-8ef4-bc45330fa9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-a153060c-325d-4cd6-a654-75390c0d358d,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-6f210c86-6e23-4bb4-88b2-c99a40e9da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-627596b7-b3e8-4de7-ae3c-63bd6626063f,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-96880ae0-da39-4ddb-afcb-dddb1e9cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-689c0e45-62af-4d2c-b266-83d519191e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ed3344fd-0e69-497c-a0af-3b28018302c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607858855-172.17.0.21-1598643641649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-8a702718-e6e5-4698-8002-eedac946f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-29926933-09f6-4fc0-8ef4-bc45330fa9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-a153060c-325d-4cd6-a654-75390c0d358d,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-6f210c86-6e23-4bb4-88b2-c99a40e9da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-627596b7-b3e8-4de7-ae3c-63bd6626063f,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-96880ae0-da39-4ddb-afcb-dddb1e9cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-689c0e45-62af-4d2c-b266-83d519191e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ed3344fd-0e69-497c-a0af-3b28018302c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350873307-172.17.0.21-1598643819200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-551e24f8-32b2-4f42-b467-56e045a57b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-e4e0f066-55dc-4f45-9e79-adf718a2405f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-96b0c2eb-d021-45ae-9092-a4120161ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-56f6d6ed-a2dd-4620-adfa-879e2b52e218,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-07b52bb9-81d3-492e-b6ee-904c8059c944,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-dca39ba4-9c4d-44f8-bb26-40c6f9c28bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a773328a-b9c8-4341-9ece-71642f99a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-e9bf8035-47d3-40f0-842f-4c460fafcecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350873307-172.17.0.21-1598643819200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-551e24f8-32b2-4f42-b467-56e045a57b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-e4e0f066-55dc-4f45-9e79-adf718a2405f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-96b0c2eb-d021-45ae-9092-a4120161ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-56f6d6ed-a2dd-4620-adfa-879e2b52e218,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-07b52bb9-81d3-492e-b6ee-904c8059c944,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-dca39ba4-9c4d-44f8-bb26-40c6f9c28bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a773328a-b9c8-4341-9ece-71642f99a1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-e9bf8035-47d3-40f0-842f-4c460fafcecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461847548-172.17.0.21-1598643859961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-06527ae1-14a2-4052-a8ab-08edea75e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-6eaeba57-05f7-4c2c-937e-7033e279b823,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d63b9e2c-f7c6-4d49-b3d5-97aea9a77337,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-31d387e4-9dec-46e4-8ecb-3d7e30e42ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-6f574742-75f4-4ac4-b5c5-d14f4767957f,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-f129c76b-1684-4c28-ad67-d8e714fbed47,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-4a198539-5fbb-4aa6-b876-1cbb311e21c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-dc3cf84b-d92f-4038-b137-0266bdf89657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461847548-172.17.0.21-1598643859961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45950,DS-06527ae1-14a2-4052-a8ab-08edea75e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-6eaeba57-05f7-4c2c-937e-7033e279b823,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d63b9e2c-f7c6-4d49-b3d5-97aea9a77337,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-31d387e4-9dec-46e4-8ecb-3d7e30e42ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-6f574742-75f4-4ac4-b5c5-d14f4767957f,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-f129c76b-1684-4c28-ad67-d8e714fbed47,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-4a198539-5fbb-4aa6-b876-1cbb311e21c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-dc3cf84b-d92f-4038-b137-0266bdf89657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420037647-172.17.0.21-1598644034535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-b5587957-b225-46df-a28c-64e26e740e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-c4e59d92-d7a4-4687-9ea0-81285aff8804,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-c97cc7b8-4192-40c5-a767-80b13d1195a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-5339d06b-8469-482a-a085-77182c449bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-08b2d242-452f-4287-8eb3-dd302b97266e,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-adeb3e9b-39e8-41cf-9c2c-1d62eb8a1071,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-7cc9210b-486c-439d-8e91-47dff2034fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-8b4b2d11-a04a-4cec-a9ad-b3563f2b5fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420037647-172.17.0.21-1598644034535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43804,DS-b5587957-b225-46df-a28c-64e26e740e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-c4e59d92-d7a4-4687-9ea0-81285aff8804,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-c97cc7b8-4192-40c5-a767-80b13d1195a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-5339d06b-8469-482a-a085-77182c449bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-08b2d242-452f-4287-8eb3-dd302b97266e,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-adeb3e9b-39e8-41cf-9c2c-1d62eb8a1071,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-7cc9210b-486c-439d-8e91-47dff2034fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-8b4b2d11-a04a-4cec-a9ad-b3563f2b5fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719009858-172.17.0.21-1598644951098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-5c922d48-6787-4f95-b5dc-66c59987d568,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-7bfb313c-bdde-4f2f-ba7c-fcb0cc2fafb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-7004b72e-4cf5-4e65-85ee-cf6624389746,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-314f37c8-a8fa-49f2-b9c7-0341dac1ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-82bf44f1-9d23-49e4-a0b2-1e52e4f1991b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-19b3c1de-aaff-43b0-b158-8ee9450f9868,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-6b5c282a-cfdd-42d1-aa99-0aae9ac31b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-b76b4f09-c6af-4e5e-9e88-cf8e83904dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719009858-172.17.0.21-1598644951098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39631,DS-5c922d48-6787-4f95-b5dc-66c59987d568,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-7bfb313c-bdde-4f2f-ba7c-fcb0cc2fafb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-7004b72e-4cf5-4e65-85ee-cf6624389746,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-314f37c8-a8fa-49f2-b9c7-0341dac1ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-82bf44f1-9d23-49e4-a0b2-1e52e4f1991b,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-19b3c1de-aaff-43b0-b158-8ee9450f9868,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-6b5c282a-cfdd-42d1-aa99-0aae9ac31b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-b76b4f09-c6af-4e5e-9e88-cf8e83904dcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412216701-172.17.0.21-1598645018952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-77b0e843-4d1b-4767-81e5-349271f02d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-42de8776-f532-436e-a9e5-aff0d7e7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-5e0fb24e-c038-4ae0-8bba-26b7b53071a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-4342805d-488c-4ef7-ac1b-6081f6e32161,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-416f7055-33d7-4517-b385-257a5e10ed16,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c5a77081-cbcd-4f4f-bf77-a24b029aee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-5291468d-c94c-43df-a805-f59877831db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f931764a-deb0-438c-be8e-4c4f30519bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412216701-172.17.0.21-1598645018952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-77b0e843-4d1b-4767-81e5-349271f02d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-42de8776-f532-436e-a9e5-aff0d7e7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-5e0fb24e-c038-4ae0-8bba-26b7b53071a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-4342805d-488c-4ef7-ac1b-6081f6e32161,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-416f7055-33d7-4517-b385-257a5e10ed16,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-c5a77081-cbcd-4f4f-bf77-a24b029aee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-5291468d-c94c-43df-a805-f59877831db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f931764a-deb0-438c-be8e-4c4f30519bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5340
