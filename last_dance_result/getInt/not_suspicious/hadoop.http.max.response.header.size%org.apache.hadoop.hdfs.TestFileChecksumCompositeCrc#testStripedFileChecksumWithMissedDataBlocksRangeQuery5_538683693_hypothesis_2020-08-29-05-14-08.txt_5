reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511168018-172.17.0.9-1598678216970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-fe19a191-3838-43b4-8956-eb5a5debc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-fe57a248-bd33-4cb5-abed-caf502e9cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-29404a4b-2d4a-4941-b437-0cad9d3f96e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-b9fa310a-c473-4996-b0a9-c731a3fe0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-4405fc31-5efe-419c-9463-8adb677985c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-a98c7158-9061-4ade-82ac-25badc7f33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-c8b6266b-c0f3-43b8-b510-d32299a70482,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-abd5fe69-8a80-4202-a27a-1e25d5d71f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511168018-172.17.0.9-1598678216970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-fe19a191-3838-43b4-8956-eb5a5debc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-fe57a248-bd33-4cb5-abed-caf502e9cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-29404a4b-2d4a-4941-b437-0cad9d3f96e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-b9fa310a-c473-4996-b0a9-c731a3fe0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-4405fc31-5efe-419c-9463-8adb677985c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-a98c7158-9061-4ade-82ac-25badc7f33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-c8b6266b-c0f3-43b8-b510-d32299a70482,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-abd5fe69-8a80-4202-a27a-1e25d5d71f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393569961-172.17.0.9-1598678319907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-036f73e8-c4c2-4308-9dfd-86a6ac54523d,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-9e58d4d9-c682-40d6-910a-e5dcdcc76e27,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-63ce2dd7-cbab-4fe6-8692-aec47b4a607d,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-3941b5d9-e96d-4065-a477-d62a0675422c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-b06c58c4-8273-44c6-a503-1d3e96bc09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-13c9ac3e-aff5-4a25-a43a-1eaaeef0a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6b334e32-593e-4458-bb30-37002ec63fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-30b4dc5c-ec6c-4234-a7d2-7ce2ef8f13ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393569961-172.17.0.9-1598678319907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-036f73e8-c4c2-4308-9dfd-86a6ac54523d,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-9e58d4d9-c682-40d6-910a-e5dcdcc76e27,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-63ce2dd7-cbab-4fe6-8692-aec47b4a607d,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-3941b5d9-e96d-4065-a477-d62a0675422c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-b06c58c4-8273-44c6-a503-1d3e96bc09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-13c9ac3e-aff5-4a25-a43a-1eaaeef0a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-6b334e32-593e-4458-bb30-37002ec63fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-30b4dc5c-ec6c-4234-a7d2-7ce2ef8f13ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658549669-172.17.0.9-1598678350801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-d65e6a55-3e3b-4562-b0ca-21610e0e9693,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-2c2d35ac-55a1-4104-9545-72335e907788,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-64c67dcc-6933-469c-b62a-e2476d694c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-1bd30db3-2965-45fd-96b9-3069f90e45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-1d59543f-018f-4726-979d-cae739d33f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-ff2b04da-e15d-48d3-ab03-8d2ba5c715f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-1170a7bc-56a4-4fb1-8f3e-a089666e9e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-733ebc6a-8589-46bd-8363-d866b92b01d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658549669-172.17.0.9-1598678350801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-d65e6a55-3e3b-4562-b0ca-21610e0e9693,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-2c2d35ac-55a1-4104-9545-72335e907788,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-64c67dcc-6933-469c-b62a-e2476d694c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-1bd30db3-2965-45fd-96b9-3069f90e45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-1d59543f-018f-4726-979d-cae739d33f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-ff2b04da-e15d-48d3-ab03-8d2ba5c715f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-1170a7bc-56a4-4fb1-8f3e-a089666e9e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-733ebc6a-8589-46bd-8363-d866b92b01d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564598947-172.17.0.9-1598678578036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-571bdeac-c291-406b-8e94-cc427b75eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-146bef51-51e6-4eea-8147-7382be86c986,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-4c1ab53a-0e45-473a-b4eb-4a621bc64e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-6fa97468-869d-4215-b7a1-edc601e1fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-4ed75a1d-4f6c-4a6d-a5d7-4ae8686ec277,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-7a4e32da-a5dc-4bc5-b3da-cff0ca10f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-b886c7a6-7a05-440e-b523-c97ecbd18a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-51c0b638-b349-409b-ba7a-5f04f1835dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564598947-172.17.0.9-1598678578036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-571bdeac-c291-406b-8e94-cc427b75eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-146bef51-51e6-4eea-8147-7382be86c986,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-4c1ab53a-0e45-473a-b4eb-4a621bc64e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-6fa97468-869d-4215-b7a1-edc601e1fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-4ed75a1d-4f6c-4a6d-a5d7-4ae8686ec277,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-7a4e32da-a5dc-4bc5-b3da-cff0ca10f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-b886c7a6-7a05-440e-b523-c97ecbd18a47,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-51c0b638-b349-409b-ba7a-5f04f1835dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857058748-172.17.0.9-1598679432738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-8d3b5212-699b-4846-b4a0-3f8afbb97c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-41e80b8a-4df5-4fb5-bf16-f4d1829a6631,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-248e0369-7754-4fa6-9316-853fc709c899,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fb6b71ff-dd3a-44a6-ba39-47203b48f794,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-8e614b1e-b577-4ff9-9651-659a0e42ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fdc7920c-c49e-40b8-a3bb-719fb5fec65a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-26a808c7-ca41-448e-bf87-8f67319f8915,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-976c560b-5a27-478a-a616-03d25cd1cb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857058748-172.17.0.9-1598679432738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-8d3b5212-699b-4846-b4a0-3f8afbb97c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-41e80b8a-4df5-4fb5-bf16-f4d1829a6631,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-248e0369-7754-4fa6-9316-853fc709c899,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-fb6b71ff-dd3a-44a6-ba39-47203b48f794,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-8e614b1e-b577-4ff9-9651-659a0e42ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fdc7920c-c49e-40b8-a3bb-719fb5fec65a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-26a808c7-ca41-448e-bf87-8f67319f8915,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-976c560b-5a27-478a-a616-03d25cd1cb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830000905-172.17.0.9-1598679616799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-44ac249f-0a0d-43e5-8722-a41c7f4e3b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-b61f9615-e121-4214-80f3-9d65c9d9509f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-dc28565e-e9d8-473c-8b31-8f35422d528e,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-27b64464-4e2b-4286-b7f1-91348c451415,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-ef61e925-09ff-451c-80c3-43036c3e40de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-9a69f5e9-bc35-43f8-bf7a-7007d4b49e40,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-fdca93e2-b69b-472a-8c7e-c9b80d52e427,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-1502c381-7ba9-4925-a975-0fb0716c0931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830000905-172.17.0.9-1598679616799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-44ac249f-0a0d-43e5-8722-a41c7f4e3b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-b61f9615-e121-4214-80f3-9d65c9d9509f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-dc28565e-e9d8-473c-8b31-8f35422d528e,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-27b64464-4e2b-4286-b7f1-91348c451415,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-ef61e925-09ff-451c-80c3-43036c3e40de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-9a69f5e9-bc35-43f8-bf7a-7007d4b49e40,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-fdca93e2-b69b-472a-8c7e-c9b80d52e427,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-1502c381-7ba9-4925-a975-0fb0716c0931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145860449-172.17.0.9-1598679674818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-5ab9a877-8b58-427e-8f76-058e0533be49,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-092cdd12-bb35-4c9a-87ad-5e4e2414490f,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-2e33a4e0-6275-4223-ba90-27b57fc4157c,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-3106dde4-2d8a-40f9-aad2-ab9001e51476,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-036be45c-5e38-4e56-a9b0-1b96e587cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-0b89fa3f-1292-480b-a6a0-50b80ea1d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-c3917f96-7240-462c-abb5-8870dcf7b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-55fc37ac-9023-4e1f-bdd1-33b6783c3bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145860449-172.17.0.9-1598679674818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-5ab9a877-8b58-427e-8f76-058e0533be49,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-092cdd12-bb35-4c9a-87ad-5e4e2414490f,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-2e33a4e0-6275-4223-ba90-27b57fc4157c,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-3106dde4-2d8a-40f9-aad2-ab9001e51476,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-036be45c-5e38-4e56-a9b0-1b96e587cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-0b89fa3f-1292-480b-a6a0-50b80ea1d14e,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-c3917f96-7240-462c-abb5-8870dcf7b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-55fc37ac-9023-4e1f-bdd1-33b6783c3bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812788313-172.17.0.9-1598680051881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-d5a779a1-e583-4ba7-b6c7-ee67c7838d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-4ede6824-0a31-4f79-8a4f-cf666bca2128,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-52c95917-8b8c-41f0-80e8-29f727f8f878,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-6510bde4-6729-4d7e-b211-b0601a1173d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e2e1a655-c402-434d-8cb3-7456341de9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-c0183014-5c01-49f0-b60d-1fb18038e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aafd29a4-44d5-420f-888e-424fc9bc7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-355c747f-02f0-40c8-b3a3-b8648dce313e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812788313-172.17.0.9-1598680051881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34489,DS-d5a779a1-e583-4ba7-b6c7-ee67c7838d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-4ede6824-0a31-4f79-8a4f-cf666bca2128,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-52c95917-8b8c-41f0-80e8-29f727f8f878,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-6510bde4-6729-4d7e-b211-b0601a1173d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e2e1a655-c402-434d-8cb3-7456341de9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-c0183014-5c01-49f0-b60d-1fb18038e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aafd29a4-44d5-420f-888e-424fc9bc7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-355c747f-02f0-40c8-b3a3-b8648dce313e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373243309-172.17.0.9-1598681705429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-43e4a2fc-0745-4b0d-bdcd-e76599d7070f,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-806cc816-34f4-4786-ae8a-fcd1d47cf38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-965b8ff2-ed36-464d-aa83-b658c6ccf16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-b3742866-1239-4e9b-b973-5ecf6e1f6800,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-ca6686eb-76c4-490c-84e7-77ad46c6cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-06b06cfe-7818-4fa2-81b7-c515c92fe0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-98bb771a-740a-4341-a4ef-0efe05388e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-b96df05f-255b-471f-b025-d5598c89e929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373243309-172.17.0.9-1598681705429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-43e4a2fc-0745-4b0d-bdcd-e76599d7070f,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-806cc816-34f4-4786-ae8a-fcd1d47cf38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-965b8ff2-ed36-464d-aa83-b658c6ccf16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-b3742866-1239-4e9b-b973-5ecf6e1f6800,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-ca6686eb-76c4-490c-84e7-77ad46c6cb79,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-06b06cfe-7818-4fa2-81b7-c515c92fe0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-98bb771a-740a-4341-a4ef-0efe05388e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-b96df05f-255b-471f-b025-d5598c89e929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112238949-172.17.0.9-1598682557656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-20983507-b723-4319-ae90-88341dd7d198,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d3a9dcae-6f34-4196-939e-58a166830346,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-e079d409-e7da-43f3-ac6d-347f2851074d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-a4099300-39e7-45b4-8a72-868537f1c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-3243a0c8-9aec-4edf-8916-7b67a1b3ec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-f45f9c4d-8d5a-42f2-94fb-11ade43061b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5f49db38-c37e-4e13-94b1-be2352b11ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-fc881605-d6d3-42f4-95ea-36979994621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112238949-172.17.0.9-1598682557656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-20983507-b723-4319-ae90-88341dd7d198,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-d3a9dcae-6f34-4196-939e-58a166830346,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-e079d409-e7da-43f3-ac6d-347f2851074d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-a4099300-39e7-45b4-8a72-868537f1c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-3243a0c8-9aec-4edf-8916-7b67a1b3ec8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-f45f9c4d-8d5a-42f2-94fb-11ade43061b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5f49db38-c37e-4e13-94b1-be2352b11ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-fc881605-d6d3-42f4-95ea-36979994621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:NameNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246190795-172.17.0.9-1598682883082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-e602afe2-ccc2-4511-b76e-c5ae22303ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-eb6f72f4-5cb2-496e-8ac6-d02cfcf58dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-20ba9aa9-0564-4e3b-8c93-60e7e470d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-9f80fd84-77c6-4e8a-8169-0512d841e624,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-503171a4-392d-46d5-817e-cdb3264ad230,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-0b1ff882-dd0c-4abf-b873-2d2f1816c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-3973b1cf-8a60-4c05-a933-81eebcb22d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-08e80ec7-eaec-4e69-b4d9-7579e06b6614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246190795-172.17.0.9-1598682883082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-e602afe2-ccc2-4511-b76e-c5ae22303ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-eb6f72f4-5cb2-496e-8ac6-d02cfcf58dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-20ba9aa9-0564-4e3b-8c93-60e7e470d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-9f80fd84-77c6-4e8a-8169-0512d841e624,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-503171a4-392d-46d5-817e-cdb3264ad230,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-0b1ff882-dd0c-4abf-b873-2d2f1816c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-3973b1cf-8a60-4c05-a933-81eebcb22d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-08e80ec7-eaec-4e69-b4d9-7579e06b6614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4998
