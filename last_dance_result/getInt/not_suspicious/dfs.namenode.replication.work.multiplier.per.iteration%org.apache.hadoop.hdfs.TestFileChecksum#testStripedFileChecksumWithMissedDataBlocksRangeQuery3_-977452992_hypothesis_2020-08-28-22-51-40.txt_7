reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96336956-172.17.0.9-1598655149353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-310ddf3b-92e9-4fec-99ef-887bd1ce145e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-151e9df6-5602-48f7-84b7-38132c4e0963,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-3600fa9a-a58b-4f8e-9946-2f427ee5d955,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-c3b6a39c-9d8f-4ee7-86ac-ee755314be6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-f060ea79-0b1a-4217-b81e-4ae480dc72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-43c23190-e08b-4356-90ef-a8d0e9c4e215,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0281c3fb-48f8-4791-a768-1d8e704dea29,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-870089a7-473b-4a26-b7dc-e3058e73f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96336956-172.17.0.9-1598655149353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-310ddf3b-92e9-4fec-99ef-887bd1ce145e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-151e9df6-5602-48f7-84b7-38132c4e0963,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-3600fa9a-a58b-4f8e-9946-2f427ee5d955,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-c3b6a39c-9d8f-4ee7-86ac-ee755314be6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-f060ea79-0b1a-4217-b81e-4ae480dc72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-43c23190-e08b-4356-90ef-a8d0e9c4e215,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0281c3fb-48f8-4791-a768-1d8e704dea29,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-870089a7-473b-4a26-b7dc-e3058e73f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938119891-172.17.0.9-1598655340726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-d41f87a1-7386-4cff-9ca9-7514dea74e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-bef661f2-1180-4eab-9b60-2f908a8b1788,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-a404a834-716b-4c13-ac92-cea329babd51,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f5d3440-6446-4b9f-9faf-0e23ec0ea9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-089b04d2-45b0-49b9-a2cd-0aeb92ab52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-61b71f24-a7a9-4cad-9081-ab413862b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-eb8541ec-63ea-4163-9f15-2219e2a24757,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-78fbcedb-8385-4d1d-8ee7-3a1353884776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938119891-172.17.0.9-1598655340726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-d41f87a1-7386-4cff-9ca9-7514dea74e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-bef661f2-1180-4eab-9b60-2f908a8b1788,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-a404a834-716b-4c13-ac92-cea329babd51,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-5f5d3440-6446-4b9f-9faf-0e23ec0ea9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-089b04d2-45b0-49b9-a2cd-0aeb92ab52a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-61b71f24-a7a9-4cad-9081-ab413862b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-eb8541ec-63ea-4163-9f15-2219e2a24757,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-78fbcedb-8385-4d1d-8ee7-3a1353884776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968493927-172.17.0.9-1598655609750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41561,DS-4174fb0f-123e-457f-a870-b6fc85474c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-41b23bd8-cb9c-41ee-804a-33e26e6df044,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-84a97932-2914-4089-8e38-14eb910dbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-77da1197-0d24-4616-a05f-3e76ef69b074,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-48a2cf33-08fd-474a-be16-69e42fc2a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-fdcb7ca1-c126-4782-964c-12aec3ec25db,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-97d60041-04dd-47d8-9ee1-fba2b4aab8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-83839126-7830-475c-8569-430dd3916b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968493927-172.17.0.9-1598655609750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41561,DS-4174fb0f-123e-457f-a870-b6fc85474c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-41b23bd8-cb9c-41ee-804a-33e26e6df044,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-84a97932-2914-4089-8e38-14eb910dbde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-77da1197-0d24-4616-a05f-3e76ef69b074,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-48a2cf33-08fd-474a-be16-69e42fc2a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-fdcb7ca1-c126-4782-964c-12aec3ec25db,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-97d60041-04dd-47d8-9ee1-fba2b4aab8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-83839126-7830-475c-8569-430dd3916b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136464394-172.17.0.9-1598655786847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-1cee2497-62fc-4945-8d7f-bc233ab9e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-005ed694-9791-4d3e-9b5a-70d3f616df53,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-76458e9b-3065-4111-ac44-ac8c99c874d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-2698d1b2-ade1-4826-b286-12f88a853274,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-ff284ec2-57ff-4ceb-a101-43a522b28f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-287d3960-0042-49f0-b8a3-5ebddbc9da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-091466ba-f870-4cd7-bb19-1123ceed9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-6376a70f-af67-4370-ab93-d831e086ab8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136464394-172.17.0.9-1598655786847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38257,DS-1cee2497-62fc-4945-8d7f-bc233ab9e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-005ed694-9791-4d3e-9b5a-70d3f616df53,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-76458e9b-3065-4111-ac44-ac8c99c874d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-2698d1b2-ade1-4826-b286-12f88a853274,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-ff284ec2-57ff-4ceb-a101-43a522b28f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-287d3960-0042-49f0-b8a3-5ebddbc9da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-091466ba-f870-4cd7-bb19-1123ceed9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-6376a70f-af67-4370-ab93-d831e086ab8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375860449-172.17.0.9-1598655866180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-a40bca23-d084-48c0-92a3-3da151dfd505,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-1641c210-cd27-45f6-bda7-732f696c5131,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-335329e2-9bc3-4d59-b610-2375cda32123,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-1464b969-74fe-464d-a500-2036592cd358,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c45ec8dc-f337-427d-8a29-a122241e001e,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-88e969f1-f992-4b2e-a693-5d0cc91be7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4f0d6eff-2b1d-48d8-8e56-c0ac03c37b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-f3459973-8a60-4740-9412-9b73255da887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375860449-172.17.0.9-1598655866180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-a40bca23-d084-48c0-92a3-3da151dfd505,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-1641c210-cd27-45f6-bda7-732f696c5131,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-335329e2-9bc3-4d59-b610-2375cda32123,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-1464b969-74fe-464d-a500-2036592cd358,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-c45ec8dc-f337-427d-8a29-a122241e001e,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-88e969f1-f992-4b2e-a693-5d0cc91be7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4f0d6eff-2b1d-48d8-8e56-c0ac03c37b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-f3459973-8a60-4740-9412-9b73255da887,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683082080-172.17.0.9-1598656119027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-3c705559-b422-450f-8943-c6a0358b9159,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-c71ff077-4dc7-4986-968e-ec27bb1a8e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-bf888f79-54c9-4a20-8459-40e994f1a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-34f875f9-cc5a-4386-a01a-0207d5ad7147,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-af29896b-3e3d-42a8-adc0-ac2fb136a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-02b82afe-b5c9-44d8-82c7-172e88d12d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-82394c6e-17b2-425a-9a6a-0dc89b0072c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-0d180c21-de04-4f82-964f-7c9c521b4c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683082080-172.17.0.9-1598656119027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-3c705559-b422-450f-8943-c6a0358b9159,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-c71ff077-4dc7-4986-968e-ec27bb1a8e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-bf888f79-54c9-4a20-8459-40e994f1a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-34f875f9-cc5a-4386-a01a-0207d5ad7147,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-af29896b-3e3d-42a8-adc0-ac2fb136a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-02b82afe-b5c9-44d8-82c7-172e88d12d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-82394c6e-17b2-425a-9a6a-0dc89b0072c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-0d180c21-de04-4f82-964f-7c9c521b4c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874771194-172.17.0.9-1598656228108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-e3b5e985-e0b8-4097-bc16-93af3eacd7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-6594b2bb-d95c-4a60-a529-233d0a12df39,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-30353e24-608b-46cd-a26e-99c080640eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-dd987e88-81f6-4bed-ac7d-d1948622882c,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-68e3fff0-c9c9-4aba-b551-ca6ca82e41fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-755ccbc6-0142-4d95-8b49-a59c76fd76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-f26d5079-ee50-4045-b7bb-bbec4ea066e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-d700247c-7306-4f53-8f95-a25ed4a4df87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874771194-172.17.0.9-1598656228108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-e3b5e985-e0b8-4097-bc16-93af3eacd7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-6594b2bb-d95c-4a60-a529-233d0a12df39,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-30353e24-608b-46cd-a26e-99c080640eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-dd987e88-81f6-4bed-ac7d-d1948622882c,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-68e3fff0-c9c9-4aba-b551-ca6ca82e41fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-755ccbc6-0142-4d95-8b49-a59c76fd76ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-f26d5079-ee50-4045-b7bb-bbec4ea066e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-d700247c-7306-4f53-8f95-a25ed4a4df87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704619151-172.17.0.9-1598656402945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-fd29daac-db48-4664-abbd-17bc7cd91f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b01dd6b-846a-4a67-8adc-55f042c62f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-526928e7-fe83-4062-87be-b8f5d98a6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-bfe6377d-59e2-48a6-935a-f0d04ce8111e,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-4ffbd817-3e94-4f51-9c5c-151c7b824875,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c56205c4-a356-4c6e-bc1e-5ae263519f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-fb44ce3e-5948-4ab5-a802-b0f7030933a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-abde2c96-b86b-41d2-966f-c219bd2c4875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704619151-172.17.0.9-1598656402945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-fd29daac-db48-4664-abbd-17bc7cd91f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5b01dd6b-846a-4a67-8adc-55f042c62f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-526928e7-fe83-4062-87be-b8f5d98a6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-bfe6377d-59e2-48a6-935a-f0d04ce8111e,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-4ffbd817-3e94-4f51-9c5c-151c7b824875,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c56205c4-a356-4c6e-bc1e-5ae263519f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-fb44ce3e-5948-4ab5-a802-b0f7030933a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-abde2c96-b86b-41d2-966f-c219bd2c4875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152274479-172.17.0.9-1598656639062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-4d3c4828-112b-4317-9610-fce63aba5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-de676660-64b3-4549-addd-730e7b4a521c,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-2f8620f9-9340-4a39-ad9d-a9491ae4c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-3ce0e2ed-df13-43ee-aa3e-ddd83cffdb91,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-ae2345fc-1cec-4965-82b8-28d025b8dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-538e2e6e-ab5e-45a8-ac58-60062cb9bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-772141fb-1480-4d21-8505-5531887747dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c73bd788-9337-4b1b-88ba-6874a6129967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152274479-172.17.0.9-1598656639062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-4d3c4828-112b-4317-9610-fce63aba5db2,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-de676660-64b3-4549-addd-730e7b4a521c,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-2f8620f9-9340-4a39-ad9d-a9491ae4c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-3ce0e2ed-df13-43ee-aa3e-ddd83cffdb91,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-ae2345fc-1cec-4965-82b8-28d025b8dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-538e2e6e-ab5e-45a8-ac58-60062cb9bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-772141fb-1480-4d21-8505-5531887747dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c73bd788-9337-4b1b-88ba-6874a6129967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124275503-172.17.0.9-1598657140278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-511bbf32-4d27-4ce8-8e33-eccfc3c6636e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-ec15d90d-1433-4697-8901-2059a7765b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-2759729d-e79c-45fe-ab78-89b093cf7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a8a25d34-a101-46d9-b370-f3a7caf7826d,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-7b11470f-02e6-4284-8131-757d49250605,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-a0345190-b43d-4bf1-9881-f276764e1897,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f07bde46-c578-4564-830e-fa0510394005,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-0d088592-201b-43ad-a35c-1b850b94e188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124275503-172.17.0.9-1598657140278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-511bbf32-4d27-4ce8-8e33-eccfc3c6636e,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-ec15d90d-1433-4697-8901-2059a7765b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-2759729d-e79c-45fe-ab78-89b093cf7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a8a25d34-a101-46d9-b370-f3a7caf7826d,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-7b11470f-02e6-4284-8131-757d49250605,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-a0345190-b43d-4bf1-9881-f276764e1897,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f07bde46-c578-4564-830e-fa0510394005,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-0d088592-201b-43ad-a35c-1b850b94e188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719821050-172.17.0.9-1598657438178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-83471b30-b887-4232-8430-71a537ab6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-7fbeb2cb-99b2-4ea4-bcfd-6ca0dbe2c305,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-f9573fe4-677d-4d05-9527-4292ecce0487,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-58f39fe9-04ed-4a5a-b34b-3296e57a3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-50dec06b-dad3-4b71-b1a4-91b6e6d35da2,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-9d068f7b-fa1e-4b2d-a56d-79bf0b787dee,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-81fc0e1c-b715-4779-b221-7c4492cf3f50,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5bf57534-0ff8-4058-b814-5185685bf398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719821050-172.17.0.9-1598657438178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-83471b30-b887-4232-8430-71a537ab6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-7fbeb2cb-99b2-4ea4-bcfd-6ca0dbe2c305,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-f9573fe4-677d-4d05-9527-4292ecce0487,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-58f39fe9-04ed-4a5a-b34b-3296e57a3c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-50dec06b-dad3-4b71-b1a4-91b6e6d35da2,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-9d068f7b-fa1e-4b2d-a56d-79bf0b787dee,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-81fc0e1c-b715-4779-b221-7c4492cf3f50,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-5bf57534-0ff8-4058-b814-5185685bf398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461997821-172.17.0.9-1598657472423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-b69a3dc0-6c88-437c-b6cc-27de3270315a,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-16cb5a2e-05e8-45e9-8816-4a26b738f4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-2e6ca367-fa5b-455f-9fac-d0e66232c450,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-0b44a6d8-d3c3-4c8c-9d2d-76ad482bd805,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-c1c81780-4090-4f55-907a-1826751ede0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4ca09763-fbfc-4b09-97f2-5ddff2e42b76,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-eeed3a12-99b3-4100-8ba8-8362078cba28,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-aa87b6cb-e786-474b-9245-942b8f8d7ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461997821-172.17.0.9-1598657472423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-b69a3dc0-6c88-437c-b6cc-27de3270315a,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-16cb5a2e-05e8-45e9-8816-4a26b738f4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-2e6ca367-fa5b-455f-9fac-d0e66232c450,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-0b44a6d8-d3c3-4c8c-9d2d-76ad482bd805,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-c1c81780-4090-4f55-907a-1826751ede0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4ca09763-fbfc-4b09-97f2-5ddff2e42b76,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-eeed3a12-99b3-4100-8ba8-8362078cba28,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-aa87b6cb-e786-474b-9245-942b8f8d7ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326753666-172.17.0.9-1598657507234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-e150f60e-671b-40cd-8b34-ba67f3963ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-ac4cbba3-f01d-407b-b4dc-7496ae689d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-fd44101f-3b2a-4f4e-952f-234676f92e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-294a4adf-bc1f-4377-a21d-e805adcbe618,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-158e6512-023a-49f7-a7c5-0fd0cedb0ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-f083ac09-50ba-4278-ab0a-b5c53b78f871,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f56c1434-c836-4a51-b67f-3f23f6a48797,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-1d947c8a-98f0-4f7c-83cb-f3d6220542fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326753666-172.17.0.9-1598657507234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-e150f60e-671b-40cd-8b34-ba67f3963ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-ac4cbba3-f01d-407b-b4dc-7496ae689d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-fd44101f-3b2a-4f4e-952f-234676f92e51,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-294a4adf-bc1f-4377-a21d-e805adcbe618,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-158e6512-023a-49f7-a7c5-0fd0cedb0ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-f083ac09-50ba-4278-ab0a-b5c53b78f871,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f56c1434-c836-4a51-b67f-3f23f6a48797,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-1d947c8a-98f0-4f7c-83cb-f3d6220542fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21018067-172.17.0.9-1598657547612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-de9bd0f8-c677-4ea7-88c2-cd7a4a094f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-c71c7005-6168-470b-a333-5ddd9a2bc359,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-057e5f2c-1236-40e7-9548-18f9df9dfa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-0f5b0d0f-dd96-4663-a0fe-b9cbe4188373,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7f87fd6a-3761-4f06-8947-295777491eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-f287cb33-2f27-470c-a8f4-ab7b22b74a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-2c15538d-b1cb-44bb-bbd7-d73596c37de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-413be015-d8ad-4004-8777-7e370ffce1b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21018067-172.17.0.9-1598657547612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-de9bd0f8-c677-4ea7-88c2-cd7a4a094f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-c71c7005-6168-470b-a333-5ddd9a2bc359,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-057e5f2c-1236-40e7-9548-18f9df9dfa09,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-0f5b0d0f-dd96-4663-a0fe-b9cbe4188373,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-7f87fd6a-3761-4f06-8947-295777491eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-f287cb33-2f27-470c-a8f4-ab7b22b74a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-2c15538d-b1cb-44bb-bbd7-d73596c37de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-413be015-d8ad-4004-8777-7e370ffce1b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779544651-172.17.0.9-1598658319816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-78cf9a70-d85d-4348-8aeb-42ca17f6db20,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-60c78ccd-a428-46f2-bcdc-96e43e36805e,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6b4deba8-4bbe-42df-ad5e-c33a945d6835,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-26af7828-d2ba-48d2-b7d4-4a15c21b20e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-c6964d50-ae0f-44b4-a672-cee6b2f90f73,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-027fc993-5ff7-4545-8eec-f9028db29793,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-36e7ddfc-9e71-4485-886e-0df2d865b251,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-5dd54517-cf7f-43f5-8d89-fd3cb22e8131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779544651-172.17.0.9-1598658319816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-78cf9a70-d85d-4348-8aeb-42ca17f6db20,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-60c78ccd-a428-46f2-bcdc-96e43e36805e,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6b4deba8-4bbe-42df-ad5e-c33a945d6835,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-26af7828-d2ba-48d2-b7d4-4a15c21b20e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-c6964d50-ae0f-44b4-a672-cee6b2f90f73,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-027fc993-5ff7-4545-8eec-f9028db29793,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-36e7ddfc-9e71-4485-886e-0df2d865b251,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-5dd54517-cf7f-43f5-8d89-fd3cb22e8131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799927800-172.17.0.9-1598658423298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-e44e6b8a-d778-4a26-a4cd-e1a891bba11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-f30ffba1-42af-41a6-90cb-a5cd92ebd12d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-4de841c8-90b2-4786-be7f-80fd6fff63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-59e498f1-6d43-487f-ac4d-1f3b75087359,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-07e30ca5-a219-46ba-9383-2c1726c5e834,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-3d7bfab4-61a2-4589-ad50-08c61271f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-08ad4617-4e32-41f1-aa57-a0b2e127aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-017342a7-b658-4cb2-8d98-75e5460bfe83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799927800-172.17.0.9-1598658423298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-e44e6b8a-d778-4a26-a4cd-e1a891bba11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-f30ffba1-42af-41a6-90cb-a5cd92ebd12d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-4de841c8-90b2-4786-be7f-80fd6fff63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-59e498f1-6d43-487f-ac4d-1f3b75087359,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-07e30ca5-a219-46ba-9383-2c1726c5e834,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-3d7bfab4-61a2-4589-ad50-08c61271f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-08ad4617-4e32-41f1-aa57-a0b2e127aa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-017342a7-b658-4cb2-8d98-75e5460bfe83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527461539-172.17.0.9-1598658843683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-49328f55-0283-4fef-b6b6-ecac0427a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-81a86c6a-a8ec-4db2-96fc-e1ac714bb367,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-d41cc0f3-09a0-4302-9dca-c37cb57deaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-e28037ec-5092-4d2b-97db-883c5092446f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-c68ee75a-5cfc-458d-bd94-c26297d71c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-9fa1fc91-9156-405a-a473-b0917ff8cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-899cc77f-ebae-4997-9c0c-8c4c1e7e93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-0d5bb7d3-f4f9-427a-b510-d2a2ca729275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527461539-172.17.0.9-1598658843683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-49328f55-0283-4fef-b6b6-ecac0427a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-81a86c6a-a8ec-4db2-96fc-e1ac714bb367,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-d41cc0f3-09a0-4302-9dca-c37cb57deaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-e28037ec-5092-4d2b-97db-883c5092446f,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-c68ee75a-5cfc-458d-bd94-c26297d71c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-9fa1fc91-9156-405a-a473-b0917ff8cc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-899cc77f-ebae-4997-9c0c-8c4c1e7e93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-0d5bb7d3-f4f9-427a-b510-d2a2ca729275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728430025-172.17.0.9-1598658939530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45354,DS-8091b5cc-0a6e-48b5-9655-15d417add18d,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-f9df2e9b-d28d-43f7-a28d-a4d03f4629d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-7db9a1dd-d1f8-4cd2-a9ec-0f4a48ee85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-81794934-499b-425b-84ef-fbc6bc65bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-acb61d8f-ff75-44c1-b936-4c4877df639e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-84922d35-21df-4142-935d-dc4bb569899d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-bff4a0ca-5b0d-4e8f-a63c-cdcdb79305b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c1976b2f-d733-4025-896d-74a21442e432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728430025-172.17.0.9-1598658939530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45354,DS-8091b5cc-0a6e-48b5-9655-15d417add18d,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-f9df2e9b-d28d-43f7-a28d-a4d03f4629d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-7db9a1dd-d1f8-4cd2-a9ec-0f4a48ee85c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-81794934-499b-425b-84ef-fbc6bc65bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-acb61d8f-ff75-44c1-b936-4c4877df639e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-84922d35-21df-4142-935d-dc4bb569899d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-bff4a0ca-5b0d-4e8f-a63c-cdcdb79305b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c1976b2f-d733-4025-896d-74a21442e432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878910949-172.17.0.9-1598659211092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-6ab21fed-262b-42bc-82e1-ba39f16bfe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e030d3e6-f1d9-4626-a0da-59931e73085d,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-041ef1d0-0d82-4d9f-a7e2-00aa7119e56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-56883320-b677-41e3-8ec8-67813ee6d628,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-7802bf4c-56a9-40c0-810f-8a20d467811f,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-1abacbf1-30e5-4426-a081-3d165399a331,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-f74306f5-0db9-47ca-8e33-1370cc714131,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-43f4c90d-3b3a-44f9-a97f-fb08ab3a6e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878910949-172.17.0.9-1598659211092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-6ab21fed-262b-42bc-82e1-ba39f16bfe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e030d3e6-f1d9-4626-a0da-59931e73085d,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-041ef1d0-0d82-4d9f-a7e2-00aa7119e56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-56883320-b677-41e3-8ec8-67813ee6d628,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-7802bf4c-56a9-40c0-810f-8a20d467811f,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-1abacbf1-30e5-4426-a081-3d165399a331,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-f74306f5-0db9-47ca-8e33-1370cc714131,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-43f4c90d-3b3a-44f9-a97f-fb08ab3a6e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144021878-172.17.0.9-1598660047739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-5de31d52-6cb1-4538-b28d-f74488e86de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-fae07b7b-befb-49ef-9320-1e943f5888b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-b1d355e9-1ad5-4ac8-9ba0-7337122ffeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-56e4d655-23f4-40a1-90f7-0ef711057fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f18cd3e2-2154-4cad-beaf-a87fd7f819f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-53391ee1-d795-4f99-bd2a-ce1939d5965b,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-093bae0d-2584-41ed-b9fc-96b756ff716f,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-59205ce5-85a7-451f-a03d-255b7bede40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144021878-172.17.0.9-1598660047739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-5de31d52-6cb1-4538-b28d-f74488e86de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-fae07b7b-befb-49ef-9320-1e943f5888b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-b1d355e9-1ad5-4ac8-9ba0-7337122ffeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-56e4d655-23f4-40a1-90f7-0ef711057fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f18cd3e2-2154-4cad-beaf-a87fd7f819f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-53391ee1-d795-4f99-bd2a-ce1939d5965b,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-093bae0d-2584-41ed-b9fc-96b756ff716f,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-59205ce5-85a7-451f-a03d-255b7bede40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 2
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608787733-172.17.0.9-1598660347582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45917,DS-a026a33b-4a54-4fcd-b769-6d85a57d1786,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-64a031d2-4193-4758-bb73-6ef06eaca07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-a24a0170-1192-4ced-91c0-967262390d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c31d5387-08cc-4cf8-873d-012500e24036,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-46c1903d-23ab-4c0b-a3a4-a64d6b16de97,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-bac9b70a-c270-45b0-bd0a-c2f56c3f24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2f55d70b-a4aa-413b-b225-c23cea404681,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-edbb9914-96b8-4bda-a8d5-870643f43267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608787733-172.17.0.9-1598660347582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45917,DS-a026a33b-4a54-4fcd-b769-6d85a57d1786,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-64a031d2-4193-4758-bb73-6ef06eaca07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-a24a0170-1192-4ced-91c0-967262390d71,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-c31d5387-08cc-4cf8-873d-012500e24036,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-46c1903d-23ab-4c0b-a3a4-a64d6b16de97,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-bac9b70a-c270-45b0-bd0a-c2f56c3f24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2f55d70b-a4aa-413b-b225-c23cea404681,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-edbb9914-96b8-4bda-a8d5-870643f43267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5262
