reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042472467-172.17.0.21-1598553713823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-dd5f0d78-12b5-4932-90eb-bf3eb2b7ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5aa93d28-b252-4704-bea0-1df5ed7b59cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-fa064724-33e3-42b4-bac3-ed4affdb9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-df097737-11d4-460d-bdf4-1e6481e27658,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-c4a94e1c-9594-4e57-90ec-c5b128251f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-eb0217c0-c276-4bed-a0ce-7487900b2877,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-b5e87b6d-a7d3-4117-86e4-f3c7709b6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-e41d5e8a-d851-4e47-ac88-8a6e256804a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042472467-172.17.0.21-1598553713823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-dd5f0d78-12b5-4932-90eb-bf3eb2b7ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5aa93d28-b252-4704-bea0-1df5ed7b59cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-fa064724-33e3-42b4-bac3-ed4affdb9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-df097737-11d4-460d-bdf4-1e6481e27658,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-c4a94e1c-9594-4e57-90ec-c5b128251f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-eb0217c0-c276-4bed-a0ce-7487900b2877,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-b5e87b6d-a7d3-4117-86e4-f3c7709b6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-e41d5e8a-d851-4e47-ac88-8a6e256804a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073834435-172.17.0.21-1598554034502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-539397c7-6001-4f20-8830-1dcdc6e2116e,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-bc2baf34-bbee-4707-8da1-5ee4cef49d30,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-5d4f873e-3a79-438c-a724-acb8b9679d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-9d3b7d24-49e6-444f-a861-58660ba7c34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-1ba515cb-aeb6-4788-a92b-a2ba758c028f,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-0c25d84b-6b54-4785-bb7d-67525a35789d,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-cf966c0d-c3bd-4601-9e66-c2b03ffc29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-364d2efb-9560-4682-ba6c-78736a64ea82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073834435-172.17.0.21-1598554034502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-539397c7-6001-4f20-8830-1dcdc6e2116e,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-bc2baf34-bbee-4707-8da1-5ee4cef49d30,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-5d4f873e-3a79-438c-a724-acb8b9679d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-9d3b7d24-49e6-444f-a861-58660ba7c34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-1ba515cb-aeb6-4788-a92b-a2ba758c028f,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-0c25d84b-6b54-4785-bb7d-67525a35789d,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-cf966c0d-c3bd-4601-9e66-c2b03ffc29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-364d2efb-9560-4682-ba6c-78736a64ea82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487587783-172.17.0.21-1598554183256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-d6435c00-fe78-4581-807c-a31613060373,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-52c200f8-bc46-43e8-a332-ea88be9986f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-7e1057aa-28ed-4660-b3e6-6b4a6113a65e,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-71018c78-5f37-427a-9715-ba22f855b579,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-2255d9d2-95af-453e-8734-385a3ad1c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-5b9d03dc-44f1-430c-b053-0bf042c533db,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8b9fa154-892d-4192-ab60-993b802d18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-f13e094a-ef28-4b1f-9be1-254a34c963f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487587783-172.17.0.21-1598554183256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-d6435c00-fe78-4581-807c-a31613060373,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-52c200f8-bc46-43e8-a332-ea88be9986f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-7e1057aa-28ed-4660-b3e6-6b4a6113a65e,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-71018c78-5f37-427a-9715-ba22f855b579,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-2255d9d2-95af-453e-8734-385a3ad1c4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-5b9d03dc-44f1-430c-b053-0bf042c533db,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-8b9fa154-892d-4192-ab60-993b802d18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-f13e094a-ef28-4b1f-9be1-254a34c963f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632958547-172.17.0.21-1598554485312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37851,DS-f98ec1f3-bb41-4d84-8430-3ff572aa2d18,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-ea3684df-3786-4a06-bf65-7fd82952dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-998e1d2f-1559-4207-818d-06feb64fbea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-231fb6d3-c927-4d9d-b7da-7fdd0345cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-dc21f636-0296-4b47-9f2b-5129a6939cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-512f60e1-86ab-41aa-8c69-cce679682535,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-c1f479ba-ff4d-49f8-a7e3-a60701c37991,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-78c85130-1006-40d1-9165-f002b98afa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632958547-172.17.0.21-1598554485312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37851,DS-f98ec1f3-bb41-4d84-8430-3ff572aa2d18,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-ea3684df-3786-4a06-bf65-7fd82952dc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-998e1d2f-1559-4207-818d-06feb64fbea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-231fb6d3-c927-4d9d-b7da-7fdd0345cd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-dc21f636-0296-4b47-9f2b-5129a6939cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-512f60e1-86ab-41aa-8c69-cce679682535,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-c1f479ba-ff4d-49f8-a7e3-a60701c37991,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-78c85130-1006-40d1-9165-f002b98afa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083422525-172.17.0.21-1598554979570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-8d14979a-69f1-4316-96e5-695cb76de6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f0ae433c-9c10-48ef-834f-f6ca633ca4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-02bf13db-8134-4cfe-9761-8d8bcc2085eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-2ef05e35-d15b-4651-8571-a756be359165,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-9bc9acd3-4e0c-4128-85ff-2570d82f636a,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-2560639c-d55f-48d1-ab72-3cad033fa23a,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-fc55653b-5101-4202-b120-35a78410281e,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-92b1a091-2ef9-4dd0-9dd4-2bebcc7bbe48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083422525-172.17.0.21-1598554979570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-8d14979a-69f1-4316-96e5-695cb76de6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-f0ae433c-9c10-48ef-834f-f6ca633ca4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-02bf13db-8134-4cfe-9761-8d8bcc2085eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-2ef05e35-d15b-4651-8571-a756be359165,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-9bc9acd3-4e0c-4128-85ff-2570d82f636a,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-2560639c-d55f-48d1-ab72-3cad033fa23a,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-fc55653b-5101-4202-b120-35a78410281e,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-92b1a091-2ef9-4dd0-9dd4-2bebcc7bbe48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073849616-172.17.0.21-1598555054352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-9c39a950-42ae-4e10-818a-83280ed8fc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-6c44b2be-235e-4f0e-8341-cb02876e0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-00b17bc2-e487-4c94-a348-cd20a45606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-2cc89f0b-dc49-4c2e-8122-17875d43864a,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-faad4b98-b978-413b-8493-2c7cd405e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-b3aaf25d-afec-4c9a-8e75-f1db8d310065,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-787d1d42-bd98-4e9d-95b9-ed9bca03c380,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-1422c0ae-d372-4ddb-9be3-3313015d3bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073849616-172.17.0.21-1598555054352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-9c39a950-42ae-4e10-818a-83280ed8fc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-6c44b2be-235e-4f0e-8341-cb02876e0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-00b17bc2-e487-4c94-a348-cd20a45606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-2cc89f0b-dc49-4c2e-8122-17875d43864a,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-faad4b98-b978-413b-8493-2c7cd405e64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-b3aaf25d-afec-4c9a-8e75-f1db8d310065,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-787d1d42-bd98-4e9d-95b9-ed9bca03c380,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-1422c0ae-d372-4ddb-9be3-3313015d3bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098784027-172.17.0.21-1598555344572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-50858fdc-db32-4a5d-ad4d-64f19df450a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-dd138675-4929-4e98-ad5f-0e73b3ab0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-73053865-16a6-469e-928b-0735595cf1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-52747961-8828-497e-b817-da729df9b307,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-f8b9a01e-9df7-4f96-9f1e-e9e64b70c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-c0c436a2-dd74-44e2-b9eb-b7f0159be2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-3a549162-3e41-4d97-8751-3b9de1428fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-70444a3b-9581-495a-9440-5925ca441c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098784027-172.17.0.21-1598555344572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-50858fdc-db32-4a5d-ad4d-64f19df450a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-dd138675-4929-4e98-ad5f-0e73b3ab0e50,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-73053865-16a6-469e-928b-0735595cf1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-52747961-8828-497e-b817-da729df9b307,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-f8b9a01e-9df7-4f96-9f1e-e9e64b70c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-c0c436a2-dd74-44e2-b9eb-b7f0159be2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-3a549162-3e41-4d97-8751-3b9de1428fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-70444a3b-9581-495a-9440-5925ca441c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772237417-172.17.0.21-1598555417955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45999,DS-2069a2b4-52ed-4bc2-8a40-3cbdba6b5183,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-6e7a9d4a-73b0-4d5f-b12d-c2fbb7fd1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-c584b76b-ee6f-4aee-b1cc-f201dd844a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-69e4ac67-ec94-42b1-8f11-ee963f451770,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-74f92a3e-156d-4788-a0a7-528771d05935,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6968676c-ea38-4b5d-8430-35d87614a132,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-9c24af8e-a7d6-4e15-ba34-1ca0cda4c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-17c84243-9972-492e-a0c2-46ae2eee0def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772237417-172.17.0.21-1598555417955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45999,DS-2069a2b4-52ed-4bc2-8a40-3cbdba6b5183,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-6e7a9d4a-73b0-4d5f-b12d-c2fbb7fd1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-c584b76b-ee6f-4aee-b1cc-f201dd844a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-69e4ac67-ec94-42b1-8f11-ee963f451770,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-74f92a3e-156d-4788-a0a7-528771d05935,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6968676c-ea38-4b5d-8430-35d87614a132,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-9c24af8e-a7d6-4e15-ba34-1ca0cda4c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-17c84243-9972-492e-a0c2-46ae2eee0def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479036426-172.17.0.21-1598555908072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-4dc85d8d-0240-482a-85d1-265861318b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-85ef83fd-8612-464d-a0f2-794e57e4d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-bdd1103f-0014-44f3-9891-1e8bfa8ca7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-a6c8a781-56dd-4017-bb79-d6f38956c94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3fe88fc8-03dc-44e0-b2ce-f0b56f1778f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-909042af-4a7d-4b8b-8e06-2873eb3e49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-6b95fca6-9047-4431-9468-c6b3845a5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-4ba17401-576f-4444-a1c9-342a1fd2d704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479036426-172.17.0.21-1598555908072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-4dc85d8d-0240-482a-85d1-265861318b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-85ef83fd-8612-464d-a0f2-794e57e4d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-bdd1103f-0014-44f3-9891-1e8bfa8ca7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-a6c8a781-56dd-4017-bb79-d6f38956c94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-3fe88fc8-03dc-44e0-b2ce-f0b56f1778f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-909042af-4a7d-4b8b-8e06-2873eb3e49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-6b95fca6-9047-4431-9468-c6b3845a5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-4ba17401-576f-4444-a1c9-342a1fd2d704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196334321-172.17.0.21-1598556340793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-c1021aab-ee00-408d-87dc-c028b4f994d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-2d17f69c-5ef5-4c89-8ce8-819b0165fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-28bb50d1-c7a2-4771-8ab2-299c2980bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-0784b6f5-fafe-466e-a2aa-56c79e11bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-e18919ce-936a-41c8-a3f2-717685e4854d,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-dcae38e7-63de-4106-87d9-464d6ba9732c,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-aa24a777-e9a4-4382-8efb-c6ff88451949,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-fedc502f-aeed-4dd6-bd3a-5f3b3cc93b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196334321-172.17.0.21-1598556340793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43543,DS-c1021aab-ee00-408d-87dc-c028b4f994d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-2d17f69c-5ef5-4c89-8ce8-819b0165fda8,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-28bb50d1-c7a2-4771-8ab2-299c2980bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-0784b6f5-fafe-466e-a2aa-56c79e11bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-e18919ce-936a-41c8-a3f2-717685e4854d,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-dcae38e7-63de-4106-87d9-464d6ba9732c,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-aa24a777-e9a4-4382-8efb-c6ff88451949,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-fedc502f-aeed-4dd6-bd3a-5f3b3cc93b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751151111-172.17.0.21-1598556457901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-31401f53-74ab-44a1-a721-2f799581f024,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6ce9fcef-232a-4a2a-a2fb-34c5c76826c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-24df862e-0bf4-42e7-9976-a2022ee2214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f015c36d-50cd-40cc-a938-84a5326942af,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-5407f5c4-4774-4aa7-90f7-e33086aa4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-fb787f67-083f-4b37-a928-c67e2c04b218,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-77d37214-315c-4ae3-b382-a67b8c965813,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-76a3ef8e-0f40-4ffe-ba0b-363be1587b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751151111-172.17.0.21-1598556457901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-31401f53-74ab-44a1-a721-2f799581f024,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6ce9fcef-232a-4a2a-a2fb-34c5c76826c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-24df862e-0bf4-42e7-9976-a2022ee2214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f015c36d-50cd-40cc-a938-84a5326942af,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-5407f5c4-4774-4aa7-90f7-e33086aa4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-fb787f67-083f-4b37-a928-c67e2c04b218,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-77d37214-315c-4ae3-b382-a67b8c965813,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-76a3ef8e-0f40-4ffe-ba0b-363be1587b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351340999-172.17.0.21-1598556915971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-afa7b5a4-90fb-44a7-9318-af09017301d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-05156fbd-c86c-4ce2-8d26-1b0bb4835b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-0e95c801-dda8-446b-9890-11bdb22e47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-cd57105f-69fe-495d-a40c-dc0243f0d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-ef696828-d395-4bb8-8498-f3b8ac926d40,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-cba77cae-9c66-4db1-bd32-abda53b14dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-783f7a39-4ef5-4d83-bb10-e847f3683ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1e2bc7dc-6bc1-4853-a29b-5eec647a2b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351340999-172.17.0.21-1598556915971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-afa7b5a4-90fb-44a7-9318-af09017301d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-05156fbd-c86c-4ce2-8d26-1b0bb4835b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-0e95c801-dda8-446b-9890-11bdb22e47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-cd57105f-69fe-495d-a40c-dc0243f0d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-ef696828-d395-4bb8-8498-f3b8ac926d40,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-cba77cae-9c66-4db1-bd32-abda53b14dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-783f7a39-4ef5-4d83-bb10-e847f3683ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-1e2bc7dc-6bc1-4853-a29b-5eec647a2b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354764623-172.17.0.21-1598557943728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-2f90d670-bf94-4add-98d9-047ebc9ae26f,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-d2da32ff-2519-40cd-a615-3a349efa585d,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-0448cbda-7b03-4316-9cd5-70427e520cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-ff9697c0-87cd-4e29-afd7-9a4c609a2142,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-3c6aaaa6-323b-4f7a-90de-74f02baa1b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-dbe8dce3-72f6-467c-b603-e9c95f4ca27c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-b5e25214-101c-436f-954d-199cf7eb09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-705eff2c-c417-4e40-b4b3-d73addea36c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354764623-172.17.0.21-1598557943728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-2f90d670-bf94-4add-98d9-047ebc9ae26f,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-d2da32ff-2519-40cd-a615-3a349efa585d,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-0448cbda-7b03-4316-9cd5-70427e520cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-ff9697c0-87cd-4e29-afd7-9a4c609a2142,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-3c6aaaa6-323b-4f7a-90de-74f02baa1b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-dbe8dce3-72f6-467c-b603-e9c95f4ca27c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-b5e25214-101c-436f-954d-199cf7eb09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-705eff2c-c417-4e40-b4b3-d73addea36c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350754407-172.17.0.21-1598557978911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-97d5e687-64e8-40d2-92d3-4e092a46e125,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-3bdeff9d-5732-454b-aa30-e6a9452ad5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-3694e09e-9343-4dd7-ae5a-a1380dfd1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-89206ec6-fc3c-4da2-8157-2a9d6b462c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-e8a73431-f67a-4d08-bdfa-1de1eb799294,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e0460593-993c-4950-9e29-8da8a0f08c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-2b3d05d5-756a-430a-8faf-29b791015cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-a2e7556d-41be-4104-81c5-505acc8d98bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350754407-172.17.0.21-1598557978911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-97d5e687-64e8-40d2-92d3-4e092a46e125,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-3bdeff9d-5732-454b-aa30-e6a9452ad5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-3694e09e-9343-4dd7-ae5a-a1380dfd1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-89206ec6-fc3c-4da2-8157-2a9d6b462c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-e8a73431-f67a-4d08-bdfa-1de1eb799294,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-e0460593-993c-4950-9e29-8da8a0f08c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-2b3d05d5-756a-430a-8faf-29b791015cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-a2e7556d-41be-4104-81c5-505acc8d98bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415006199-172.17.0.21-1598558066889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39360,DS-0f835bdc-823a-44a1-8bde-00f17aaaef37,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-29de2065-54ff-4caf-bd99-ebfa1c42bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-7a1dffb0-554b-4996-b0ae-96d01393e798,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-abfb5f86-604d-4688-8ce0-9f68046e3393,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-28984abc-d061-4787-b8e2-2b085709f124,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-ce8f1428-9dc9-4b09-b1aa-18d67303c219,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-efc3906d-914f-4d3e-90a2-d023fab77ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-e17978da-b9bb-4d39-bd52-17b577c08348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415006199-172.17.0.21-1598558066889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39360,DS-0f835bdc-823a-44a1-8bde-00f17aaaef37,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-29de2065-54ff-4caf-bd99-ebfa1c42bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-7a1dffb0-554b-4996-b0ae-96d01393e798,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-abfb5f86-604d-4688-8ce0-9f68046e3393,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-28984abc-d061-4787-b8e2-2b085709f124,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-ce8f1428-9dc9-4b09-b1aa-18d67303c219,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-efc3906d-914f-4d3e-90a2-d023fab77ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-e17978da-b9bb-4d39-bd52-17b577c08348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433503447-172.17.0.21-1598558103553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-71df6d21-cf55-4094-90ca-f82c3abc37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-fea2a1ab-1c64-49b4-9373-ccc232adec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-41fd143e-a0f0-4cf6-acae-a3b49614d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-31f4fd8c-fcf6-4548-82e0-902e0c5a193e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-5acb1f8d-56ab-4fb9-b4df-1901e37f5192,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-17e1de02-b152-4641-80fd-932fabcff699,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-80d6380f-f78c-411e-bfd9-b2823c2da4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-14e4b4bc-c989-406c-a02a-5e76f03619e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433503447-172.17.0.21-1598558103553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-71df6d21-cf55-4094-90ca-f82c3abc37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-fea2a1ab-1c64-49b4-9373-ccc232adec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-41fd143e-a0f0-4cf6-acae-a3b49614d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-31f4fd8c-fcf6-4548-82e0-902e0c5a193e,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-5acb1f8d-56ab-4fb9-b4df-1901e37f5192,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-17e1de02-b152-4641-80fd-932fabcff699,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-80d6380f-f78c-411e-bfd9-b2823c2da4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-14e4b4bc-c989-406c-a02a-5e76f03619e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241065557-172.17.0.21-1598558480448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-1094af15-0019-4bd0-8b51-6435e347bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-3005d599-0073-4164-a944-3de9564ab214,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-7f594764-a678-4e92-9ad0-c6d4b23cd878,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-24094043-8217-4eea-976b-4ae100aab976,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-b6eab2f0-074e-42e1-86ff-d17db03a9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-2e1c52d5-daaf-4c40-ac58-64a05611c5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-95db7a6e-fca6-4e69-b237-402a092bfe06,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-424fcb4b-b7f6-4c8e-8ff8-3e5a8682dacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241065557-172.17.0.21-1598558480448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-1094af15-0019-4bd0-8b51-6435e347bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-3005d599-0073-4164-a944-3de9564ab214,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-7f594764-a678-4e92-9ad0-c6d4b23cd878,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-24094043-8217-4eea-976b-4ae100aab976,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-b6eab2f0-074e-42e1-86ff-d17db03a9a71,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-2e1c52d5-daaf-4c40-ac58-64a05611c5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-95db7a6e-fca6-4e69-b237-402a092bfe06,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-424fcb4b-b7f6-4c8e-8ff8-3e5a8682dacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5221
