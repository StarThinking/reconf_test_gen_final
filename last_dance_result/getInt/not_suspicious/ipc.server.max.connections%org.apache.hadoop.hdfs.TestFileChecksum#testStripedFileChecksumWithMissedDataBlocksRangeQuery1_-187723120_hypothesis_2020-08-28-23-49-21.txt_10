reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35742034-172.17.0.7-1598658636116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-58b77b97-712a-4db7-8869-8f4821f4bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b87790e2-3320-4727-b63c-a66987b256ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-0dcb5a6f-f573-4d86-ba97-d9a6bb60514d,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-da7aada0-1510-4786-8444-d21bb8d8a879,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-60c6a74c-42f9-47d7-9980-d60678ea2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-e664dcfd-1091-4632-9eae-3b3706c2d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-d7fff5cd-2602-4957-aa7e-3f292f172f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-ed9605cf-5536-4e82-b7ba-c381738c435e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35742034-172.17.0.7-1598658636116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-58b77b97-712a-4db7-8869-8f4821f4bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-b87790e2-3320-4727-b63c-a66987b256ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-0dcb5a6f-f573-4d86-ba97-d9a6bb60514d,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-da7aada0-1510-4786-8444-d21bb8d8a879,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-60c6a74c-42f9-47d7-9980-d60678ea2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-e664dcfd-1091-4632-9eae-3b3706c2d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-d7fff5cd-2602-4957-aa7e-3f292f172f03,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-ed9605cf-5536-4e82-b7ba-c381738c435e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553013160-172.17.0.7-1598659352530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-9fbf9a58-e478-4cc9-b82f-22556bcb8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3e03783b-6c85-4564-bf2c-128a08c5716c,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-8087b5e1-23d3-4f9a-a99e-35edc97a9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ec4007de-5ba4-4e01-997a-28af873bf44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-3719d832-ac34-46a9-a087-0476cac23357,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-6c17902c-623d-44aa-b8c7-751844270250,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-76c05ee0-1146-4afb-9f1f-0c9e31480c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-f642fdb8-fc5a-41e7-a0ea-56bc21df1b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553013160-172.17.0.7-1598659352530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-9fbf9a58-e478-4cc9-b82f-22556bcb8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3e03783b-6c85-4564-bf2c-128a08c5716c,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-8087b5e1-23d3-4f9a-a99e-35edc97a9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-ec4007de-5ba4-4e01-997a-28af873bf44e,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-3719d832-ac34-46a9-a087-0476cac23357,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-6c17902c-623d-44aa-b8c7-751844270250,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-76c05ee0-1146-4afb-9f1f-0c9e31480c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-f642fdb8-fc5a-41e7-a0ea-56bc21df1b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618736580-172.17.0.7-1598659465836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45455,DS-a0cb2573-bb0a-415b-b05b-83ce4585d2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f87c5325-0de9-436d-96e1-f3df9ebca8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-db44be04-e0e0-45fa-a594-a1f3cd6ba66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-0279c314-78bb-435a-b70c-f2c25c1d6186,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-d0d8e8d7-1f63-4bb9-93d4-bb467a87a933,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-1676842c-679c-4b2c-9e8c-68c1337e5a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-d1553097-98be-4436-b4b7-e3e8e39e6ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6431cb87-3d30-4173-b82f-0b8e2940c757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618736580-172.17.0.7-1598659465836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45455,DS-a0cb2573-bb0a-415b-b05b-83ce4585d2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f87c5325-0de9-436d-96e1-f3df9ebca8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-db44be04-e0e0-45fa-a594-a1f3cd6ba66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-0279c314-78bb-435a-b70c-f2c25c1d6186,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-d0d8e8d7-1f63-4bb9-93d4-bb467a87a933,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-1676842c-679c-4b2c-9e8c-68c1337e5a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-d1553097-98be-4436-b4b7-e3e8e39e6ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6431cb87-3d30-4173-b82f-0b8e2940c757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235625144-172.17.0.7-1598659498334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-b4c20df1-23cb-4c9e-8cf9-d372612c8524,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-793c7662-a310-4209-a3bd-7325e185a184,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-60345f7c-fc2f-4734-a920-7ca515c9b634,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-9be6686d-fc6b-47bc-90c9-5508f7af8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-f768d14a-f5b3-46c4-8985-20489563923a,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f91a340f-6dc1-44f3-ac75-e888166492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-14e64811-7910-4578-883e-ff2f4927d298,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-64aa78e1-f1bb-49a4-9818-195605f0f2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235625144-172.17.0.7-1598659498334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-b4c20df1-23cb-4c9e-8cf9-d372612c8524,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-793c7662-a310-4209-a3bd-7325e185a184,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-60345f7c-fc2f-4734-a920-7ca515c9b634,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-9be6686d-fc6b-47bc-90c9-5508f7af8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-f768d14a-f5b3-46c4-8985-20489563923a,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f91a340f-6dc1-44f3-ac75-e888166492b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-14e64811-7910-4578-883e-ff2f4927d298,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-64aa78e1-f1bb-49a4-9818-195605f0f2b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958708518-172.17.0.7-1598659692185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-cf378e96-49f2-4abc-82fc-53b2fb4dd844,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-346fc832-26da-447a-99fe-889b9c9a66e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f0b6b6b7-23cb-422c-b0a5-a79e024dedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-9bedf349-7ceb-49b9-9ff1-38ddb71b15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-14294734-e0b0-4f5a-8dcd-6583d20ad8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-04ce51b0-8b81-4977-b4e3-c948ba6e2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-fb833cd3-bc7a-43d2-a9b5-96a9d12ed299,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-a1fc7528-0fc6-400c-bdb1-a80f75138847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958708518-172.17.0.7-1598659692185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-cf378e96-49f2-4abc-82fc-53b2fb4dd844,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-346fc832-26da-447a-99fe-889b9c9a66e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f0b6b6b7-23cb-422c-b0a5-a79e024dedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-9bedf349-7ceb-49b9-9ff1-38ddb71b15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-14294734-e0b0-4f5a-8dcd-6583d20ad8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-04ce51b0-8b81-4977-b4e3-c948ba6e2c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-fb833cd3-bc7a-43d2-a9b5-96a9d12ed299,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-a1fc7528-0fc6-400c-bdb1-a80f75138847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35038749-172.17.0.7-1598659836003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-f102ad63-a3ba-4c88-a2d6-605e229c1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-3f8f82b6-4f6a-4423-8d5c-789d1019a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ceed3ffc-1843-4a92-83f2-f36879d56d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-3fb6efe0-ef8f-4efc-b7af-954d65f245dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-52c5f796-6cd2-46d0-8a96-f27479a64e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-dd325b1f-0889-4497-b1e8-3dbfeee1403f,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-21200d54-26bd-47d0-bb0c-ac76bebce89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-408f8164-43b5-4c3e-bf93-c23c7b06861e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35038749-172.17.0.7-1598659836003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-f102ad63-a3ba-4c88-a2d6-605e229c1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-3f8f82b6-4f6a-4423-8d5c-789d1019a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-ceed3ffc-1843-4a92-83f2-f36879d56d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-3fb6efe0-ef8f-4efc-b7af-954d65f245dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-52c5f796-6cd2-46d0-8a96-f27479a64e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-dd325b1f-0889-4497-b1e8-3dbfeee1403f,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-21200d54-26bd-47d0-bb0c-ac76bebce89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-408f8164-43b5-4c3e-bf93-c23c7b06861e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300605042-172.17.0.7-1598660506127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38029,DS-fe03dd93-502f-41f4-ae59-f33a1dab2826,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-2cf56216-37d2-4f71-9bf6-9e088c6a0afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-d7b4f2bd-6689-4eda-8098-23a404504b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-30c97442-2165-45c7-8cc0-0543603e2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-be08e210-57ad-47c9-af28-3a79c8d72992,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-35f29333-0dd0-4a73-8cfb-e7319f922ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-849cf09b-4e2f-4f3f-912b-3313a9266eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-17817178-672c-4506-a83f-5cbf342a83ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300605042-172.17.0.7-1598660506127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38029,DS-fe03dd93-502f-41f4-ae59-f33a1dab2826,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-2cf56216-37d2-4f71-9bf6-9e088c6a0afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-d7b4f2bd-6689-4eda-8098-23a404504b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-30c97442-2165-45c7-8cc0-0543603e2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-be08e210-57ad-47c9-af28-3a79c8d72992,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-35f29333-0dd0-4a73-8cfb-e7319f922ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-849cf09b-4e2f-4f3f-912b-3313a9266eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-17817178-672c-4506-a83f-5cbf342a83ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514306185-172.17.0.7-1598660865018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-f118405a-040d-4935-8044-d4a8b58ec274,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-1f044585-809a-42ba-8b94-162510d26fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-b24a179f-e2bf-4b73-885e-0919e19bc875,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-16dd1793-c9ee-44f3-b13d-69113e7bdcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-fbc719a7-3aec-4f14-9564-751fef5f4d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-3f78d5ed-fb18-4f1b-b61c-6f19846bcd97,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-98346fc2-eee1-4f7b-969b-2763028e639c,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-a0592e8e-eb2d-4c63-b0ba-92e5c24d7e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514306185-172.17.0.7-1598660865018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36120,DS-f118405a-040d-4935-8044-d4a8b58ec274,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-1f044585-809a-42ba-8b94-162510d26fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-b24a179f-e2bf-4b73-885e-0919e19bc875,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-16dd1793-c9ee-44f3-b13d-69113e7bdcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-fbc719a7-3aec-4f14-9564-751fef5f4d89,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-3f78d5ed-fb18-4f1b-b61c-6f19846bcd97,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-98346fc2-eee1-4f7b-969b-2763028e639c,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-a0592e8e-eb2d-4c63-b0ba-92e5c24d7e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112559578-172.17.0.7-1598661092617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34945,DS-00d1c8b5-4a26-4269-be36-dfa80c8df634,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-a497d776-cc25-42c0-bc2d-6de9e8d71bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-64ecb39d-b976-4638-905c-bb90880b08db,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-5c69acc5-c4ac-46c7-a3ba-d1750a152af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-9049a6b7-1aa7-4cf6-b851-80da6cd2e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-89ff0320-54e7-4ad7-b72f-09b4f4d3f097,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-e7f87df0-d9f9-42d6-8ed4-431336fa2b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e20e181a-ffa7-4a2b-b638-f90214e99994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112559578-172.17.0.7-1598661092617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34945,DS-00d1c8b5-4a26-4269-be36-dfa80c8df634,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-a497d776-cc25-42c0-bc2d-6de9e8d71bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-64ecb39d-b976-4638-905c-bb90880b08db,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-5c69acc5-c4ac-46c7-a3ba-d1750a152af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-9049a6b7-1aa7-4cf6-b851-80da6cd2e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-89ff0320-54e7-4ad7-b72f-09b4f4d3f097,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-e7f87df0-d9f9-42d6-8ed4-431336fa2b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e20e181a-ffa7-4a2b-b638-f90214e99994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057017985-172.17.0.7-1598661754082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36336,DS-d1256c8a-2e1a-414c-8be6-dddda55e7e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b34af56b-d370-4760-98c2-4f852f5ac177,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-72f7aa64-f68e-41dd-b317-8aa82ba3f037,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-48f10400-98ab-4328-9f44-cd53cba76f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-dd8dfeb8-9525-426b-a5e9-cd0e992c7e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-d4c57879-e510-4627-994d-b2efdc715f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4f014447-1bac-41e7-ba2a-43fb02935682,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-fe5dcae2-9e50-442c-8b5f-251aae6e0a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057017985-172.17.0.7-1598661754082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36336,DS-d1256c8a-2e1a-414c-8be6-dddda55e7e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-b34af56b-d370-4760-98c2-4f852f5ac177,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-72f7aa64-f68e-41dd-b317-8aa82ba3f037,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-48f10400-98ab-4328-9f44-cd53cba76f80,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-dd8dfeb8-9525-426b-a5e9-cd0e992c7e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-d4c57879-e510-4627-994d-b2efdc715f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4f014447-1bac-41e7-ba2a-43fb02935682,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-fe5dcae2-9e50-442c-8b5f-251aae6e0a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144312124-172.17.0.7-1598662100525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-e1ca4f0f-ac71-43a9-be32-0f652d774144,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-ceac95b1-9570-456d-afab-63e3833a4763,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-cf4971d5-a54b-4ed6-94b4-5e0595c2e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-45305a8b-1a56-4213-88e5-d16965cc49d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-7ce883a8-48d8-4c89-94bb-87507d3ce929,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-931e9d9c-b349-456f-8a53-469d16869aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-e50e6dde-48a9-40d0-ac57-84b142e58a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-3aff4a91-ab3e-45d8-9bd1-b1a039db05f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144312124-172.17.0.7-1598662100525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45198,DS-e1ca4f0f-ac71-43a9-be32-0f652d774144,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-ceac95b1-9570-456d-afab-63e3833a4763,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-cf4971d5-a54b-4ed6-94b4-5e0595c2e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-45305a8b-1a56-4213-88e5-d16965cc49d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-7ce883a8-48d8-4c89-94bb-87507d3ce929,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-931e9d9c-b349-456f-8a53-469d16869aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-e50e6dde-48a9-40d0-ac57-84b142e58a22,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-3aff4a91-ab3e-45d8-9bd1-b1a039db05f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130136797-172.17.0.7-1598662160205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-44d6187a-d852-4f92-839d-3cf423864e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-2ef7b4c8-0be8-46ef-80de-4ef2d6a74880,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-edc2f2aa-4d70-40af-b0b4-796edfa755e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-718ced7d-bbf7-4ec4-a530-13b6589d9953,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-0b43a422-650b-4b62-a4e6-4d91375185ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-b2863fed-01ab-4d2a-9ef3-896ca7e0a555,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-7ee5b581-fc3c-4039-b9ea-6dc279e27b37,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-3e19bf0b-08a5-4642-9a09-7e8e449aebc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130136797-172.17.0.7-1598662160205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-44d6187a-d852-4f92-839d-3cf423864e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-2ef7b4c8-0be8-46ef-80de-4ef2d6a74880,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-edc2f2aa-4d70-40af-b0b4-796edfa755e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-718ced7d-bbf7-4ec4-a530-13b6589d9953,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-0b43a422-650b-4b62-a4e6-4d91375185ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-b2863fed-01ab-4d2a-9ef3-896ca7e0a555,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-7ee5b581-fc3c-4039-b9ea-6dc279e27b37,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-3e19bf0b-08a5-4642-9a09-7e8e449aebc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355172015-172.17.0.7-1598662921602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-474d4871-6b4d-477a-9510-ec39d03fe1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-391a9c43-4d22-42e7-a62b-9d449fdeb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-11520a5e-e488-4ea0-92ff-0cc49842b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-c71fc306-7b04-4b69-a595-42bbaa66d3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-4efb00ad-8f4a-4a48-a1f7-f694a0af72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-8b58016f-8206-403f-bfe9-120f8ebfeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0c681d9f-41e5-49e5-b6e1-e28ed7b4e294,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-2db68db7-a7fc-4716-babf-7e8d76c7b485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355172015-172.17.0.7-1598662921602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-474d4871-6b4d-477a-9510-ec39d03fe1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-391a9c43-4d22-42e7-a62b-9d449fdeb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-11520a5e-e488-4ea0-92ff-0cc49842b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-c71fc306-7b04-4b69-a595-42bbaa66d3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-4efb00ad-8f4a-4a48-a1f7-f694a0af72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-8b58016f-8206-403f-bfe9-120f8ebfeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-0c681d9f-41e5-49e5-b6e1-e28ed7b4e294,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-2db68db7-a7fc-4716-babf-7e8d76c7b485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599577389-172.17.0.7-1598663067632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-7f50ca21-48fb-4a23-b706-18946cfadbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e6ea9f4b-b78d-4e82-9305-991a4e0a0204,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c91f5c6a-8d3c-4603-94c7-01d1309910cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-d1e479b8-ccff-4049-8e85-6897eee17302,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-d4ea351d-8e1f-43b8-a1b3-0733ff34c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-80a0ba6d-054b-40fb-9e24-1c955d91e189,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-87604ff2-1006-4f54-a436-2ce01287a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6136490d-ba82-48b9-a31c-5c78b0c7a409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599577389-172.17.0.7-1598663067632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-7f50ca21-48fb-4a23-b706-18946cfadbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e6ea9f4b-b78d-4e82-9305-991a4e0a0204,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c91f5c6a-8d3c-4603-94c7-01d1309910cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-d1e479b8-ccff-4049-8e85-6897eee17302,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-d4ea351d-8e1f-43b8-a1b3-0733ff34c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-80a0ba6d-054b-40fb-9e24-1c955d91e189,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-87604ff2-1006-4f54-a436-2ce01287a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6136490d-ba82-48b9-a31c-5c78b0c7a409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:DataNode
v1: 2
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757987431-172.17.0.7-1598663606384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-95b9578f-06a6-4261-9ae9-cb9708a69b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-e645d38f-1d91-4623-8fec-fb436f63cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-67e37d70-0879-465a-9b1f-5f8ed0491215,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-38002ebb-829a-4ec1-9699-e3785a75828d,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ac2c99c7-61b5-4438-8d59-49abe7ceb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-161e8982-9110-4bf2-bbfe-b39a419e27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-c6d3c63d-db2c-42fd-ac51-4a3867c2b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-dbdc6b6e-e16b-41d4-aa28-925eee8a4a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757987431-172.17.0.7-1598663606384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-95b9578f-06a6-4261-9ae9-cb9708a69b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-e645d38f-1d91-4623-8fec-fb436f63cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-67e37d70-0879-465a-9b1f-5f8ed0491215,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-38002ebb-829a-4ec1-9699-e3785a75828d,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ac2c99c7-61b5-4438-8d59-49abe7ceb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-161e8982-9110-4bf2-bbfe-b39a419e27ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-c6d3c63d-db2c-42fd-ac51-4a3867c2b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-dbdc6b6e-e16b-41d4-aa28-925eee8a4a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5106
