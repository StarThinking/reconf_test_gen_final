reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947119039-172.17.0.2-1598639236925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-35596ad8-d484-4f20-a55c-632019356625,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-de7f3664-8eb2-4ddf-a283-59fa248a0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-af73efd5-fb5f-4e07-a68c-00c222f31975,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-4f798485-b09d-4cd4-9ec2-646e084e5f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-0c2077a2-3bd4-4999-980f-a4b431fbeac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-eb3b94a4-0e9c-41fa-8440-6f9baa3a5ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-031d87ae-804f-4a0c-8531-9da582d4f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-d934a170-c26b-42ce-b317-c720dd6b756f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947119039-172.17.0.2-1598639236925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39578,DS-35596ad8-d484-4f20-a55c-632019356625,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-de7f3664-8eb2-4ddf-a283-59fa248a0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-af73efd5-fb5f-4e07-a68c-00c222f31975,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-4f798485-b09d-4cd4-9ec2-646e084e5f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-0c2077a2-3bd4-4999-980f-a4b431fbeac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-eb3b94a4-0e9c-41fa-8440-6f9baa3a5ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-031d87ae-804f-4a0c-8531-9da582d4f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-d934a170-c26b-42ce-b317-c720dd6b756f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139147694-172.17.0.2-1598639925778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-e4c4d4fe-c4f5-474b-8ef1-a6fc403e37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-2a07401a-034d-4832-9d90-4d17bc9de725,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-bd8f56e6-8c59-4a6e-a8d7-4d370f362e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-4857805a-677b-42bf-91e2-f93caf058b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4a456b1e-6174-4c42-92a0-9877b4ae63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-aca0b136-8d59-4a0d-90f0-f50b8624a347,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-5e5daff4-83aa-4c17-9459-5e6eb549506d,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-8ead2b6b-aa8c-45f3-9cdb-e7dd50a5d107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139147694-172.17.0.2-1598639925778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-e4c4d4fe-c4f5-474b-8ef1-a6fc403e37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-2a07401a-034d-4832-9d90-4d17bc9de725,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-bd8f56e6-8c59-4a6e-a8d7-4d370f362e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-4857805a-677b-42bf-91e2-f93caf058b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4a456b1e-6174-4c42-92a0-9877b4ae63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-aca0b136-8d59-4a0d-90f0-f50b8624a347,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-5e5daff4-83aa-4c17-9459-5e6eb549506d,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-8ead2b6b-aa8c-45f3-9cdb-e7dd50a5d107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138662799-172.17.0.2-1598640566701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-eac6c761-6330-4577-b76d-a7c153c2cbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6fa300cd-9558-4f5e-a6a0-0a76b219b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-e1f0f706-b01c-4c0a-b4bb-cc86a284a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-a6fe54c4-05ed-4aa4-a7fe-b37a31cae914,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-fdb10128-da3d-4a16-98fb-cab32c6f00a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-a04cf1ae-8fea-45c4-a6bf-2937046b888a,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-b1744a0d-88c4-4ff3-8e85-0a3eadced648,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-a099aa26-e3e1-44a0-a325-b48c345480ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138662799-172.17.0.2-1598640566701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-eac6c761-6330-4577-b76d-a7c153c2cbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6fa300cd-9558-4f5e-a6a0-0a76b219b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-e1f0f706-b01c-4c0a-b4bb-cc86a284a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-a6fe54c4-05ed-4aa4-a7fe-b37a31cae914,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-fdb10128-da3d-4a16-98fb-cab32c6f00a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-a04cf1ae-8fea-45c4-a6bf-2937046b888a,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-b1744a0d-88c4-4ff3-8e85-0a3eadced648,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-a099aa26-e3e1-44a0-a325-b48c345480ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830401319-172.17.0.2-1598640880480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-c9b6dcb0-d885-4b4c-98fb-028e87f85e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-cc8ddc13-0f8f-4904-8c92-3bfb9e46c800,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-4b2e1717-d26a-4165-b73c-0ff909859422,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-66572297-61fd-470e-9e41-3eef3dd2eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-060107de-7e57-465e-b81c-5e23b54b5035,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-88b83f7f-6f60-4919-8fe4-963215ec48d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-7ffe5833-4e23-44a4-84ce-f6a04542fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-4b1cf3c6-32e8-4273-922b-6ce1d53380a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830401319-172.17.0.2-1598640880480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-c9b6dcb0-d885-4b4c-98fb-028e87f85e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-cc8ddc13-0f8f-4904-8c92-3bfb9e46c800,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-4b2e1717-d26a-4165-b73c-0ff909859422,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-66572297-61fd-470e-9e41-3eef3dd2eb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-060107de-7e57-465e-b81c-5e23b54b5035,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-88b83f7f-6f60-4919-8fe4-963215ec48d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-7ffe5833-4e23-44a4-84ce-f6a04542fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-4b1cf3c6-32e8-4273-922b-6ce1d53380a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010742540-172.17.0.2-1598641144029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-a271518b-5999-4231-8b0f-beb909d3b625,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4e263577-9798-40bc-a6a3-d47dfc0dca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-20b98c38-3555-4f48-a36a-f27f263cca42,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-df070428-a184-4383-a8aa-b92a1c26f762,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-8c8f7270-da01-4310-bc0c-58cbeb5e4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-4b83450d-c3d0-48c1-84a7-50fd157c42e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-e2213b21-b450-40d9-8754-1086477f8994,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-6f66b9c3-26b3-4ed9-b41b-e8ccdc51856d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010742540-172.17.0.2-1598641144029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-a271518b-5999-4231-8b0f-beb909d3b625,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4e263577-9798-40bc-a6a3-d47dfc0dca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-20b98c38-3555-4f48-a36a-f27f263cca42,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-df070428-a184-4383-a8aa-b92a1c26f762,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-8c8f7270-da01-4310-bc0c-58cbeb5e4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-4b83450d-c3d0-48c1-84a7-50fd157c42e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-e2213b21-b450-40d9-8754-1086477f8994,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-6f66b9c3-26b3-4ed9-b41b-e8ccdc51856d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936982726-172.17.0.2-1598641301128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-8ffe143f-ebc5-47ce-b1b4-b380f99cd325,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-cf8cc775-a05c-4dd5-b9e5-77ef850c0c97,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-54a8eabd-ab08-4f2f-ad3e-51d4c8e8825e,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-3697b973-b655-4ac6-b99f-c586ec0a38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-c975fbfd-f2df-417e-8a71-19f1d21b470b,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-2835f2b9-f540-4db4-8bd1-45245ab341ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-892c63bc-13bd-45ac-8fce-a72395d4fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7607b7c0-4913-4393-a506-9b7d910257e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936982726-172.17.0.2-1598641301128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-8ffe143f-ebc5-47ce-b1b4-b380f99cd325,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-cf8cc775-a05c-4dd5-b9e5-77ef850c0c97,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-54a8eabd-ab08-4f2f-ad3e-51d4c8e8825e,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-3697b973-b655-4ac6-b99f-c586ec0a38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-c975fbfd-f2df-417e-8a71-19f1d21b470b,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-2835f2b9-f540-4db4-8bd1-45245ab341ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-892c63bc-13bd-45ac-8fce-a72395d4fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-7607b7c0-4913-4393-a506-9b7d910257e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619661753-172.17.0.2-1598641364002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-0b1d1008-651c-4d4f-9677-206c5659b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-c595a250-24de-45e4-a55c-25b436baada8,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-0f042e20-cf25-477f-a1b3-10d6b110e819,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-be31c455-d819-4d63-b92a-2f6cf998934c,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8755560a-79db-4430-88ac-6d0b182cc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-262466d7-0f45-4645-b85c-02687facd0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-49372dd0-74ba-4de8-aad0-d98e6c634cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-144521bf-d3b1-4cef-b87a-cbcb1f06371c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619661753-172.17.0.2-1598641364002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-0b1d1008-651c-4d4f-9677-206c5659b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-c595a250-24de-45e4-a55c-25b436baada8,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-0f042e20-cf25-477f-a1b3-10d6b110e819,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-be31c455-d819-4d63-b92a-2f6cf998934c,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8755560a-79db-4430-88ac-6d0b182cc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-262466d7-0f45-4645-b85c-02687facd0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-49372dd0-74ba-4de8-aad0-d98e6c634cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-144521bf-d3b1-4cef-b87a-cbcb1f06371c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886649-172.17.0.2-1598641428652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-3a0ae58a-499a-4760-8853-638621f797ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-79b147e9-d40c-4187-8884-a10a43a6aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-053a3e50-5d57-475e-9bbc-1773ceb60723,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-e0e8b745-8dd5-44a8-ae8f-8e05c0927968,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-a8eef307-00c0-45da-88db-32e953bf7da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-36a86d6a-2c36-48a1-9de2-76702e3cc8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-65efc25f-f0fa-4cbf-ad47-41da35d5da03,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-455d926c-27ed-44a2-8474-f7f0c5e4ee08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886649-172.17.0.2-1598641428652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-3a0ae58a-499a-4760-8853-638621f797ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-79b147e9-d40c-4187-8884-a10a43a6aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-053a3e50-5d57-475e-9bbc-1773ceb60723,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-e0e8b745-8dd5-44a8-ae8f-8e05c0927968,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-a8eef307-00c0-45da-88db-32e953bf7da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-36a86d6a-2c36-48a1-9de2-76702e3cc8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-65efc25f-f0fa-4cbf-ad47-41da35d5da03,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-455d926c-27ed-44a2-8474-f7f0c5e4ee08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886568698-172.17.0.2-1598642321347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44656,DS-850a77ee-7657-40fa-8194-b8b6201cdef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-f573ca3e-66e8-4702-848f-c54699ca5426,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-7d5e3b0d-92b3-4b9e-b033-1933a7f3939a,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-c33f848b-6293-4c73-a216-3bea4e148eca,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-10ea1358-fa2f-47ab-90b7-81669ca03245,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-b761dbd0-bb38-47dd-94cb-c79551717f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-f7f159e3-300d-47a0-80e5-1f325ee55d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-b0f19a76-6d46-4bbc-ac75-05a33f252b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886568698-172.17.0.2-1598642321347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44656,DS-850a77ee-7657-40fa-8194-b8b6201cdef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-f573ca3e-66e8-4702-848f-c54699ca5426,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-7d5e3b0d-92b3-4b9e-b033-1933a7f3939a,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-c33f848b-6293-4c73-a216-3bea4e148eca,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-10ea1358-fa2f-47ab-90b7-81669ca03245,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-b761dbd0-bb38-47dd-94cb-c79551717f37,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-f7f159e3-300d-47a0-80e5-1f325ee55d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-b0f19a76-6d46-4bbc-ac75-05a33f252b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377336761-172.17.0.2-1598642769045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-5620093f-f52b-4c8f-b303-267ce890a51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-ac7279e7-dd43-4a09-8548-ec71eb6c207f,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-bfa42acd-ea33-4170-ac5d-72ec92b8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-fa9b7589-5d8f-471a-bace-4547606a097f,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7c6c47e-9bf7-49e0-af9e-929f1fe973d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-70ca280d-b629-4c49-b72e-849cb5db1816,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-2c89c83b-005e-46c3-92ca-2ddd78973d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-c7089c08-b588-47e9-8c65-53f43537add1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377336761-172.17.0.2-1598642769045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-5620093f-f52b-4c8f-b303-267ce890a51c,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-ac7279e7-dd43-4a09-8548-ec71eb6c207f,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-bfa42acd-ea33-4170-ac5d-72ec92b8bfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-fa9b7589-5d8f-471a-bace-4547606a097f,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7c6c47e-9bf7-49e0-af9e-929f1fe973d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-70ca280d-b629-4c49-b72e-849cb5db1816,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-2c89c83b-005e-46c3-92ca-2ddd78973d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-c7089c08-b588-47e9-8c65-53f43537add1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250006129-172.17.0.2-1598643062660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34743,DS-21817122-f14e-47f3-888f-e9f3984a3685,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-832ef5ec-8c01-4f5a-bdac-04d3340bda9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-d65123e7-3ecd-4ec3-be87-f523a5c664d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-5fe8ff36-5f4d-449e-85f3-5981aa43d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-56232131-df15-4809-94c7-dce0a47b4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-edb5aee1-1a17-410e-83e6-b51219e8debd,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-ec6c68bd-446f-4804-9e4c-185599d3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-28fdb3a4-dc33-4012-9630-158105300f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250006129-172.17.0.2-1598643062660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34743,DS-21817122-f14e-47f3-888f-e9f3984a3685,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-832ef5ec-8c01-4f5a-bdac-04d3340bda9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-d65123e7-3ecd-4ec3-be87-f523a5c664d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-5fe8ff36-5f4d-449e-85f3-5981aa43d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-56232131-df15-4809-94c7-dce0a47b4a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-edb5aee1-1a17-410e-83e6-b51219e8debd,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-ec6c68bd-446f-4804-9e4c-185599d3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-28fdb3a4-dc33-4012-9630-158105300f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58104379-172.17.0.2-1598643156700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-1087ed5e-b5cd-46f4-a44a-bfe7dc3419a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-f6bea3f3-d3a7-4615-a7d2-a1e76fae99e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ee724db3-a2f0-4c43-ac7d-ceb498b28643,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-b0845981-d615-47da-824e-b0f32bb14951,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-53208852-c9ad-4cc9-b380-fe971cb7b292,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-096ba62a-0cca-4442-9c26-3000bc8b58bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-61349d2e-9483-4fcd-86ca-52022971754b,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-78b7a866-38a3-472e-824b-23e2578e0e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58104379-172.17.0.2-1598643156700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33132,DS-1087ed5e-b5cd-46f4-a44a-bfe7dc3419a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-f6bea3f3-d3a7-4615-a7d2-a1e76fae99e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ee724db3-a2f0-4c43-ac7d-ceb498b28643,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-b0845981-d615-47da-824e-b0f32bb14951,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-53208852-c9ad-4cc9-b380-fe971cb7b292,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-096ba62a-0cca-4442-9c26-3000bc8b58bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-61349d2e-9483-4fcd-86ca-52022971754b,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-78b7a866-38a3-472e-824b-23e2578e0e65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219752143-172.17.0.2-1598643909978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-6659072f-16a4-4fc8-9379-d20eb375b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-465f3150-d0b0-450e-aade-56fcd9300e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-58d6f701-e288-463c-bff7-eb4f6d79c533,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-cf03bf25-f13f-4c0d-baca-cd83f50326b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-ef1877e7-8093-49df-9dc3-d23223ee2792,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-8d7cbecf-41df-4120-adf8-3eea1d746462,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-e78a057f-dc53-40c7-8670-b96514e02b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-d1e2e366-ac71-472f-809f-072f6f21570e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219752143-172.17.0.2-1598643909978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37025,DS-6659072f-16a4-4fc8-9379-d20eb375b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-465f3150-d0b0-450e-aade-56fcd9300e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-58d6f701-e288-463c-bff7-eb4f6d79c533,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-cf03bf25-f13f-4c0d-baca-cd83f50326b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-ef1877e7-8093-49df-9dc3-d23223ee2792,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-8d7cbecf-41df-4120-adf8-3eea1d746462,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-e78a057f-dc53-40c7-8670-b96514e02b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-d1e2e366-ac71-472f-809f-072f6f21570e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2047
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524507000-172.17.0.2-1598644026114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-6fdde931-26a4-4107-8997-d6ecd271a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-82b2b835-21b8-4534-b7c6-e47408b56a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-91ab757d-de66-4d6e-8cb7-1120c117ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5b4f6397-b3fd-4ad2-96b9-735394447b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-a36f5614-df3d-4d2c-8adb-6ed7f4217ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-1346d6c9-79b9-4ee4-97d5-7f420bfd6206,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-05075cf5-6ca2-4d2e-8dc8-69716228b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-c198cbbe-03be-41b6-b82c-8e971592c890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524507000-172.17.0.2-1598644026114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42920,DS-6fdde931-26a4-4107-8997-d6ecd271a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-82b2b835-21b8-4534-b7c6-e47408b56a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-91ab757d-de66-4d6e-8cb7-1120c117ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5b4f6397-b3fd-4ad2-96b9-735394447b10,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-a36f5614-df3d-4d2c-8adb-6ed7f4217ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-1346d6c9-79b9-4ee4-97d5-7f420bfd6206,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-05075cf5-6ca2-4d2e-8dc8-69716228b7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-c198cbbe-03be-41b6-b82c-8e971592c890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5008
