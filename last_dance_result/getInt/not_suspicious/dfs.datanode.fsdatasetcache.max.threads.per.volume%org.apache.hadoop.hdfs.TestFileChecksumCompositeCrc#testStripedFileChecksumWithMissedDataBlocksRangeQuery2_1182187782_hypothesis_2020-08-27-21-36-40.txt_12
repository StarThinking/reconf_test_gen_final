reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736053446-172.17.0.11-1598564422306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-9612aa5e-63f5-4d75-a801-a1b94437e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-2d465797-7424-43d5-8fe3-4e52e8cb2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-9379941c-9b8c-49e4-b81d-ee3cffa6acee,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-77ca6340-8423-401c-9dc6-d239514d4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-ca7b0fd8-df28-492e-8a16-143d5aa2506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-e415fe80-7867-4ac1-b0d7-388592d8b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-7fb91fb5-0684-4009-8da1-705feac8c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-b52a42e0-ba27-4706-8304-d924c7490838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736053446-172.17.0.11-1598564422306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36721,DS-9612aa5e-63f5-4d75-a801-a1b94437e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-2d465797-7424-43d5-8fe3-4e52e8cb2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-9379941c-9b8c-49e4-b81d-ee3cffa6acee,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-77ca6340-8423-401c-9dc6-d239514d4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-ca7b0fd8-df28-492e-8a16-143d5aa2506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-e415fe80-7867-4ac1-b0d7-388592d8b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-7fb91fb5-0684-4009-8da1-705feac8c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-b52a42e0-ba27-4706-8304-d924c7490838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803178087-172.17.0.11-1598564491801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-108d947e-63c3-457b-9384-ef9126e81c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7e60e41b-f0c9-4576-be26-0dad5c69944d,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-24600ed2-8d24-45fc-aa02-557bb1742cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-6c88b600-aad1-498f-8d8c-da1b8dcf0610,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-714b22ad-b932-4bee-b67f-1bd502ff5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c0c71887-bebb-4385-9909-0b3c86d2572b,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-3a579f32-06cb-4505-9a65-0800b685fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-7b1422fe-87ff-4d52-8a3d-9d088263158f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803178087-172.17.0.11-1598564491801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-108d947e-63c3-457b-9384-ef9126e81c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7e60e41b-f0c9-4576-be26-0dad5c69944d,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-24600ed2-8d24-45fc-aa02-557bb1742cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-6c88b600-aad1-498f-8d8c-da1b8dcf0610,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-714b22ad-b932-4bee-b67f-1bd502ff5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-c0c71887-bebb-4385-9909-0b3c86d2572b,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-3a579f32-06cb-4505-9a65-0800b685fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-7b1422fe-87ff-4d52-8a3d-9d088263158f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805300543-172.17.0.11-1598564568618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-c9415b42-2c2d-4ff5-b846-6222ef09a140,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-05e1795d-95a6-49c2-8967-20d8a7506f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-769686c5-3657-4e09-854b-33da885f605a,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-14c1762d-90c4-4f21-8d19-e9e0a4221ace,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-598c4bb4-2c8a-4483-9c65-1d6fc0f87071,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7a0c7cc7-2e07-4459-a70c-aa695427a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-90862ce3-9add-4e78-a431-dbbfa2f14d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-0452652d-7fc8-4b60-b047-bbffbae2dcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805300543-172.17.0.11-1598564568618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-c9415b42-2c2d-4ff5-b846-6222ef09a140,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-05e1795d-95a6-49c2-8967-20d8a7506f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-769686c5-3657-4e09-854b-33da885f605a,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-14c1762d-90c4-4f21-8d19-e9e0a4221ace,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-598c4bb4-2c8a-4483-9c65-1d6fc0f87071,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7a0c7cc7-2e07-4459-a70c-aa695427a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-90862ce3-9add-4e78-a431-dbbfa2f14d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-0452652d-7fc8-4b60-b047-bbffbae2dcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633399681-172.17.0.11-1598564647240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-69550170-f446-4c5e-8599-ebe9a8d4c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-d956220c-65e8-4a4b-b436-cd1cd37f72e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-78d3e63a-33ff-4e23-97dc-05edcc180653,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d3c4318c-f2df-4980-8c02-8a1b15df4169,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-02d35456-852f-44ce-b882-02a202511c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-08824cf0-c7a4-4287-ba2c-c0d42315168a,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-38688df2-16e3-47a1-bffa-1531e9f1db05,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-52870a82-8825-48b9-aa2a-d967c45ef094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633399681-172.17.0.11-1598564647240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-69550170-f446-4c5e-8599-ebe9a8d4c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-d956220c-65e8-4a4b-b436-cd1cd37f72e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-78d3e63a-33ff-4e23-97dc-05edcc180653,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d3c4318c-f2df-4980-8c02-8a1b15df4169,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-02d35456-852f-44ce-b882-02a202511c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-08824cf0-c7a4-4287-ba2c-c0d42315168a,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-38688df2-16e3-47a1-bffa-1531e9f1db05,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-52870a82-8825-48b9-aa2a-d967c45ef094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002532444-172.17.0.11-1598564977050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-689740ab-5220-4598-bd1a-41588ab576c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-2e296255-18cb-4906-8d4a-cbfa0bbc0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-df8ed31e-38fd-42fe-9a9c-fa0cf6db31bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-7336b3bb-a34f-4fd7-9ffb-bfe11fb1c7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-7469548d-5507-411e-917f-ebd820f84faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-83d77f35-3aab-4df9-b2c3-056561429d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-87edee04-c012-4cbc-9aad-efb32597f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-9221d015-e9b8-4dd4-8cac-e91744dde0ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002532444-172.17.0.11-1598564977050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-689740ab-5220-4598-bd1a-41588ab576c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-2e296255-18cb-4906-8d4a-cbfa0bbc0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-df8ed31e-38fd-42fe-9a9c-fa0cf6db31bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-7336b3bb-a34f-4fd7-9ffb-bfe11fb1c7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-7469548d-5507-411e-917f-ebd820f84faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-83d77f35-3aab-4df9-b2c3-056561429d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-87edee04-c012-4cbc-9aad-efb32597f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-9221d015-e9b8-4dd4-8cac-e91744dde0ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815421550-172.17.0.11-1598565049968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-65fa3b3b-95db-43a6-bf6d-9e2c2c7a9046,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-61d7c762-815d-4932-9bd7-a1aa9cc8dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-eb90bd7d-8c52-4a01-b1c2-96ca07f27c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-1fe6f277-f45f-4abf-9348-e43ea8354bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-9d6f235e-d00a-4047-abd5-583caf413d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-046daa3e-5e39-4597-8223-cf8de2fc815a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-cea30268-c0f2-4d81-84fc-d4f2bc6aa622,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b6a81732-72d4-4281-a34e-e4aa76f4be9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815421550-172.17.0.11-1598565049968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-65fa3b3b-95db-43a6-bf6d-9e2c2c7a9046,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-61d7c762-815d-4932-9bd7-a1aa9cc8dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-eb90bd7d-8c52-4a01-b1c2-96ca07f27c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-1fe6f277-f45f-4abf-9348-e43ea8354bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-9d6f235e-d00a-4047-abd5-583caf413d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-046daa3e-5e39-4597-8223-cf8de2fc815a,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-cea30268-c0f2-4d81-84fc-d4f2bc6aa622,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-b6a81732-72d4-4281-a34e-e4aa76f4be9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609191261-172.17.0.11-1598565206193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-fde96073-7c7b-4373-ae27-96feb043e505,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-6060a52f-a3a3-4a04-a1e1-0c35426af933,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-8d698377-4dae-48a9-9d1c-3df55d21a19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-b97a45da-8130-4c4e-b0aa-ee0830e9627f,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a3a03814-48fd-4d00-82b6-7cb990694d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-e1a930cd-fd85-40b3-bd2e-f865718f0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ead2646d-3350-4556-98f1-db4908878bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d1f4fd1a-18cb-405b-bfb9-a77943420a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609191261-172.17.0.11-1598565206193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-fde96073-7c7b-4373-ae27-96feb043e505,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-6060a52f-a3a3-4a04-a1e1-0c35426af933,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-8d698377-4dae-48a9-9d1c-3df55d21a19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-b97a45da-8130-4c4e-b0aa-ee0830e9627f,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a3a03814-48fd-4d00-82b6-7cb990694d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-e1a930cd-fd85-40b3-bd2e-f865718f0aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ead2646d-3350-4556-98f1-db4908878bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-d1f4fd1a-18cb-405b-bfb9-a77943420a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643573098-172.17.0.11-1598565362865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-2add2fc7-64cf-407e-82b9-95ecdc0dd0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7719efde-0d26-4d50-af79-a8db1441e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-83ec9e7c-f451-4052-ab77-732d469f2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ee8667b7-8649-46e0-bf0c-04a1f424b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-d3c945f0-638a-4445-8a86-8e663ccb06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-9885ea24-cc27-46d9-8029-ce46c59aa939,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-20a9980d-de10-4f31-9c42-dc6bbf504345,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-7e7ad87a-d792-4657-bd8d-94c0971cf890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643573098-172.17.0.11-1598565362865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-2add2fc7-64cf-407e-82b9-95ecdc0dd0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7719efde-0d26-4d50-af79-a8db1441e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-83ec9e7c-f451-4052-ab77-732d469f2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ee8667b7-8649-46e0-bf0c-04a1f424b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-d3c945f0-638a-4445-8a86-8e663ccb06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-9885ea24-cc27-46d9-8029-ce46c59aa939,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-20a9980d-de10-4f31-9c42-dc6bbf504345,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-7e7ad87a-d792-4657-bd8d-94c0971cf890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612925602-172.17.0.11-1598565525548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37597,DS-7cb97ddb-34a5-463b-901b-91d4e347e842,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-97f0be5d-b87b-459f-9fa4-06bea2ac8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-87cbfe14-7ea3-4e67-805f-647e9482745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0ba77012-896c-491d-8ffc-b9791b500b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-66619757-bed9-4451-9e65-e4dd3ace2bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-2a22d2a3-4e58-4dbd-ac38-677002110af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-2cee8524-88be-4b2e-aac3-36067f5b498b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-c9675302-80da-482b-8eb1-5fc66847f8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612925602-172.17.0.11-1598565525548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37597,DS-7cb97ddb-34a5-463b-901b-91d4e347e842,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-97f0be5d-b87b-459f-9fa4-06bea2ac8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-87cbfe14-7ea3-4e67-805f-647e9482745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0ba77012-896c-491d-8ffc-b9791b500b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-66619757-bed9-4451-9e65-e4dd3ace2bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-2a22d2a3-4e58-4dbd-ac38-677002110af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-2cee8524-88be-4b2e-aac3-36067f5b498b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-c9675302-80da-482b-8eb1-5fc66847f8af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229569643-172.17.0.11-1598566349202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-762a2d79-10b2-441c-a0c0-305b46550c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-41bac9e9-e416-46b3-8a6c-9c8f3f0bff27,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-598cd121-5c4b-461b-8ea8-8d6b207ed44e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-055e3870-9057-4cb0-9ae5-938f1ebba18e,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-1cc08b51-f00c-47bd-a0ed-a6601077e707,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-cdf9b05b-42cc-4c37-8eaa-1ef07037d8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-03a1fb22-e30b-4a47-ae57-3e09f725dda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-aeb6cd6a-f2be-4361-9553-a0fc2a660b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229569643-172.17.0.11-1598566349202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-762a2d79-10b2-441c-a0c0-305b46550c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-41bac9e9-e416-46b3-8a6c-9c8f3f0bff27,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-598cd121-5c4b-461b-8ea8-8d6b207ed44e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-055e3870-9057-4cb0-9ae5-938f1ebba18e,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-1cc08b51-f00c-47bd-a0ed-a6601077e707,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-cdf9b05b-42cc-4c37-8eaa-1ef07037d8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-03a1fb22-e30b-4a47-ae57-3e09f725dda0,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-aeb6cd6a-f2be-4361-9553-a0fc2a660b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631032241-172.17.0.11-1598566644026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-10e14f08-d1db-424d-9e52-61bfaf3a3e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-6671142b-d1c9-415a-a44a-c014a23d5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2d8957a9-f2fa-4db6-8106-d57b55655c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-29b1b9e0-3bcf-49c6-b999-4e81421a2184,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-7708b99b-59bc-4ff4-b567-60e37e9d37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-149cd51e-0353-4d76-aa3e-67b3d72c9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4bd8273b-00a5-4a6e-8a54-fbdf44e95b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-f4b5de9c-1cd4-4291-b0c5-0bc9f718240e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631032241-172.17.0.11-1598566644026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45228,DS-10e14f08-d1db-424d-9e52-61bfaf3a3e52,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-6671142b-d1c9-415a-a44a-c014a23d5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2d8957a9-f2fa-4db6-8106-d57b55655c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-29b1b9e0-3bcf-49c6-b999-4e81421a2184,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-7708b99b-59bc-4ff4-b567-60e37e9d37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-149cd51e-0353-4d76-aa3e-67b3d72c9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4bd8273b-00a5-4a6e-8a54-fbdf44e95b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-f4b5de9c-1cd4-4291-b0c5-0bc9f718240e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436380121-172.17.0.11-1598566716657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-36e6fc2d-a62a-4eb1-8747-61a02c7a7418,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-aff5e1b1-35a7-4f9e-99e6-fe726be8aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-567b37bc-ea36-4562-8f1c-22c1dfb65536,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-fd29d7bb-38db-4b49-9b60-6997ce11dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-8736c36a-5ca3-4e69-9227-a12048515ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-18cba735-039a-4ea2-aec2-11f4494b2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-1476d82e-70d4-40df-86f1-ce64fdca122a,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-e78c168b-cb69-4e1e-9817-1129e2b7ceb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436380121-172.17.0.11-1598566716657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-36e6fc2d-a62a-4eb1-8747-61a02c7a7418,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-aff5e1b1-35a7-4f9e-99e6-fe726be8aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-567b37bc-ea36-4562-8f1c-22c1dfb65536,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-fd29d7bb-38db-4b49-9b60-6997ce11dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-8736c36a-5ca3-4e69-9227-a12048515ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-18cba735-039a-4ea2-aec2-11f4494b2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-1476d82e-70d4-40df-86f1-ce64fdca122a,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-e78c168b-cb69-4e1e-9817-1129e2b7ceb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353421305-172.17.0.11-1598566950541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-b5fd0d55-f72a-4222-9eba-43fa0aa2cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-b2b4e6ee-bc6c-4e8e-9e31-a2bf2b37f167,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-0b2c7cbd-a4a3-4ff2-b869-19c90ba9b331,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f0b21529-e57e-44cd-aaa6-b1b870633227,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-5ed8fa1a-2386-418a-aa23-095e59e3458b,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-8992f3c4-a580-43eb-8935-faf993f61e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-6c10fadd-30fb-4c71-932c-e486e0a3f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-519408ab-f554-45ac-a41f-d6a733f1475a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353421305-172.17.0.11-1598566950541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-b5fd0d55-f72a-4222-9eba-43fa0aa2cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-b2b4e6ee-bc6c-4e8e-9e31-a2bf2b37f167,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-0b2c7cbd-a4a3-4ff2-b869-19c90ba9b331,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f0b21529-e57e-44cd-aaa6-b1b870633227,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-5ed8fa1a-2386-418a-aa23-095e59e3458b,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-8992f3c4-a580-43eb-8935-faf993f61e90,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-6c10fadd-30fb-4c71-932c-e486e0a3f9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-519408ab-f554-45ac-a41f-d6a733f1475a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239881271-172.17.0.11-1598567402182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-60d71537-d049-476b-9675-8230c99aea10,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-611adf5b-cdae-4527-91a7-402f83d28860,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-ce840024-7452-4f69-b711-ad6ddf3cfb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-6bf2f91e-8d0e-4e0c-a8cb-460fcf00fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-e3cd352f-5888-4b26-bb68-8077720f742d,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-c40b7e2d-77c4-4173-85ca-ab3b4158899d,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-bece7050-fb1c-449f-96d9-c301ba496eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-b4b8ff35-b3c3-4b1b-a575-1da4c252d4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239881271-172.17.0.11-1598567402182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-60d71537-d049-476b-9675-8230c99aea10,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-611adf5b-cdae-4527-91a7-402f83d28860,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-ce840024-7452-4f69-b711-ad6ddf3cfb35,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-6bf2f91e-8d0e-4e0c-a8cb-460fcf00fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-e3cd352f-5888-4b26-bb68-8077720f742d,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-c40b7e2d-77c4-4173-85ca-ab3b4158899d,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-bece7050-fb1c-449f-96d9-c301ba496eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-b4b8ff35-b3c3-4b1b-a575-1da4c252d4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637150637-172.17.0.11-1598567554826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-46146223-f8d5-4c11-a587-49ea7be82acc,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-a069385b-3034-46b7-bb7b-76448905ee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-303df270-f36b-4636-a79e-8b78a908a921,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-40d6ceb2-7e8b-4d2b-a01a-3f8ac95a6711,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-9083e40f-60b6-44c4-99be-b0fa0a13acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-82919585-dcfc-4c1f-897c-2bac98f1c7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-3d95de6a-9eda-47ec-aab9-9ca00177ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0ccb859d-0625-4bec-96ba-70b73112f39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637150637-172.17.0.11-1598567554826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-46146223-f8d5-4c11-a587-49ea7be82acc,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-a069385b-3034-46b7-bb7b-76448905ee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-303df270-f36b-4636-a79e-8b78a908a921,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-40d6ceb2-7e8b-4d2b-a01a-3f8ac95a6711,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-9083e40f-60b6-44c4-99be-b0fa0a13acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-82919585-dcfc-4c1f-897c-2bac98f1c7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-3d95de6a-9eda-47ec-aab9-9ca00177ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0ccb859d-0625-4bec-96ba-70b73112f39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774670011-172.17.0.11-1598567727884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-5ecbfb64-c2ab-4baa-b260-6cd15cbd61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-a7227f0e-df93-443e-bb20-7e7956e8cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-3ab275e5-de0a-455d-ba50-5691d9128e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b016c9e3-69f1-4217-98d7-4d1943113bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-e7aefbd6-b4f3-4806-8700-80467cb354f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-96194757-3886-40a8-86cd-64133e1d3627,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-b0ec092f-116b-43c4-8c9c-b54ed3b6cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-a152c3c2-6aca-4c82-aee5-597874d9d8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774670011-172.17.0.11-1598567727884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-5ecbfb64-c2ab-4baa-b260-6cd15cbd61e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-a7227f0e-df93-443e-bb20-7e7956e8cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-3ab275e5-de0a-455d-ba50-5691d9128e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-b016c9e3-69f1-4217-98d7-4d1943113bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-e7aefbd6-b4f3-4806-8700-80467cb354f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-96194757-3886-40a8-86cd-64133e1d3627,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-b0ec092f-116b-43c4-8c9c-b54ed3b6cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-a152c3c2-6aca-4c82-aee5-597874d9d8ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068133327-172.17.0.11-1598567842852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-50306d6e-c26f-41ec-901c-2d8848e4d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-45fd9ab6-4933-45d1-b566-25615fbdf666,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-383f78bb-a626-4881-8f50-243ced22d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-d82c4b68-bf76-45ad-8488-c26e30de724c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-13c3e058-f052-44b7-9295-42c645fa5dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-8c152505-e382-46fc-988c-1438e5ce4817,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c1cc7fb1-9787-46b7-9110-8f040ac204b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-55cb5636-7531-4162-9355-15d2cf1dd20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068133327-172.17.0.11-1598567842852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-50306d6e-c26f-41ec-901c-2d8848e4d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-45fd9ab6-4933-45d1-b566-25615fbdf666,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-383f78bb-a626-4881-8f50-243ced22d4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-d82c4b68-bf76-45ad-8488-c26e30de724c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-13c3e058-f052-44b7-9295-42c645fa5dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-8c152505-e382-46fc-988c-1438e5ce4817,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-c1cc7fb1-9787-46b7-9110-8f040ac204b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-55cb5636-7531-4162-9355-15d2cf1dd20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341196297-172.17.0.11-1598568002211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-b9e6252d-9f67-45c3-8338-a295a7a51c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-0bec8a39-7625-48ea-ab90-b42720693f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-b0517fd4-98ab-410c-83dc-6fbc768dbc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-9d14a265-0b37-4cb6-be0e-3ee69ac5f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-fcedbed8-68c7-4ab6-aae1-fe3dd63dd6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-bc512f05-a18c-47d6-9063-99d2a29363de,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-fb1b13ab-daf9-4521-9667-2af5d687a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-57a07e88-8a7c-45c9-8dda-48d4169c41db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341196297-172.17.0.11-1598568002211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-b9e6252d-9f67-45c3-8338-a295a7a51c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-0bec8a39-7625-48ea-ab90-b42720693f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-b0517fd4-98ab-410c-83dc-6fbc768dbc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-9d14a265-0b37-4cb6-be0e-3ee69ac5f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-fcedbed8-68c7-4ab6-aae1-fe3dd63dd6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-bc512f05-a18c-47d6-9063-99d2a29363de,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-fb1b13ab-daf9-4521-9667-2af5d687a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-57a07e88-8a7c-45c9-8dda-48d4169c41db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369754916-172.17.0.11-1598568780486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35822,DS-a25d3486-d9d7-4fee-9e88-c11e6e9556b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-fb4ad971-91a9-41a9-8aa8-7f5ebcc83ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d900e8a6-f6b6-4be7-aaa7-ec0c62ea2c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-2f3e9c76-7a2c-40bf-bfe5-0c8fb8592cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-7560640a-af56-4c22-8474-ce15815737fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-f80f2930-6fea-4750-b8c1-d7eebefac373,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-1f0819b2-1229-4893-b71b-8b9b629b38cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-2647c831-1ca5-4762-9c05-ba85f8895c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369754916-172.17.0.11-1598568780486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35822,DS-a25d3486-d9d7-4fee-9e88-c11e6e9556b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-fb4ad971-91a9-41a9-8aa8-7f5ebcc83ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d900e8a6-f6b6-4be7-aaa7-ec0c62ea2c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-2f3e9c76-7a2c-40bf-bfe5-0c8fb8592cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-7560640a-af56-4c22-8474-ce15815737fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-f80f2930-6fea-4750-b8c1-d7eebefac373,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-1f0819b2-1229-4893-b71b-8b9b629b38cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-2647c831-1ca5-4762-9c05-ba85f8895c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915615350-172.17.0.11-1598569462082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-b20e6f40-3a9f-4c0a-ab55-41c23127266c,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-ab5243a4-0cf1-4c3e-ba7b-33da67f54a54,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-303beb27-0386-4f98-ad43-92d0ae244ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-f285a8cb-b993-451c-a507-0a0b8c851de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-18c063d9-b8de-4ae2-9baf-01f675096953,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ced673cb-46cb-4fdc-8c78-87713fadf852,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-34dafed5-3c43-4f3c-a8a5-e60c95ec32ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b3655aa2-ced9-445d-b9a5-928bfc731b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915615350-172.17.0.11-1598569462082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44958,DS-b20e6f40-3a9f-4c0a-ab55-41c23127266c,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-ab5243a4-0cf1-4c3e-ba7b-33da67f54a54,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-303beb27-0386-4f98-ad43-92d0ae244ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-f285a8cb-b993-451c-a507-0a0b8c851de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-18c063d9-b8de-4ae2-9baf-01f675096953,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ced673cb-46cb-4fdc-8c78-87713fadf852,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-34dafed5-3c43-4f3c-a8a5-e60c95ec32ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b3655aa2-ced9-445d-b9a5-928bfc731b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 3
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968433597-172.17.0.11-1598569533381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42198,DS-75ea717c-cc95-48e5-b5e1-7ba53ad4c2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-5429ea80-6791-4a09-ae0d-5e7c0f28c611,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-106c3fd4-9cd5-4540-bb71-954d2989b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-f1f501b1-9890-4a0a-9046-c460da03ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-29cd30e8-084b-40c3-9a8c-322d49a1ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-f56b9640-07ca-41c2-b6fd-647ade89f472,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-0c2945ab-53e5-4ddc-9821-5704b343989d,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-5c91b019-5003-49e3-99bd-1389c50760b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968433597-172.17.0.11-1598569533381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42198,DS-75ea717c-cc95-48e5-b5e1-7ba53ad4c2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-5429ea80-6791-4a09-ae0d-5e7c0f28c611,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-106c3fd4-9cd5-4540-bb71-954d2989b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-f1f501b1-9890-4a0a-9046-c460da03ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-29cd30e8-084b-40c3-9a8c-322d49a1ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-f56b9640-07ca-41c2-b6fd-647ade89f472,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-0c2945ab-53e5-4ddc-9821-5704b343989d,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-5c91b019-5003-49e3-99bd-1389c50760b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5502
