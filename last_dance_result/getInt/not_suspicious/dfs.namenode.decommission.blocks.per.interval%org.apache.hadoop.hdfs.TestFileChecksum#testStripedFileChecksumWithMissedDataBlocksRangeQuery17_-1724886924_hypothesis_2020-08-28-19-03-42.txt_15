reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986021202-172.17.0.17-1598641814408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-52a3b969-fb8b-4c93-b6bb-207f0a45e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-e0f9c178-92d8-4665-bf9a-439b32f8ab7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-ef0c56e3-16bb-41d3-ace2-95833f1c903f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-a0e7990d-8642-4ea5-af91-15ad696874fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-86921100-3ff3-491c-b2e5-586b05497a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-462c0832-0664-425f-ab4a-f2b6763da85e,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0eccbfbb-bab6-41a4-983b-e26322da7093,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-87dcc8ea-f723-438a-80b6-a118499d4188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986021202-172.17.0.17-1598641814408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-52a3b969-fb8b-4c93-b6bb-207f0a45e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-e0f9c178-92d8-4665-bf9a-439b32f8ab7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-ef0c56e3-16bb-41d3-ace2-95833f1c903f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-a0e7990d-8642-4ea5-af91-15ad696874fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-86921100-3ff3-491c-b2e5-586b05497a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-462c0832-0664-425f-ab4a-f2b6763da85e,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-0eccbfbb-bab6-41a4-983b-e26322da7093,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-87dcc8ea-f723-438a-80b6-a118499d4188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787551406-172.17.0.17-1598642186191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-1ebb1267-5adc-40a4-a415-c22615346459,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7a487c07-1a7d-4968-9085-0d2cfef74861,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-f2b11071-d14c-43c7-8805-3d73db7b166a,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-13d615bb-52cd-4d7e-bcad-2e3e40defb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a654fa8b-e893-4c50-8c34-a8cddf36f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-72e1fd0d-70ae-4d6b-9cd8-2d84c7f01e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-043909dd-1b2f-4939-aafa-e99e44fdc601,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3dbc858f-3f43-4ae1-aa04-0b5ce4c99b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787551406-172.17.0.17-1598642186191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-1ebb1267-5adc-40a4-a415-c22615346459,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7a487c07-1a7d-4968-9085-0d2cfef74861,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-f2b11071-d14c-43c7-8805-3d73db7b166a,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-13d615bb-52cd-4d7e-bcad-2e3e40defb27,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-a654fa8b-e893-4c50-8c34-a8cddf36f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-72e1fd0d-70ae-4d6b-9cd8-2d84c7f01e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-043909dd-1b2f-4939-aafa-e99e44fdc601,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3dbc858f-3f43-4ae1-aa04-0b5ce4c99b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475470334-172.17.0.17-1598642354843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-590e5aaa-7bb4-4464-beb4-17a2792047e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-85c3f33c-a4d3-4078-9b4d-e5aa6e4ee46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-b6e36ab2-e8b6-41d1-a456-fe5a58e6aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-2089488f-47b8-4dd4-8b0d-145cc0db2759,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-64d7e6b5-588b-4e31-88a0-c3837d020f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-9b88cebd-b3d2-40c2-91dd-888cfe584f92,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-a60e29e2-9a7d-462f-b700-c2c3614bc67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e5d52eac-53e4-4a17-b264-c614729bf725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475470334-172.17.0.17-1598642354843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-590e5aaa-7bb4-4464-beb4-17a2792047e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-85c3f33c-a4d3-4078-9b4d-e5aa6e4ee46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-b6e36ab2-e8b6-41d1-a456-fe5a58e6aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-2089488f-47b8-4dd4-8b0d-145cc0db2759,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-64d7e6b5-588b-4e31-88a0-c3837d020f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-9b88cebd-b3d2-40c2-91dd-888cfe584f92,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-a60e29e2-9a7d-462f-b700-c2c3614bc67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e5d52eac-53e4-4a17-b264-c614729bf725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141561545-172.17.0.17-1598642514547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-f2453063-b7e7-48e8-ae83-b7f3b51cff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-40b6e809-e184-42e8-bdb2-94790a607e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-f62183d6-b0e9-4241-8401-9859f293b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-d5453a37-bcd0-4851-a818-67eebcecaca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-44e01b1c-8ac2-4666-b371-9fbc30a95567,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-936ff481-6a77-475b-b35b-16a74bddab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-3834601b-2fb9-4233-b444-69ee5a03db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-9484920d-2bdf-48c2-8ec3-7fbec766c39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141561545-172.17.0.17-1598642514547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-f2453063-b7e7-48e8-ae83-b7f3b51cff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-40b6e809-e184-42e8-bdb2-94790a607e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-f62183d6-b0e9-4241-8401-9859f293b93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-d5453a37-bcd0-4851-a818-67eebcecaca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-44e01b1c-8ac2-4666-b371-9fbc30a95567,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-936ff481-6a77-475b-b35b-16a74bddab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-3834601b-2fb9-4233-b444-69ee5a03db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-9484920d-2bdf-48c2-8ec3-7fbec766c39e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270429788-172.17.0.17-1598642642114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-eda0a994-0468-4186-879e-9cd8b80b363a,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-6c29f5c0-1b67-4d98-9525-28e72370e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-bf2571f1-10d9-418c-899a-01ccc13e49dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-45ac4f6c-0c39-403f-a0a8-e7e4846fcefa,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-732daec8-8208-4ea9-843f-c4e75158c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8b918d5c-b654-40b3-9426-086ac4703e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6951219d-fb21-40e9-a54a-6097d91cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-56fa33d8-0b4e-4c3b-80c6-82e38c41c6b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270429788-172.17.0.17-1598642642114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-eda0a994-0468-4186-879e-9cd8b80b363a,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-6c29f5c0-1b67-4d98-9525-28e72370e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-bf2571f1-10d9-418c-899a-01ccc13e49dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-45ac4f6c-0c39-403f-a0a8-e7e4846fcefa,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-732daec8-8208-4ea9-843f-c4e75158c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8b918d5c-b654-40b3-9426-086ac4703e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6951219d-fb21-40e9-a54a-6097d91cdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-56fa33d8-0b4e-4c3b-80c6-82e38c41c6b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482251257-172.17.0.17-1598643107529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-7bba18ed-9baf-4923-bb45-bf81eafd8533,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-66cc1fef-1477-44c9-8f2d-43bf70d3bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-40adbc27-af16-404d-9106-d6be60820edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-079729c9-fd88-462a-b56b-48156edb234c,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-0e3f4b09-861c-4167-b257-0c0075bb4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-9a222fe4-d394-4c98-9099-e53e8d31f730,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-746a7503-7383-46aa-b1ca-2d71bb7fd436,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-3953b09e-8ec7-4fbb-9631-7f2a12b48c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482251257-172.17.0.17-1598643107529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-7bba18ed-9baf-4923-bb45-bf81eafd8533,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-66cc1fef-1477-44c9-8f2d-43bf70d3bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-40adbc27-af16-404d-9106-d6be60820edc,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-079729c9-fd88-462a-b56b-48156edb234c,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-0e3f4b09-861c-4167-b257-0c0075bb4d98,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-9a222fe4-d394-4c98-9099-e53e8d31f730,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-746a7503-7383-46aa-b1ca-2d71bb7fd436,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-3953b09e-8ec7-4fbb-9631-7f2a12b48c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541162642-172.17.0.17-1598643729695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-94afb4ca-7e51-4f80-99e2-54b164b36ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-a9fe46de-74e6-41d8-8ecd-ba98a4f03216,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-90946d81-9990-455a-b59b-2ce84afb6515,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-60629812-9629-491d-a72c-09efb82d3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-c4078727-15d2-483d-96f3-b7a80351974f,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-6e5b1f0b-b4c1-437f-8848-27361d72cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-58ac5efe-14ef-4b16-bf5c-50811e9ddbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-d0760250-1c31-4922-800a-8e0fbab722c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541162642-172.17.0.17-1598643729695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-94afb4ca-7e51-4f80-99e2-54b164b36ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-a9fe46de-74e6-41d8-8ecd-ba98a4f03216,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-90946d81-9990-455a-b59b-2ce84afb6515,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-60629812-9629-491d-a72c-09efb82d3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-c4078727-15d2-483d-96f3-b7a80351974f,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-6e5b1f0b-b4c1-437f-8848-27361d72cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-58ac5efe-14ef-4b16-bf5c-50811e9ddbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-d0760250-1c31-4922-800a-8e0fbab722c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564439311-172.17.0.17-1598644297075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-09cb7933-e5c5-4b7f-91ad-5df4e3261b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-9c592bd0-e39c-4ae7-841a-4f126c155e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-562867ef-a966-4503-8edd-932ab75d86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0ef4ec5a-a84c-4835-bb90-2d9d5eac4137,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-fe4670df-a13f-4287-a0b9-829461b3b598,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-b586b5a9-87ca-4fbd-ac21-892aef4122a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-7f7bbc4c-4f0c-4168-b699-6f691c257bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-d499b62b-6743-4a81-a837-337cbb3285bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564439311-172.17.0.17-1598644297075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-09cb7933-e5c5-4b7f-91ad-5df4e3261b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-9c592bd0-e39c-4ae7-841a-4f126c155e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-562867ef-a966-4503-8edd-932ab75d86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-0ef4ec5a-a84c-4835-bb90-2d9d5eac4137,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-fe4670df-a13f-4287-a0b9-829461b3b598,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-b586b5a9-87ca-4fbd-ac21-892aef4122a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-7f7bbc4c-4f0c-4168-b699-6f691c257bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-d499b62b-6743-4a81-a837-337cbb3285bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326415040-172.17.0.17-1598644978422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-33f23a5a-95dc-4ab6-8c29-42a5475e7284,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9a305bf4-de7e-49d4-ba6a-78eb8d73fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-13152ad1-72f6-4d08-8eb6-e47801993fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-81570087-1cdc-4187-96aa-2457c2b2a6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-ab807c4d-a88f-4ba2-94a2-20e95603284e,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-c723b336-2021-4969-95ae-dd1e1713b106,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-f95da0d3-e94a-4975-8ccd-bc8e4d0d7966,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ebda7df9-b6c6-4ed1-91ee-159a6ba4ca72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326415040-172.17.0.17-1598644978422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41398,DS-33f23a5a-95dc-4ab6-8c29-42a5475e7284,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9a305bf4-de7e-49d4-ba6a-78eb8d73fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-13152ad1-72f6-4d08-8eb6-e47801993fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-81570087-1cdc-4187-96aa-2457c2b2a6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-ab807c4d-a88f-4ba2-94a2-20e95603284e,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-c723b336-2021-4969-95ae-dd1e1713b106,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-f95da0d3-e94a-4975-8ccd-bc8e4d0d7966,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ebda7df9-b6c6-4ed1-91ee-159a6ba4ca72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678619500-172.17.0.17-1598645093115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-8e7c9300-9dea-478d-9afd-4559802333bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-31243132-e7cc-41e7-bad8-d9fd60c39315,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-227f7092-3d84-438d-86ab-38f14fa25c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-f3abe46e-367d-470b-ad23-5ec97e7fb1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-79395911-c089-4d74-856c-a582d733d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-a350d64e-d580-4688-9ec8-ed2b8585419d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-b0b16f2a-a86e-429f-a596-e9d3b691f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-70d8cad4-6d5a-4ca5-b3b4-7881344b547a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678619500-172.17.0.17-1598645093115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-8e7c9300-9dea-478d-9afd-4559802333bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-31243132-e7cc-41e7-bad8-d9fd60c39315,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-227f7092-3d84-438d-86ab-38f14fa25c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-f3abe46e-367d-470b-ad23-5ec97e7fb1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-79395911-c089-4d74-856c-a582d733d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-a350d64e-d580-4688-9ec8-ed2b8585419d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-b0b16f2a-a86e-429f-a596-e9d3b691f3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-70d8cad4-6d5a-4ca5-b3b4-7881344b547a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585925290-172.17.0.17-1598645349731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-ff2dee34-7d21-4443-98a8-81168005c248,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-010492e0-2490-4f55-a508-3dcc5d33c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-53528477-eb9a-4766-828f-72a100823a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9388884d-2a16-4d22-a72a-0ba673685fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-0b074fc1-5a79-448e-80e6-40db90180ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-fbbb7b2b-8cc0-44bd-b063-562f9732be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-ec5a30fd-7aae-4079-9002-2e719d8c6178,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-97830b13-5f5f-4856-a88c-27ae9a451f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-585925290-172.17.0.17-1598645349731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-ff2dee34-7d21-4443-98a8-81168005c248,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-010492e0-2490-4f55-a508-3dcc5d33c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-53528477-eb9a-4766-828f-72a100823a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9388884d-2a16-4d22-a72a-0ba673685fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-0b074fc1-5a79-448e-80e6-40db90180ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-fbbb7b2b-8cc0-44bd-b063-562f9732be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-ec5a30fd-7aae-4079-9002-2e719d8c6178,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-97830b13-5f5f-4856-a88c-27ae9a451f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377473903-172.17.0.17-1598645908897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-12c3c184-1219-45a6-93d2-ad60e7ecff57,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f0dac0ab-f3cb-4cfe-ac53-6e39964121f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-ffee0548-418b-4ca8-b2f7-ceebf6b65942,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-2f2aff93-8353-41d0-b511-cc95ce416980,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-3e79d3a5-b03a-497b-9ceb-a52fc3e01e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-c961b326-1ea6-4ac3-9f1d-6a2bae367597,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-364361a8-331f-4413-bee1-fb11b572469c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-e414c302-d8d2-446b-bba1-878b8512d504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377473903-172.17.0.17-1598645908897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-12c3c184-1219-45a6-93d2-ad60e7ecff57,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-f0dac0ab-f3cb-4cfe-ac53-6e39964121f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-ffee0548-418b-4ca8-b2f7-ceebf6b65942,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-2f2aff93-8353-41d0-b511-cc95ce416980,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-3e79d3a5-b03a-497b-9ceb-a52fc3e01e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-c961b326-1ea6-4ac3-9f1d-6a2bae367597,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-364361a8-331f-4413-bee1-fb11b572469c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-e414c302-d8d2-446b-bba1-878b8512d504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814067287-172.17.0.17-1598646133242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-3da90292-4c60-4a63-82b3-3b56def4f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-209f9b07-fd8d-4a1e-9fd8-34992e05dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-037f054d-4de7-4ea3-8f73-2e6038163a56,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-4acc22fa-fe2c-4cdb-aedb-461183d0340e,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-f04da83a-6942-4906-8cc9-6602ac4deb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-d3c4698e-4b93-4358-b2b7-ba1fbb693467,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-dbd03785-a8b0-4d16-90e3-401ff8870b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ec8c6f75-7392-4544-880d-480543955180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814067287-172.17.0.17-1598646133242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-3da90292-4c60-4a63-82b3-3b56def4f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-209f9b07-fd8d-4a1e-9fd8-34992e05dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-037f054d-4de7-4ea3-8f73-2e6038163a56,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-4acc22fa-fe2c-4cdb-aedb-461183d0340e,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-f04da83a-6942-4906-8cc9-6602ac4deb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-d3c4698e-4b93-4358-b2b7-ba1fbb693467,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-dbd03785-a8b0-4d16-90e3-401ff8870b95,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ec8c6f75-7392-4544-880d-480543955180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515758573-172.17.0.17-1598646210547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-1ceaeaa3-32ce-43ec-9704-1525151ad8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-36b34b39-9863-4880-8913-6f59e4ddf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5d36e88f-5b5d-459e-b55f-733e09fd1586,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-bc9f1653-9dae-4a2f-963b-5094d8595ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-fcaa6212-505b-417b-b8b1-29868acc359b,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-94fc2962-fedd-4bc0-8177-c349e803b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-7a01fc14-f22c-4797-ab04-1ec5e56276b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-2d72d58f-1e3c-43bd-9801-8059118fd040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515758573-172.17.0.17-1598646210547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-1ceaeaa3-32ce-43ec-9704-1525151ad8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-36b34b39-9863-4880-8913-6f59e4ddf0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5d36e88f-5b5d-459e-b55f-733e09fd1586,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-bc9f1653-9dae-4a2f-963b-5094d8595ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-fcaa6212-505b-417b-b8b1-29868acc359b,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-94fc2962-fedd-4bc0-8177-c349e803b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-7a01fc14-f22c-4797-ab04-1ec5e56276b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-2d72d58f-1e3c-43bd-9801-8059118fd040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 50000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582594476-172.17.0.17-1598646453006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-e22b8073-2025-4a88-b993-b09501ebab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-648c3085-e500-4268-87bb-7d9fde63960d,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6d8a424a-0de2-4b94-a4ed-b3c7283b50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-5c7a1675-9aa4-48e2-b613-66e0d3368075,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-d4ac5f7d-4301-48b2-9fcb-d62a7140a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-67f2c837-aa95-4ea4-bedb-21fa79064b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-8fe56dec-c6a8-4285-b460-b0676bd5d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-4bcf09a9-6715-49cc-8237-b2c11c4c2a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582594476-172.17.0.17-1598646453006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-e22b8073-2025-4a88-b993-b09501ebab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-648c3085-e500-4268-87bb-7d9fde63960d,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6d8a424a-0de2-4b94-a4ed-b3c7283b50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-5c7a1675-9aa4-48e2-b613-66e0d3368075,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-d4ac5f7d-4301-48b2-9fcb-d62a7140a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-67f2c837-aa95-4ea4-bedb-21fa79064b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-8fe56dec-c6a8-4285-b460-b0676bd5d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-4bcf09a9-6715-49cc-8237-b2c11c4c2a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5214
