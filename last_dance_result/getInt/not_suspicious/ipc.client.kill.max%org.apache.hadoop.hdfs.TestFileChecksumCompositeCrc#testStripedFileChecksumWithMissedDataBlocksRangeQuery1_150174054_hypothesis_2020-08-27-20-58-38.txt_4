reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49715674-172.17.0.20-1598562415049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35699,DS-88eb5aa3-2b1c-4c95-ba9c-6d71702d25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-27a2473a-9c0b-43f4-9b67-512afd916157,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-8e3c93a3-d539-4215-977b-cd5a6a2f0cac,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-f2da5f71-07bf-4bfc-8944-9f0bccb55faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-e9899248-027b-4783-8f20-f3b74fd65641,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-59ec4adc-0f67-4dcc-9e87-e5d2f0d7b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-bdac1921-359d-4408-a374-ab162bbb2b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-f75a7406-f0b5-4c53-a351-c69574c791ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49715674-172.17.0.20-1598562415049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35699,DS-88eb5aa3-2b1c-4c95-ba9c-6d71702d25d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-27a2473a-9c0b-43f4-9b67-512afd916157,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-8e3c93a3-d539-4215-977b-cd5a6a2f0cac,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-f2da5f71-07bf-4bfc-8944-9f0bccb55faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-e9899248-027b-4783-8f20-f3b74fd65641,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-59ec4adc-0f67-4dcc-9e87-e5d2f0d7b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-bdac1921-359d-4408-a374-ab162bbb2b41,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-f75a7406-f0b5-4c53-a351-c69574c791ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055186435-172.17.0.20-1598562577654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-af57dfcb-4302-429d-a0a2-4720705e79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-9bcb4174-4b1f-4c8b-95af-0c1492a32b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-6f6dac94-dc07-42b3-a6a1-f4d5bebc1ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-bf8053d4-90af-4c10-b3bc-71ed134217aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-69f0427f-4e9c-4596-96fe-0ed93fe779c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-b98c4697-df75-47d1-aaf8-a1c8b7a5d775,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-27b9446a-f7a5-4b90-bd6b-41f1ea850195,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-208b8827-523b-43f2-b1e0-57cdb34b9537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055186435-172.17.0.20-1598562577654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-af57dfcb-4302-429d-a0a2-4720705e79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-9bcb4174-4b1f-4c8b-95af-0c1492a32b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-6f6dac94-dc07-42b3-a6a1-f4d5bebc1ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-bf8053d4-90af-4c10-b3bc-71ed134217aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-69f0427f-4e9c-4596-96fe-0ed93fe779c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-b98c4697-df75-47d1-aaf8-a1c8b7a5d775,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-27b9446a-f7a5-4b90-bd6b-41f1ea850195,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-208b8827-523b-43f2-b1e0-57cdb34b9537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759592158-172.17.0.20-1598562719539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39069,DS-b43afb13-d060-4610-ba5d-a87039a42739,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-586a6d04-bd04-432f-9934-07bac7dc4474,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-df3e6557-dd62-4227-8f97-510f6babffdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-f3c1319d-38ae-4f72-b383-910a710c495e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-9c6103f8-c72a-463f-aa92-d987ac024648,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-d828ba80-689b-4092-9db2-853429ff0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e550ea94-4753-4650-be7d-fd48edce2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-c8278744-19cc-4601-8d3b-5ff13d803859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759592158-172.17.0.20-1598562719539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39069,DS-b43afb13-d060-4610-ba5d-a87039a42739,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-586a6d04-bd04-432f-9934-07bac7dc4474,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-df3e6557-dd62-4227-8f97-510f6babffdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-f3c1319d-38ae-4f72-b383-910a710c495e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-9c6103f8-c72a-463f-aa92-d987ac024648,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-d828ba80-689b-4092-9db2-853429ff0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e550ea94-4753-4650-be7d-fd48edce2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-c8278744-19cc-4601-8d3b-5ff13d803859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633295705-172.17.0.20-1598562894179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-14f4fb3a-80a3-4be1-ae59-7dac07a9776e,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-3dbeac2b-de1e-421c-a86f-317237a2f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-2a235818-274b-4438-bab1-e8a39c985b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-88b307c5-ccc7-43cc-b4ff-541f6978fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-8840c8e3-c655-4fda-99ce-66b73aff4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-475de4a4-39d7-456d-9f74-2ec335462891,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-2e81cf59-d95a-49e7-965a-6d4f326c1fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-53a83c7c-cfa6-4162-ad7b-385e8a5e05d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633295705-172.17.0.20-1598562894179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-14f4fb3a-80a3-4be1-ae59-7dac07a9776e,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-3dbeac2b-de1e-421c-a86f-317237a2f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-2a235818-274b-4438-bab1-e8a39c985b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-88b307c5-ccc7-43cc-b4ff-541f6978fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-8840c8e3-c655-4fda-99ce-66b73aff4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-475de4a4-39d7-456d-9f74-2ec335462891,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-2e81cf59-d95a-49e7-965a-6d4f326c1fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-53a83c7c-cfa6-4162-ad7b-385e8a5e05d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922549828-172.17.0.20-1598563000997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-cd2c26c6-67f5-4d19-8144-03c75afe6c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-e8f021c2-35d0-4050-a77e-8f6d53ab83dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-30a9e6e8-98f0-4935-86d1-6c7142b7e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-4547121d-07b7-4990-9fa5-7d07cd4f5c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-01236aef-d008-43ce-9557-168d8e9e5663,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-9f09db84-e7a8-43bc-aaf4-261981a0a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-a031ce83-5186-4348-b15b-63f04e71c784,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-41c6d86f-746d-42fb-bcbf-6bbc63bcc996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922549828-172.17.0.20-1598563000997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34560,DS-cd2c26c6-67f5-4d19-8144-03c75afe6c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-e8f021c2-35d0-4050-a77e-8f6d53ab83dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-30a9e6e8-98f0-4935-86d1-6c7142b7e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-4547121d-07b7-4990-9fa5-7d07cd4f5c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-01236aef-d008-43ce-9557-168d8e9e5663,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-9f09db84-e7a8-43bc-aaf4-261981a0a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-a031ce83-5186-4348-b15b-63f04e71c784,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-41c6d86f-746d-42fb-bcbf-6bbc63bcc996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054590109-172.17.0.20-1598563683192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-791c3d55-6e11-420e-af44-d684abd19176,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-7cea025f-3812-4504-98c3-a30ad42ea788,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-54a5f043-acb5-4a1a-8c63-da43ec81ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-44bb6ad7-cc12-49fc-afcd-ea3ba12e1eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-997dc87f-bf5b-4ab3-b0ee-da4a0349801c,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5f0fd851-760e-4f73-b1ea-204314a61319,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-019d9970-ddc9-4252-8e20-4ff52f613b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-4748c8f0-c4d6-438c-8c36-e7cdfb0cec00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054590109-172.17.0.20-1598563683192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-791c3d55-6e11-420e-af44-d684abd19176,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-7cea025f-3812-4504-98c3-a30ad42ea788,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-54a5f043-acb5-4a1a-8c63-da43ec81ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-44bb6ad7-cc12-49fc-afcd-ea3ba12e1eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-997dc87f-bf5b-4ab3-b0ee-da4a0349801c,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-5f0fd851-760e-4f73-b1ea-204314a61319,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-019d9970-ddc9-4252-8e20-4ff52f613b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-4748c8f0-c4d6-438c-8c36-e7cdfb0cec00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242344799-172.17.0.20-1598564478917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-3c30670c-a625-495c-959b-462aa0c948ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-adfec1e1-85f4-49af-9290-937c6fa14756,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-8ae31875-9a61-42fe-8629-581684f79074,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-da0e8c96-ae18-48f8-8fe1-621d7363658f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-a9561195-baa0-4bc8-90d1-ebca2c9d38a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-b28ec4f5-0ed8-414e-8a9f-483fdee00972,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-686758e1-c30e-44ce-a128-eb8c4f4daf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-7ff576c2-85f6-4d95-82c2-980290174921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242344799-172.17.0.20-1598564478917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-3c30670c-a625-495c-959b-462aa0c948ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-adfec1e1-85f4-49af-9290-937c6fa14756,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-8ae31875-9a61-42fe-8629-581684f79074,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-da0e8c96-ae18-48f8-8fe1-621d7363658f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-a9561195-baa0-4bc8-90d1-ebca2c9d38a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-b28ec4f5-0ed8-414e-8a9f-483fdee00972,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-686758e1-c30e-44ce-a128-eb8c4f4daf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-7ff576c2-85f6-4d95-82c2-980290174921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843444504-172.17.0.20-1598564655676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-b19675a9-6d52-43ba-a1f7-bea3534ec8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-764855c4-21ce-4cec-ae4a-15f7c77f4900,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c9102a45-81f0-4320-9f44-c23b7408bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-577e0f3b-d767-447f-8deb-f0c9b5fe7307,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-a278f7af-f9fb-4fa9-b482-b02ccbadd432,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-ea03da28-2218-41dd-ac06-c455a56b5d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-74b062df-674a-4e0b-8ec0-d3282eb72572,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-06ee9438-86fb-4ee4-82d9-99a976baf9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843444504-172.17.0.20-1598564655676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-b19675a9-6d52-43ba-a1f7-bea3534ec8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-764855c4-21ce-4cec-ae4a-15f7c77f4900,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-c9102a45-81f0-4320-9f44-c23b7408bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-577e0f3b-d767-447f-8deb-f0c9b5fe7307,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-a278f7af-f9fb-4fa9-b482-b02ccbadd432,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-ea03da28-2218-41dd-ac06-c455a56b5d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-74b062df-674a-4e0b-8ec0-d3282eb72572,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-06ee9438-86fb-4ee4-82d9-99a976baf9fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187105190-172.17.0.20-1598564738937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-42932672-8780-417e-affd-e6083e339324,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-d6b9a976-0795-4a38-9b0f-dbd42a3079b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-0a127c8b-f074-4f6d-8da2-250282bcee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-fe5394a0-a2dd-4959-9208-9bb05a3ce12f,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-1a501cb7-2dd9-4589-8abd-0519593d948a,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-8ec70840-c268-4251-8884-39e0408ed801,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-727b39b9-aff5-4a14-ba82-48153e8d89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-612fc27a-980e-43f8-ac7c-84f1c7577ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187105190-172.17.0.20-1598564738937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-42932672-8780-417e-affd-e6083e339324,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-d6b9a976-0795-4a38-9b0f-dbd42a3079b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-0a127c8b-f074-4f6d-8da2-250282bcee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-fe5394a0-a2dd-4959-9208-9bb05a3ce12f,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-1a501cb7-2dd9-4589-8abd-0519593d948a,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-8ec70840-c268-4251-8884-39e0408ed801,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-727b39b9-aff5-4a14-ba82-48153e8d89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-612fc27a-980e-43f8-ac7c-84f1c7577ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523245563-172.17.0.20-1598564847840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40592,DS-5ee617bf-3040-4624-ba13-04b011c4f848,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-df5c009f-9973-48ae-ad44-403035af7352,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-56e0de87-1bc8-49ae-8462-579745b796b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-676bdcb4-f609-4de1-ba07-0b8cf619511e,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-7f8b2130-f25d-4953-b7ef-385d10670f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-b57dc1a3-d09a-4a51-937c-81a620d26f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-669fa185-9bb1-429a-840f-0a03a7349013,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-3ef815af-7a9d-450a-b637-40fc6387e811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523245563-172.17.0.20-1598564847840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40592,DS-5ee617bf-3040-4624-ba13-04b011c4f848,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-df5c009f-9973-48ae-ad44-403035af7352,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-56e0de87-1bc8-49ae-8462-579745b796b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-676bdcb4-f609-4de1-ba07-0b8cf619511e,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-7f8b2130-f25d-4953-b7ef-385d10670f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-b57dc1a3-d09a-4a51-937c-81a620d26f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-669fa185-9bb1-429a-840f-0a03a7349013,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-3ef815af-7a9d-450a-b637-40fc6387e811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364492871-172.17.0.20-1598565028581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-0fc53cb7-b8e0-482c-af13-253a65a73286,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-b803fb88-30ff-4740-a227-d72072a8f5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-1a0a9cec-6577-4db1-871b-93aee7c1a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-f775e93e-b7c8-4865-b85b-60d8c2aac94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-6a06dbff-34fa-4ef9-895e-11b74f37d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-7fb4cf3a-e070-4123-af44-d296af3a1617,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-67251c1b-690a-4a51-9826-8179f825810d,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-9b619d85-5ea8-449f-b118-02d4cf37b270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364492871-172.17.0.20-1598565028581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-0fc53cb7-b8e0-482c-af13-253a65a73286,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-b803fb88-30ff-4740-a227-d72072a8f5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-1a0a9cec-6577-4db1-871b-93aee7c1a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-f775e93e-b7c8-4865-b85b-60d8c2aac94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-6a06dbff-34fa-4ef9-895e-11b74f37d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-7fb4cf3a-e070-4123-af44-d296af3a1617,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-67251c1b-690a-4a51-9826-8179f825810d,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-9b619d85-5ea8-449f-b118-02d4cf37b270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521278286-172.17.0.20-1598565364206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-6e92695f-8ae8-46d0-8908-e1467ffa5be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-05e6188d-af4a-47e2-b1a3-33632960f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-3efac8d9-cdfb-4959-b940-7552f4d42988,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-f8dc9cdb-9fb8-4d1d-8e20-da8d35aaecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-5e550b46-c5bd-41e0-aab3-45b2ce6e423b,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-04bfc1c8-5013-4c13-a4c2-6bb7bffdf2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-503b7584-de7e-43ca-92da-83dcfe62b993,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-4d45ba51-be75-4741-9ee2-0a23d455ab72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521278286-172.17.0.20-1598565364206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-6e92695f-8ae8-46d0-8908-e1467ffa5be7,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-05e6188d-af4a-47e2-b1a3-33632960f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-3efac8d9-cdfb-4959-b940-7552f4d42988,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-f8dc9cdb-9fb8-4d1d-8e20-da8d35aaecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-5e550b46-c5bd-41e0-aab3-45b2ce6e423b,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-04bfc1c8-5013-4c13-a4c2-6bb7bffdf2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-503b7584-de7e-43ca-92da-83dcfe62b993,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-4d45ba51-be75-4741-9ee2-0a23d455ab72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203246999-172.17.0.20-1598565436675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43440,DS-e7395c6a-c490-429e-ba9d-2911ff21c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-a3fff4de-b797-42ef-9aae-3724ad1634c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-947e29b4-b616-4238-bf54-d271c2bfe31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-cb5c2de7-226f-48d1-8c86-23722fe05f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-d58e5eff-a100-4b04-9db9-30ebfd59c847,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-f0e8d8f2-0070-4681-a7b0-c4707c91a842,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-9ac88b19-fe37-485d-b511-7b544826bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-931b744a-2b1a-4fe5-bb46-90ab9d5cda37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203246999-172.17.0.20-1598565436675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43440,DS-e7395c6a-c490-429e-ba9d-2911ff21c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-a3fff4de-b797-42ef-9aae-3724ad1634c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-947e29b4-b616-4238-bf54-d271c2bfe31f,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-cb5c2de7-226f-48d1-8c86-23722fe05f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-d58e5eff-a100-4b04-9db9-30ebfd59c847,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-f0e8d8f2-0070-4681-a7b0-c4707c91a842,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-9ac88b19-fe37-485d-b511-7b544826bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-931b744a-2b1a-4fe5-bb46-90ab9d5cda37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39479844-172.17.0.20-1598565469403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-bfd200d4-f2c4-4683-ba68-1212dc3ed4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-d31d33b3-7971-433d-9e5d-75c638ad4238,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-83e82d91-55e4-431a-b8ac-d3854d978d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-c209a4bf-cef7-4239-a6d4-94e7ca65f489,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-f6d2c759-3a54-4572-b502-beb8602c13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-b83a7549-9454-483e-bf6c-70d43982f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-c0dac1a6-6918-4bcc-8b22-3741452760c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-dde72efc-2acd-46a3-bca4-7ea2702dc9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39479844-172.17.0.20-1598565469403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-bfd200d4-f2c4-4683-ba68-1212dc3ed4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-d31d33b3-7971-433d-9e5d-75c638ad4238,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-83e82d91-55e4-431a-b8ac-d3854d978d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-c209a4bf-cef7-4239-a6d4-94e7ca65f489,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-f6d2c759-3a54-4572-b502-beb8602c13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-b83a7549-9454-483e-bf6c-70d43982f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-c0dac1a6-6918-4bcc-8b22-3741452760c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-dde72efc-2acd-46a3-bca4-7ea2702dc9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29311003-172.17.0.20-1598565504200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-87e90301-548a-4217-aed9-8d5279e4a631,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-e99c2794-1a37-47a5-888b-89d734ad1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-30c8f88a-a16e-4804-98d1-fbd71c6645ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-bad3dc96-c420-4d9d-866d-14fedce5e177,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a10359cb-97fe-44d6-800f-c800ccfe3436,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-850605f8-a2e5-4418-afe6-81d99e5dad54,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-d1aa63b4-5186-468a-a3ad-69b468095a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-66482458-f305-48c6-b78c-4c5fb82a5672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29311003-172.17.0.20-1598565504200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-87e90301-548a-4217-aed9-8d5279e4a631,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-e99c2794-1a37-47a5-888b-89d734ad1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-30c8f88a-a16e-4804-98d1-fbd71c6645ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-bad3dc96-c420-4d9d-866d-14fedce5e177,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a10359cb-97fe-44d6-800f-c800ccfe3436,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-850605f8-a2e5-4418-afe6-81d99e5dad54,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-d1aa63b4-5186-468a-a3ad-69b468095a64,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-66482458-f305-48c6-b78c-4c5fb82a5672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113087648-172.17.0.20-1598565540847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-fa04e970-9f46-4582-a2dc-3d697c178cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-550f4cc5-9646-4616-82b3-7de8362dd283,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-5e7ef6b4-c238-4f12-88b3-10f9399ac586,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-66b73391-4e5e-4acb-bf39-6d3c2cf7a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-dc9ca116-bca3-40b7-ab46-6fd202ce28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-76cc67f0-8a55-41fb-8e02-c7c91abbedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ae5a7cc9-1f1f-437e-b4cd-27bbeca9929d,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-3fe1b853-1d04-489b-b30b-1fd4c2ed260a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113087648-172.17.0.20-1598565540847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-fa04e970-9f46-4582-a2dc-3d697c178cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-550f4cc5-9646-4616-82b3-7de8362dd283,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-5e7ef6b4-c238-4f12-88b3-10f9399ac586,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-66b73391-4e5e-4acb-bf39-6d3c2cf7a95f,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-dc9ca116-bca3-40b7-ab46-6fd202ce28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-76cc67f0-8a55-41fb-8e02-c7c91abbedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ae5a7cc9-1f1f-437e-b4cd-27bbeca9929d,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-3fe1b853-1d04-489b-b30b-1fd4c2ed260a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489868412-172.17.0.20-1598565925088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-5991c618-59a8-423b-8c69-6d93ec73453c,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-ef9aebc7-e231-4f03-b673-fe949aff6e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-6b31dba2-d81f-46a7-b529-d62a8323b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-02aff580-c8ae-4f9f-8db5-616d57ff6a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-a4761295-c23d-4591-9410-5782195f8e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-d12d13bd-a32d-49d1-b843-cc73730c3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f02b40b0-9d03-402e-91d1-21f728b01e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-59e4aae4-d4cd-4757-81d4-0ce82079e780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489868412-172.17.0.20-1598565925088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-5991c618-59a8-423b-8c69-6d93ec73453c,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-ef9aebc7-e231-4f03-b673-fe949aff6e53,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-6b31dba2-d81f-46a7-b529-d62a8323b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-02aff580-c8ae-4f9f-8db5-616d57ff6a05,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-a4761295-c23d-4591-9410-5782195f8e30,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-d12d13bd-a32d-49d1-b843-cc73730c3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f02b40b0-9d03-402e-91d1-21f728b01e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-59e4aae4-d4cd-4757-81d4-0ce82079e780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563881097-172.17.0.20-1598566842526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-dd271e92-7920-41d9-b76a-3d407bd5a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-5ea737b1-fedb-48ee-b423-332fa0897177,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-bff3e86c-26a2-49fd-b060-c6792e014f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-5fd02767-3575-41ea-ba87-61e59c66f165,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-8f7a178a-ecaf-4db1-ab9c-add552c77bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-75fd16c8-ce8e-4fd6-86bd-ca7ad1f6bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f0b6aeb7-aa33-4445-848b-06a051babd07,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-77fde6af-dbef-4b21-9729-9adfa7b29281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563881097-172.17.0.20-1598566842526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-dd271e92-7920-41d9-b76a-3d407bd5a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-5ea737b1-fedb-48ee-b423-332fa0897177,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-bff3e86c-26a2-49fd-b060-c6792e014f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-5fd02767-3575-41ea-ba87-61e59c66f165,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-8f7a178a-ecaf-4db1-ab9c-add552c77bda,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-75fd16c8-ce8e-4fd6-86bd-ca7ad1f6bdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f0b6aeb7-aa33-4445-848b-06a051babd07,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-77fde6af-dbef-4b21-9729-9adfa7b29281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837715500-172.17.0.20-1598566877891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35133,DS-17e4813c-d7a3-4ae4-90bf-376abdc7ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-7d9f470b-f5ae-4c9e-a913-148e85db388d,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-57978803-d4da-4a93-9409-fd2b0d5f8554,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-2d559655-1d36-4ef7-b16e-d34e309222ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-65cde4d6-6d2b-4a3f-9bb7-0f76179bc7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-9e1bbdc8-c45c-4da7-bd87-3354c53a712e,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-bd809b28-fb9c-47e1-9ddb-2d18ce9cff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-331d52d2-d46c-4489-b48d-720f9e232a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837715500-172.17.0.20-1598566877891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35133,DS-17e4813c-d7a3-4ae4-90bf-376abdc7ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-7d9f470b-f5ae-4c9e-a913-148e85db388d,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-57978803-d4da-4a93-9409-fd2b0d5f8554,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-2d559655-1d36-4ef7-b16e-d34e309222ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-65cde4d6-6d2b-4a3f-9bb7-0f76179bc7db,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-9e1bbdc8-c45c-4da7-bd87-3354c53a712e,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-bd809b28-fb9c-47e1-9ddb-2d18ce9cff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-331d52d2-d46c-4489-b48d-720f9e232a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828638542-172.17.0.20-1598566909208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-137ae845-930b-4290-a4b5-99de979f2421,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-ec81114d-046b-4c76-b81f-7ae677cc8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-9c823dd8-58d1-4ecd-8456-5e2967f0d2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-465de657-7b27-4c53-aacb-255ee4dfd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-b04a3877-e335-4f0d-b866-777d471cd731,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-69bc4285-2e40-42ac-b574-708dd973b419,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-5eff9166-9bf3-4568-b179-7363bd4ecdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-eb01bfed-939f-48ec-a237-3b15b058c487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828638542-172.17.0.20-1598566909208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-137ae845-930b-4290-a4b5-99de979f2421,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-ec81114d-046b-4c76-b81f-7ae677cc8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-9c823dd8-58d1-4ecd-8456-5e2967f0d2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-465de657-7b27-4c53-aacb-255ee4dfd39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-b04a3877-e335-4f0d-b866-777d471cd731,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-69bc4285-2e40-42ac-b574-708dd973b419,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-5eff9166-9bf3-4568-b179-7363bd4ecdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-eb01bfed-939f-48ec-a237-3b15b058c487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5329
