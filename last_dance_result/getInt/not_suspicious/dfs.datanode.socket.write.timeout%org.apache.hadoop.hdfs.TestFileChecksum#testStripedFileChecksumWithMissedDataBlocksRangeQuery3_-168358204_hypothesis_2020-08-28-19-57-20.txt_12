reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811616420-172.17.0.15-1598645569837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-cf74dade-e972-4852-9da7-3c26ca55ac19,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-fdfc05e0-449a-4873-a9bb-249f46ae7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-122c90ee-5425-4cf2-9552-1f966c12f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-5b778a15-5dc7-443e-9644-b61de406e771,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-306e22ed-f67d-4873-b9d4-9c191d819d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-cea7e571-dbad-4264-8f5b-e618f8e5cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-7b8df63f-966d-481b-867f-0d88ca4b7861,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-ecf0e8cd-a696-494c-bf99-6c341b8b542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811616420-172.17.0.15-1598645569837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-cf74dade-e972-4852-9da7-3c26ca55ac19,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-fdfc05e0-449a-4873-a9bb-249f46ae7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-122c90ee-5425-4cf2-9552-1f966c12f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-5b778a15-5dc7-443e-9644-b61de406e771,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-306e22ed-f67d-4873-b9d4-9c191d819d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-cea7e571-dbad-4264-8f5b-e618f8e5cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-7b8df63f-966d-481b-867f-0d88ca4b7861,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-ecf0e8cd-a696-494c-bf99-6c341b8b542e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985431301-172.17.0.15-1598645671916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-ef4e04b0-655b-4b54-8988-11849a28f040,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-83e518b8-460f-401d-933d-d8b6a38874a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-6f5c3c6d-9b61-49a5-8378-c2ec7739a062,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-9a33302d-f9ec-4b8e-b45f-71cbe035730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-4a3735cf-bd78-4443-8c0e-22870c52dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-7380c453-8978-4c55-9a46-34a11f4da6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-451a6de1-49b3-4a56-ba1e-04a586d84931,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-eedcfc67-3ad6-4ec0-a5aa-e11100ba08dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985431301-172.17.0.15-1598645671916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-ef4e04b0-655b-4b54-8988-11849a28f040,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-83e518b8-460f-401d-933d-d8b6a38874a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-6f5c3c6d-9b61-49a5-8378-c2ec7739a062,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-9a33302d-f9ec-4b8e-b45f-71cbe035730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-4a3735cf-bd78-4443-8c0e-22870c52dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-7380c453-8978-4c55-9a46-34a11f4da6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-451a6de1-49b3-4a56-ba1e-04a586d84931,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-eedcfc67-3ad6-4ec0-a5aa-e11100ba08dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850157495-172.17.0.15-1598645737956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-c1da9d05-bd96-486e-a65c-d7a033f816d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c3c2a35c-2d87-4917-9f82-6c9b84e8b179,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-09044178-2a2e-4875-a395-9e8dcee57b63,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-21873e55-b682-449b-88f2-4a92fca081a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-a367dfba-e372-47e2-94cc-98ee3ec2036c,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-df1fba43-b5ae-45f3-b271-9a972b43118c,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-db408b7f-0392-44ed-8243-26d89f476c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-eeaf8531-7404-442c-8898-943887f1d4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850157495-172.17.0.15-1598645737956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-c1da9d05-bd96-486e-a65c-d7a033f816d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c3c2a35c-2d87-4917-9f82-6c9b84e8b179,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-09044178-2a2e-4875-a395-9e8dcee57b63,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-21873e55-b682-449b-88f2-4a92fca081a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-a367dfba-e372-47e2-94cc-98ee3ec2036c,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-df1fba43-b5ae-45f3-b271-9a972b43118c,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-db408b7f-0392-44ed-8243-26d89f476c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-eeaf8531-7404-442c-8898-943887f1d4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102156271-172.17.0.15-1598645937082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-796ca2b2-e1c2-4b27-910f-1282f8386717,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-1472c0aa-046c-4606-a6d6-aee9532da922,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6d3c5e93-e7c0-4036-b840-a9269f7788b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3d8ea0fa-1d17-465d-9a31-b229c375c8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-2e5b4ffe-a9c0-45d4-ad9f-36d77362b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-fce1f564-4635-4852-9603-86973c135d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9da100e1-aaf5-4e03-8f88-40ccde9a226a,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-dd66539e-89c4-4dae-af5e-90350ecf75b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102156271-172.17.0.15-1598645937082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-796ca2b2-e1c2-4b27-910f-1282f8386717,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-1472c0aa-046c-4606-a6d6-aee9532da922,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6d3c5e93-e7c0-4036-b840-a9269f7788b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3d8ea0fa-1d17-465d-9a31-b229c375c8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-2e5b4ffe-a9c0-45d4-ad9f-36d77362b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-fce1f564-4635-4852-9603-86973c135d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9da100e1-aaf5-4e03-8f88-40ccde9a226a,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-dd66539e-89c4-4dae-af5e-90350ecf75b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379530723-172.17.0.15-1598646150353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-1d53f0e9-e61d-4fae-a8f7-90c95a234c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a9563e04-83dd-4d6b-9a29-7287c926905c,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c053cd2c-aea7-4db0-8395-72f1ed5889d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ec0ffec8-6dee-45dd-b963-24ea5ff4a389,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-69a62b13-beb4-451d-95d5-820e1f520e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-93001185-5a72-4c89-a284-58e2bc4f7b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-ac0b9aae-e661-4742-a1a0-eec80de27886,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-4dafbb7b-bf85-4406-a082-3881906fea55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379530723-172.17.0.15-1598646150353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-1d53f0e9-e61d-4fae-a8f7-90c95a234c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-a9563e04-83dd-4d6b-9a29-7287c926905c,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c053cd2c-aea7-4db0-8395-72f1ed5889d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ec0ffec8-6dee-45dd-b963-24ea5ff4a389,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-69a62b13-beb4-451d-95d5-820e1f520e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-93001185-5a72-4c89-a284-58e2bc4f7b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-ac0b9aae-e661-4742-a1a0-eec80de27886,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-4dafbb7b-bf85-4406-a082-3881906fea55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300252267-172.17.0.15-1598646293031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-aa2bb36a-27b5-42f0-8ac4-4c96c9324b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-7bc6833e-476b-4080-ad96-006cae1611ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-e92daa98-1442-45e5-887d-1a24dade3a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-070a4fe3-1ce2-4f34-934a-ae717ac9a572,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-60f79aca-e63f-4866-a38f-b014f1fab240,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-08040475-72ec-41ae-bd9f-06fa0afff337,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-49afbc04-ac36-41b2-bfd4-582ff1b915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-96078dbe-5180-4be8-a6d6-a0e462d83048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300252267-172.17.0.15-1598646293031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-aa2bb36a-27b5-42f0-8ac4-4c96c9324b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-7bc6833e-476b-4080-ad96-006cae1611ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-e92daa98-1442-45e5-887d-1a24dade3a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-070a4fe3-1ce2-4f34-934a-ae717ac9a572,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-60f79aca-e63f-4866-a38f-b014f1fab240,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-08040475-72ec-41ae-bd9f-06fa0afff337,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-49afbc04-ac36-41b2-bfd4-582ff1b915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-96078dbe-5180-4be8-a6d6-a0e462d83048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655535923-172.17.0.15-1598646396282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-92cbc6f6-f0c7-465e-821b-182332503620,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-ac21055d-c03d-4a81-a9d8-d9e03c327037,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-40100236-74fa-4c35-9d3b-d1b1c9c23d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0ee1304d-a618-48c5-a6d0-753018ce1c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-61591bef-2405-462a-9789-3e4d5cd94e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-3d0ffcff-2799-4f17-abd6-3a62d8a67949,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-b90b9125-308e-4ced-8986-8c442bbda833,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-2d19abb6-c40a-4fe1-aed5-89a35a11aaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655535923-172.17.0.15-1598646396282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-92cbc6f6-f0c7-465e-821b-182332503620,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-ac21055d-c03d-4a81-a9d8-d9e03c327037,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-40100236-74fa-4c35-9d3b-d1b1c9c23d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0ee1304d-a618-48c5-a6d0-753018ce1c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-61591bef-2405-462a-9789-3e4d5cd94e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-3d0ffcff-2799-4f17-abd6-3a62d8a67949,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-b90b9125-308e-4ced-8986-8c442bbda833,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-2d19abb6-c40a-4fe1-aed5-89a35a11aaa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763097055-172.17.0.15-1598646469591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7011f5cc-0918-425e-a305-6bc791c2ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-f57034ef-c13b-49fd-b4f6-01786288c512,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-58e968a4-fdeb-478c-802f-1141c59f4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-45b4fa4c-3175-426d-8912-30ba95f78f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-bd96c712-3d53-4aa5-92d6-b480608d137d,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fc597218-5901-4278-afbd-bc3d58f76251,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-011fd799-fcd3-4cc7-b377-a164bbf376e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-11302559-7005-4bd4-be9b-f631ba831fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763097055-172.17.0.15-1598646469591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7011f5cc-0918-425e-a305-6bc791c2ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-f57034ef-c13b-49fd-b4f6-01786288c512,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-58e968a4-fdeb-478c-802f-1141c59f4eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-45b4fa4c-3175-426d-8912-30ba95f78f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-bd96c712-3d53-4aa5-92d6-b480608d137d,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fc597218-5901-4278-afbd-bc3d58f76251,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-011fd799-fcd3-4cc7-b377-a164bbf376e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-11302559-7005-4bd4-be9b-f631ba831fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918515965-172.17.0.15-1598646500803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-76af0194-c79f-4423-b740-89eb58a60e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f36e0d91-56ba-4a9d-9f29-6fd5a1056ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1e6b4b16-3979-40bd-8dec-08f38887a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-471ea7df-9a18-4009-8eb1-fbba33d0ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-2ec11607-06a8-4c6b-a920-958f6c74b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-25501a2d-7a07-4705-9131-f9fa156b3efd,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-1bc67586-b6d2-4961-8f49-46017009f7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5a2f8c68-6423-47db-a3cc-f3821e79a062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918515965-172.17.0.15-1598646500803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-76af0194-c79f-4423-b740-89eb58a60e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f36e0d91-56ba-4a9d-9f29-6fd5a1056ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1e6b4b16-3979-40bd-8dec-08f38887a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-471ea7df-9a18-4009-8eb1-fbba33d0ed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-2ec11607-06a8-4c6b-a920-958f6c74b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-25501a2d-7a07-4705-9131-f9fa156b3efd,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-1bc67586-b6d2-4961-8f49-46017009f7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-5a2f8c68-6423-47db-a3cc-f3821e79a062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812421877-172.17.0.15-1598646540540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-c454f6ab-905a-4625-96d6-fbb3bda58e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6e6f251f-abc3-4e0e-910c-b176ab49e2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-c81637d4-303b-46d6-b678-bd74ae55c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-72353127-fc4f-4912-a810-5d98c9ff5ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-c1fa4077-c8aa-46b8-9360-2af5a1a28c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-9fcb6925-91df-4548-9052-4dd169417aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5fba4220-a02d-4c7e-a22a-2822a51cf14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-9bf6715f-5b1e-4c73-8bec-08ab5d79b5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812421877-172.17.0.15-1598646540540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-c454f6ab-905a-4625-96d6-fbb3bda58e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6e6f251f-abc3-4e0e-910c-b176ab49e2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-c81637d4-303b-46d6-b678-bd74ae55c67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-72353127-fc4f-4912-a810-5d98c9ff5ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-c1fa4077-c8aa-46b8-9360-2af5a1a28c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-9fcb6925-91df-4548-9052-4dd169417aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5fba4220-a02d-4c7e-a22a-2822a51cf14c,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-9bf6715f-5b1e-4c73-8bec-08ab5d79b5c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472857574-172.17.0.15-1598646774340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-4752b871-522d-44db-8138-18131a1b2207,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-702baea1-b43b-4613-9ece-92eb6ffebae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-bf388043-630f-4cec-a64d-c75c4d1fa8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-1b26cdda-1995-46ae-9b95-f2a4b4a1ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-abbd4fa0-2cc7-4f56-ad13-919d453e64ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-26f2764c-a76f-4bd4-a15c-a3a0d9de01cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-3f9c8540-09f5-414b-b59e-6f0f83384ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-a4d693aa-f5af-4886-b198-faf10e8742f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472857574-172.17.0.15-1598646774340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-4752b871-522d-44db-8138-18131a1b2207,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-702baea1-b43b-4613-9ece-92eb6ffebae7,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-bf388043-630f-4cec-a64d-c75c4d1fa8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-1b26cdda-1995-46ae-9b95-f2a4b4a1ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-abbd4fa0-2cc7-4f56-ad13-919d453e64ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-26f2764c-a76f-4bd4-a15c-a3a0d9de01cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-3f9c8540-09f5-414b-b59e-6f0f83384ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-a4d693aa-f5af-4886-b198-faf10e8742f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708860146-172.17.0.15-1598647138208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-110fbe39-d6dd-483d-9504-f5f84c984bba,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-5ed93475-13e6-409e-8701-145139a3a6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-57f96741-3c3f-4e80-a61b-88b8a795e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-e354e0c9-354d-404b-bf91-1228057dbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-da03786a-f234-48fd-827f-533c9271b730,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-59bf463e-a54a-4cc6-abe4-7416e6c3300e,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-e45e6fdd-a698-48d0-95c4-2bf47bace835,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e9377791-ccad-4a1f-a1d9-7612b9d760c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708860146-172.17.0.15-1598647138208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-110fbe39-d6dd-483d-9504-f5f84c984bba,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-5ed93475-13e6-409e-8701-145139a3a6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-57f96741-3c3f-4e80-a61b-88b8a795e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-e354e0c9-354d-404b-bf91-1228057dbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-da03786a-f234-48fd-827f-533c9271b730,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-59bf463e-a54a-4cc6-abe4-7416e6c3300e,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-e45e6fdd-a698-48d0-95c4-2bf47bace835,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e9377791-ccad-4a1f-a1d9-7612b9d760c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988781045-172.17.0.15-1598647583641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-bac226fd-6522-4b8e-b573-6c2b34daf89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4b60638f-0c4f-4570-84a6-99e9deb39678,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3afabf8b-7976-42e3-805f-8365d311473a,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-23f5b7e4-2b3f-4fc8-9daf-b005fe48b147,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-f1c6dfb0-45c5-405d-a719-9a97e62d798e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-771d5ee6-bada-4022-801b-34bda137916c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-06f2eb8a-c552-4d74-bb17-6030d20c0d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-2af7f411-6ed0-4340-a65d-be13a8e25379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988781045-172.17.0.15-1598647583641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43345,DS-bac226fd-6522-4b8e-b573-6c2b34daf89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4b60638f-0c4f-4570-84a6-99e9deb39678,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3afabf8b-7976-42e3-805f-8365d311473a,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-23f5b7e4-2b3f-4fc8-9daf-b005fe48b147,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-f1c6dfb0-45c5-405d-a719-9a97e62d798e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-771d5ee6-bada-4022-801b-34bda137916c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-06f2eb8a-c552-4d74-bb17-6030d20c0d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-2af7f411-6ed0-4340-a65d-be13a8e25379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101238661-172.17.0.15-1598647674115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-a4711cca-c9f9-43b4-a3a7-d327b6583298,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-be7b134b-3a8b-4ada-9978-52bc1135098c,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-adf9d2c3-e4df-43df-98c3-2fedfafeee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-46fc4ff6-f469-460e-bda9-1c65e6b5d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-939b8efd-ca32-4805-92f1-a89c7b6ec9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-5b5c5def-3d76-4b55-ba99-b0bca0e3ba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8b5f155f-f62b-451b-9106-51f283e677d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-728351c0-7776-415f-92e1-b86dc8956bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101238661-172.17.0.15-1598647674115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-a4711cca-c9f9-43b4-a3a7-d327b6583298,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-be7b134b-3a8b-4ada-9978-52bc1135098c,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-adf9d2c3-e4df-43df-98c3-2fedfafeee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-46fc4ff6-f469-460e-bda9-1c65e6b5d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-939b8efd-ca32-4805-92f1-a89c7b6ec9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-5b5c5def-3d76-4b55-ba99-b0bca0e3ba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8b5f155f-f62b-451b-9106-51f283e677d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-728351c0-7776-415f-92e1-b86dc8956bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681260297-172.17.0.15-1598648051614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-3ccacb52-2219-4124-bbd8-01aae0e01538,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b5299fd5-df68-4560-ad4f-f5d504427061,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-8531bd90-827f-4c36-a460-6f817265b441,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-c883bb83-4ee3-4b3b-84d3-01d9d9957c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-93e1d7c1-daa5-43e8-8eaa-5e0a4ba76b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-9b9960c8-b1d9-4090-bd3f-a12cb107bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-25a313f1-83e9-4a6b-8972-516aadf2210c,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-dd9652b6-ef9f-4f16-baee-03f219990ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681260297-172.17.0.15-1598648051614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-3ccacb52-2219-4124-bbd8-01aae0e01538,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b5299fd5-df68-4560-ad4f-f5d504427061,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-8531bd90-827f-4c36-a460-6f817265b441,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-c883bb83-4ee3-4b3b-84d3-01d9d9957c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-93e1d7c1-daa5-43e8-8eaa-5e0a4ba76b93,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-9b9960c8-b1d9-4090-bd3f-a12cb107bb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-25a313f1-83e9-4a6b-8972-516aadf2210c,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-dd9652b6-ef9f-4f16-baee-03f219990ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930907618-172.17.0.15-1598648121641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-5f6ad945-c863-425a-9383-6189c58040ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-44f3b951-76f7-4d97-807d-323212fed3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-8c653061-a442-4bf1-b6a7-cbf2b63dd1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-61f526d3-22a3-484b-a7d2-2e4ad2ade470,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-9d97a72c-2bde-4cb6-a4a5-86f25139c043,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-514115da-619a-420b-baa2-fbbc3f594eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-ad947458-8a8a-4f0c-a4c4-2ca8985bca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-6c8c622c-625f-45ba-a354-94d12e44c320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930907618-172.17.0.15-1598648121641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-5f6ad945-c863-425a-9383-6189c58040ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-44f3b951-76f7-4d97-807d-323212fed3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-8c653061-a442-4bf1-b6a7-cbf2b63dd1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-61f526d3-22a3-484b-a7d2-2e4ad2ade470,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-9d97a72c-2bde-4cb6-a4a5-86f25139c043,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-514115da-619a-420b-baa2-fbbc3f594eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-ad947458-8a8a-4f0c-a4c4-2ca8985bca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-6c8c622c-625f-45ba-a354-94d12e44c320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003570709-172.17.0.15-1598648381212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35879,DS-132e4485-4621-4c94-a610-6e6436a26cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-6cdf15d3-d8d8-4b04-baf5-104f3778ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-b25d8eff-4d1f-4cdc-b1e4-7352d747dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-06678220-6ed5-48bb-9e03-6df86c7aa283,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-95c432ee-d1c3-4873-8a49-9923cabea4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-beafe74c-1c88-432d-b94f-9fc44f4f3a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-c6e53c13-d8a0-4091-abfb-3352fd6cefde,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-145415cb-2e6e-4e06-a6ac-e6c1b6acefd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003570709-172.17.0.15-1598648381212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35879,DS-132e4485-4621-4c94-a610-6e6436a26cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-6cdf15d3-d8d8-4b04-baf5-104f3778ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-b25d8eff-4d1f-4cdc-b1e4-7352d747dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-06678220-6ed5-48bb-9e03-6df86c7aa283,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-95c432ee-d1c3-4873-8a49-9923cabea4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-beafe74c-1c88-432d-b94f-9fc44f4f3a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-c6e53c13-d8a0-4091-abfb-3352fd6cefde,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-145415cb-2e6e-4e06-a6ac-e6c1b6acefd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399481473-172.17.0.15-1598648780605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-5d5ec4c6-adf1-4fb4-80f2-11d05c458226,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-e6dde43d-438e-4e9b-83f8-80c308f95bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-8aa7f946-e7ec-4fa0-a65e-96de416a35de,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2f935274-ebb8-4611-a74e-727369e453ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-ecd42e33-8ed9-4fad-81cd-4c66a10b78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-da127da3-523a-4868-bd76-28eaa8720c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-e16fc22c-1403-4a19-858f-3e32c6f87263,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f5eb5ee5-6a5a-45bc-8350-9b6b2857b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399481473-172.17.0.15-1598648780605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34673,DS-5d5ec4c6-adf1-4fb4-80f2-11d05c458226,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-e6dde43d-438e-4e9b-83f8-80c308f95bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-8aa7f946-e7ec-4fa0-a65e-96de416a35de,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2f935274-ebb8-4611-a74e-727369e453ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-ecd42e33-8ed9-4fad-81cd-4c66a10b78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-da127da3-523a-4868-bd76-28eaa8720c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-e16fc22c-1403-4a19-858f-3e32c6f87263,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f5eb5ee5-6a5a-45bc-8350-9b6b2857b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130971595-172.17.0.15-1598649220704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38316,DS-3aee340d-b4bb-42b3-b7ee-508fa5fd3bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-e694fb55-9acf-4956-8850-944a4df5f0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-92896f72-6e27-468e-be3c-6cabb5d3005d,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-a21b0c98-e538-4536-bbdf-e1666192f994,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-f3368f1d-273c-453f-ad90-c62ba1a80a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-57053e42-85e8-4ac7-8769-6d503cbb2407,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-b13ac6ac-fd06-4df3-ada4-d06bc59cedeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-7c101ecd-c283-410d-918d-b62c37f198b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130971595-172.17.0.15-1598649220704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38316,DS-3aee340d-b4bb-42b3-b7ee-508fa5fd3bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-e694fb55-9acf-4956-8850-944a4df5f0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-92896f72-6e27-468e-be3c-6cabb5d3005d,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-a21b0c98-e538-4536-bbdf-e1666192f994,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-f3368f1d-273c-453f-ad90-c62ba1a80a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-57053e42-85e8-4ac7-8769-6d503cbb2407,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-b13ac6ac-fd06-4df3-ada4-d06bc59cedeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-7c101ecd-c283-410d-918d-b62c37f198b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056685360-172.17.0.15-1598649595516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40510,DS-356f285a-5a13-41cb-9e9c-ea64abe897ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-3ebc57cf-5fd0-408c-9caa-485b4b7743c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-d233d5bf-51a6-43db-9c9d-b890e60dcd14,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-1114f5db-a8fd-4b05-b64b-89371453f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-bb090c1c-787f-46a7-bd7b-e67bf537ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-14a22eb4-a7e0-484b-bdf9-714ae0a7c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-460fa068-eb12-4c91-9191-d9860f77d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5fc54520-3bb9-4c8c-968f-667d82008473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056685360-172.17.0.15-1598649595516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40510,DS-356f285a-5a13-41cb-9e9c-ea64abe897ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-3ebc57cf-5fd0-408c-9caa-485b4b7743c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-d233d5bf-51a6-43db-9c9d-b890e60dcd14,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-1114f5db-a8fd-4b05-b64b-89371453f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-bb090c1c-787f-46a7-bd7b-e67bf537ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-14a22eb4-a7e0-484b-bdf9-714ae0a7c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-460fa068-eb12-4c91-9191-d9860f77d2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5fc54520-3bb9-4c8c-968f-667d82008473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5222
