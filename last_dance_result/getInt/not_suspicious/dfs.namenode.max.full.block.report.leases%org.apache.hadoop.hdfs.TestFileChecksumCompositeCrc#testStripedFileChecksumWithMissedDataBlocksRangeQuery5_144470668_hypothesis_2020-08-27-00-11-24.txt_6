reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796075556-172.17.0.13-1598487715134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-b9c38cf6-4e11-4c57-936d-bdd163b52f77,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-0a00cf8b-e709-4243-831d-a72947052cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-f012200e-fa66-4071-814e-23ec893a2a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-32aa1764-57e4-42f0-b059-c50274d6eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-387a9f2f-675b-4f9b-9ae5-957e79b4ef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-9109d6e8-ec50-4316-817d-5b8a9b395a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-55254cbd-a6a2-4bb5-aaf0-b40f5c8dc805,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-b95cfeb1-e5aa-492a-8807-a01e410f5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796075556-172.17.0.13-1598487715134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-b9c38cf6-4e11-4c57-936d-bdd163b52f77,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-0a00cf8b-e709-4243-831d-a72947052cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-f012200e-fa66-4071-814e-23ec893a2a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-32aa1764-57e4-42f0-b059-c50274d6eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-387a9f2f-675b-4f9b-9ae5-957e79b4ef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-9109d6e8-ec50-4316-817d-5b8a9b395a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-55254cbd-a6a2-4bb5-aaf0-b40f5c8dc805,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-b95cfeb1-e5aa-492a-8807-a01e410f5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179161966-172.17.0.13-1598487829250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-5356633a-04b7-4104-8f0b-e3ebe10bacf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-05442699-0baa-46c7-a0e0-1832b24c667e,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-c2c65ca5-85ef-4294-874b-381d35d6a385,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-f7a6c118-d7da-430a-91c0-6bfa990bccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-09039a6e-3eb0-4f4e-b3b8-2c9b23c3d45b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-2ad3c054-2539-46fa-b772-4892137241c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-85dce8fb-22d8-4038-9544-aae31e9965b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-ce0d7b67-10cb-46a7-bb6e-35b7aa6188ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179161966-172.17.0.13-1598487829250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-5356633a-04b7-4104-8f0b-e3ebe10bacf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-05442699-0baa-46c7-a0e0-1832b24c667e,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-c2c65ca5-85ef-4294-874b-381d35d6a385,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-f7a6c118-d7da-430a-91c0-6bfa990bccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-09039a6e-3eb0-4f4e-b3b8-2c9b23c3d45b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-2ad3c054-2539-46fa-b772-4892137241c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-85dce8fb-22d8-4038-9544-aae31e9965b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-ce0d7b67-10cb-46a7-bb6e-35b7aa6188ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212376022-172.17.0.13-1598487868573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-587ff63a-5618-4dd0-b5f6-144cb7b3ff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-3320db8f-8acc-4bff-bb67-572ac5fbcf10,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-868afdcb-aebf-45ec-9d59-2b0deb685cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-22bb8a7f-135c-434c-b7bf-9e1ea8c0c29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-050caac0-b26f-4f87-9871-480392cd00da,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3eda5b4d-8aab-4b3d-8e0d-7e8ffa68a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-62dafde5-b8a8-4fe8-bc63-b1c93470e034,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-d75857f3-0f04-4b9c-9a13-8ee49f84a3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212376022-172.17.0.13-1598487868573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40325,DS-587ff63a-5618-4dd0-b5f6-144cb7b3ff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-3320db8f-8acc-4bff-bb67-572ac5fbcf10,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-868afdcb-aebf-45ec-9d59-2b0deb685cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-22bb8a7f-135c-434c-b7bf-9e1ea8c0c29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-050caac0-b26f-4f87-9871-480392cd00da,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3eda5b4d-8aab-4b3d-8e0d-7e8ffa68a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-62dafde5-b8a8-4fe8-bc63-b1c93470e034,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-d75857f3-0f04-4b9c-9a13-8ee49f84a3e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229827193-172.17.0.13-1598488025407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33434,DS-0146a6c3-9ed8-4d75-984d-ee7b512e5848,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-801c1a10-265d-479c-83c2-c42690c8255e,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-ca656924-c8fd-4021-8621-198903d35965,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-6fa25bd9-4e80-4fb5-9642-ad714addf840,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-a9355662-b1e4-4e2f-8a48-12766977fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-9c41a7de-8d82-4d72-b452-edfe0710026b,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-988f8d30-2a31-4c58-9bf6-9ef3ba0a475a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-85cf560c-63c0-4404-8b6e-ec146d4679dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229827193-172.17.0.13-1598488025407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33434,DS-0146a6c3-9ed8-4d75-984d-ee7b512e5848,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-801c1a10-265d-479c-83c2-c42690c8255e,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-ca656924-c8fd-4021-8621-198903d35965,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-6fa25bd9-4e80-4fb5-9642-ad714addf840,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-a9355662-b1e4-4e2f-8a48-12766977fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-9c41a7de-8d82-4d72-b452-edfe0710026b,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-988f8d30-2a31-4c58-9bf6-9ef3ba0a475a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-85cf560c-63c0-4404-8b6e-ec146d4679dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981242482-172.17.0.13-1598488469973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-28ecc1fd-1494-4505-b2b2-6a4a1ae1cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-650ec2fb-056b-404d-a027-5dd77caeaa45,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e87be169-a043-4334-86dc-ffac71762383,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-24c467b8-d3d7-4763-8e4c-3b12d73cd5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-4e2f0479-196e-4f3c-8f23-5de218e6d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-92393996-f416-4b79-89d7-d3d3ba3cfff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-853e0365-68e0-4c7d-99ec-ed4be64005e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-c534c28d-02d7-4bb0-b7eb-2a2e76a7ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981242482-172.17.0.13-1598488469973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-28ecc1fd-1494-4505-b2b2-6a4a1ae1cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-650ec2fb-056b-404d-a027-5dd77caeaa45,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e87be169-a043-4334-86dc-ffac71762383,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-24c467b8-d3d7-4763-8e4c-3b12d73cd5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-4e2f0479-196e-4f3c-8f23-5de218e6d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-92393996-f416-4b79-89d7-d3d3ba3cfff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-853e0365-68e0-4c7d-99ec-ed4be64005e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-c534c28d-02d7-4bb0-b7eb-2a2e76a7ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264563851-172.17.0.13-1598489464997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-5f7ac23e-0a04-41ea-84d2-4fadbe194e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-68560cdf-78f1-47f3-849f-c53368070410,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-397e44ab-029d-4447-a756-6fd1beb09dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-6e962956-8f78-4459-8178-11e63dabed62,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-a6ba6e3c-7a4f-42c3-9adc-779c9975ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-b0d464a3-db7d-420a-b83c-6b35b7955673,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-7025758b-5696-4d3b-b72c-75f625c1116d,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-9c09636d-2faa-464e-a0e0-a218788dfee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264563851-172.17.0.13-1598489464997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45460,DS-5f7ac23e-0a04-41ea-84d2-4fadbe194e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-68560cdf-78f1-47f3-849f-c53368070410,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-397e44ab-029d-4447-a756-6fd1beb09dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-6e962956-8f78-4459-8178-11e63dabed62,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-a6ba6e3c-7a4f-42c3-9adc-779c9975ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-b0d464a3-db7d-420a-b83c-6b35b7955673,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-7025758b-5696-4d3b-b72c-75f625c1116d,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-9c09636d-2faa-464e-a0e0-a218788dfee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731651702-172.17.0.13-1598489780687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-b048e20a-5f12-43e2-87b7-2394086145ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-bcb76207-28bc-4fe3-a6e9-2c4d4a24298d,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-449f701e-0c58-4591-b56e-4726757d9275,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-a0838431-80e6-41c0-8e90-3354adfb3045,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-966ded6d-80cc-4b1a-82cc-fb0bb26d31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-9cc19df4-2ae8-45ef-aa38-ca5983f1d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-d82f726e-da05-419c-8de8-5d87e2c3785e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-94c9ef17-9d72-405e-861e-e08604780384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731651702-172.17.0.13-1598489780687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-b048e20a-5f12-43e2-87b7-2394086145ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-bcb76207-28bc-4fe3-a6e9-2c4d4a24298d,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-449f701e-0c58-4591-b56e-4726757d9275,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-a0838431-80e6-41c0-8e90-3354adfb3045,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-966ded6d-80cc-4b1a-82cc-fb0bb26d31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-9cc19df4-2ae8-45ef-aa38-ca5983f1d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-d82f726e-da05-419c-8de8-5d87e2c3785e,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-94c9ef17-9d72-405e-861e-e08604780384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944499055-172.17.0.13-1598490448274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-c2417adf-357e-4415-a410-5e623a8a2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-74107bf5-6875-4696-916d-9a06ca444fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-2b3dc1c4-1b06-4a3f-8307-5eddd3754508,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-1a8dd5e2-ce13-4602-8246-09f760c33712,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-077e26ae-79eb-4b6a-ab5b-4384fb94defe,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-224d3477-cb8d-4396-8ac2-89a57012164f,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f3223c3e-10e9-49f5-adbf-2fba5114f403,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4e593de6-6618-4da3-9ae7-f7f4dfc9e050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944499055-172.17.0.13-1598490448274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45977,DS-c2417adf-357e-4415-a410-5e623a8a2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-74107bf5-6875-4696-916d-9a06ca444fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-2b3dc1c4-1b06-4a3f-8307-5eddd3754508,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-1a8dd5e2-ce13-4602-8246-09f760c33712,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-077e26ae-79eb-4b6a-ab5b-4384fb94defe,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-224d3477-cb8d-4396-8ac2-89a57012164f,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-f3223c3e-10e9-49f5-adbf-2fba5114f403,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-4e593de6-6618-4da3-9ae7-f7f4dfc9e050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213323818-172.17.0.13-1598490636385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-5ba8f995-2a54-4f31-9f1d-ab7d197e4057,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-9f70313b-1cf5-4eb2-88d7-d87ee88d3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-44129422-5406-48bd-9be2-72d69cf8963c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-c491db75-f0ab-4589-a60e-011c2dad1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-5693e22f-42ce-423c-acd8-7e4f85b5c187,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-4ca38a2f-2bb4-4813-889c-d978dfd23206,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-5e48ce29-fea1-4fb8-9f25-9c656eaa351c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-c9d88ba1-432e-446c-a64e-e24f1978495b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1213323818-172.17.0.13-1598490636385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-5ba8f995-2a54-4f31-9f1d-ab7d197e4057,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-9f70313b-1cf5-4eb2-88d7-d87ee88d3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-44129422-5406-48bd-9be2-72d69cf8963c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-c491db75-f0ab-4589-a60e-011c2dad1b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-5693e22f-42ce-423c-acd8-7e4f85b5c187,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-4ca38a2f-2bb4-4813-889c-d978dfd23206,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-5e48ce29-fea1-4fb8-9f25-9c656eaa351c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-c9d88ba1-432e-446c-a64e-e24f1978495b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728523239-172.17.0.13-1598490710761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-c02eac4d-ae7e-4f77-af69-18862e2042bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-0c6cfb5d-72bb-471c-b801-630b25b567f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-b0f9efa1-6e7a-464c-9ea0-6ef669656848,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-f0b28b69-929e-44e5-be70-8cfb1e7de5de,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-e97f9ebb-90dc-42b3-a6b4-fab1c9bda376,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-8630bda5-daac-460d-977f-f37f0a1f061e,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-59b3a048-b189-48fd-b73b-7ee62d3ea382,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-8841946a-3c6c-46dc-a5a1-03844aecf138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728523239-172.17.0.13-1598490710761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-c02eac4d-ae7e-4f77-af69-18862e2042bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-0c6cfb5d-72bb-471c-b801-630b25b567f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-b0f9efa1-6e7a-464c-9ea0-6ef669656848,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-f0b28b69-929e-44e5-be70-8cfb1e7de5de,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-e97f9ebb-90dc-42b3-a6b4-fab1c9bda376,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-8630bda5-daac-460d-977f-f37f0a1f061e,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-59b3a048-b189-48fd-b73b-7ee62d3ea382,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-8841946a-3c6c-46dc-a5a1-03844aecf138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348715480-172.17.0.13-1598490949054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-44241a07-aebd-4d2b-8e77-6c8be5f573f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-2300299c-808e-4068-929c-e71c147ab80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-8044c438-9acb-4cd6-b608-d599059a0690,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-a19dc1df-6f7a-4171-8969-c5d21ad7bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-8e612a72-f57e-46e6-95e6-0e3a1cc1b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-0a95f699-7477-4618-b4da-0d9d04a88769,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-b3f2a7c4-0cdb-41d7-bed0-6e083b0c6536,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-2040715c-3519-4049-888c-6599377d8c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348715480-172.17.0.13-1598490949054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-44241a07-aebd-4d2b-8e77-6c8be5f573f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-2300299c-808e-4068-929c-e71c147ab80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-8044c438-9acb-4cd6-b608-d599059a0690,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-a19dc1df-6f7a-4171-8969-c5d21ad7bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-8e612a72-f57e-46e6-95e6-0e3a1cc1b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-0a95f699-7477-4618-b4da-0d9d04a88769,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-b3f2a7c4-0cdb-41d7-bed0-6e083b0c6536,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-2040715c-3519-4049-888c-6599377d8c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417472849-172.17.0.13-1598490988485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-d5031ede-b35c-4706-8c62-8515b85474da,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-9fafe503-f6f2-4226-948d-d86fac41db07,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b8a7ed77-3819-48c1-88b0-a13870d231f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-c7eabed7-af39-418f-9f5b-97b4ac8e657a,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-e42c3b5b-fab2-4837-953c-3ea65390d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-2e1db69e-fefc-4d2d-8db5-15dc81a29de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-261eb478-de76-4585-976d-30361c494be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-008b77fa-d5b5-49aa-b866-5b8d0a9c8c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417472849-172.17.0.13-1598490988485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36429,DS-d5031ede-b35c-4706-8c62-8515b85474da,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-9fafe503-f6f2-4226-948d-d86fac41db07,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-b8a7ed77-3819-48c1-88b0-a13870d231f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-c7eabed7-af39-418f-9f5b-97b4ac8e657a,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-e42c3b5b-fab2-4837-953c-3ea65390d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-2e1db69e-fefc-4d2d-8db5-15dc81a29de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-261eb478-de76-4585-976d-30361c494be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-008b77fa-d5b5-49aa-b866-5b8d0a9c8c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748311081-172.17.0.13-1598491145168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-e8b8b3e1-8c04-4556-a34c-4423e0f070cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-cda4472a-6dc6-4ec6-8308-b169b49d45aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-43b40d4d-afa4-4f25-941a-333ef6107268,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d664296e-5c48-4fa3-9c93-655cd39395fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-e1101f49-ce1d-4cdd-aa42-9032c5a8a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-0c124952-1216-4234-828a-3b314e287c54,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-6fea26e3-a259-403e-9ca7-855e5eff2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-91337957-a852-4736-8a17-ac513430d0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748311081-172.17.0.13-1598491145168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-e8b8b3e1-8c04-4556-a34c-4423e0f070cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-cda4472a-6dc6-4ec6-8308-b169b49d45aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-43b40d4d-afa4-4f25-941a-333ef6107268,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-d664296e-5c48-4fa3-9c93-655cd39395fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-e1101f49-ce1d-4cdd-aa42-9032c5a8a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-0c124952-1216-4234-828a-3b314e287c54,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-6fea26e3-a259-403e-9ca7-855e5eff2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-91337957-a852-4736-8a17-ac513430d0eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793317076-172.17.0.13-1598491536698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-a1c8eb34-d907-4a00-812f-a045a5a92699,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-1c03f4ac-2eee-43c1-b6c8-973357223fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-8b70e787-1d2b-45f3-b8fd-c9a14eda094b,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-7339644b-d170-43bb-b480-edf35ee976ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-97301a90-aaad-4410-8ef2-6efce6dfec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-89b9ffeb-b25d-4644-b888-647a65cce03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-618d8fe2-6c71-4501-bc96-e167354b46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-03c81026-45f8-45bd-937d-c1237fd286f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793317076-172.17.0.13-1598491536698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42033,DS-a1c8eb34-d907-4a00-812f-a045a5a92699,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-1c03f4ac-2eee-43c1-b6c8-973357223fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-8b70e787-1d2b-45f3-b8fd-c9a14eda094b,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-7339644b-d170-43bb-b480-edf35ee976ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-97301a90-aaad-4410-8ef2-6efce6dfec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-89b9ffeb-b25d-4644-b888-647a65cce03f,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-618d8fe2-6c71-4501-bc96-e167354b46ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-03c81026-45f8-45bd-937d-c1237fd286f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230438192-172.17.0.13-1598491927805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41021,DS-5bd15a6a-102a-440c-a6e7-510502372008,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-f313d21f-b8f5-4c4b-815a-782bd7962a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-7d06ab43-6cb2-48bb-b06c-350a0b44f875,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-7dc834c9-953f-4853-837e-87e7d792be4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-177b0b07-0b45-45be-9a56-fbde09b76818,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-ce256273-dc80-49cb-a734-7de33661a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-3427b874-2fcb-4566-8f96-4e1ae708a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-19726f30-5957-49f1-b963-7ecdfcf8baa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230438192-172.17.0.13-1598491927805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41021,DS-5bd15a6a-102a-440c-a6e7-510502372008,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-f313d21f-b8f5-4c4b-815a-782bd7962a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-7d06ab43-6cb2-48bb-b06c-350a0b44f875,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-7dc834c9-953f-4853-837e-87e7d792be4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-177b0b07-0b45-45be-9a56-fbde09b76818,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-ce256273-dc80-49cb-a734-7de33661a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-3427b874-2fcb-4566-8f96-4e1ae708a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-19726f30-5957-49f1-b963-7ecdfcf8baa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103319187-172.17.0.13-1598492007685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-c7cdcacd-6786-4ea5-b79b-fe6466713b38,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-0aad9360-e6b3-4b9e-aedc-70409d3617f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5155ba60-f0c9-4796-b5d6-f1c5aa3f1ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-337c25b4-b9f7-4927-b942-eee328d1b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-0ed741ee-aa5b-438f-926b-ad83be853b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-1daf4222-cc29-48f2-8e1e-3a32f39544d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-2164b086-59d5-472e-982d-6ed03ca014fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6e5a67a3-2798-43e1-9ec3-1f9293b2706b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103319187-172.17.0.13-1598492007685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-c7cdcacd-6786-4ea5-b79b-fe6466713b38,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-0aad9360-e6b3-4b9e-aedc-70409d3617f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5155ba60-f0c9-4796-b5d6-f1c5aa3f1ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-337c25b4-b9f7-4927-b942-eee328d1b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-0ed741ee-aa5b-438f-926b-ad83be853b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-1daf4222-cc29-48f2-8e1e-3a32f39544d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-2164b086-59d5-472e-982d-6ed03ca014fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-6e5a67a3-2798-43e1-9ec3-1f9293b2706b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740850664-172.17.0.13-1598492045540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-76e29907-3e92-484a-9105-3323d6b242ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-acdff8ac-1f78-4f23-91dc-3c0d68ce13a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5e72b6b6-57c9-462d-9ae2-1d02bcbac089,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-042509a8-eba6-4da4-95ca-9b7eedcd4164,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-44b56206-756e-4a31-b57e-5f9463612093,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-45e1856c-48fc-42c2-9a52-459e02ecbd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-28fc494c-d71d-4151-ac30-a224db1797c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-5ef6653f-f3f9-4154-b447-00b0318c8f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740850664-172.17.0.13-1598492045540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-76e29907-3e92-484a-9105-3323d6b242ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-acdff8ac-1f78-4f23-91dc-3c0d68ce13a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5e72b6b6-57c9-462d-9ae2-1d02bcbac089,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-042509a8-eba6-4da4-95ca-9b7eedcd4164,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-44b56206-756e-4a31-b57e-5f9463612093,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-45e1856c-48fc-42c2-9a52-459e02ecbd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-28fc494c-d71d-4151-ac30-a224db1797c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-5ef6653f-f3f9-4154-b447-00b0318c8f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195447836-172.17.0.13-1598492201319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-c971713a-1422-4464-9dc2-d1dbf6b843b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-45d7da04-ac51-49c7-84b9-8dcd7f43b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-344842d0-179b-463e-b40a-037a3eaf5604,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-e443aa18-b7b4-454b-a217-c9e0e77a96ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-d47d7aa5-b254-4840-95f6-91301adb7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-7aa4d611-0311-45c0-9369-ceac645461ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-aa8982eb-f023-427c-a629-661f7b27610b,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-100d0ccf-5263-4c99-a1ee-b818d2f33734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195447836-172.17.0.13-1598492201319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-c971713a-1422-4464-9dc2-d1dbf6b843b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-45d7da04-ac51-49c7-84b9-8dcd7f43b3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-344842d0-179b-463e-b40a-037a3eaf5604,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-e443aa18-b7b4-454b-a217-c9e0e77a96ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-d47d7aa5-b254-4840-95f6-91301adb7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-7aa4d611-0311-45c0-9369-ceac645461ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-aa8982eb-f023-427c-a629-661f7b27610b,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-100d0ccf-5263-4c99-a1ee-b818d2f33734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634108296-172.17.0.13-1598492284027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-02ffe584-040a-4e75-b486-07b74e50b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a93cf9a1-f43f-4c46-80bb-64fcf77ee171,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-cf5a2fc5-eb04-48c2-a0fb-511965729436,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-af14de79-5ffb-493d-be5f-75f9d9e15301,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-4343f872-2c92-4164-a582-de0b292ac264,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-1a689431-fac9-4f72-afb8-16d524af01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-8df45e62-ae59-42db-ae27-ce9855718905,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-289d139d-072e-4f82-8b9c-fa1987866c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634108296-172.17.0.13-1598492284027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-02ffe584-040a-4e75-b486-07b74e50b1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a93cf9a1-f43f-4c46-80bb-64fcf77ee171,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-cf5a2fc5-eb04-48c2-a0fb-511965729436,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-af14de79-5ffb-493d-be5f-75f9d9e15301,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-4343f872-2c92-4164-a582-de0b292ac264,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-1a689431-fac9-4f72-afb8-16d524af01a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-8df45e62-ae59-42db-ae27-ce9855718905,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-289d139d-072e-4f82-8b9c-fa1987866c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421397120-172.17.0.13-1598492324418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-c0790e3a-d657-43ee-b4a9-760e066c0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-dcd330fe-b297-4760-a95e-f4eb445188a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-2d24bdc7-89c7-4c63-85b8-770f0d267ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-3716519c-bf70-4a29-8dfe-b8ffcd792852,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f791da71-9e3f-48a1-8819-7f4c6d0c6388,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-9471eee3-1af9-4d75-9a42-eb355080518a,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-c16a4093-0666-4e33-9ec5-3f19aceae255,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-0dcb6dd1-38e4-4085-a969-57b0c8ac2739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421397120-172.17.0.13-1598492324418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-c0790e3a-d657-43ee-b4a9-760e066c0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-dcd330fe-b297-4760-a95e-f4eb445188a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-2d24bdc7-89c7-4c63-85b8-770f0d267ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-3716519c-bf70-4a29-8dfe-b8ffcd792852,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-f791da71-9e3f-48a1-8819-7f4c6d0c6388,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-9471eee3-1af9-4d75-9a42-eb355080518a,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-c16a4093-0666-4e33-9ec5-3f19aceae255,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-0dcb6dd1-38e4-4085-a969-57b0c8ac2739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760451329-172.17.0.13-1598492365699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40917,DS-63987d01-5f75-461b-8a67-3647b3ded9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-b56802dc-b389-4908-9569-8fdd88de63d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-80f6d7c9-51cf-4144-a9ae-3ba7de924bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-5531d994-27dd-478d-bdba-96fcd347c526,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c5399781-3bac-4273-82e2-b44654b5bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-f6f54f45-8017-4edb-a68b-b5d5ecee46de,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-07621982-7430-4b83-94e6-424c00636608,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-a7afe9fb-cdd7-4a65-abbf-5ef177a58778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760451329-172.17.0.13-1598492365699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40917,DS-63987d01-5f75-461b-8a67-3647b3ded9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-b56802dc-b389-4908-9569-8fdd88de63d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-80f6d7c9-51cf-4144-a9ae-3ba7de924bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-5531d994-27dd-478d-bdba-96fcd347c526,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-c5399781-3bac-4273-82e2-b44654b5bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-f6f54f45-8017-4edb-a68b-b5d5ecee46de,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-07621982-7430-4b83-94e6-424c00636608,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-a7afe9fb-cdd7-4a65-abbf-5ef177a58778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5530
