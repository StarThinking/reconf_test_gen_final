reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984967674-172.17.0.13-1598653421312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-4e54c4ba-1a74-48fe-8dfe-47d876b3c141,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-309c9ede-3dde-4eb6-9dd5-389b70fc5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-a04bdb44-146d-4fe0-acb5-b799f7a4d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-47179cd8-1b19-4722-be31-68cdb3bcc32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-ab2dc312-4697-4560-bbc4-a11a4c1938a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-e5128322-3c8a-4fcf-8c46-1bb63e9a2ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-a51cb8d0-f1cb-46f5-97f0-919a1b929870,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-219fc7b2-5315-40c0-9030-b4219ff6a7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984967674-172.17.0.13-1598653421312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35024,DS-4e54c4ba-1a74-48fe-8dfe-47d876b3c141,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-309c9ede-3dde-4eb6-9dd5-389b70fc5ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-a04bdb44-146d-4fe0-acb5-b799f7a4d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-47179cd8-1b19-4722-be31-68cdb3bcc32d,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-ab2dc312-4697-4560-bbc4-a11a4c1938a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-e5128322-3c8a-4fcf-8c46-1bb63e9a2ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-a51cb8d0-f1cb-46f5-97f0-919a1b929870,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-219fc7b2-5315-40c0-9030-b4219ff6a7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299901953-172.17.0.13-1598653770557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-f7699b38-aeac-43a9-9e2a-4cb9a39cc4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-deb6e9ed-477c-4854-a282-e305cad0befb,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-d6265837-b524-4485-82c7-16a8540c5437,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8fc17212-411c-4549-a920-073f7ae7d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-54d6138c-b26e-42e1-a26c-505378fed0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-6c552ee2-f42b-4c55-8606-30f113c01bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-12de2011-8bda-43df-8555-4d4487e33214,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-40d9acf4-ad4b-4e47-8f01-4cf2ae0eb45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299901953-172.17.0.13-1598653770557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-f7699b38-aeac-43a9-9e2a-4cb9a39cc4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-deb6e9ed-477c-4854-a282-e305cad0befb,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-d6265837-b524-4485-82c7-16a8540c5437,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8fc17212-411c-4549-a920-073f7ae7d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-54d6138c-b26e-42e1-a26c-505378fed0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-6c552ee2-f42b-4c55-8606-30f113c01bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-12de2011-8bda-43df-8555-4d4487e33214,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-40d9acf4-ad4b-4e47-8f01-4cf2ae0eb45a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174686480-172.17.0.13-1598653836132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-d670e19a-f23d-4cce-8795-6fac432d5c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-d7f8980a-f8bb-465f-b974-618f8cb66fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-19ec0ba2-a409-4d38-9ae5-406029f719f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-2aad3dca-a55a-4820-85c9-aff82833e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9479e369-b6ff-42c5-b5dd-bd1cd24b2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-38b902ad-32f9-4cb5-9569-9ec50949a951,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-875b02fd-6e0c-4507-971b-0ff94ede4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-cadc1c58-ca4c-4c3d-bd96-87aea4b8b8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174686480-172.17.0.13-1598653836132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-d670e19a-f23d-4cce-8795-6fac432d5c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-d7f8980a-f8bb-465f-b974-618f8cb66fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-19ec0ba2-a409-4d38-9ae5-406029f719f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-2aad3dca-a55a-4820-85c9-aff82833e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9479e369-b6ff-42c5-b5dd-bd1cd24b2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-38b902ad-32f9-4cb5-9569-9ec50949a951,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-875b02fd-6e0c-4507-971b-0ff94ede4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-cadc1c58-ca4c-4c3d-bd96-87aea4b8b8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326508217-172.17.0.13-1598654284057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-370e2c38-a77e-492e-ae48-203a079c5635,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-28629c05-e17b-43ed-a845-26cf1980774a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-1ee0a0da-cecc-4f3e-86eb-062d1acc3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-8da50e4c-5a69-4f8a-b1cc-3cab9f55d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f202e276-cf4c-4c17-8743-850c326c1458,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-dc58c64d-6d9f-4059-bf0c-9d3cdee4bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-7d1971bf-988f-41c1-99cf-0498c8a750dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-066a107f-b433-4ea2-b75d-7777dd133e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326508217-172.17.0.13-1598654284057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-370e2c38-a77e-492e-ae48-203a079c5635,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-28629c05-e17b-43ed-a845-26cf1980774a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-1ee0a0da-cecc-4f3e-86eb-062d1acc3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-8da50e4c-5a69-4f8a-b1cc-3cab9f55d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-f202e276-cf4c-4c17-8743-850c326c1458,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-dc58c64d-6d9f-4059-bf0c-9d3cdee4bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-7d1971bf-988f-41c1-99cf-0498c8a750dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-066a107f-b433-4ea2-b75d-7777dd133e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963434090-172.17.0.13-1598654519284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-89a311e8-bbf2-4abf-ad84-e8eed41efa48,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-37025f02-cbed-4a7b-b6a9-a4356042d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-273131c8-600b-4569-b7bb-4b73b5f446d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-a2f610ef-0e9f-4ef2-894d-3a3c6f71d209,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-3b823c9a-e150-4e97-a36f-b6f0ea79bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-7f60afd7-2818-4e8c-b997-0f358cd55316,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-15d3dad6-92f7-4f0f-9300-733d9efdaa32,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-936e35f8-5dfc-451d-a381-628450951cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963434090-172.17.0.13-1598654519284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-89a311e8-bbf2-4abf-ad84-e8eed41efa48,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-37025f02-cbed-4a7b-b6a9-a4356042d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-273131c8-600b-4569-b7bb-4b73b5f446d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-a2f610ef-0e9f-4ef2-894d-3a3c6f71d209,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-3b823c9a-e150-4e97-a36f-b6f0ea79bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-7f60afd7-2818-4e8c-b997-0f358cd55316,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-15d3dad6-92f7-4f0f-9300-733d9efdaa32,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-936e35f8-5dfc-451d-a381-628450951cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908765629-172.17.0.13-1598654788044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-4746f6f0-03c8-404d-8482-bf2b69e5e519,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-ab0862dc-f686-46fd-a09a-76b4a3d23fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-b03923f1-7125-4a03-8ece-4dae66819c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-ee4ee010-90f2-427b-bd22-0a7e7cd75eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-2bfe4340-23cc-4aac-942a-73482a8404cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-13b10701-307b-4c0e-9d17-fc3010d58c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-fa7de9a3-9d58-4fac-8bbb-f37fc669b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-785ede1c-a7c8-4cfe-a1b4-25c5dda0df22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908765629-172.17.0.13-1598654788044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40284,DS-4746f6f0-03c8-404d-8482-bf2b69e5e519,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-ab0862dc-f686-46fd-a09a-76b4a3d23fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-b03923f1-7125-4a03-8ece-4dae66819c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-ee4ee010-90f2-427b-bd22-0a7e7cd75eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-2bfe4340-23cc-4aac-942a-73482a8404cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-13b10701-307b-4c0e-9d17-fc3010d58c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-fa7de9a3-9d58-4fac-8bbb-f37fc669b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-785ede1c-a7c8-4cfe-a1b4-25c5dda0df22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391127269-172.17.0.13-1598654919071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-5544fce8-3bac-46b7-9879-ecc0f5afe0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-780d9c7c-4ac7-4f48-821d-78191d3c1d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-091905dc-655d-4bfc-b9dc-d912ee80ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e09f6e9d-44e3-4eb5-b9af-ca67ab9d2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-77af1687-722d-42b3-8a93-af5d31811366,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-17932dc2-a2e6-4684-b2f3-7912f4953af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-f5cf4bf6-d68c-45f9-bb37-e808ef19bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f26d701d-240e-4d45-846e-4d21b93750a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391127269-172.17.0.13-1598654919071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-5544fce8-3bac-46b7-9879-ecc0f5afe0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-780d9c7c-4ac7-4f48-821d-78191d3c1d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-091905dc-655d-4bfc-b9dc-d912ee80ebc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e09f6e9d-44e3-4eb5-b9af-ca67ab9d2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-77af1687-722d-42b3-8a93-af5d31811366,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-17932dc2-a2e6-4684-b2f3-7912f4953af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-f5cf4bf6-d68c-45f9-bb37-e808ef19bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-f26d701d-240e-4d45-846e-4d21b93750a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460847743-172.17.0.13-1598655058386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38409,DS-c79fa2ab-06a1-4509-b5fd-acffbfeb3c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-511e20bc-ff15-4e3a-b7cb-44a3ce8a23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-304c38f7-2636-4b17-93f8-bb0fcf89464f,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-18e7697f-448c-4f83-a88e-63e33e64cfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-171a20b6-729c-4f5e-a0e3-4d0569479da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-da7a7af0-1efc-43d5-8685-bf4ee7e87537,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-ccabfaa7-7235-487b-8a1b-1f9dba02491b,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-2197538e-17e1-4cb2-b7d2-bc564c0b83f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460847743-172.17.0.13-1598655058386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38409,DS-c79fa2ab-06a1-4509-b5fd-acffbfeb3c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-511e20bc-ff15-4e3a-b7cb-44a3ce8a23bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-304c38f7-2636-4b17-93f8-bb0fcf89464f,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-18e7697f-448c-4f83-a88e-63e33e64cfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-171a20b6-729c-4f5e-a0e3-4d0569479da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-da7a7af0-1efc-43d5-8685-bf4ee7e87537,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-ccabfaa7-7235-487b-8a1b-1f9dba02491b,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-2197538e-17e1-4cb2-b7d2-bc564c0b83f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403356514-172.17.0.13-1598655255332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-3e484358-21fd-448d-a45a-9c40c61424e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-b4652d32-1f80-4716-afe8-4de207e21bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-12d63261-920a-48bf-bde7-dbe497f2bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8a763eb0-3110-48fa-aa1e-b2f87660253e,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-eb5546a2-7a92-4e92-8c84-06ae53346a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-7fd19a0f-ef54-427b-82da-64568e9b9a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-23434a95-d414-461c-94b4-55056ccdb6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-c040efc6-1ef4-451f-a37b-7ff09ab77754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403356514-172.17.0.13-1598655255332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-3e484358-21fd-448d-a45a-9c40c61424e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-b4652d32-1f80-4716-afe8-4de207e21bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-12d63261-920a-48bf-bde7-dbe497f2bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8a763eb0-3110-48fa-aa1e-b2f87660253e,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-eb5546a2-7a92-4e92-8c84-06ae53346a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-7fd19a0f-ef54-427b-82da-64568e9b9a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-23434a95-d414-461c-94b4-55056ccdb6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-c040efc6-1ef4-451f-a37b-7ff09ab77754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163572333-172.17.0.13-1598655455594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-086613a1-9d13-446b-9d21-338945e9891e,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-46c010e5-b652-418d-9bd3-7c40aa1f0add,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-ad8d28f4-f452-47f8-8a01-eaf1312f25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-31a3e380-6c0c-464f-9d92-d34c81238885,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-5c849979-99e5-494c-82ef-c95416a5b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-db1aa617-202a-4d47-a648-d906d88c65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-9165a952-23f3-4192-9e77-e5a6591f2d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-c9cd1cfa-e444-4d19-a4ed-e46f2970f6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163572333-172.17.0.13-1598655455594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42312,DS-086613a1-9d13-446b-9d21-338945e9891e,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-46c010e5-b652-418d-9bd3-7c40aa1f0add,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-ad8d28f4-f452-47f8-8a01-eaf1312f25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-31a3e380-6c0c-464f-9d92-d34c81238885,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-5c849979-99e5-494c-82ef-c95416a5b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-db1aa617-202a-4d47-a648-d906d88c65b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-9165a952-23f3-4192-9e77-e5a6591f2d47,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-c9cd1cfa-e444-4d19-a4ed-e46f2970f6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838336853-172.17.0.13-1598655492883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-8aceb5d1-6a4c-434d-b356-fad4932a382f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-85079850-5438-45e7-8ec0-04304327efa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-ebffae5d-30cb-4a58-bc05-98cad883298f,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-0db7b7e4-ef6b-4da6-87cd-5bff5e615e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-3915545d-cd5e-4a70-ad2a-179b746214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-a4ee18c2-1e87-48eb-a0c3-bb361a277fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-9cd8360b-e64e-4e6e-8086-c109e4b7a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-92f1ac0e-6e78-433e-83cd-e869383d31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838336853-172.17.0.13-1598655492883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-8aceb5d1-6a4c-434d-b356-fad4932a382f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-85079850-5438-45e7-8ec0-04304327efa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-ebffae5d-30cb-4a58-bc05-98cad883298f,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-0db7b7e4-ef6b-4da6-87cd-5bff5e615e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-3915545d-cd5e-4a70-ad2a-179b746214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-a4ee18c2-1e87-48eb-a0c3-bb361a277fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-9cd8360b-e64e-4e6e-8086-c109e4b7a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-92f1ac0e-6e78-433e-83cd-e869383d31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853381973-172.17.0.13-1598655896095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-eea9e336-181c-4bcc-8090-00664c141c73,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-bf9871d3-20ea-4057-824e-46a556fbd640,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-08eae50e-b852-451b-9bde-2bba0b81bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-869720a7-8c11-4a63-aad2-7e64780e3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-e048b993-9253-4f44-b6aa-e1973a6112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-9e342d8d-1670-4eeb-93c0-81a5cc2848e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-9c687373-e99c-43f9-98f3-e8ac77584a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-adf4573e-bdda-4190-8683-8aa3c23b6241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853381973-172.17.0.13-1598655896095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-eea9e336-181c-4bcc-8090-00664c141c73,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-bf9871d3-20ea-4057-824e-46a556fbd640,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-08eae50e-b852-451b-9bde-2bba0b81bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-869720a7-8c11-4a63-aad2-7e64780e3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-e048b993-9253-4f44-b6aa-e1973a6112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-9e342d8d-1670-4eeb-93c0-81a5cc2848e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-9c687373-e99c-43f9-98f3-e8ac77584a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-adf4573e-bdda-4190-8683-8aa3c23b6241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499360319-172.17.0.13-1598655967966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-f8fc763d-eeba-49b5-87cb-d42b934490d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-a7ac1c76-169e-47d1-b2e6-3f670da815ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-00f4925d-df73-4560-8445-7c689058ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-7444e8b3-fca5-4f8f-92d1-33fb47e90a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-576f98bc-a278-46d7-a0b3-d258cd431d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-5670731c-8052-4b59-9560-5e01da68e905,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-73c6a956-1daa-41ce-aea5-6d0450b7acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a634719d-8c33-43d1-b9bb-98f37c803fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499360319-172.17.0.13-1598655967966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-f8fc763d-eeba-49b5-87cb-d42b934490d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-a7ac1c76-169e-47d1-b2e6-3f670da815ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-00f4925d-df73-4560-8445-7c689058ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-7444e8b3-fca5-4f8f-92d1-33fb47e90a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-576f98bc-a278-46d7-a0b3-d258cd431d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-5670731c-8052-4b59-9560-5e01da68e905,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-73c6a956-1daa-41ce-aea5-6d0450b7acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a634719d-8c33-43d1-b9bb-98f37c803fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542919888-172.17.0.13-1598656619991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35529,DS-c3b8c452-064d-4fcd-acb9-60b96074c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-89f2ff95-99ce-4f9b-9052-8cb0dfa62e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-d12bc8de-46f5-4897-a2c8-6f9954dc406c,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-4dcc50da-062d-4cac-9a27-d67dc55411f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-f8348d10-c9d8-4193-93fc-6f7903e2b354,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-9405b5c0-854d-4315-8b19-27d14fe54831,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-696f17b7-ef03-4d90-959c-9552bd308872,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d039498e-e611-4d3b-84e5-53f52aa8c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542919888-172.17.0.13-1598656619991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35529,DS-c3b8c452-064d-4fcd-acb9-60b96074c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-89f2ff95-99ce-4f9b-9052-8cb0dfa62e57,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-d12bc8de-46f5-4897-a2c8-6f9954dc406c,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-4dcc50da-062d-4cac-9a27-d67dc55411f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-f8348d10-c9d8-4193-93fc-6f7903e2b354,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-9405b5c0-854d-4315-8b19-27d14fe54831,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-696f17b7-ef03-4d90-959c-9552bd308872,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-d039498e-e611-4d3b-84e5-53f52aa8c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548628174-172.17.0.13-1598656651257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-4f647cda-38be-49b1-81d5-af99e38401f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d54b1309-5adc-4629-9dfd-3be6f2326ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-e388b3d3-5abe-455c-8f40-0da5159fd7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-93ed27c9-f223-4980-9471-640e0776af6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-d05fa8a2-ba8b-4644-9dbd-44ca6df8cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-463a3ab0-fc00-4abd-94c2-6b5f2c9d98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-0c297c2b-82c0-4b26-bc55-d4046c008f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-333c9438-03f2-4688-9226-240367a93265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548628174-172.17.0.13-1598656651257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-4f647cda-38be-49b1-81d5-af99e38401f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d54b1309-5adc-4629-9dfd-3be6f2326ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-e388b3d3-5abe-455c-8f40-0da5159fd7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-93ed27c9-f223-4980-9471-640e0776af6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-d05fa8a2-ba8b-4644-9dbd-44ca6df8cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-463a3ab0-fc00-4abd-94c2-6b5f2c9d98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-0c297c2b-82c0-4b26-bc55-d4046c008f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-333c9438-03f2-4688-9226-240367a93265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743248823-172.17.0.13-1598656686487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-0ccc5333-b98e-4a3b-a069-a20753334c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-d197edfd-248a-4b86-b411-9b86dbb80f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-cb1446d1-56fb-4afe-a358-760dfd235cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-bd596efc-8682-4d43-ac20-460629cf46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e6e5ccb2-3c80-4cba-bffc-47fd9e663974,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-abf434ef-c84e-4330-b984-ad5d81fd1489,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-1cac7994-0bf7-46e7-8d5a-5315bd0762c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-318f79cf-c3a6-44c3-a416-8796d04cae12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743248823-172.17.0.13-1598656686487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-0ccc5333-b98e-4a3b-a069-a20753334c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-d197edfd-248a-4b86-b411-9b86dbb80f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-cb1446d1-56fb-4afe-a358-760dfd235cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-bd596efc-8682-4d43-ac20-460629cf46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e6e5ccb2-3c80-4cba-bffc-47fd9e663974,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-abf434ef-c84e-4330-b984-ad5d81fd1489,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-1cac7994-0bf7-46e7-8d5a-5315bd0762c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-318f79cf-c3a6-44c3-a416-8796d04cae12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279428812-172.17.0.13-1598656723619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-c4bb550c-941e-4675-84c4-da1a80259125,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-fcbe1fae-6b67-4b85-b058-e91caa0696b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8dafa666-2902-4a97-a006-0a0c002da7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-5c536f9e-95b9-47e7-8e2f-ce919ecba21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-561119d8-8803-45a7-9433-3699881a0aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-a1a416a3-4862-44c8-8f5e-6705e7899fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-92ac7a76-c3db-420a-a73c-f5cd0720ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-0ff20551-caaf-4240-b1e8-dc6151846eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279428812-172.17.0.13-1598656723619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-c4bb550c-941e-4675-84c4-da1a80259125,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-fcbe1fae-6b67-4b85-b058-e91caa0696b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8dafa666-2902-4a97-a006-0a0c002da7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-5c536f9e-95b9-47e7-8e2f-ce919ecba21e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-561119d8-8803-45a7-9433-3699881a0aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-a1a416a3-4862-44c8-8f5e-6705e7899fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-92ac7a76-c3db-420a-a73c-f5cd0720ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-0ff20551-caaf-4240-b1e8-dc6151846eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877267230-172.17.0.13-1598656831888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-06a97427-915a-46af-9817-da92c2891fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-01cee190-70b8-4d09-bd80-0608e99d32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-d5ab159e-b73b-4d98-85a2-442a8667b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-de219c7b-db77-4bb9-b126-a4cce555017e,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-16e4a3bc-0c4b-4b4d-9a4f-97edbebfef53,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-244a047e-be45-47c7-bea0-15e83e97d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a6cfd262-a543-41d6-be1c-3474888ac8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-2b0ef116-306e-4110-b2b0-11b4747bff91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877267230-172.17.0.13-1598656831888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-06a97427-915a-46af-9817-da92c2891fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-01cee190-70b8-4d09-bd80-0608e99d32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-d5ab159e-b73b-4d98-85a2-442a8667b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-de219c7b-db77-4bb9-b126-a4cce555017e,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-16e4a3bc-0c4b-4b4d-9a4f-97edbebfef53,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-244a047e-be45-47c7-bea0-15e83e97d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-a6cfd262-a543-41d6-be1c-3474888ac8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-2b0ef116-306e-4110-b2b0-11b4747bff91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489412924-172.17.0.13-1598657358024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43469,DS-4f0bf33b-02c8-496a-baab-51345254b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-977cf0ab-0756-42fd-8e2b-14c1babc656a,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-4b1d4274-c928-4640-a730-e8e37dff51c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-1d03e705-12f5-43a7-a365-6746b909b091,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e4a00262-efa4-4b4d-b409-bc5f1ac474c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-81d7f59f-da42-4ee2-8aa1-d165061a81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-ac66af7c-ad60-4c4a-be2c-3425c1c992d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-31e3ebd6-5e5f-4ae1-81c5-f96ac6651fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489412924-172.17.0.13-1598657358024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43469,DS-4f0bf33b-02c8-496a-baab-51345254b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-977cf0ab-0756-42fd-8e2b-14c1babc656a,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-4b1d4274-c928-4640-a730-e8e37dff51c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-1d03e705-12f5-43a7-a365-6746b909b091,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-e4a00262-efa4-4b4d-b409-bc5f1ac474c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-81d7f59f-da42-4ee2-8aa1-d165061a81ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-ac66af7c-ad60-4c4a-be2c-3425c1c992d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-31e3ebd6-5e5f-4ae1-81c5-f96ac6651fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910470125-172.17.0.13-1598657683137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-6e44e878-dc0c-41c7-9a37-7fa6a60f60d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f17251b1-a790-40b6-b13f-7303ca7e72c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-c56f0475-d5e3-4d3c-a9af-40ee9afe339b,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-59e2595a-8433-4bb4-b234-31116cfdd4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-bf8a7d9e-e02b-4d06-90a8-e56b82bb9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-31ee8afb-f18b-470f-97d8-d7dcfb50eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-cdc7c518-0915-4fc3-ae56-9b36fa10ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e96d255f-10cd-4705-9392-4a1e07f2664c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910470125-172.17.0.13-1598657683137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33723,DS-6e44e878-dc0c-41c7-9a37-7fa6a60f60d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-f17251b1-a790-40b6-b13f-7303ca7e72c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-c56f0475-d5e3-4d3c-a9af-40ee9afe339b,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-59e2595a-8433-4bb4-b234-31116cfdd4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-bf8a7d9e-e02b-4d06-90a8-e56b82bb9c63,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-31ee8afb-f18b-470f-97d8-d7dcfb50eb99,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-cdc7c518-0915-4fc3-ae56-9b36fa10ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e96d255f-10cd-4705-9392-4a1e07f2664c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.metrics.logger.period.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062489691-172.17.0.13-1598658058769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-5614af85-613d-43bf-bf0c-7b6d05be802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9503796d-d5b3-4cf5-8fc9-0333c5a2b491,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-69c7302b-e797-41d9-9c4e-fc1af6bd3d91,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-3cba1061-7b8f-4cac-87bb-70157e6a57cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-2d7806cd-8fc1-4219-9cf1-e22370287e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-856c8958-e2a4-4fa2-9ee4-edee71acb1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-cb06152d-47e1-4463-bce5-10f4a501296b,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-a00c6dca-df6a-4f50-8892-490779e40d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062489691-172.17.0.13-1598658058769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-5614af85-613d-43bf-bf0c-7b6d05be802a,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9503796d-d5b3-4cf5-8fc9-0333c5a2b491,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-69c7302b-e797-41d9-9c4e-fc1af6bd3d91,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-3cba1061-7b8f-4cac-87bb-70157e6a57cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-2d7806cd-8fc1-4219-9cf1-e22370287e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-856c8958-e2a4-4fa2-9ee4-edee71acb1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-cb06152d-47e1-4463-bce5-10f4a501296b,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-a00c6dca-df6a-4f50-8892-490779e40d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4920
