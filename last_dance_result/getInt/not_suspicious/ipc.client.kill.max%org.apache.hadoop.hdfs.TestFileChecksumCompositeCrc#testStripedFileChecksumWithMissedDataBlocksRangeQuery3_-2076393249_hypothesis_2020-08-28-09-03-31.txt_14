reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841094591-172.17.0.13-1598605425229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-365c947c-714b-4a9e-a192-4f46a8f2b042,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-8af1c0e7-26d8-4d9f-955d-a68db0e377b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c53bb049-4034-40f5-8c46-01b88e5b55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-0cab1785-8d60-4c75-9a69-8364a10bfaef,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-32feb021-4cb8-4b46-ad05-5cc450d71475,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1f8e04d6-50b8-40af-afc1-b8ec53b52b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6d4560d7-2b64-4df1-95d5-9cade57b25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-273dd61b-6f91-49c1-b3a4-cab21bcb7b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841094591-172.17.0.13-1598605425229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-365c947c-714b-4a9e-a192-4f46a8f2b042,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-8af1c0e7-26d8-4d9f-955d-a68db0e377b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-c53bb049-4034-40f5-8c46-01b88e5b55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-0cab1785-8d60-4c75-9a69-8364a10bfaef,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-32feb021-4cb8-4b46-ad05-5cc450d71475,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1f8e04d6-50b8-40af-afc1-b8ec53b52b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6d4560d7-2b64-4df1-95d5-9cade57b25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-273dd61b-6f91-49c1-b3a4-cab21bcb7b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619040276-172.17.0.13-1598605458957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-90ce09d2-23be-4cdd-83d3-ec3da4e04ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-fd287c8b-6336-436e-ab9a-8cac4b0279b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-e7e272c5-d463-407c-96de-bcbbf0c8d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-7517a998-fb8c-4fd6-919c-1bf39e8ff12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-c446c155-f673-44d8-9afe-7d1d06f96c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-4e391161-12d9-412f-8f9b-cc43503a49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-e9cec767-829d-45d6-a3aa-fb56e434faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-e4fb4cca-55d2-477b-bc05-809a07105164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619040276-172.17.0.13-1598605458957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-90ce09d2-23be-4cdd-83d3-ec3da4e04ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-fd287c8b-6336-436e-ab9a-8cac4b0279b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-e7e272c5-d463-407c-96de-bcbbf0c8d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-7517a998-fb8c-4fd6-919c-1bf39e8ff12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-c446c155-f673-44d8-9afe-7d1d06f96c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-4e391161-12d9-412f-8f9b-cc43503a49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-e9cec767-829d-45d6-a3aa-fb56e434faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-e4fb4cca-55d2-477b-bc05-809a07105164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459443536-172.17.0.13-1598605590766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35435,DS-92bf1b83-fbce-4ee0-8a47-51c48d08761d,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-11aed147-1a5b-4be6-9b30-c982d5755004,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-022b0897-d090-4d81-a4bc-8d3f58415cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-f07d719b-838b-4c70-a73a-b98953716314,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e813c524-1d4a-4ba3-8ca3-5b0aa721febc,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-33b6cbee-3a97-4b79-979b-72120c6af7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-5d4303ce-050e-4dc1-88c7-681de7872d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-fe369d2c-9746-451c-b802-67c53081cb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459443536-172.17.0.13-1598605590766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35435,DS-92bf1b83-fbce-4ee0-8a47-51c48d08761d,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-11aed147-1a5b-4be6-9b30-c982d5755004,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-022b0897-d090-4d81-a4bc-8d3f58415cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-f07d719b-838b-4c70-a73a-b98953716314,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-e813c524-1d4a-4ba3-8ca3-5b0aa721febc,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-33b6cbee-3a97-4b79-979b-72120c6af7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-5d4303ce-050e-4dc1-88c7-681de7872d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-fe369d2c-9746-451c-b802-67c53081cb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648157128-172.17.0.13-1598605764565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-a43fbabf-f33c-439f-9b56-4b8013c840f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-ff8dcb02-bac9-4a16-b8ac-5579505749c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-804b11f2-b751-4485-9261-d09d898688bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c7c58c45-c059-43f4-86d1-675658693bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-77a85428-8262-4a3c-9650-82ddd61bfbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-e396dee0-a403-4689-b16d-02740d3b5295,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-991e6cf0-43cd-4322-85de-ee2b31f21ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-916d96ab-e340-407c-82f0-a835b63a47d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648157128-172.17.0.13-1598605764565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-a43fbabf-f33c-439f-9b56-4b8013c840f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-ff8dcb02-bac9-4a16-b8ac-5579505749c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-804b11f2-b751-4485-9261-d09d898688bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-c7c58c45-c059-43f4-86d1-675658693bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-77a85428-8262-4a3c-9650-82ddd61bfbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-e396dee0-a403-4689-b16d-02740d3b5295,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-991e6cf0-43cd-4322-85de-ee2b31f21ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-916d96ab-e340-407c-82f0-a835b63a47d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215306137-172.17.0.13-1598606482739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-ab03328a-d262-4098-9895-50a75a8e5722,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d89c6fda-b185-4689-9258-6e6a9cb7b398,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-196bc9c0-418a-4ace-a584-69d2d6541c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-9c5390db-529f-4cd8-880a-f04c0aa3dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-7f2ed2aa-d691-46f5-b2c2-8612153a1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-14467880-77c7-411d-84d8-a3dee7f60796,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-effd94be-035d-4f96-b5fc-81aa9ed040cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-97a60107-1204-48fb-961e-e60a2677ba7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215306137-172.17.0.13-1598606482739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-ab03328a-d262-4098-9895-50a75a8e5722,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d89c6fda-b185-4689-9258-6e6a9cb7b398,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-196bc9c0-418a-4ace-a584-69d2d6541c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-9c5390db-529f-4cd8-880a-f04c0aa3dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-7f2ed2aa-d691-46f5-b2c2-8612153a1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-14467880-77c7-411d-84d8-a3dee7f60796,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-effd94be-035d-4f96-b5fc-81aa9ed040cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-97a60107-1204-48fb-961e-e60a2677ba7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843672818-172.17.0.13-1598606856574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-35ed80fa-b67d-49f0-a793-2e34a77f4e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-56fb9d3c-0e67-4fcd-aa89-b2b7bd3ee7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-dc780eb9-27fd-4d0d-b29a-bc2f16124d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-509d21c5-4902-4566-ad22-8af69a28135b,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-266d6758-6fbe-4ac5-a34e-a55be88c2951,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-fbd7217e-13bc-49c1-a8e3-00cb06729213,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-15e8d3e0-798d-40fd-af83-96128d11cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-d2e6fca2-3bf0-4a1b-8bd5-58e48cb5188e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843672818-172.17.0.13-1598606856574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-35ed80fa-b67d-49f0-a793-2e34a77f4e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-56fb9d3c-0e67-4fcd-aa89-b2b7bd3ee7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-dc780eb9-27fd-4d0d-b29a-bc2f16124d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-509d21c5-4902-4566-ad22-8af69a28135b,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-266d6758-6fbe-4ac5-a34e-a55be88c2951,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-fbd7217e-13bc-49c1-a8e3-00cb06729213,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-15e8d3e0-798d-40fd-af83-96128d11cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-d2e6fca2-3bf0-4a1b-8bd5-58e48cb5188e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755157965-172.17.0.13-1598607070622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-e0547d31-bb5b-4bea-9b47-47ff58d9afed,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-46feb2d2-120e-4eb0-adc2-5759886a1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-31f674a2-b460-41a8-a454-4aecade631a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-e2dbaae1-26b6-4916-8941-38c46ff9654a,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-d815eddd-2c5f-4688-addc-e445f89b633f,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-e4cecb9c-e99a-4f2d-b5cf-684cd41870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-cc8f9e9d-d635-41f6-b4f6-fd4cea71bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0e4bf8c-3fe9-43e0-b57d-109575f014b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755157965-172.17.0.13-1598607070622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-e0547d31-bb5b-4bea-9b47-47ff58d9afed,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-46feb2d2-120e-4eb0-adc2-5759886a1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-31f674a2-b460-41a8-a454-4aecade631a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-e2dbaae1-26b6-4916-8941-38c46ff9654a,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-d815eddd-2c5f-4688-addc-e445f89b633f,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-e4cecb9c-e99a-4f2d-b5cf-684cd41870cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-cc8f9e9d-d635-41f6-b4f6-fd4cea71bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0e4bf8c-3fe9-43e0-b57d-109575f014b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024527020-172.17.0.13-1598607145552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-18359f5d-7346-4ab9-b4fb-700e38e82bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-840b21aa-16cd-4bec-9772-778a34a9fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-06897fcd-1cb7-4c19-be8c-2abcca24d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-6b38333b-1d34-4274-956f-0c8f7be52ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-ed424c00-3464-4cb4-a38f-8997a402e847,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-71703e5f-497c-428e-916f-0b1059d808de,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-c0250abd-e553-4584-b367-03fba998b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-21668a80-f3ba-483f-82b9-549a5ee333f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024527020-172.17.0.13-1598607145552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-18359f5d-7346-4ab9-b4fb-700e38e82bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-840b21aa-16cd-4bec-9772-778a34a9fda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-06897fcd-1cb7-4c19-be8c-2abcca24d101,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-6b38333b-1d34-4274-956f-0c8f7be52ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-ed424c00-3464-4cb4-a38f-8997a402e847,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-71703e5f-497c-428e-916f-0b1059d808de,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-c0250abd-e553-4584-b367-03fba998b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-21668a80-f3ba-483f-82b9-549a5ee333f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486708875-172.17.0.13-1598607516229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-8e3a11ea-2d83-4e3f-8a46-5f409775f991,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-1969c47c-3a76-43ee-9145-d82744cd7200,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-4f7bec5a-d9d9-497c-afc6-a262efc3c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-6fd6da1e-39d3-4070-a829-873111005e44,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-5e595eba-cd10-4890-8110-091199c2082a,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-e8538c14-e3a8-454b-9d1f-16bd1106d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-96817d3c-263a-4552-88b3-1d9868efde47,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-fb2ea8d4-bddf-4906-a93f-ca7805f32c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486708875-172.17.0.13-1598607516229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-8e3a11ea-2d83-4e3f-8a46-5f409775f991,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-1969c47c-3a76-43ee-9145-d82744cd7200,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-4f7bec5a-d9d9-497c-afc6-a262efc3c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-6fd6da1e-39d3-4070-a829-873111005e44,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-5e595eba-cd10-4890-8110-091199c2082a,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-e8538c14-e3a8-454b-9d1f-16bd1106d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-96817d3c-263a-4552-88b3-1d9868efde47,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-fb2ea8d4-bddf-4906-a93f-ca7805f32c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652612150-172.17.0.13-1598607944556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-24311a83-7998-4656-89be-8c46d0e79ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-c685ce54-8d76-461b-bf7a-7c17aed41f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-55a0ea59-f174-4946-bba6-c680c685a269,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-93bcc367-5a94-43c5-9d4a-4e94247d77bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-fded0524-8059-4604-8f2c-f5327c4ffaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-2e0cff44-b077-410f-917c-2b6426ad07c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-8c5b8f55-b3c1-49a6-8a93-0e36712db5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-02374330-4e88-469d-a261-a9a54a34c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652612150-172.17.0.13-1598607944556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44682,DS-24311a83-7998-4656-89be-8c46d0e79ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-c685ce54-8d76-461b-bf7a-7c17aed41f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-55a0ea59-f174-4946-bba6-c680c685a269,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-93bcc367-5a94-43c5-9d4a-4e94247d77bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-fded0524-8059-4604-8f2c-f5327c4ffaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-2e0cff44-b077-410f-917c-2b6426ad07c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-8c5b8f55-b3c1-49a6-8a93-0e36712db5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-02374330-4e88-469d-a261-a9a54a34c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459095356-172.17.0.13-1598608468404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35267,DS-11e09b20-5459-41bb-9590-633b710ec2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f8afd7eb-99b6-4331-bcd9-4fa6ee2b9ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-66b041fa-5937-49a2-921f-9ed917673406,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-c00f8715-9743-47cc-980e-58091e4c5699,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b301d4fd-98bd-45de-acb1-47b37b5e951c,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-6365ccdc-c4cb-4d0b-ac8d-197a8cf35c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-228b18c0-cc46-442f-8b9e-1d9673ac221e,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-b76fe819-05e2-499e-8a3b-b7f9adb6e5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459095356-172.17.0.13-1598608468404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35267,DS-11e09b20-5459-41bb-9590-633b710ec2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f8afd7eb-99b6-4331-bcd9-4fa6ee2b9ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-66b041fa-5937-49a2-921f-9ed917673406,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-c00f8715-9743-47cc-980e-58091e4c5699,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b301d4fd-98bd-45de-acb1-47b37b5e951c,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-6365ccdc-c4cb-4d0b-ac8d-197a8cf35c61,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-228b18c0-cc46-442f-8b9e-1d9673ac221e,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-b76fe819-05e2-499e-8a3b-b7f9adb6e5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865108131-172.17.0.13-1598609090783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-2c41e743-bc3d-4422-a64c-f13dbe9e6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-ddd6d857-6981-4b29-856c-764709a63d27,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-3794e590-572f-4d9b-b079-0b53dfa4cf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-77614fa0-692b-4720-9a38-1672d01ca752,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-7b5dba8e-e732-4b16-8ed2-1b2544011ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-68fde9d9-921c-4fd6-8285-1f85d78eac47,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-f56dfbd8-db5e-4a81-8a3c-fcbdd691c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-4da76a13-077b-4c84-8fbd-ce645f49fe80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865108131-172.17.0.13-1598609090783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-2c41e743-bc3d-4422-a64c-f13dbe9e6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-ddd6d857-6981-4b29-856c-764709a63d27,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-3794e590-572f-4d9b-b079-0b53dfa4cf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-77614fa0-692b-4720-9a38-1672d01ca752,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-7b5dba8e-e732-4b16-8ed2-1b2544011ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-68fde9d9-921c-4fd6-8285-1f85d78eac47,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-f56dfbd8-db5e-4a81-8a3c-fcbdd691c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-4da76a13-077b-4c84-8fbd-ce645f49fe80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77330240-172.17.0.13-1598609358756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35079,DS-496f34b6-fff7-4492-bc1b-c35b8c234bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-44be4eb5-cc69-4ef0-a4f1-49bcd0564046,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-6f220324-99a2-46f5-a79b-ffb48cc5e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-504c4293-350e-414f-a647-5bfeaf67e303,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-9bc4ceca-0e41-4657-b931-5a0d6ad6c990,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-44aa9d40-3e57-4ad3-a71e-9e7814c72e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-27d35371-5c9b-459c-b748-805c1c4dedb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-81ba3c71-aee8-40f2-89a1-2e12e1fac29f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77330240-172.17.0.13-1598609358756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35079,DS-496f34b6-fff7-4492-bc1b-c35b8c234bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-44be4eb5-cc69-4ef0-a4f1-49bcd0564046,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-6f220324-99a2-46f5-a79b-ffb48cc5e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-504c4293-350e-414f-a647-5bfeaf67e303,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-9bc4ceca-0e41-4657-b931-5a0d6ad6c990,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-44aa9d40-3e57-4ad3-a71e-9e7814c72e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-27d35371-5c9b-459c-b748-805c1c4dedb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-81ba3c71-aee8-40f2-89a1-2e12e1fac29f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471199944-172.17.0.13-1598609460301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36049,DS-a5c2890e-64bd-463f-a2d6-48d90e52d092,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5c5a2f05-8e9b-400d-a9c3-1e0ae9238663,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-b11e4697-e1ae-4e2b-9549-e8b8b638c197,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-7069b5ce-f249-4c1e-9dd3-56610b3ba5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-b14fba02-0651-4792-8737-c73fc2827e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0755f117-e442-432c-8521-e035567d692c,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ceb579f2-92d0-43ae-aae1-6a7253fd069c,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-052f3421-52eb-4787-b319-db5259c29e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471199944-172.17.0.13-1598609460301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36049,DS-a5c2890e-64bd-463f-a2d6-48d90e52d092,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-5c5a2f05-8e9b-400d-a9c3-1e0ae9238663,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-b11e4697-e1ae-4e2b-9549-e8b8b638c197,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-7069b5ce-f249-4c1e-9dd3-56610b3ba5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-b14fba02-0651-4792-8737-c73fc2827e13,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-0755f117-e442-432c-8521-e035567d692c,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-ceb579f2-92d0-43ae-aae1-6a7253fd069c,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-052f3421-52eb-4787-b319-db5259c29e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764280194-172.17.0.13-1598609952112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44069,DS-91edf108-bb40-4fc0-bf4a-f963b1f8359c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-80e17468-66b6-41d4-a424-6904ce9d0e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-4dda7105-ca59-415b-be7a-f6474c2b2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-2d4a51e8-fb08-4bcb-b39b-2bb0a95f43a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-ce06e16a-6522-434a-a596-a8ccc8c65411,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-0e7b88d2-8fd4-4391-9f8c-1cdaeab9213d,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-3d07a2ee-9ce1-4326-a05f-fc801c5d6d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-d59792af-ee19-4679-8ef6-fb402f19c42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764280194-172.17.0.13-1598609952112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44069,DS-91edf108-bb40-4fc0-bf4a-f963b1f8359c,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-80e17468-66b6-41d4-a424-6904ce9d0e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-4dda7105-ca59-415b-be7a-f6474c2b2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-2d4a51e8-fb08-4bcb-b39b-2bb0a95f43a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-ce06e16a-6522-434a-a596-a8ccc8c65411,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-0e7b88d2-8fd4-4391-9f8c-1cdaeab9213d,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-3d07a2ee-9ce1-4326-a05f-fc801c5d6d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-d59792af-ee19-4679-8ef6-fb402f19c42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045087651-172.17.0.13-1598610065206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-d070d164-dfbb-4f0a-a3ff-8b216d2af74c,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-6f497ac5-d211-43d8-a412-66467c2b0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-e95da6a3-3e47-468e-a2b1-20e4884414a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-6285e4dc-1dd3-4e24-b390-01c9bc5ccd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-93b50e21-a9f8-43d5-91d4-8fe1df89e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-0ea62f29-1076-428e-84e0-e26be0663d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-19cc3b4b-d994-42c8-bf96-4343fac72305,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-e631b2e7-6abb-4310-984a-85f6617f2e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045087651-172.17.0.13-1598610065206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-d070d164-dfbb-4f0a-a3ff-8b216d2af74c,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-6f497ac5-d211-43d8-a412-66467c2b0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-e95da6a3-3e47-468e-a2b1-20e4884414a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-6285e4dc-1dd3-4e24-b390-01c9bc5ccd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-93b50e21-a9f8-43d5-91d4-8fe1df89e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-0ea62f29-1076-428e-84e0-e26be0663d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-19cc3b4b-d994-42c8-bf96-4343fac72305,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-e631b2e7-6abb-4310-984a-85f6617f2e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10380490-172.17.0.13-1598610219345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-d7ac50dc-69bf-4d88-ba83-ef8298ec65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-453c4aa1-550d-4983-9dcf-ca540c8c696d,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-a96737ee-eab6-47ef-84f7-02c2cb262000,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-2f604600-a3d1-40c0-ad06-92f0aa969bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a819743b-5e3d-4b97-86f3-c2f9c0466e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-2fb3d236-6574-48f6-9e1e-f0c8eda035c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-d6231d5e-6b85-466e-85a4-02924594e117,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2e93834f-ca36-49d8-8579-20a23199ee27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10380490-172.17.0.13-1598610219345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39532,DS-d7ac50dc-69bf-4d88-ba83-ef8298ec65ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-453c4aa1-550d-4983-9dcf-ca540c8c696d,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-a96737ee-eab6-47ef-84f7-02c2cb262000,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-2f604600-a3d1-40c0-ad06-92f0aa969bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a819743b-5e3d-4b97-86f3-c2f9c0466e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-2fb3d236-6574-48f6-9e1e-f0c8eda035c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-d6231d5e-6b85-466e-85a4-02924594e117,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2e93834f-ca36-49d8-8579-20a23199ee27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5243
