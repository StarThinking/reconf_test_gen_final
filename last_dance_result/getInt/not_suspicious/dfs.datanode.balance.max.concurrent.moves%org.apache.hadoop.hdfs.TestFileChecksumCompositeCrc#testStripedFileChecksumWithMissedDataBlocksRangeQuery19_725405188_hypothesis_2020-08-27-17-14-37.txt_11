reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515686426-172.17.0.4-1598548622674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-05e18ec1-b822-485b-aa6c-a8e434adaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-89b0604e-4198-44a2-9c02-6d3a5d125b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-d5ea2231-4fe3-4944-a06e-40327c923ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-c6427cdf-b6a9-47ab-9613-7803da2cbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-9c798636-fc54-45d1-be83-3ebce9b5403e,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5ca9835f-246a-4162-89ec-4907f8f68ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ba29912b-23ec-4cc6-b273-06c836288b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-e16d0662-8005-494e-9e6d-a67362c9f8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515686426-172.17.0.4-1598548622674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-05e18ec1-b822-485b-aa6c-a8e434adaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-89b0604e-4198-44a2-9c02-6d3a5d125b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-d5ea2231-4fe3-4944-a06e-40327c923ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-c6427cdf-b6a9-47ab-9613-7803da2cbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-9c798636-fc54-45d1-be83-3ebce9b5403e,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-5ca9835f-246a-4162-89ec-4907f8f68ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ba29912b-23ec-4cc6-b273-06c836288b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-e16d0662-8005-494e-9e6d-a67362c9f8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085813052-172.17.0.4-1598548695774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-a75b7a94-71c9-4bed-b1e2-86f6cd85df47,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e581c69f-53e6-4f4d-915b-f6618fe9dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-76a50d07-2bfc-4272-8301-63a026fb621b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-52ea63a1-f878-46c9-99ad-e13aac454d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2481714c-7fcf-4ec5-a688-64c533817253,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-2f265b84-5589-4996-a649-a752af2abb56,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-96ed293e-7a7e-4885-ab60-290ffd9f3640,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-ff4dfa6d-278f-448f-ac76-4725f87ffb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085813052-172.17.0.4-1598548695774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-a75b7a94-71c9-4bed-b1e2-86f6cd85df47,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e581c69f-53e6-4f4d-915b-f6618fe9dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-76a50d07-2bfc-4272-8301-63a026fb621b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-52ea63a1-f878-46c9-99ad-e13aac454d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2481714c-7fcf-4ec5-a688-64c533817253,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-2f265b84-5589-4996-a649-a752af2abb56,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-96ed293e-7a7e-4885-ab60-290ffd9f3640,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-ff4dfa6d-278f-448f-ac76-4725f87ffb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142634994-172.17.0.4-1598549179434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-2d06a441-d74a-4e69-8856-2e0349b41ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-690821dd-c23a-497b-93dc-d69bbc2524c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-09e35523-8bf1-466f-b59e-f0f2d82d2608,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-6c7c6eb1-40ab-4c00-b7b9-588b9eceea23,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-a3d8e724-e964-43e3-9087-1f27f6ceed96,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-e56c329b-b8c8-499e-b64e-0d4d8ac9361f,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-872c1f05-43b7-409b-a656-e897e939adcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-a0e81455-d74b-4930-8c32-49b877bc1571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142634994-172.17.0.4-1598549179434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-2d06a441-d74a-4e69-8856-2e0349b41ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-690821dd-c23a-497b-93dc-d69bbc2524c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-09e35523-8bf1-466f-b59e-f0f2d82d2608,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-6c7c6eb1-40ab-4c00-b7b9-588b9eceea23,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-a3d8e724-e964-43e3-9087-1f27f6ceed96,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-e56c329b-b8c8-499e-b64e-0d4d8ac9361f,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-872c1f05-43b7-409b-a656-e897e939adcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-a0e81455-d74b-4930-8c32-49b877bc1571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121875669-172.17.0.4-1598549615946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-c1c42d8b-4cbc-41b7-94d9-ac99bdcbfc35,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-aa98e3da-6af5-4956-bb57-02178e05656f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-ed866d66-ff53-4f4d-8fd5-4509b3fef4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-bdf39c70-4cf8-49b0-8013-60bc0f98aab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b48bc3d0-e8b8-4608-b943-e561fc551b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-8bbfa051-3bb3-46f8-a125-0ec6b131c712,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-d7e46068-a1ba-44b5-9a8f-ef84f39ea7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-bd9cc9c8-df44-4290-97dd-b88817032e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121875669-172.17.0.4-1598549615946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42738,DS-c1c42d8b-4cbc-41b7-94d9-ac99bdcbfc35,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-aa98e3da-6af5-4956-bb57-02178e05656f,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-ed866d66-ff53-4f4d-8fd5-4509b3fef4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-bdf39c70-4cf8-49b0-8013-60bc0f98aab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b48bc3d0-e8b8-4608-b943-e561fc551b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-8bbfa051-3bb3-46f8-a125-0ec6b131c712,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-d7e46068-a1ba-44b5-9a8f-ef84f39ea7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-bd9cc9c8-df44-4290-97dd-b88817032e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184640793-172.17.0.4-1598549691967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-79fa44b4-3dc2-435d-8255-6c24e0e54957,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3895fc26-7108-4ed6-b889-0e1f519345af,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-d910c4cc-af8d-40ad-b3cf-27539e0890f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-f5124b1c-3792-4adb-bfb5-1c96acae70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7a48a5a2-acef-42c9-be47-e01b53d09cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a70add49-592a-4d64-9be5-2c1f74bb2a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-41dcfcbd-1f9f-4f3a-9b68-80c067062ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-75141e81-d0a0-414e-80db-4b09a7a3c44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184640793-172.17.0.4-1598549691967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-79fa44b4-3dc2-435d-8255-6c24e0e54957,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3895fc26-7108-4ed6-b889-0e1f519345af,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-d910c4cc-af8d-40ad-b3cf-27539e0890f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-f5124b1c-3792-4adb-bfb5-1c96acae70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7a48a5a2-acef-42c9-be47-e01b53d09cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a70add49-592a-4d64-9be5-2c1f74bb2a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-41dcfcbd-1f9f-4f3a-9b68-80c067062ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-75141e81-d0a0-414e-80db-4b09a7a3c44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834028366-172.17.0.4-1598549807507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-0a907488-0af8-43fc-aace-c8d6413fd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-11390da1-6292-4bac-b79e-34c4bade3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-30183bb1-8c16-4704-939f-1edb850c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-01fa15b7-9835-44e3-b52d-d3ee1d03db8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-bc61f2e3-e8b4-4c1f-8dd0-72d94cbe95ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-b3e77ccc-2a8d-48ea-af6a-22e2752928d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-793ba932-02f4-42d8-9799-adaf51a9b422,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-ab8c516c-2040-47c9-9e11-320f09645710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1834028366-172.17.0.4-1598549807507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-0a907488-0af8-43fc-aace-c8d6413fd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-11390da1-6292-4bac-b79e-34c4bade3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-30183bb1-8c16-4704-939f-1edb850c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-01fa15b7-9835-44e3-b52d-d3ee1d03db8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-bc61f2e3-e8b4-4c1f-8dd0-72d94cbe95ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-b3e77ccc-2a8d-48ea-af6a-22e2752928d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-793ba932-02f4-42d8-9799-adaf51a9b422,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-ab8c516c-2040-47c9-9e11-320f09645710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382921104-172.17.0.4-1598549882954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-3420bf47-0c90-4c09-8467-69c98f3ef3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-9c071f83-7f64-47cf-9c2a-ec5649e64519,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-a5521015-0a16-4c94-901f-9e4296b032a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e08b350b-ee22-4a44-bd7e-1a575b1b746c,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-14474f41-14f5-407d-826b-9cd03e86a4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-b72d0797-e5c4-41d7-afcc-cd630b460a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-3bf35c92-7506-4c66-b488-3394cf540df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-29ba947a-cf51-4cbd-bd82-d1c7e90de2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382921104-172.17.0.4-1598549882954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-3420bf47-0c90-4c09-8467-69c98f3ef3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-9c071f83-7f64-47cf-9c2a-ec5649e64519,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-a5521015-0a16-4c94-901f-9e4296b032a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e08b350b-ee22-4a44-bd7e-1a575b1b746c,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-14474f41-14f5-407d-826b-9cd03e86a4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-b72d0797-e5c4-41d7-afcc-cd630b460a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-3bf35c92-7506-4c66-b488-3394cf540df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-29ba947a-cf51-4cbd-bd82-d1c7e90de2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483135122-172.17.0.4-1598550191117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46590,DS-67b624da-5876-45bf-9914-4f6538761101,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-a74b6ab4-d9c7-4832-a43d-5e6320b77cab,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-004b5495-2454-4aa4-8350-afd3843dcd86,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-9906c1cc-45dd-4313-a4ee-840e395e366d,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-85d9e6f3-bfa5-4aaa-9f86-0a412b42fac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-72813fc5-e147-46c9-8d4e-6e1d21c5bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f327dd6d-70d0-4807-b4de-9fa6835bcb01,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f40086e0-1f42-4dc7-9ed3-b2db8ddb101e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483135122-172.17.0.4-1598550191117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46590,DS-67b624da-5876-45bf-9914-4f6538761101,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-a74b6ab4-d9c7-4832-a43d-5e6320b77cab,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-004b5495-2454-4aa4-8350-afd3843dcd86,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-9906c1cc-45dd-4313-a4ee-840e395e366d,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-85d9e6f3-bfa5-4aaa-9f86-0a412b42fac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-72813fc5-e147-46c9-8d4e-6e1d21c5bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-f327dd6d-70d0-4807-b4de-9fa6835bcb01,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f40086e0-1f42-4dc7-9ed3-b2db8ddb101e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224154432-172.17.0.4-1598550403290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-1e9d4aee-4049-46d1-88f6-14c703a679a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-3b8189df-143c-40d2-a022-2216ceab7935,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-e54ce86b-bbaf-4233-9e43-406296b19d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-618b6748-5857-4ad2-aa7b-a54b0183fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-9a6ace3c-f990-4acc-ae29-f3a479565bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-a7db0e06-71a7-41b9-ad74-6c76f48b29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-44bc7e11-eb8c-46cc-940f-6504a2e7bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-92773ae4-63aa-4b3f-98ea-e643d1a8b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224154432-172.17.0.4-1598550403290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-1e9d4aee-4049-46d1-88f6-14c703a679a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-3b8189df-143c-40d2-a022-2216ceab7935,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-e54ce86b-bbaf-4233-9e43-406296b19d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-618b6748-5857-4ad2-aa7b-a54b0183fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-9a6ace3c-f990-4acc-ae29-f3a479565bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-a7db0e06-71a7-41b9-ad74-6c76f48b29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-44bc7e11-eb8c-46cc-940f-6504a2e7bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-92773ae4-63aa-4b3f-98ea-e643d1a8b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29373223-172.17.0.4-1598550935612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-e81b04c3-75ef-45ba-9b9d-c33d5ef98c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-19b42395-ff4f-4ee0-9ad7-95ff9e04cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-8e3a373f-d0cc-408b-823f-2657cd97539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-5fda01b2-0c21-4832-90fe-0728bd3c9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-d6dd304d-b6eb-4d0a-bf3b-e5448020a696,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-3531a96a-0ff1-4620-8143-c436de5247b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-8efc62b4-60ab-47eb-9728-e2069fd527fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-9de3e492-fbb9-4eff-b917-02d1f3c8a95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29373223-172.17.0.4-1598550935612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-e81b04c3-75ef-45ba-9b9d-c33d5ef98c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-19b42395-ff4f-4ee0-9ad7-95ff9e04cbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-8e3a373f-d0cc-408b-823f-2657cd97539f,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-5fda01b2-0c21-4832-90fe-0728bd3c9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-d6dd304d-b6eb-4d0a-bf3b-e5448020a696,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-3531a96a-0ff1-4620-8143-c436de5247b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-8efc62b4-60ab-47eb-9728-e2069fd527fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-9de3e492-fbb9-4eff-b917-02d1f3c8a95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726803713-172.17.0.4-1598551047121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-0d65769d-76bb-4723-aa30-18ef9dc491c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-3e89463c-2eff-462d-ae47-c2f3512ff7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-f3c73158-9949-42d6-a199-1fde2a4bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d9e46e9b-6a3d-4bd5-9006-82fe42891be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-3fd07e90-d3c0-40f3-b564-d7cc0765131f,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cd207a7c-dcd0-4fc2-929f-1433189249a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-d1191fd0-c32b-4cd1-a198-13ebe938f890,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-a2e00a94-cfa7-4f63-8548-257dcf08c4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726803713-172.17.0.4-1598551047121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-0d65769d-76bb-4723-aa30-18ef9dc491c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-3e89463c-2eff-462d-ae47-c2f3512ff7da,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-f3c73158-9949-42d6-a199-1fde2a4bbb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-d9e46e9b-6a3d-4bd5-9006-82fe42891be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-3fd07e90-d3c0-40f3-b564-d7cc0765131f,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cd207a7c-dcd0-4fc2-929f-1433189249a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-d1191fd0-c32b-4cd1-a198-13ebe938f890,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-a2e00a94-cfa7-4f63-8548-257dcf08c4be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948277948-172.17.0.4-1598551124379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-0a124188-094a-4210-8819-c433e6fc77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-76de67e5-6446-456c-955f-50601b9ae219,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-059c3f8b-9dc8-41f5-8871-1120a896fcba,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-296068e8-1c7e-409c-a6b1-27d6dcdc1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-6ac5a61f-75ab-4289-bfe4-571101f8c414,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-b1b9bfeb-70e4-4f0b-a36b-b74c731f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-5deb8936-e055-4290-8f2e-2fefaa13c31b,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-2c7a7c30-54e0-49c1-9de2-cbd5f63cb276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948277948-172.17.0.4-1598551124379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-0a124188-094a-4210-8819-c433e6fc77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-76de67e5-6446-456c-955f-50601b9ae219,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-059c3f8b-9dc8-41f5-8871-1120a896fcba,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-296068e8-1c7e-409c-a6b1-27d6dcdc1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-6ac5a61f-75ab-4289-bfe4-571101f8c414,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-b1b9bfeb-70e4-4f0b-a36b-b74c731f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-5deb8936-e055-4290-8f2e-2fefaa13c31b,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-2c7a7c30-54e0-49c1-9de2-cbd5f63cb276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965604078-172.17.0.4-1598551470634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-d9e9698b-fb37-456e-a6fc-4e7bf51ead62,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-fc5975a6-602b-416b-91b2-2a3dcd79da56,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-da0d7399-387c-4284-a60a-1bcb457f237d,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-78e52088-be7d-4756-9e28-fd87e81e96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-91e0f43a-c876-4ef2-9172-b84bfeaaf881,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-121b1a55-acd7-4991-8266-77c67a4c3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d377199a-90e8-43a2-a666-bb8bac5b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a451217f-870c-4737-81aa-cca6f138db12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965604078-172.17.0.4-1598551470634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-d9e9698b-fb37-456e-a6fc-4e7bf51ead62,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-fc5975a6-602b-416b-91b2-2a3dcd79da56,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-da0d7399-387c-4284-a60a-1bcb457f237d,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-78e52088-be7d-4756-9e28-fd87e81e96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-91e0f43a-c876-4ef2-9172-b84bfeaaf881,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-121b1a55-acd7-4991-8266-77c67a4c3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d377199a-90e8-43a2-a666-bb8bac5b5221,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a451217f-870c-4737-81aa-cca6f138db12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092597343-172.17.0.4-1598551740235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-4af6e386-869e-473b-a386-26d5d6155848,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-d201fbd6-9255-480e-9860-920e1a99c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-85db1891-ab1e-46c3-a0e9-e04156c6280f,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-58cb6227-1120-4557-82f4-2214d1a17fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-33f6fe4e-111e-4c91-87f5-5e3922d82710,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-ed422a7f-4a95-480c-ab15-a7273007ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-8c38ff0e-273d-4313-bc88-93c51478d374,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-9ba91676-99b1-4e39-878c-fa2c18c6f94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092597343-172.17.0.4-1598551740235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-4af6e386-869e-473b-a386-26d5d6155848,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-d201fbd6-9255-480e-9860-920e1a99c2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-85db1891-ab1e-46c3-a0e9-e04156c6280f,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-58cb6227-1120-4557-82f4-2214d1a17fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-33f6fe4e-111e-4c91-87f5-5e3922d82710,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-ed422a7f-4a95-480c-ab15-a7273007ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-8c38ff0e-273d-4313-bc88-93c51478d374,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-9ba91676-99b1-4e39-878c-fa2c18c6f94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359718879-172.17.0.4-1598551967755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-f4fbea8e-9277-4540-a3e9-1618fc8a171c,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-e9187c84-ed7f-4c5d-83a5-a018d4b66e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-ca7c75bc-b7c3-4d85-a45a-145105f83a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-20767beb-0c43-4aa3-bddf-6197cab6cbee,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-77a46f0d-8912-46ce-b802-641c7487d937,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-1cb5f3c1-b59f-44c9-b903-2f9c0aa2fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-06ef5ffa-f201-4a7d-95a1-1de254fe2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-bfac237c-0018-4724-ada2-55180829a356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359718879-172.17.0.4-1598551967755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-f4fbea8e-9277-4540-a3e9-1618fc8a171c,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-e9187c84-ed7f-4c5d-83a5-a018d4b66e58,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-ca7c75bc-b7c3-4d85-a45a-145105f83a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-20767beb-0c43-4aa3-bddf-6197cab6cbee,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-77a46f0d-8912-46ce-b802-641c7487d937,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-1cb5f3c1-b59f-44c9-b903-2f9c0aa2fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-06ef5ffa-f201-4a7d-95a1-1de254fe2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-bfac237c-0018-4724-ada2-55180829a356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348104412-172.17.0.4-1598552546290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-34076f19-7ef3-4e34-b047-1f77119fcf07,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-ba6e2c73-8ddb-4c69-babe-8af28afa68a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-25184675-b7ed-403b-b9f4-4e151a191640,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-2400f5d6-60f1-4c26-93fe-8ee37d6e6318,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-0a22966e-05c5-44ec-bb67-a8c267fa0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-88c26041-29bb-469a-b378-500ec4c9de30,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-d6f7bb12-e8ec-4ae6-a837-0c95aa571e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-ad1c386a-9f34-40c6-bd39-1203068327c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348104412-172.17.0.4-1598552546290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-34076f19-7ef3-4e34-b047-1f77119fcf07,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-ba6e2c73-8ddb-4c69-babe-8af28afa68a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-25184675-b7ed-403b-b9f4-4e151a191640,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-2400f5d6-60f1-4c26-93fe-8ee37d6e6318,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-0a22966e-05c5-44ec-bb67-a8c267fa0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-88c26041-29bb-469a-b378-500ec4c9de30,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-d6f7bb12-e8ec-4ae6-a837-0c95aa571e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-ad1c386a-9f34-40c6-bd39-1203068327c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975667026-172.17.0.4-1598552859027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-b79f53c1-fa98-41b9-a8b3-ce2277e6428f,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-97ab224b-1743-4285-b815-0be707b67823,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-7a97c6a2-7515-4191-a952-76b34bfe384a,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-090dc005-2d54-4008-adeb-79d0abf8799d,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-386153d9-3ce1-43a0-ab43-763bb9d3501a,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c2d31752-69f6-4407-8725-0cb73cea4556,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-f2949144-d4a5-4a6c-a575-29619b67bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-fe0a9dbf-2e3f-4691-85ba-0aad87e73a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975667026-172.17.0.4-1598552859027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-b79f53c1-fa98-41b9-a8b3-ce2277e6428f,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-97ab224b-1743-4285-b815-0be707b67823,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-7a97c6a2-7515-4191-a952-76b34bfe384a,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-090dc005-2d54-4008-adeb-79d0abf8799d,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-386153d9-3ce1-43a0-ab43-763bb9d3501a,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-c2d31752-69f6-4407-8725-0cb73cea4556,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-f2949144-d4a5-4a6c-a575-29619b67bd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-fe0a9dbf-2e3f-4691-85ba-0aad87e73a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964732580-172.17.0.4-1598553022704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-6ca82160-1d8a-4bf0-86c1-fa4ba064b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-3951ee93-2e19-4af2-995e-4a2365abb957,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-76c6028d-603e-4ca8-9a95-a47fd589c559,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-b6e12aa6-cedf-4213-9fab-a2c371e1a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-d40515f4-6ac0-42b8-a328-ecacc0060b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c2981620-4a06-4d22-b7d7-6498d4756986,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-08560515-a4b5-45f2-8f96-e741dce1ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-e6cf7367-d8c4-4006-b0ad-17ff9d37bc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964732580-172.17.0.4-1598553022704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46476,DS-6ca82160-1d8a-4bf0-86c1-fa4ba064b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-3951ee93-2e19-4af2-995e-4a2365abb957,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-76c6028d-603e-4ca8-9a95-a47fd589c559,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-b6e12aa6-cedf-4213-9fab-a2c371e1a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-d40515f4-6ac0-42b8-a328-ecacc0060b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-c2981620-4a06-4d22-b7d7-6498d4756986,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-08560515-a4b5-45f2-8f96-e741dce1ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-e6cf7367-d8c4-4006-b0ad-17ff9d37bc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091208736-172.17.0.4-1598553091288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-8a83bfba-7157-4627-affc-0c7a35c86a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-1dce3643-1ba6-423e-81dd-4e3e90ef8518,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fd31be2b-0bc9-485a-a2b7-1a2775a55ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-cb21714e-77ed-4264-b68a-3fd059c6324b,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-caee5727-d814-4bcb-929d-8aa71ee91807,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-2129c3aa-23af-4aab-9dd5-bb92346d57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-86a2a956-ed5d-41c5-bf5c-f875871093e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-491b55ee-7faf-408d-ac97-189cec6b551e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091208736-172.17.0.4-1598553091288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-8a83bfba-7157-4627-affc-0c7a35c86a82,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-1dce3643-1ba6-423e-81dd-4e3e90ef8518,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fd31be2b-0bc9-485a-a2b7-1a2775a55ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-cb21714e-77ed-4264-b68a-3fd059c6324b,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-caee5727-d814-4bcb-929d-8aa71ee91807,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-2129c3aa-23af-4aab-9dd5-bb92346d57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-86a2a956-ed5d-41c5-bf5c-f875871093e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-491b55ee-7faf-408d-ac97-189cec6b551e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326297272-172.17.0.4-1598553191846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-81d9fc2b-4fef-4313-a359-8c554fd5e027,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-cee70454-d49d-4e77-abb6-9e17e3d7c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-06f9e472-8c58-46a1-902a-bbda5264384d,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7c878d87-870e-43a0-897e-b280573c59de,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-ad3599ec-0c71-4610-a315-d21051cce3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-f493bfb7-8221-4233-ab43-72976027f590,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-aacfd8d9-7960-44ff-8df0-949e8ac476f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-49994c82-c4b2-46ee-a7b2-539bd5358279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326297272-172.17.0.4-1598553191846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-81d9fc2b-4fef-4313-a359-8c554fd5e027,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-cee70454-d49d-4e77-abb6-9e17e3d7c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-06f9e472-8c58-46a1-902a-bbda5264384d,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-7c878d87-870e-43a0-897e-b280573c59de,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-ad3599ec-0c71-4610-a315-d21051cce3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-f493bfb7-8221-4233-ab43-72976027f590,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-aacfd8d9-7960-44ff-8df0-949e8ac476f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-49994c82-c4b2-46ee-a7b2-539bd5358279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560891792-172.17.0.4-1598553227491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-fb1b3e5f-2cd0-4e9e-82a4-4a921ade52da,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b6515ecc-c1f2-47c2-a4ec-cabdcf62f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-48d1044f-928c-43e2-9384-f5bf40d24075,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-31d6339a-5085-4833-8804-a66b2fb2185f,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-869145d1-a4fd-43ed-b09a-21efbd767536,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7d00cc75-9a71-45b5-9ea5-4c282ab48174,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-c974d37f-663c-443c-b75e-d530fd4c3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-300ed7c7-2c3f-41f5-82bb-77e6f1ffbe0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560891792-172.17.0.4-1598553227491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39497,DS-fb1b3e5f-2cd0-4e9e-82a4-4a921ade52da,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b6515ecc-c1f2-47c2-a4ec-cabdcf62f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-48d1044f-928c-43e2-9384-f5bf40d24075,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-31d6339a-5085-4833-8804-a66b2fb2185f,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-869145d1-a4fd-43ed-b09a-21efbd767536,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7d00cc75-9a71-45b5-9ea5-4c282ab48174,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-c974d37f-663c-443c-b75e-d530fd4c3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-300ed7c7-2c3f-41f5-82bb-77e6f1ffbe0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137918507-172.17.0.4-1598553363272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-4121ddf7-fe38-4373-ac93-0e54468becb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-b05338b5-a75d-4ee2-9bdd-5857ecfd3100,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-b0a9cc73-27a6-428a-9cfb-4c0c3c5ea945,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-67875e8c-6462-4b4a-a0c2-26e60067db51,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5152d0af-9235-42ac-a21c-6c83893b33cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e351af74-613b-44b6-bdae-5d852fce9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c81e5360-24a9-452c-93c9-c74c893f8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-9a06ca72-7160-4d35-afb0-d65038a69cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137918507-172.17.0.4-1598553363272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-4121ddf7-fe38-4373-ac93-0e54468becb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-b05338b5-a75d-4ee2-9bdd-5857ecfd3100,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-b0a9cc73-27a6-428a-9cfb-4c0c3c5ea945,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-67875e8c-6462-4b4a-a0c2-26e60067db51,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5152d0af-9235-42ac-a21c-6c83893b33cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e351af74-613b-44b6-bdae-5d852fce9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-c81e5360-24a9-452c-93c9-c74c893f8dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-9a06ca72-7160-4d35-afb0-d65038a69cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194766253-172.17.0.4-1598553696108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-79b7217b-f5f6-4040-a513-e9b0ddbd60de,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-835ecbf7-5340-41f0-a0ab-196c79cfac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c1e23840-d1f7-4fcd-8867-113bcce441a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-6a453660-83d9-4a4a-98ea-1437e2e6c645,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-70fa14cc-224a-4e85-b669-de7b810b7267,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-e8d5ccbb-f670-4ec8-993a-4276d02f6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-579ac3ec-7f86-4d73-b0d3-575a7599ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-90742ab7-ac58-41cb-ab7c-6446244d6915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194766253-172.17.0.4-1598553696108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-79b7217b-f5f6-4040-a513-e9b0ddbd60de,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-835ecbf7-5340-41f0-a0ab-196c79cfac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c1e23840-d1f7-4fcd-8867-113bcce441a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-6a453660-83d9-4a4a-98ea-1437e2e6c645,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-70fa14cc-224a-4e85-b669-de7b810b7267,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-e8d5ccbb-f670-4ec8-993a-4276d02f6ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-579ac3ec-7f86-4d73-b0d3-575a7599ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-90742ab7-ac58-41cb-ab7c-6446244d6915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 80
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151189280-172.17.0.4-1598553953797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-96fd5651-6b5c-4170-9741-dcb401447373,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-f4af1213-3e87-4f71-b611-6639feec9642,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-9a8ec9dd-c6e7-463f-9298-efe93dc7ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-c548cd52-27f6-409a-a1ac-a33e7c222b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-42808eec-aef5-47a8-8325-52196f9212c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-999f3f47-e96d-4df0-b0a5-283b9bf5d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-bc13f855-66e4-4dd9-a593-eb05baf82513,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8098a42b-96f3-4476-92c0-1b98c767023a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151189280-172.17.0.4-1598553953797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-96fd5651-6b5c-4170-9741-dcb401447373,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-f4af1213-3e87-4f71-b611-6639feec9642,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-9a8ec9dd-c6e7-463f-9298-efe93dc7ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-c548cd52-27f6-409a-a1ac-a33e7c222b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-42808eec-aef5-47a8-8325-52196f9212c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-999f3f47-e96d-4df0-b0a5-283b9bf5d21c,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-bc13f855-66e4-4dd9-a593-eb05baf82513,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8098a42b-96f3-4476-92c0-1b98c767023a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5612
