reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069019195-172.17.0.11-1598507828766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-64cfb197-fd49-41ae-87ec-2af5a7ac4936,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-c81d6ca3-b700-4adc-a32d-33c6728934e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-dfc23ac5-71d6-4b75-ac62-36865f086967,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-001c6dad-319b-41e6-a048-46c158e66e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-7ad8399b-a50b-4a54-bf69-2f9dbe0e8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-804671be-09d2-4477-acc8-6dbf87c38a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-d23ec750-8602-4399-aabd-6e245ab0edc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-49b42e45-f72d-4cd0-ae2a-ae5bde41be3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069019195-172.17.0.11-1598507828766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-64cfb197-fd49-41ae-87ec-2af5a7ac4936,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-c81d6ca3-b700-4adc-a32d-33c6728934e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-dfc23ac5-71d6-4b75-ac62-36865f086967,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-001c6dad-319b-41e6-a048-46c158e66e20,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-7ad8399b-a50b-4a54-bf69-2f9dbe0e8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-804671be-09d2-4477-acc8-6dbf87c38a97,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-d23ec750-8602-4399-aabd-6e245ab0edc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-49b42e45-f72d-4cd0-ae2a-ae5bde41be3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226471344-172.17.0.11-1598507941131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-323752ff-a3f9-48a1-885a-27fa164134b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-3bd4c3fe-6783-43eb-8b71-806d0050fe78,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-9f852c76-0983-436a-bca2-0413546c18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-c2b3f8bd-2512-443c-8e8e-43f9dd28117c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-51b0df5c-8cdd-449a-9429-1291b7b70506,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-249714ea-423e-4263-8ab4-f2cf2856ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-a58f4772-a88f-4c8d-8c0c-3933658d7267,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-f3623bbc-b6cd-4586-a421-719e7ca30f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226471344-172.17.0.11-1598507941131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-323752ff-a3f9-48a1-885a-27fa164134b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-3bd4c3fe-6783-43eb-8b71-806d0050fe78,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-9f852c76-0983-436a-bca2-0413546c18b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-c2b3f8bd-2512-443c-8e8e-43f9dd28117c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-51b0df5c-8cdd-449a-9429-1291b7b70506,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-249714ea-423e-4263-8ab4-f2cf2856ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-a58f4772-a88f-4c8d-8c0c-3933658d7267,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-f3623bbc-b6cd-4586-a421-719e7ca30f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862452208-172.17.0.11-1598508484679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-ffe820f0-c622-4c4a-a6fc-a7f6b077c641,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-9dae956a-59b1-4d45-be62-bbe650a73898,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0bf72a2a-07ac-44d9-925e-fd2e1eb2cfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-54f320cc-b583-4946-b180-b887b6f0075f,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-60887752-13a9-4048-8074-1b1c4555dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-06b32627-8df6-43f5-bfe8-518d96936de8,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-f9970643-9ea7-4a03-9901-10076e931592,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2c2c3337-b9a2-4320-ae9b-266cfe95a327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862452208-172.17.0.11-1598508484679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-ffe820f0-c622-4c4a-a6fc-a7f6b077c641,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-9dae956a-59b1-4d45-be62-bbe650a73898,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0bf72a2a-07ac-44d9-925e-fd2e1eb2cfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-54f320cc-b583-4946-b180-b887b6f0075f,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-60887752-13a9-4048-8074-1b1c4555dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-06b32627-8df6-43f5-bfe8-518d96936de8,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-f9970643-9ea7-4a03-9901-10076e931592,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-2c2c3337-b9a2-4320-ae9b-266cfe95a327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613251652-172.17.0.11-1598508920025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-985d3ace-bbeb-410d-936d-7748a841bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-8e959875-1bbd-40ae-996a-ae1a1f143d37,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-c66ea954-1b1a-48f2-b6eb-b7071162baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-46ab02ad-c63d-43b5-bb0b-c4f95d46779f,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-9ba7801e-0116-40c8-b607-d5519454cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-674c8b32-004d-46a9-b03e-b69825cb2f53,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1a20b26b-7dc2-4599-b4af-6014fdb04daf,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-b2451531-3bd5-421d-8cd0-7f5710d53476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613251652-172.17.0.11-1598508920025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-985d3ace-bbeb-410d-936d-7748a841bbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-8e959875-1bbd-40ae-996a-ae1a1f143d37,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-c66ea954-1b1a-48f2-b6eb-b7071162baf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-46ab02ad-c63d-43b5-bb0b-c4f95d46779f,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-9ba7801e-0116-40c8-b607-d5519454cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-674c8b32-004d-46a9-b03e-b69825cb2f53,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1a20b26b-7dc2-4599-b4af-6014fdb04daf,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-b2451531-3bd5-421d-8cd0-7f5710d53476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861815193-172.17.0.11-1598509033700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-21b2ed44-4dea-4233-9cc3-c6ce896a29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-6c555007-061d-417c-a1c0-0dda3d09d030,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-4836e785-9a69-4e2e-907d-f65205901db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-b7b6f6c7-0d97-4f41-96cd-28b130a47fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-8c0f1320-5499-4e25-b4cd-4807c4480245,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9e846bc6-d6b4-4687-a17c-e835284870a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-2dcfb234-bf04-43b4-a463-dc498d26a333,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-cce8c4d2-377c-4848-9bcb-8e54a877bb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861815193-172.17.0.11-1598509033700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-21b2ed44-4dea-4233-9cc3-c6ce896a29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-6c555007-061d-417c-a1c0-0dda3d09d030,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-4836e785-9a69-4e2e-907d-f65205901db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-b7b6f6c7-0d97-4f41-96cd-28b130a47fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-8c0f1320-5499-4e25-b4cd-4807c4480245,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9e846bc6-d6b4-4687-a17c-e835284870a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-2dcfb234-bf04-43b4-a463-dc498d26a333,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-cce8c4d2-377c-4848-9bcb-8e54a877bb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112434431-172.17.0.11-1598509136208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-99dae527-6e61-4ccb-9615-c72620f9bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3db8a173-89cf-4e7f-b86c-99a22f3633c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-af17a2fb-4ac2-48ad-8001-c7deedd145f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-b292cad7-6745-47dd-bebf-9fc21997cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-9e0f8708-e25b-495a-96cb-aaba1c6f8f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-fcb159c8-bd9a-4407-857a-de8940270b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-f15eac0a-d2b6-4f3c-b53f-8b6c4024a562,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-503bff39-99a1-431a-b56f-4d9b1f237a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112434431-172.17.0.11-1598509136208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-99dae527-6e61-4ccb-9615-c72620f9bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3db8a173-89cf-4e7f-b86c-99a22f3633c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-af17a2fb-4ac2-48ad-8001-c7deedd145f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-b292cad7-6745-47dd-bebf-9fc21997cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-9e0f8708-e25b-495a-96cb-aaba1c6f8f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-fcb159c8-bd9a-4407-857a-de8940270b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-f15eac0a-d2b6-4f3c-b53f-8b6c4024a562,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-503bff39-99a1-431a-b56f-4d9b1f237a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468905718-172.17.0.11-1598509201838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-8cc2f133-4326-47c5-a6b4-dac631d5afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-e8788d3f-76c9-4f46-90f9-2d130c2bf2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-5775476b-57c6-4c74-ac54-3e602327840e,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-63790287-2872-4670-97b4-8e7d2e4c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-d2e427e5-f5d7-45ce-b64e-60b4fba3df04,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7cfa06c0-7350-45eb-96c5-31f905ae8396,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-9c58ef6f-5ec6-40d3-9b7f-3d52508eab76,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-aac02f85-0da1-4baf-8d3c-010ed927e70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468905718-172.17.0.11-1598509201838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-8cc2f133-4326-47c5-a6b4-dac631d5afd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-e8788d3f-76c9-4f46-90f9-2d130c2bf2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-5775476b-57c6-4c74-ac54-3e602327840e,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-63790287-2872-4670-97b4-8e7d2e4c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-d2e427e5-f5d7-45ce-b64e-60b4fba3df04,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7cfa06c0-7350-45eb-96c5-31f905ae8396,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-9c58ef6f-5ec6-40d3-9b7f-3d52508eab76,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-aac02f85-0da1-4baf-8d3c-010ed927e70e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709562158-172.17.0.11-1598509387121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-37a63f05-4aa6-48d4-8cd8-2bc2b0f53f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c7faab81-0716-447f-8a3d-6438efd20703,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-cdd9d51c-7a62-4f8b-90a3-6ca3ee2a4e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-7ed69a89-1523-4890-a206-5b5df6f4f313,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-4645d773-44a1-4e9a-8ac0-cdc3eabcc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-11fc0e51-e1e3-4a1e-8de5-502dfea464ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-068499e3-c16d-48c0-86aa-74bc17be00b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-d84b21ac-5864-423f-9146-86a0af8583a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709562158-172.17.0.11-1598509387121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-37a63f05-4aa6-48d4-8cd8-2bc2b0f53f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-c7faab81-0716-447f-8a3d-6438efd20703,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-cdd9d51c-7a62-4f8b-90a3-6ca3ee2a4e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-7ed69a89-1523-4890-a206-5b5df6f4f313,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-4645d773-44a1-4e9a-8ac0-cdc3eabcc3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-11fc0e51-e1e3-4a1e-8de5-502dfea464ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-068499e3-c16d-48c0-86aa-74bc17be00b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-d84b21ac-5864-423f-9146-86a0af8583a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999563761-172.17.0.11-1598509461476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-9d4c5a07-84b9-4f21-bee6-7da0239b29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-d9c3c7d6-0ab8-4909-9c3a-a1b58c80d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-3d9d87b9-01b8-4257-bd2c-8b8a736dc295,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-0ec6594b-f3c7-4887-87ff-5719a751c8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-54d77cb1-8db1-478d-a0ca-6726677a4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-3d72561a-bd88-4f8c-9d4e-c4057464f737,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2b44178f-9c91-4098-ba1d-9e71379c3052,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-0ff0ef2b-0ba6-428e-a50b-9ab48f35afe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999563761-172.17.0.11-1598509461476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-9d4c5a07-84b9-4f21-bee6-7da0239b29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-d9c3c7d6-0ab8-4909-9c3a-a1b58c80d7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-3d9d87b9-01b8-4257-bd2c-8b8a736dc295,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-0ec6594b-f3c7-4887-87ff-5719a751c8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-54d77cb1-8db1-478d-a0ca-6726677a4e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-3d72561a-bd88-4f8c-9d4e-c4057464f737,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-2b44178f-9c91-4098-ba1d-9e71379c3052,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-0ff0ef2b-0ba6-428e-a50b-9ab48f35afe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676156892-172.17.0.11-1598510363851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32866,DS-1839f795-d02b-4dec-b055-702bcb437f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-3d9a8d4e-38ed-4c4f-ad1e-3db0f047eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-56917f92-f9ad-43b8-a487-029e9900cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-a3965af1-7cf5-462a-9e60-4767baa171b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a62b8ddf-cf11-45d4-b9ee-ac6cc93e6268,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-0f726b91-be89-484c-8dce-0e0634bcdf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-5a7f8653-b9e9-4363-8fdb-06f37d5e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-5e83e174-ca3c-4188-8444-94632dd47b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676156892-172.17.0.11-1598510363851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32866,DS-1839f795-d02b-4dec-b055-702bcb437f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-3d9a8d4e-38ed-4c4f-ad1e-3db0f047eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-56917f92-f9ad-43b8-a487-029e9900cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-a3965af1-7cf5-462a-9e60-4767baa171b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a62b8ddf-cf11-45d4-b9ee-ac6cc93e6268,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-0f726b91-be89-484c-8dce-0e0634bcdf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-5a7f8653-b9e9-4363-8fdb-06f37d5e8c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-5e83e174-ca3c-4188-8444-94632dd47b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657140246-172.17.0.11-1598510514802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-549fa4d1-5d76-4d11-8ce7-4520ef39b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-51dfae76-7d48-4760-8d4b-18d5aab0e316,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2270ddb5-1b16-4efc-80ac-710bdb60dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-57bbe71c-6287-4a8f-8070-47a2206024ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b31b5dba-ed13-4a3d-93f4-627a57c6617b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-711d2663-9ff5-4feb-bff2-ab744a1e6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-96982498-da6b-4c1f-b3d9-ba5e911adc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1a00bd3c-54ba-475a-baeb-0f7ed01b7ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657140246-172.17.0.11-1598510514802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-549fa4d1-5d76-4d11-8ce7-4520ef39b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-51dfae76-7d48-4760-8d4b-18d5aab0e316,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2270ddb5-1b16-4efc-80ac-710bdb60dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-57bbe71c-6287-4a8f-8070-47a2206024ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b31b5dba-ed13-4a3d-93f4-627a57c6617b,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-711d2663-9ff5-4feb-bff2-ab744a1e6ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-96982498-da6b-4c1f-b3d9-ba5e911adc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-1a00bd3c-54ba-475a-baeb-0f7ed01b7ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899490194-172.17.0.11-1598511541764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-3f822c11-c285-48cf-b4af-43dbc2e172bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-853bdd96-9c5e-4a5d-9cda-f6de3b28878f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-940ba11e-fe0b-41e9-8a47-7c8ed7874eef,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6f4c69ba-d6be-4141-8243-235612af394b,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6587e5d7-2e28-4f08-bc14-743a729b0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-60619628-c72f-4d5a-80cc-34d5f91e0e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-dc9603bf-3f79-404c-a899-599e3a290762,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-f4278a9a-fb37-4b0f-9243-ee36215dcec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899490194-172.17.0.11-1598511541764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-3f822c11-c285-48cf-b4af-43dbc2e172bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-853bdd96-9c5e-4a5d-9cda-f6de3b28878f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-940ba11e-fe0b-41e9-8a47-7c8ed7874eef,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6f4c69ba-d6be-4141-8243-235612af394b,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6587e5d7-2e28-4f08-bc14-743a729b0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-60619628-c72f-4d5a-80cc-34d5f91e0e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-dc9603bf-3f79-404c-a899-599e3a290762,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-f4278a9a-fb37-4b0f-9243-ee36215dcec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539695497-172.17.0.11-1598511681341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-8d106684-2cfd-4507-b0df-c79581e84670,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-157d1892-df9f-472e-8730-72f0fbea9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-80c798cf-ea4c-479c-bca8-c8b52819163b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-1afd2c40-5bfc-41b5-83e9-385e8bc016bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-b5cb8513-b1f0-4dbd-9e80-319ff3450e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-e23ce56a-4d0d-4a8b-ae5a-df060f8f4171,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-a915675f-9948-4f3a-a8da-33e1f2e037bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-b14d34a7-3e7e-4f79-812d-33cf97926d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539695497-172.17.0.11-1598511681341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-8d106684-2cfd-4507-b0df-c79581e84670,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-157d1892-df9f-472e-8730-72f0fbea9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-80c798cf-ea4c-479c-bca8-c8b52819163b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-1afd2c40-5bfc-41b5-83e9-385e8bc016bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-b5cb8513-b1f0-4dbd-9e80-319ff3450e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-e23ce56a-4d0d-4a8b-ae5a-df060f8f4171,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-a915675f-9948-4f3a-a8da-33e1f2e037bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-b14d34a7-3e7e-4f79-812d-33cf97926d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081675424-172.17.0.11-1598511824935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-66e242cf-d25b-4442-9acd-664bc28baa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-88bc257c-00a5-4ce3-b27a-1b3d40216b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-6808cd1b-0a3f-4da4-94d2-ed7909f1e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-15e58f90-d2de-4c42-92ba-54ba9ae807d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-8d8f0b2f-a43a-481a-b0df-e2530f9b8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-2af87b25-17a3-4da8-a8f8-816cf849551e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a81e3d35-a582-4f0b-9605-2d85e1e0756d,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-0ab0a97d-a39e-4d7d-8924-50d8443b7ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081675424-172.17.0.11-1598511824935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-66e242cf-d25b-4442-9acd-664bc28baa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-88bc257c-00a5-4ce3-b27a-1b3d40216b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-6808cd1b-0a3f-4da4-94d2-ed7909f1e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-15e58f90-d2de-4c42-92ba-54ba9ae807d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-8d8f0b2f-a43a-481a-b0df-e2530f9b8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-2af87b25-17a3-4da8-a8f8-816cf849551e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-a81e3d35-a582-4f0b-9605-2d85e1e0756d,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-0ab0a97d-a39e-4d7d-8924-50d8443b7ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058676569-172.17.0.11-1598512155136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-f9cc6e0c-94ca-49cf-8b5c-8fd27ac3f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-abfb8375-e265-473e-b296-f8f33ef4a94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-9e40a965-aaeb-4bc8-88e8-01f7aa72a978,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-a876aa3d-ed65-41f3-9bb7-c671f68ea8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-0e7b60a8-f35b-4c0e-9cd3-367030fe4d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-6e60bc64-282b-4651-9b7d-9174a612242a,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-4501e851-df5c-4dbc-9936-2f546545a347,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ded2e20b-2874-4162-a5be-88df5f0b9807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058676569-172.17.0.11-1598512155136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-f9cc6e0c-94ca-49cf-8b5c-8fd27ac3f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-abfb8375-e265-473e-b296-f8f33ef4a94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-9e40a965-aaeb-4bc8-88e8-01f7aa72a978,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-a876aa3d-ed65-41f3-9bb7-c671f68ea8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-0e7b60a8-f35b-4c0e-9cd3-367030fe4d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-6e60bc64-282b-4651-9b7d-9174a612242a,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-4501e851-df5c-4dbc-9936-2f546545a347,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-ded2e20b-2874-4162-a5be-88df5f0b9807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957003815-172.17.0.11-1598512701549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-7cca9123-cb07-4262-aaed-f0a6da8e027a,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-3a4b9d60-5248-45c8-9dbc-8d6baea2592a,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-d02da106-fbed-4d4c-b9cc-2e5de6f96314,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-45af4ab1-4b24-43a1-9933-ab691a0ac730,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-5c3d96e7-c55e-45f6-874d-df7fd31c294b,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-bd293a95-87a0-49ad-8f87-4c810377c025,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3b36f8ff-bc34-4a3d-b9aa-24d2ff18f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-7334173c-8d74-4bcd-851f-b7d8638ee6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957003815-172.17.0.11-1598512701549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-7cca9123-cb07-4262-aaed-f0a6da8e027a,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-3a4b9d60-5248-45c8-9dbc-8d6baea2592a,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-d02da106-fbed-4d4c-b9cc-2e5de6f96314,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-45af4ab1-4b24-43a1-9933-ab691a0ac730,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-5c3d96e7-c55e-45f6-874d-df7fd31c294b,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-bd293a95-87a0-49ad-8f87-4c810377c025,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-3b36f8ff-bc34-4a3d-b9aa-24d2ff18f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-7334173c-8d74-4bcd-851f-b7d8638ee6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5369
