reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862802311-172.17.0.12-1598573412945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-f17e9a5f-137e-4896-a143-84c5cb49fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-6f0c55ef-cc7b-468e-9c00-a72569615797,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ff2f6aec-b305-43fc-b93e-c90e0587b842,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-20cb5fa1-bacb-4bdb-ba48-28b0c8c09137,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-910a5628-8e29-45f6-9de5-2dbd12cdfbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-0f23b995-e6c4-4065-b3c6-c3b7b68ee4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-efb3e72b-b7d2-4668-acc8-f578207a0ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-64c129b5-5b6c-4a80-b4c6-bc408b2757f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862802311-172.17.0.12-1598573412945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-f17e9a5f-137e-4896-a143-84c5cb49fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-6f0c55ef-cc7b-468e-9c00-a72569615797,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ff2f6aec-b305-43fc-b93e-c90e0587b842,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-20cb5fa1-bacb-4bdb-ba48-28b0c8c09137,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-910a5628-8e29-45f6-9de5-2dbd12cdfbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-0f23b995-e6c4-4065-b3c6-c3b7b68ee4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-efb3e72b-b7d2-4668-acc8-f578207a0ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-64c129b5-5b6c-4a80-b4c6-bc408b2757f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522482216-172.17.0.12-1598573660106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-9d45e727-f3dc-472a-b7b2-f8d2dbec7217,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-89c3e022-911a-4d0e-b4ba-82d71d44d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-01758dbf-0792-40b9-b050-f7edc5403c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-a4070ca5-37df-4840-9f8a-d0b5d3c22d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-3d02cee6-395d-4415-be73-f4656c46d9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-571e158a-eb9e-4dc1-a493-44003ec1aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-58011f7c-307f-452f-891b-3a7946082ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-f92aecd1-0b06-4ce2-8ca2-55ce7ccfb74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522482216-172.17.0.12-1598573660106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-9d45e727-f3dc-472a-b7b2-f8d2dbec7217,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-89c3e022-911a-4d0e-b4ba-82d71d44d6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-01758dbf-0792-40b9-b050-f7edc5403c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-a4070ca5-37df-4840-9f8a-d0b5d3c22d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-3d02cee6-395d-4415-be73-f4656c46d9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-571e158a-eb9e-4dc1-a493-44003ec1aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-58011f7c-307f-452f-891b-3a7946082ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-f92aecd1-0b06-4ce2-8ca2-55ce7ccfb74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905187934-172.17.0.12-1598574798993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-0c156efc-ffd7-4190-98bd-521398db8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-05d8de07-bc6b-421d-bbe6-a7015cac5327,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-db8e7aea-0863-4387-85df-e3983c8efd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-64944bdb-7e9d-4ba3-9cac-a314d039960a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f38bf5e4-b712-4b0d-8358-2332a488cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-f8e755c1-a3a8-4fd1-b3dc-275577bbf23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-448037a1-06e5-4af8-b7c4-922b9f76fc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-ff3a02d0-62f8-475c-8b86-692831752439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905187934-172.17.0.12-1598574798993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-0c156efc-ffd7-4190-98bd-521398db8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-05d8de07-bc6b-421d-bbe6-a7015cac5327,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-db8e7aea-0863-4387-85df-e3983c8efd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-64944bdb-7e9d-4ba3-9cac-a314d039960a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f38bf5e4-b712-4b0d-8358-2332a488cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-f8e755c1-a3a8-4fd1-b3dc-275577bbf23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-448037a1-06e5-4af8-b7c4-922b9f76fc13,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-ff3a02d0-62f8-475c-8b86-692831752439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553036165-172.17.0.12-1598575439206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-f281ec53-cd90-40a7-9dac-1bdeed76e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-5c4c4d73-db59-4ff0-b871-b3be62aa3987,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-cc94373b-1c55-42ec-82df-9b8ff64e9269,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-13a83931-b531-4771-a3b3-ce8fdae65354,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-f4bb585c-5ad0-485b-ac44-c3ca0b1c0374,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-9b0ae60d-99ff-4000-895e-8434247ab4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-51d73183-95e2-4e85-a0c2-2c86d3d42a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-fb2f4112-744e-4456-a532-7d625132f529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553036165-172.17.0.12-1598575439206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-f281ec53-cd90-40a7-9dac-1bdeed76e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-5c4c4d73-db59-4ff0-b871-b3be62aa3987,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-cc94373b-1c55-42ec-82df-9b8ff64e9269,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-13a83931-b531-4771-a3b3-ce8fdae65354,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-f4bb585c-5ad0-485b-ac44-c3ca0b1c0374,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-9b0ae60d-99ff-4000-895e-8434247ab4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-51d73183-95e2-4e85-a0c2-2c86d3d42a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-fb2f4112-744e-4456-a532-7d625132f529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525368004-172.17.0.12-1598575582514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-fb77c237-18dc-47e2-a973-aab439051189,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-c706e5de-41db-44b2-a832-b8d528792931,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-cbbd4925-e333-489a-851c-c3ea6bc02412,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-a0632216-4880-482e-af53-41851943a825,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-b343bbd2-d582-4033-82df-6694c02eed84,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-2cfd188c-1efb-41f5-b0e2-388f7a976799,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-cf50045d-7ea4-4553-bb2f-9c29386dcac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-ab2aa8cb-c520-463c-a965-4695c03221ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525368004-172.17.0.12-1598575582514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-fb77c237-18dc-47e2-a973-aab439051189,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-c706e5de-41db-44b2-a832-b8d528792931,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-cbbd4925-e333-489a-851c-c3ea6bc02412,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-a0632216-4880-482e-af53-41851943a825,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-b343bbd2-d582-4033-82df-6694c02eed84,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-2cfd188c-1efb-41f5-b0e2-388f7a976799,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-cf50045d-7ea4-4553-bb2f-9c29386dcac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-ab2aa8cb-c520-463c-a965-4695c03221ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061147854-172.17.0.12-1598575651887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-6d01a04e-7bd1-4ad4-a17c-a55019a14090,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-5fe4fa3f-52b7-444a-80c9-a6abc4137b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-86d25a4d-84bb-4eb8-831a-c73bfeb62339,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-ed3e02a4-85df-4809-bd73-823f333629a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-466f1c68-70f9-4101-86d9-0909430f1d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-25632504-a750-4d9b-9043-841ecdf63003,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-16e8d09f-2ebf-43c2-88e7-d8636a73e717,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-c55f37cd-265c-4b97-8063-01178c27ebf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061147854-172.17.0.12-1598575651887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-6d01a04e-7bd1-4ad4-a17c-a55019a14090,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-5fe4fa3f-52b7-444a-80c9-a6abc4137b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-86d25a4d-84bb-4eb8-831a-c73bfeb62339,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-ed3e02a4-85df-4809-bd73-823f333629a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-466f1c68-70f9-4101-86d9-0909430f1d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-25632504-a750-4d9b-9043-841ecdf63003,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-16e8d09f-2ebf-43c2-88e7-d8636a73e717,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-c55f37cd-265c-4b97-8063-01178c27ebf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547530954-172.17.0.12-1598575726439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-7c71f6bb-69b5-4a2f-8b3f-c278acfe3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-1cb2cd0c-abce-4584-a106-ebdd11494180,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-86d114e9-4320-4610-a4d4-8a2c781f1909,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-0dc04ae0-ebcc-475d-8812-2f97e02ccf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-d19bbc0f-f9ba-4bde-9c29-21a895750b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-01b400ae-2b20-4ea7-91f6-2a5daf5a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-77c0b645-b7d2-4b13-930c-c9d9e77a87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-c9f25c5b-e3ab-4964-810a-9a9a59728b6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547530954-172.17.0.12-1598575726439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-7c71f6bb-69b5-4a2f-8b3f-c278acfe3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-1cb2cd0c-abce-4584-a106-ebdd11494180,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-86d114e9-4320-4610-a4d4-8a2c781f1909,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-0dc04ae0-ebcc-475d-8812-2f97e02ccf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-d19bbc0f-f9ba-4bde-9c29-21a895750b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-01b400ae-2b20-4ea7-91f6-2a5daf5a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-77c0b645-b7d2-4b13-930c-c9d9e77a87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-c9f25c5b-e3ab-4964-810a-9a9a59728b6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911913561-172.17.0.12-1598576414742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-59c4a876-dd43-46ee-850a-eee1774648b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-861af052-0f52-41b3-a3ab-a8e35eaeb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-d51ceef1-db82-498d-a1ca-8d61d3a41966,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9cb3f42c-b431-47f3-b647-a22343a13807,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-70b59082-0214-4489-b3ed-0665a57da49d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-ed773022-34e2-48d8-a2c9-4c6f6b47165c,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0af1641c-b606-4b79-a70e-dfa2fa2e03af,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-40b3b6ef-7d9e-4480-9761-208f60920a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911913561-172.17.0.12-1598576414742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-59c4a876-dd43-46ee-850a-eee1774648b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-861af052-0f52-41b3-a3ab-a8e35eaeb9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-d51ceef1-db82-498d-a1ca-8d61d3a41966,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9cb3f42c-b431-47f3-b647-a22343a13807,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-70b59082-0214-4489-b3ed-0665a57da49d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-ed773022-34e2-48d8-a2c9-4c6f6b47165c,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0af1641c-b606-4b79-a70e-dfa2fa2e03af,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-40b3b6ef-7d9e-4480-9761-208f60920a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941141479-172.17.0.12-1598576804294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-ddbc46e3-a853-4801-b7bc-93c0789cddac,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-36d3dadd-8c1c-4c56-ba93-11252eed23cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-6a69a579-8af8-4157-bafe-f1794472b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7d9f7d27-4b0f-4f8a-95b9-95e20c2c92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-3686c4ac-f085-4d78-aad3-fcf5879b9dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-5d72376e-c707-47f9-807d-dbaaa99bf4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d1bce459-1c07-46e6-923d-894dc89de63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-24baf1b7-709b-4483-b59a-a8b6a86158a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941141479-172.17.0.12-1598576804294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-ddbc46e3-a853-4801-b7bc-93c0789cddac,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-36d3dadd-8c1c-4c56-ba93-11252eed23cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-6a69a579-8af8-4157-bafe-f1794472b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7d9f7d27-4b0f-4f8a-95b9-95e20c2c92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-3686c4ac-f085-4d78-aad3-fcf5879b9dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-5d72376e-c707-47f9-807d-dbaaa99bf4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d1bce459-1c07-46e6-923d-894dc89de63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-24baf1b7-709b-4483-b59a-a8b6a86158a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144652606-172.17.0.12-1598576970093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-753cca32-3b3d-47bd-bfc0-56935047c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-52d86892-2992-4a58-996b-0847fdf2ade8,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-f3a984be-4e05-4a2d-85e7-f4e9b0869563,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-cc9584cb-d463-4dcd-96b1-1ec24586521f,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-c567cafd-c61f-4dc4-9d67-6545db5f7dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-dc4f7b53-f965-4812-8e92-2d453b601f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-cf08c1df-80ac-4213-b466-dd2ce972f334,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-f7e36134-b945-4fd9-b256-0f0f77d8264f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144652606-172.17.0.12-1598576970093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-753cca32-3b3d-47bd-bfc0-56935047c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-52d86892-2992-4a58-996b-0847fdf2ade8,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-f3a984be-4e05-4a2d-85e7-f4e9b0869563,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-cc9584cb-d463-4dcd-96b1-1ec24586521f,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-c567cafd-c61f-4dc4-9d67-6545db5f7dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-dc4f7b53-f965-4812-8e92-2d453b601f67,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-cf08c1df-80ac-4213-b466-dd2ce972f334,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-f7e36134-b945-4fd9-b256-0f0f77d8264f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106933676-172.17.0.12-1598577110775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-5bd9bdac-e0a3-4cdd-99a8-c6a1f2fcc641,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-fa12b423-9088-4d46-9f2b-c8e474f195a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-fc7280ad-19c2-425b-90e0-82db3ea95616,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-fcbc71f2-1544-42ef-9ada-1d368da27d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0e2330ba-5265-488c-a1ca-943cbe3ea656,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-73efa5f6-6cd6-430a-9b7a-e5b62bc26cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-057401cd-335f-4731-8684-6021201b2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-e04929a3-0539-4609-94fa-8922dae11296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106933676-172.17.0.12-1598577110775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-5bd9bdac-e0a3-4cdd-99a8-c6a1f2fcc641,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-fa12b423-9088-4d46-9f2b-c8e474f195a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-fc7280ad-19c2-425b-90e0-82db3ea95616,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-fcbc71f2-1544-42ef-9ada-1d368da27d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0e2330ba-5265-488c-a1ca-943cbe3ea656,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-73efa5f6-6cd6-430a-9b7a-e5b62bc26cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-057401cd-335f-4731-8684-6021201b2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-e04929a3-0539-4609-94fa-8922dae11296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687206543-172.17.0.12-1598577146199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-bd60f3f3-041b-4744-bbe8-eaaf74a9f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-4504d294-05ef-4d16-a646-37ea6c1733eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-7e3c34de-c6d1-4435-8eba-b928d890ef09,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-639fd4f7-71ab-46ed-bc85-34703767980d,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-5ea98330-ebb7-4ed0-8ad1-6327d3cffe19,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f79a62bf-855c-43e8-85ba-2c7ced3f6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-4bec9cd2-5745-4692-82c2-07964be41e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-cb9f8e70-05ca-4fea-bd58-102f13e7dcd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687206543-172.17.0.12-1598577146199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-bd60f3f3-041b-4744-bbe8-eaaf74a9f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-4504d294-05ef-4d16-a646-37ea6c1733eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-7e3c34de-c6d1-4435-8eba-b928d890ef09,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-639fd4f7-71ab-46ed-bc85-34703767980d,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-5ea98330-ebb7-4ed0-8ad1-6327d3cffe19,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f79a62bf-855c-43e8-85ba-2c7ced3f6cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-4bec9cd2-5745-4692-82c2-07964be41e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-cb9f8e70-05ca-4fea-bd58-102f13e7dcd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589232748-172.17.0.12-1598577553679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-f376cbfe-30c1-4b22-b336-7eedd5a098ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-616ce9cb-01bc-40e6-9e2c-46d457806264,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-5b8a62ca-c225-4077-8236-dda5d2aded8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-beae00b3-0cca-4c03-bb77-206281fc6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-f6f8bae7-fb18-40f4-94a4-a63a55c9ba08,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-b8bb4bf2-0379-402b-9a6f-282c91b4b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-9d1d4662-0787-4399-90f7-9ca4c481b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-28855a4c-48e5-4445-8843-24b57293f487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589232748-172.17.0.12-1598577553679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-f376cbfe-30c1-4b22-b336-7eedd5a098ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-616ce9cb-01bc-40e6-9e2c-46d457806264,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-5b8a62ca-c225-4077-8236-dda5d2aded8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-beae00b3-0cca-4c03-bb77-206281fc6fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-f6f8bae7-fb18-40f4-94a4-a63a55c9ba08,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-b8bb4bf2-0379-402b-9a6f-282c91b4b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-9d1d4662-0787-4399-90f7-9ca4c481b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-28855a4c-48e5-4445-8843-24b57293f487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290092141-172.17.0.12-1598577863866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-a0d99b96-222a-496f-85b3-b91a53d7e154,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-bd5d619c-272f-4ab5-a8ef-dc28879349f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-b043945d-6e00-48df-b20c-c1cb8d5fd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-df229272-ef81-44da-b455-4a4f41f2b458,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7f8c525e-dbf6-41fa-abaf-23903046cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-750d3e01-0694-4d08-9e35-6d2f7cbb21d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-3ec2528c-f9c7-4b39-ba01-5cf008abb945,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-dd112e2f-f0bd-4df4-8a22-395253f15c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290092141-172.17.0.12-1598577863866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-a0d99b96-222a-496f-85b3-b91a53d7e154,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-bd5d619c-272f-4ab5-a8ef-dc28879349f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-b043945d-6e00-48df-b20c-c1cb8d5fd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-df229272-ef81-44da-b455-4a4f41f2b458,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7f8c525e-dbf6-41fa-abaf-23903046cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-750d3e01-0694-4d08-9e35-6d2f7cbb21d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-3ec2528c-f9c7-4b39-ba01-5cf008abb945,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-dd112e2f-f0bd-4df4-8a22-395253f15c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899727376-172.17.0.12-1598578084292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39480,DS-f0640b0a-0dcb-4d24-aea7-3369857c41a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-58dc712b-ad46-4cc8-a30e-30a065420dec,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-46e45af9-bdbb-4d77-a0f1-031e9af0ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-d98cc247-611c-463e-8cb3-d5db99217115,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-e15b6359-0665-4955-b78b-6a04bffe42ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-ce6526ee-4f9a-4074-a6df-6d5e85db051a,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-1551f898-9997-4ae7-8987-011a10280d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-5d21b07e-2550-4678-8630-1debf5d8a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-899727376-172.17.0.12-1598578084292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39480,DS-f0640b0a-0dcb-4d24-aea7-3369857c41a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-58dc712b-ad46-4cc8-a30e-30a065420dec,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-46e45af9-bdbb-4d77-a0f1-031e9af0ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-d98cc247-611c-463e-8cb3-d5db99217115,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-e15b6359-0665-4955-b78b-6a04bffe42ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-ce6526ee-4f9a-4074-a6df-6d5e85db051a,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-1551f898-9997-4ae7-8987-011a10280d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-5d21b07e-2550-4678-8630-1debf5d8a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5248
