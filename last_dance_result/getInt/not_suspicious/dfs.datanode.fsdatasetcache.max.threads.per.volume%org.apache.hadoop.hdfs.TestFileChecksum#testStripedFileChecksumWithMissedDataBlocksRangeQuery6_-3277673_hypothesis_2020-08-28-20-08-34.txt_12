reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343314092-172.17.0.2-1598645487807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39543,DS-2bfd09e7-c7c6-42c6-b81b-b3a3cdfe499b,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-db696021-a78f-4e41-a4e6-c9662265ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c417da85-4e75-4e13-bb85-31be3820bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-eb3cad43-2571-4adc-81c0-1d6b20f20a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-b3987665-56c8-4d1c-a927-b024901aac02,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-5c3c6b3b-a0d7-43dc-ab6e-6ecfd419bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-d4491af9-78f1-473e-9259-702fb80a5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-cbc22537-2a4e-41fc-a5d1-8cb51102f62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343314092-172.17.0.2-1598645487807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39543,DS-2bfd09e7-c7c6-42c6-b81b-b3a3cdfe499b,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-db696021-a78f-4e41-a4e6-c9662265ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-c417da85-4e75-4e13-bb85-31be3820bbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-eb3cad43-2571-4adc-81c0-1d6b20f20a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-b3987665-56c8-4d1c-a927-b024901aac02,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-5c3c6b3b-a0d7-43dc-ab6e-6ecfd419bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-d4491af9-78f1-473e-9259-702fb80a5c30,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-cbc22537-2a4e-41fc-a5d1-8cb51102f62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694989993-172.17.0.2-1598645623901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-00f22665-f3f8-4632-9a84-64a8e6a5cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-e8121fed-5d79-4143-962f-610ea64b1428,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-63d7c09f-3e5f-4231-9c41-d66bd119b778,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0add6d3c-26bd-4192-b118-0d14a68330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-b658e6cc-64c5-4b61-9b26-abed6823c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0e0afb65-a8ed-4e52-a4ac-2602876b6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-45773d6d-bad7-4680-aad3-f2f6168c4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-762ddf4d-0bd9-404a-86eb-137c79293897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694989993-172.17.0.2-1598645623901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41019,DS-00f22665-f3f8-4632-9a84-64a8e6a5cf65,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-e8121fed-5d79-4143-962f-610ea64b1428,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-63d7c09f-3e5f-4231-9c41-d66bd119b778,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0add6d3c-26bd-4192-b118-0d14a68330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-b658e6cc-64c5-4b61-9b26-abed6823c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-0e0afb65-a8ed-4e52-a4ac-2602876b6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-45773d6d-bad7-4680-aad3-f2f6168c4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-762ddf4d-0bd9-404a-86eb-137c79293897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757067576-172.17.0.2-1598645658372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-d5189320-3a31-49f5-86b6-cdc401da28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-8310f4fe-87ca-4f7d-b877-b390e9be3e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-245674a2-b23c-4280-81f2-6bfb16b38bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-cf849ee3-6ed8-4ed8-ac83-e67a47157dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-c50dbcab-4917-4db2-8ef9-0e498c19194e,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-9e0bb67c-03f8-4bdc-8f87-fe755060cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-0e7c8a8e-d05e-49e8-8469-ec139190b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-fd822b93-10e8-4dd2-9a98-07455e13879a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757067576-172.17.0.2-1598645658372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-d5189320-3a31-49f5-86b6-cdc401da28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-8310f4fe-87ca-4f7d-b877-b390e9be3e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-245674a2-b23c-4280-81f2-6bfb16b38bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-cf849ee3-6ed8-4ed8-ac83-e67a47157dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-c50dbcab-4917-4db2-8ef9-0e498c19194e,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-9e0bb67c-03f8-4bdc-8f87-fe755060cc51,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-0e7c8a8e-d05e-49e8-8469-ec139190b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-fd822b93-10e8-4dd2-9a98-07455e13879a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970262373-172.17.0.2-1598645757433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-ae00f6b4-18e3-450c-9cd9-9d44c65629e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-803530fe-7c2c-4738-8f94-8910fe6ae493,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0b5272af-c484-4e65-862b-4f8b7c58075a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-3896f77d-280f-4161-baa7-d5bfa8fdd3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1daa7732-f248-4f23-827b-556a714df727,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-c5ad6271-957e-4aa9-82df-5cc5871e04ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-972dfeb9-2f90-4b71-8e28-1776e02bea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-1194bc07-c95c-407a-8f9b-bfe60dd3c07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970262373-172.17.0.2-1598645757433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-ae00f6b4-18e3-450c-9cd9-9d44c65629e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-803530fe-7c2c-4738-8f94-8910fe6ae493,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-0b5272af-c484-4e65-862b-4f8b7c58075a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-3896f77d-280f-4161-baa7-d5bfa8fdd3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1daa7732-f248-4f23-827b-556a714df727,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-c5ad6271-957e-4aa9-82df-5cc5871e04ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-972dfeb9-2f90-4b71-8e28-1776e02bea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-1194bc07-c95c-407a-8f9b-bfe60dd3c07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045585993-172.17.0.2-1598646575046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37524,DS-dd362d17-1263-4897-ab0f-5a2335e448b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-cf5d5ece-fdc2-4726-9d19-f9b2a4f9cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-0d5c4cf7-b125-46f1-9a94-f351e88decc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-3f6671d4-4913-4d1f-b8e5-fc4434089734,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-c5004c2b-4d49-45c0-ad17-e184d6963c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-660d6ad3-d0d2-4ca5-8fff-e0325bf91b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-224e5c12-8626-4e91-9572-83c230090838,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-63365385-5dba-4362-9269-be5443185623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045585993-172.17.0.2-1598646575046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37524,DS-dd362d17-1263-4897-ab0f-5a2335e448b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-cf5d5ece-fdc2-4726-9d19-f9b2a4f9cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-0d5c4cf7-b125-46f1-9a94-f351e88decc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-3f6671d4-4913-4d1f-b8e5-fc4434089734,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-c5004c2b-4d49-45c0-ad17-e184d6963c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-660d6ad3-d0d2-4ca5-8fff-e0325bf91b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-224e5c12-8626-4e91-9572-83c230090838,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-63365385-5dba-4362-9269-be5443185623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93540001-172.17.0.2-1598646617953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43209,DS-15b25c7d-00f6-42c4-9c29-c818ca6b92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-1e51547d-4cd7-47d0-9b0a-e54bd1981d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-b56c0d43-c678-4d86-ae6f-6ab67b03de45,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c2ab21e9-26be-4be3-bd67-fc9dccfaf71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-dac9d34f-0209-4155-bded-1f23d6d702ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-bddfc50a-7696-4a10-b47a-fbebdde96ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-92bc1eb9-b589-4592-a261-203c9abd34c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-5ce05b4a-307c-4879-a75c-1633724e5167,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93540001-172.17.0.2-1598646617953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43209,DS-15b25c7d-00f6-42c4-9c29-c818ca6b92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-1e51547d-4cd7-47d0-9b0a-e54bd1981d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-b56c0d43-c678-4d86-ae6f-6ab67b03de45,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-c2ab21e9-26be-4be3-bd67-fc9dccfaf71c,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-dac9d34f-0209-4155-bded-1f23d6d702ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-bddfc50a-7696-4a10-b47a-fbebdde96ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-92bc1eb9-b589-4592-a261-203c9abd34c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-5ce05b4a-307c-4879-a75c-1633724e5167,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774445986-172.17.0.2-1598646697355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-b6929d13-69e9-4ece-a26a-10d8bb9fb178,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-36768c3d-428b-4d81-abf4-5a681ad69918,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-176c4dfe-b672-4706-9538-f0d76ad79dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-a40db112-121e-4fd7-97e2-80fc2093f015,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-1c9f8331-dc1d-488a-8fa7-e20bec3a2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c495b785-4483-46d4-b545-bab78f1194d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-48ed5123-e70a-4c3b-89b9-4c9452f805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-3e190271-c01f-426e-ba72-a392d9e53b3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774445986-172.17.0.2-1598646697355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-b6929d13-69e9-4ece-a26a-10d8bb9fb178,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-36768c3d-428b-4d81-abf4-5a681ad69918,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-176c4dfe-b672-4706-9538-f0d76ad79dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-a40db112-121e-4fd7-97e2-80fc2093f015,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-1c9f8331-dc1d-488a-8fa7-e20bec3a2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c495b785-4483-46d4-b545-bab78f1194d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-48ed5123-e70a-4c3b-89b9-4c9452f805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-3e190271-c01f-426e-ba72-a392d9e53b3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345638409-172.17.0.2-1598646927170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-c473626e-eab4-4780-b89c-0a33e024e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6f696282-e187-411e-b304-7e72511ae74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-d1c833b0-f40f-4536-bc34-b5ada397029b,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-c7ad8a8c-b5ea-45c9-a52c-8b62c8d9674e,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-513c46b3-2953-4be6-9f9d-8d642f854bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-d58117ee-c6cd-44e2-a365-cc301f01db3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-d0f57e23-3ba1-4c91-b051-6d9a64d86292,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-7c1dd40c-c350-42f4-8b48-d0bea008f232,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345638409-172.17.0.2-1598646927170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-c473626e-eab4-4780-b89c-0a33e024e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6f696282-e187-411e-b304-7e72511ae74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-d1c833b0-f40f-4536-bc34-b5ada397029b,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-c7ad8a8c-b5ea-45c9-a52c-8b62c8d9674e,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-513c46b3-2953-4be6-9f9d-8d642f854bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-d58117ee-c6cd-44e2-a365-cc301f01db3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-d0f57e23-3ba1-4c91-b051-6d9a64d86292,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-7c1dd40c-c350-42f4-8b48-d0bea008f232,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142447352-172.17.0.2-1598647034630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-eb932c72-6867-45b0-8f79-d5048c99bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-96bf5c39-c374-445e-97b3-0cd3ebbaa82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-d0c6044b-7f66-4bd3-942c-f09dd04f8486,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-00c8bf10-743b-4da0-991f-f416582e35a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-992e219f-090c-4acb-9b62-de4c7d9a6018,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-7ba48af3-a6fb-4e7c-a3c6-9ba03c57ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-6bcd8963-54c9-47b8-9c44-d5d7324c12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-75a41412-a1fc-48c3-8251-c851220fe421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142447352-172.17.0.2-1598647034630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-eb932c72-6867-45b0-8f79-d5048c99bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-96bf5c39-c374-445e-97b3-0cd3ebbaa82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-d0c6044b-7f66-4bd3-942c-f09dd04f8486,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-00c8bf10-743b-4da0-991f-f416582e35a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-992e219f-090c-4acb-9b62-de4c7d9a6018,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-7ba48af3-a6fb-4e7c-a3c6-9ba03c57ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-6bcd8963-54c9-47b8-9c44-d5d7324c12ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-75a41412-a1fc-48c3-8251-c851220fe421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097962309-172.17.0.2-1598647181161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-03f5c685-2299-4107-8c92-3a2b745c0147,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-73ca8809-8b51-4e85-b614-9672731b68c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1365221f-2165-4e79-b9ba-da2c4ac9ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-6f3f1f87-1b83-4b2c-9061-23368dc1c227,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-dc9b0290-8cb0-4034-83fe-8c611c9a73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-7963c083-650a-4e7c-b690-840d05e738a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-240a1eb1-c810-4256-ab1d-4da2528db05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-c2faf36a-9542-41b9-a854-0361cffd101d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097962309-172.17.0.2-1598647181161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-03f5c685-2299-4107-8c92-3a2b745c0147,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-73ca8809-8b51-4e85-b614-9672731b68c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1365221f-2165-4e79-b9ba-da2c4ac9ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-6f3f1f87-1b83-4b2c-9061-23368dc1c227,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-dc9b0290-8cb0-4034-83fe-8c611c9a73aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-7963c083-650a-4e7c-b690-840d05e738a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-240a1eb1-c810-4256-ab1d-4da2528db05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-c2faf36a-9542-41b9-a854-0361cffd101d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240598098-172.17.0.2-1598647211425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-656edd62-33dd-4119-ac61-d181f2f6eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-2923a007-f66a-4b7a-835a-483878e9c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-fbd240b6-67eb-40f8-aac3-7d4a39e92c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-213f1767-9fff-400f-8787-694a0bbc0c05,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-fe5802ba-ba49-4db4-b2a1-f54d76708477,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-62a802f9-8d75-4292-8603-e495dcd3a8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8b9680c0-58ae-4d51-971d-bfd6c4c58408,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-bdad9a6d-1b9f-4a43-9f03-e8c57dfc67a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240598098-172.17.0.2-1598647211425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-656edd62-33dd-4119-ac61-d181f2f6eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-2923a007-f66a-4b7a-835a-483878e9c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-fbd240b6-67eb-40f8-aac3-7d4a39e92c41,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-213f1767-9fff-400f-8787-694a0bbc0c05,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-fe5802ba-ba49-4db4-b2a1-f54d76708477,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-62a802f9-8d75-4292-8603-e495dcd3a8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8b9680c0-58ae-4d51-971d-bfd6c4c58408,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-bdad9a6d-1b9f-4a43-9f03-e8c57dfc67a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266132366-172.17.0.2-1598647782832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-bf2331c7-ca98-4efb-bcf0-4897416d439e,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-231641c7-8526-48e3-8e4b-b3089ff93269,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-87dc8e84-aaaf-424b-b980-3cd83ec52169,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-715d1f8f-1a47-4078-baeb-fa7a9d54d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-c0ac1532-cd2c-4668-ac67-bbcccf7c968d,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-96cde901-3ccd-41bb-b29f-c29528b0b4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-cac5b2cb-5270-426d-baa7-a91f01ca6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-452bf2ad-b3bf-43df-a28c-0102c0a7d20a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266132366-172.17.0.2-1598647782832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-bf2331c7-ca98-4efb-bcf0-4897416d439e,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-231641c7-8526-48e3-8e4b-b3089ff93269,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-87dc8e84-aaaf-424b-b980-3cd83ec52169,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-715d1f8f-1a47-4078-baeb-fa7a9d54d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-c0ac1532-cd2c-4668-ac67-bbcccf7c968d,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-96cde901-3ccd-41bb-b29f-c29528b0b4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-cac5b2cb-5270-426d-baa7-a91f01ca6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-452bf2ad-b3bf-43df-a28c-0102c0a7d20a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391222832-172.17.0.2-1598648095469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-76d32f23-fcab-4072-95ce-43bcae146780,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-f6007e7e-2003-42e3-93b8-5558a934cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-2806b693-d362-4789-9fe5-8bc6802fc809,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-4c8c0388-5c79-41c6-ae6d-5aea75025325,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-be9ffa86-f3ec-4408-bf1c-986579058993,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-f80fb180-7730-40c2-aee3-dd9dac63619c,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1de30816-793f-47c7-9284-f4e16f738c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-dfb71e6b-824d-4b0e-898c-418fc4229e94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391222832-172.17.0.2-1598648095469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-76d32f23-fcab-4072-95ce-43bcae146780,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-f6007e7e-2003-42e3-93b8-5558a934cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-2806b693-d362-4789-9fe5-8bc6802fc809,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-4c8c0388-5c79-41c6-ae6d-5aea75025325,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-be9ffa86-f3ec-4408-bf1c-986579058993,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-f80fb180-7730-40c2-aee3-dd9dac63619c,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1de30816-793f-47c7-9284-f4e16f738c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-dfb71e6b-824d-4b0e-898c-418fc4229e94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95915386-172.17.0.2-1598648161490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-0dc6b972-546f-4a5f-8699-75c5679e4415,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-05e8fe05-b16f-4ec2-8c68-9030f1452105,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-52d09b01-d557-49e4-a019-9859491aefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-0e9f5271-a5f7-4c4a-8a23-af420e2b7479,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-4f29fe08-3c8d-4e76-bc32-a8cd8c54d981,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-40d028f4-cfa7-43ff-a3ae-cb437029b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-26288b05-a650-4bbe-9b5c-c4d06aa9b275,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-617ad8e0-297a-440c-93a8-40c5b85920ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95915386-172.17.0.2-1598648161490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-0dc6b972-546f-4a5f-8699-75c5679e4415,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-05e8fe05-b16f-4ec2-8c68-9030f1452105,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-52d09b01-d557-49e4-a019-9859491aefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-0e9f5271-a5f7-4c4a-8a23-af420e2b7479,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-4f29fe08-3c8d-4e76-bc32-a8cd8c54d981,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-40d028f4-cfa7-43ff-a3ae-cb437029b11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-26288b05-a650-4bbe-9b5c-c4d06aa9b275,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-617ad8e0-297a-440c-93a8-40c5b85920ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567304155-172.17.0.2-1598648302495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-f0cea537-df2f-474e-b044-e6a7132ed1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-38f6cc88-a8f8-4345-8066-57ebfc6a9142,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-34458a7c-b415-4f50-9e38-ff07db7028d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-dd890122-3162-49c8-8b74-8b01af591170,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-0505def1-0500-4497-b214-0be4599b4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-35cc6f9d-2379-45e3-9e82-f1f4f82aafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1aaa3fc4-7d6f-407e-b40e-3b2d4bfea738,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-2c11a85c-5259-41e1-a917-9782ff05081c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567304155-172.17.0.2-1598648302495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-f0cea537-df2f-474e-b044-e6a7132ed1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-38f6cc88-a8f8-4345-8066-57ebfc6a9142,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-34458a7c-b415-4f50-9e38-ff07db7028d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-dd890122-3162-49c8-8b74-8b01af591170,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-0505def1-0500-4497-b214-0be4599b4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-35cc6f9d-2379-45e3-9e82-f1f4f82aafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1aaa3fc4-7d6f-407e-b40e-3b2d4bfea738,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-2c11a85c-5259-41e1-a917-9782ff05081c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109020258-172.17.0.2-1598648338342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43177,DS-6debf666-e44d-4b23-826c-601791003547,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-80324e94-0ce1-4370-b006-a95ef8b83827,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-8296e4bc-97d2-421c-9d64-0fc3f9c44202,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-02f927a8-de24-4be9-8d4b-d4424bd606fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-034103ef-a89b-4a53-8ad3-7b59eb5a1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-23021460-3bdb-4c06-9c90-f17d3000567d,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-5ef5b90c-53ba-4716-8a71-826f943bd077,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-c4e56560-d3b0-432e-95dd-ef633dd48491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109020258-172.17.0.2-1598648338342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43177,DS-6debf666-e44d-4b23-826c-601791003547,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-80324e94-0ce1-4370-b006-a95ef8b83827,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-8296e4bc-97d2-421c-9d64-0fc3f9c44202,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-02f927a8-de24-4be9-8d4b-d4424bd606fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-034103ef-a89b-4a53-8ad3-7b59eb5a1f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-23021460-3bdb-4c06-9c90-f17d3000567d,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-5ef5b90c-53ba-4716-8a71-826f943bd077,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-c4e56560-d3b0-432e-95dd-ef633dd48491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778881793-172.17.0.2-1598648422171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-62a425f9-585a-4234-bd65-0fb7c95b329d,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-da45eaf9-6369-4484-b9f0-ecb529324438,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-8c883a98-7b2a-4c18-b579-4b861b0550c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-4961b97b-6135-4b43-9838-34b98f601d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ebb5fecd-28e6-466c-b9a7-2b4e672bd3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-b8bcd341-d86a-4b07-b0fe-a28debac5810,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-5c6d6650-7570-45f7-aeec-22875485ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-bb3c0370-2e89-4073-ae53-6d3f13234a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778881793-172.17.0.2-1598648422171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-62a425f9-585a-4234-bd65-0fb7c95b329d,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-da45eaf9-6369-4484-b9f0-ecb529324438,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-8c883a98-7b2a-4c18-b579-4b861b0550c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-4961b97b-6135-4b43-9838-34b98f601d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-ebb5fecd-28e6-466c-b9a7-2b4e672bd3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-b8bcd341-d86a-4b07-b0fe-a28debac5810,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-5c6d6650-7570-45f7-aeec-22875485ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-bb3c0370-2e89-4073-ae53-6d3f13234a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435983633-172.17.0.2-1598648732314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43897,DS-aa66598e-7487-47a3-b7ae-5edd9012e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-8e250957-1f49-4b34-bcaa-32f88353d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-a0f53877-a05d-46f8-ac4a-1f32556ca06f,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-e3ec7723-0155-417e-84fd-99bc07296e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-45d5b285-aaeb-4b88-8b1c-dffa333c2146,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-f2840513-f8a0-405b-a95d-be066238270b,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-45d218f3-9bbe-49ac-be5d-b227ff983d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-2b063102-eacd-46a3-9d80-331159e7f42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435983633-172.17.0.2-1598648732314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43897,DS-aa66598e-7487-47a3-b7ae-5edd9012e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-8e250957-1f49-4b34-bcaa-32f88353d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-a0f53877-a05d-46f8-ac4a-1f32556ca06f,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-e3ec7723-0155-417e-84fd-99bc07296e37,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-45d5b285-aaeb-4b88-8b1c-dffa333c2146,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-f2840513-f8a0-405b-a95d-be066238270b,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-45d218f3-9bbe-49ac-be5d-b227ff983d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-2b063102-eacd-46a3-9d80-331159e7f42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819541353-172.17.0.2-1598648803547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-9745190e-7d0b-41e1-bc72-4f4802ddb120,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-8213a87c-b271-48ed-839f-277ec0369a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-598bc770-4c2e-4660-8f29-b7d6eca89bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-5ddf6e75-fc07-4c28-81c6-f703eebbd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-717dc9ce-2031-4886-8071-dd1f45e783bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-842e3a56-d809-4466-9eaa-dd78260645b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-25944501-6c84-4ccb-aa12-2b27b847b034,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c0655f0d-ece3-4c90-8440-981ea92266c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819541353-172.17.0.2-1598648803547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-9745190e-7d0b-41e1-bc72-4f4802ddb120,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-8213a87c-b271-48ed-839f-277ec0369a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-598bc770-4c2e-4660-8f29-b7d6eca89bff,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-5ddf6e75-fc07-4c28-81c6-f703eebbd1de,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-717dc9ce-2031-4886-8071-dd1f45e783bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-842e3a56-d809-4466-9eaa-dd78260645b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-25944501-6c84-4ccb-aa12-2b27b847b034,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c0655f0d-ece3-4c90-8440-981ea92266c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182496520-172.17.0.2-1598649075816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f94de9ec-d963-4926-999b-3c1668f1e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-f63d12bf-3551-484e-ad6c-572a3771ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0b4b146e-c2e7-43ae-b418-ec960eba1017,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-560a29a4-1722-445e-bb2b-5696e1410abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-f6cbc9df-9442-4b23-912e-edc0ba197db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-b2eca44f-6962-461c-adf6-fc1717671609,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-5fea00a7-4d37-4389-8c8d-f740cdbdb07b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-2f241ac7-755f-4d0a-8bc4-424e69de8bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182496520-172.17.0.2-1598649075816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f94de9ec-d963-4926-999b-3c1668f1e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-f63d12bf-3551-484e-ad6c-572a3771ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0b4b146e-c2e7-43ae-b418-ec960eba1017,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-560a29a4-1722-445e-bb2b-5696e1410abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-f6cbc9df-9442-4b23-912e-edc0ba197db8,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-b2eca44f-6962-461c-adf6-fc1717671609,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-5fea00a7-4d37-4389-8c8d-f740cdbdb07b,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-2f241ac7-755f-4d0a-8bc4-424e69de8bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977038927-172.17.0.2-1598649112325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-c6c9d32a-69ad-48fe-8392-6530b9efce27,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-51e4a978-3e04-491e-b4fb-d1a2f8d6855d,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-50fe9ee9-d649-42b3-b8c3-8d9c3f82ccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-68bbbf20-95c3-41d9-a9f7-19cd282c1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-c41c4a06-51e2-4cbe-a186-e5113303990b,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-048a1eef-7bd5-4995-b797-3d5c4286cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-ff334fd6-a6c2-4e77-97cc-6dd28dd2ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-dd3ddb13-034e-4c27-9197-b388353f8c31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977038927-172.17.0.2-1598649112325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-c6c9d32a-69ad-48fe-8392-6530b9efce27,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-51e4a978-3e04-491e-b4fb-d1a2f8d6855d,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-50fe9ee9-d649-42b3-b8c3-8d9c3f82ccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-68bbbf20-95c3-41d9-a9f7-19cd282c1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-c41c4a06-51e2-4cbe-a186-e5113303990b,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-048a1eef-7bd5-4995-b797-3d5c4286cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-ff334fd6-a6c2-4e77-97cc-6dd28dd2ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-dd3ddb13-034e-4c27-9197-b388353f8c31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712158845-172.17.0.2-1598649352482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-d7c16114-70ff-43d0-93e1-b919403866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-6f46f1ee-fecd-48fc-a17d-2a5f369bb1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-4b4f0e8c-b5d4-472e-9213-016fdd19ae36,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-891062be-2059-425e-aa13-d69a251ba57e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-3750a5d5-c21c-4367-88e8-e9aba8e8ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-d18c4866-99ac-4452-bfd9-4f8714e38900,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f124c14a-592f-49ae-bd5e-5d3300540a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-3d66d9fe-b789-4275-99a6-7e05694a95b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712158845-172.17.0.2-1598649352482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39316,DS-d7c16114-70ff-43d0-93e1-b919403866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-6f46f1ee-fecd-48fc-a17d-2a5f369bb1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-4b4f0e8c-b5d4-472e-9213-016fdd19ae36,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-891062be-2059-425e-aa13-d69a251ba57e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-3750a5d5-c21c-4367-88e8-e9aba8e8ba2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-d18c4866-99ac-4452-bfd9-4f8714e38900,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f124c14a-592f-49ae-bd5e-5d3300540a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-3d66d9fe-b789-4275-99a6-7e05694a95b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118614467-172.17.0.2-1598649422396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41914,DS-2034deca-b05e-4f02-a1ba-58372228ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-08803b18-088b-4dd0-83b4-2c44dcf6ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-b27850d3-d0dc-44b2-a8e0-eda4c907d933,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-d933d387-0fd3-4efd-9597-703fd319eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-829b292a-45d4-4002-9835-849d2eda720e,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-955497b4-9129-4079-b116-d843a2c24610,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-ccf85269-9826-485f-a073-0094c0f4d429,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d4e46600-ebd0-4b00-88be-5f887a07f488,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118614467-172.17.0.2-1598649422396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41914,DS-2034deca-b05e-4f02-a1ba-58372228ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-08803b18-088b-4dd0-83b4-2c44dcf6ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-b27850d3-d0dc-44b2-a8e0-eda4c907d933,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-d933d387-0fd3-4efd-9597-703fd319eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-829b292a-45d4-4002-9835-849d2eda720e,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-955497b4-9129-4079-b116-d843a2c24610,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-ccf85269-9826-485f-a073-0094c0f4d429,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d4e46600-ebd0-4b00-88be-5f887a07f488,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260813168-172.17.0.2-1598649502407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-c1771c2e-0f15-4212-91d4-bccd09c6f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-654c3ac5-fece-4dc9-9244-b23e3d29ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7b77664c-12d2-4c05-853c-b228a05dc662,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-3588111b-ce48-47e2-ae15-439141d7907e,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-4807625e-c679-456b-bae9-b0004d7106aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-a981d979-4341-4ea3-af44-06f7a557979b,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-0f2720b6-3f74-4f22-8acb-286d1cd5e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-ae8f5815-83bb-448b-ade5-7364a2b6b78e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260813168-172.17.0.2-1598649502407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-c1771c2e-0f15-4212-91d4-bccd09c6f9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-654c3ac5-fece-4dc9-9244-b23e3d29ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7b77664c-12d2-4c05-853c-b228a05dc662,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-3588111b-ce48-47e2-ae15-439141d7907e,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-4807625e-c679-456b-bae9-b0004d7106aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-a981d979-4341-4ea3-af44-06f7a557979b,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-0f2720b6-3f74-4f22-8acb-286d1cd5e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-ae8f5815-83bb-448b-ade5-7364a2b6b78e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629402865-172.17.0.2-1598649535264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-6252beea-b252-4ed5-a2df-5cc168a61bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-50a0e832-1bcd-4fcf-b3ac-3012e7fb8232,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-02e9c41a-9c45-4f16-93f6-83f77e139f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c9beec45-a602-447a-9190-03b4925186a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-dcdea07a-556a-42d0-88c1-6feceb1685cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-a7bd23e3-42cb-412c-9fff-8f4829994def,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-57edad9b-a09e-40b6-8205-fabefad2092c,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-020adb69-5062-4430-b905-ccd086e50f19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629402865-172.17.0.2-1598649535264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-6252beea-b252-4ed5-a2df-5cc168a61bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-50a0e832-1bcd-4fcf-b3ac-3012e7fb8232,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-02e9c41a-9c45-4f16-93f6-83f77e139f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-c9beec45-a602-447a-9190-03b4925186a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-dcdea07a-556a-42d0-88c1-6feceb1685cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-a7bd23e3-42cb-412c-9fff-8f4829994def,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-57edad9b-a09e-40b6-8205-fabefad2092c,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-020adb69-5062-4430-b905-ccd086e50f19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896598140-172.17.0.2-1598649596952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-36f99de1-dfff-4db0-b914-f9a50d0e1bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-b12f3376-501e-44b0-b43d-a5087fc059f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-1d6d2a10-f7b9-4e98-af03-e3371d114275,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-bc946184-eb68-4694-8f0a-39737261a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-c2a8254f-f783-47a0-9b80-cb5cc583a177,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-646de510-72de-464a-8938-4f22bf3ed2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-2824ebd1-909e-4664-ae40-858b1d5bdeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-3e0438f1-80c6-405f-94c5-28fac07f8a51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896598140-172.17.0.2-1598649596952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-36f99de1-dfff-4db0-b914-f9a50d0e1bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-b12f3376-501e-44b0-b43d-a5087fc059f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-1d6d2a10-f7b9-4e98-af03-e3371d114275,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-bc946184-eb68-4694-8f0a-39737261a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-c2a8254f-f783-47a0-9b80-cb5cc583a177,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-646de510-72de-464a-8938-4f22bf3ed2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-2824ebd1-909e-4664-ae40-858b1d5bdeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-3e0438f1-80c6-405f-94c5-28fac07f8a51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500060540-172.17.0.2-1598649808349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-a6489d5f-0156-4c44-98d7-f38b1febe4da,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-d479b6ec-aa16-4945-a19a-a007ec7833c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-64876b3e-58d8-46b7-8865-32f0aa446452,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-5172ce6a-8415-4864-97bf-015ffbac6637,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-d8cc0ed1-5b8c-4903-8fdc-638a1e45fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-8956dfb0-f4d9-4ce9-8ce4-e668e3abb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-70edef01-f253-4bd2-8d7e-3ea005748654,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-59e7cf64-b462-4d8e-9945-9a558bc06954,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500060540-172.17.0.2-1598649808349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-a6489d5f-0156-4c44-98d7-f38b1febe4da,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-d479b6ec-aa16-4945-a19a-a007ec7833c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-64876b3e-58d8-46b7-8865-32f0aa446452,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-5172ce6a-8415-4864-97bf-015ffbac6637,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-d8cc0ed1-5b8c-4903-8fdc-638a1e45fc53,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-8956dfb0-f4d9-4ce9-8ce4-e668e3abb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-70edef01-f253-4bd2-8d7e-3ea005748654,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-59e7cf64-b462-4d8e-9945-9a558bc06954,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626955687-172.17.0.2-1598649981720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-3481a216-e1cd-4e9a-953d-3519bc71519f,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-a57233d3-2b77-41ec-9617-704594644d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-a57bb17b-242b-4ae5-8f27-feace66af6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-4ae25ce4-3e15-41b6-b446-1ce59c3facfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-355c4110-d60c-45b6-8610-c1ead75e05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-f7a264d1-0832-4d9d-8f89-0fc2741fa1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-7756398b-1e34-42bb-997b-0497f178f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-818bcf87-ecd8-4726-ab15-edc30ef3d292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626955687-172.17.0.2-1598649981720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46243,DS-3481a216-e1cd-4e9a-953d-3519bc71519f,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-a57233d3-2b77-41ec-9617-704594644d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-a57bb17b-242b-4ae5-8f27-feace66af6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-4ae25ce4-3e15-41b6-b446-1ce59c3facfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-355c4110-d60c-45b6-8610-c1ead75e05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-f7a264d1-0832-4d9d-8f89-0fc2741fa1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-7756398b-1e34-42bb-997b-0497f178f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-818bcf87-ecd8-4726-ab15-edc30ef3d292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 5
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302290679-172.17.0.2-1598650041698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-8ebd184a-c723-4c3d-b1c0-5c16cc1cd724,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-c53e6d9f-1cf3-4b26-a2f6-d83fcbe584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1fc7c300-8726-4218-9154-5419159898cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-ff48d3b9-5d20-4d6d-9f26-fe859d3238fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-075e9dd2-5368-4a10-8794-61ca64562fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-6b9a1f26-df56-4658-806c-156d30bd8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-7282642d-c142-47b2-a584-44b43445f4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-5b469472-dc77-4056-97db-eff117262008,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302290679-172.17.0.2-1598650041698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-8ebd184a-c723-4c3d-b1c0-5c16cc1cd724,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-c53e6d9f-1cf3-4b26-a2f6-d83fcbe584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1fc7c300-8726-4218-9154-5419159898cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-ff48d3b9-5d20-4d6d-9f26-fe859d3238fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-075e9dd2-5368-4a10-8794-61ca64562fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-6b9a1f26-df56-4658-806c-156d30bd8e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-7282642d-c142-47b2-a584-44b43445f4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-5b469472-dc77-4056-97db-eff117262008,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5180
