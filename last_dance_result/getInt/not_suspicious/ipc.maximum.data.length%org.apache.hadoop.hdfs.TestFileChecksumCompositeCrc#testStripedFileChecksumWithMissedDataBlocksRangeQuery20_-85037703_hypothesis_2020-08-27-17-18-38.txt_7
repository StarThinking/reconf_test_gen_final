reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119944388-172.17.0.13-1598548728413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-e98095b5-272c-4a48-afb2-b2d3f370f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-e752389e-26f4-4fa2-ac02-86ea07fa0870,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-3e74b321-d09a-463d-9558-9fda34c18826,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-dd2fca2b-113a-440d-a7b9-ba2d29baa783,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-61a68bde-4381-47b5-a8c5-7afc57217dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-7c7446b7-8c7e-49bb-ac49-49322372f6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-42c3efc5-90d8-4ec3-8a99-6e19ca6a2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-746a861d-1f04-4472-b400-b47d0f41ec9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119944388-172.17.0.13-1598548728413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-e98095b5-272c-4a48-afb2-b2d3f370f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-e752389e-26f4-4fa2-ac02-86ea07fa0870,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-3e74b321-d09a-463d-9558-9fda34c18826,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-dd2fca2b-113a-440d-a7b9-ba2d29baa783,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-61a68bde-4381-47b5-a8c5-7afc57217dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-7c7446b7-8c7e-49bb-ac49-49322372f6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-42c3efc5-90d8-4ec3-8a99-6e19ca6a2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-746a861d-1f04-4472-b400-b47d0f41ec9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142164427-172.17.0.13-1598548845336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-5406785e-8a1c-42fe-a9d6-2063d5d3259d,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-0ba03243-6a07-48e5-9c50-4b4c8e42ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c1b57dc5-be31-4e62-878e-143803afea59,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-39306f28-bb55-4545-a42d-8bbd88e84d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-9283a268-fda1-43ac-b94d-7385de88c598,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-b548f3a9-b188-46d7-ad45-8389cc185473,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-ffe95c06-9e3f-479d-9452-1f843a119e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-0982b80c-cd39-4117-a44f-4d03f3bd0555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142164427-172.17.0.13-1598548845336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39813,DS-5406785e-8a1c-42fe-a9d6-2063d5d3259d,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-0ba03243-6a07-48e5-9c50-4b4c8e42ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c1b57dc5-be31-4e62-878e-143803afea59,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-39306f28-bb55-4545-a42d-8bbd88e84d32,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-9283a268-fda1-43ac-b94d-7385de88c598,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-b548f3a9-b188-46d7-ad45-8389cc185473,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-ffe95c06-9e3f-479d-9452-1f843a119e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-0982b80c-cd39-4117-a44f-4d03f3bd0555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945919855-172.17.0.13-1598549029349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-dbd5bda9-d216-445e-aa6e-6366ab4b93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-fdd464a7-9aba-49cc-851e-81351c0a46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-833d6b61-04c0-4ada-be59-fb5a6ed0abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-61339d3b-e3be-4833-ac8f-0ffc6a401cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-89ca587a-7e8c-4694-a4c9-b98a9036f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-232c8dd8-02ad-48ca-bfd9-4e24ddd5af72,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ec455513-3ca8-41cb-9896-9337429688ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-38b35a73-38a5-4d23-afc9-2df36e8a16b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945919855-172.17.0.13-1598549029349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-dbd5bda9-d216-445e-aa6e-6366ab4b93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-fdd464a7-9aba-49cc-851e-81351c0a46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-833d6b61-04c0-4ada-be59-fb5a6ed0abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-61339d3b-e3be-4833-ac8f-0ffc6a401cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-89ca587a-7e8c-4694-a4c9-b98a9036f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-232c8dd8-02ad-48ca-bfd9-4e24ddd5af72,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ec455513-3ca8-41cb-9896-9337429688ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-38b35a73-38a5-4d23-afc9-2df36e8a16b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418979149-172.17.0.13-1598549273496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-5fc0d98e-2726-4bf3-953f-16b5633d0825,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-4ac37486-36f5-4442-909b-f33e098f1960,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2bcf21d6-5c41-4e8e-9b70-1ecc1e982727,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-8d7880bc-13bb-4a88-8313-f21825d76315,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-67e363bb-090a-45ff-9047-da284a75c38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-1de4c2b1-5088-48d0-9b2f-349bf6c0f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-9684b70f-741a-4199-8806-49079548690d,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-dc7b0207-3e7c-4398-9b3f-ac063266bf26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418979149-172.17.0.13-1598549273496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-5fc0d98e-2726-4bf3-953f-16b5633d0825,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-4ac37486-36f5-4442-909b-f33e098f1960,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2bcf21d6-5c41-4e8e-9b70-1ecc1e982727,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-8d7880bc-13bb-4a88-8313-f21825d76315,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-67e363bb-090a-45ff-9047-da284a75c38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-1de4c2b1-5088-48d0-9b2f-349bf6c0f5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-9684b70f-741a-4199-8806-49079548690d,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-dc7b0207-3e7c-4398-9b3f-ac063266bf26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874319476-172.17.0.13-1598549701667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40659,DS-0ee7baca-770f-4089-b41b-59bd3d20cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-191c4932-55f5-4743-b3b3-fac62d780877,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-07c8d017-9879-4165-9e60-22029487b263,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-17541dc4-ab3d-4940-a40b-e5ac2ffb7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-0795871c-30d9-44da-b624-353a1e35b164,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-49ecdbd9-cbc5-49f8-b32b-a16c6d352882,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-898328ee-babf-43e4-a9ac-3b55a79973b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-2df8a7c9-4242-4ad1-9636-d3ec385c3c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874319476-172.17.0.13-1598549701667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40659,DS-0ee7baca-770f-4089-b41b-59bd3d20cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-191c4932-55f5-4743-b3b3-fac62d780877,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-07c8d017-9879-4165-9e60-22029487b263,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-17541dc4-ab3d-4940-a40b-e5ac2ffb7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-0795871c-30d9-44da-b624-353a1e35b164,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-49ecdbd9-cbc5-49f8-b32b-a16c6d352882,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-898328ee-babf-43e4-a9ac-3b55a79973b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-2df8a7c9-4242-4ad1-9636-d3ec385c3c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452378123-172.17.0.13-1598549878283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-7452090f-47e0-4df3-8a2e-315543bfcded,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-8f73b417-42d8-430d-932a-5162d2f693f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-3964088e-7db7-4271-9e80-47ec7b0189b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-b988f81f-ad7c-47cd-a3e4-f4b480a5df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c969e7c1-ab38-40dd-ae83-3353c23d0523,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4bf998c0-139f-4f09-ab88-5c1eb7020655,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-101988d5-d42f-4e82-8511-ba57b4b732f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-5fb1232a-6f96-4590-b990-08c14fbea6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452378123-172.17.0.13-1598549878283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-7452090f-47e0-4df3-8a2e-315543bfcded,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-8f73b417-42d8-430d-932a-5162d2f693f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-3964088e-7db7-4271-9e80-47ec7b0189b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-b988f81f-ad7c-47cd-a3e4-f4b480a5df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c969e7c1-ab38-40dd-ae83-3353c23d0523,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-4bf998c0-139f-4f09-ab88-5c1eb7020655,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-101988d5-d42f-4e82-8511-ba57b4b732f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-5fb1232a-6f96-4590-b990-08c14fbea6ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862938183-172.17.0.13-1598550638275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-f02b03f5-7b1c-4951-8bdb-b5fd0d66685b,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-663b1565-3c3f-4226-8d2b-e6c18c864e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-db82ed7e-b7d9-4cbf-a391-1d643f996740,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-fb4c2dfb-8908-4c8c-a5fb-d296805a0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-7d80b1c9-4fc0-439f-877d-61d84726fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-94b4d89b-dc7d-496e-8451-bbe5dd5a09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-b84fd49e-2908-466e-8aa0-32aa9fe5ff72,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5e6a67ac-98d0-47df-a281-43763c66b179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862938183-172.17.0.13-1598550638275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-f02b03f5-7b1c-4951-8bdb-b5fd0d66685b,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-663b1565-3c3f-4226-8d2b-e6c18c864e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-db82ed7e-b7d9-4cbf-a391-1d643f996740,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-fb4c2dfb-8908-4c8c-a5fb-d296805a0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-7d80b1c9-4fc0-439f-877d-61d84726fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-94b4d89b-dc7d-496e-8451-bbe5dd5a09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-b84fd49e-2908-466e-8aa0-32aa9fe5ff72,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5e6a67ac-98d0-47df-a281-43763c66b179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802253388-172.17.0.13-1598551091967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-66143f9b-43d8-4776-b5a0-23b1181d1100,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-234584d8-5849-4dc5-82c7-0b1dbb71df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-fe0ccb4d-04ef-4180-8fe9-5de83bbb5c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-dbfbbfe8-90ff-46ca-ae9b-02f4e907d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5f7bf6b-a0cc-41f2-9557-fa23973a4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-7fbfb780-5671-4227-b548-24cf80c4ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-e4fb302a-c7e4-46c6-86a2-44b92ff99035,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-97118622-f708-4f3d-9ec5-315b496c6cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802253388-172.17.0.13-1598551091967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-66143f9b-43d8-4776-b5a0-23b1181d1100,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-234584d8-5849-4dc5-82c7-0b1dbb71df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-fe0ccb4d-04ef-4180-8fe9-5de83bbb5c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-dbfbbfe8-90ff-46ca-ae9b-02f4e907d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c5f7bf6b-a0cc-41f2-9557-fa23973a4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-7fbfb780-5671-4227-b548-24cf80c4ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-e4fb302a-c7e4-46c6-86a2-44b92ff99035,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-97118622-f708-4f3d-9ec5-315b496c6cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110871774-172.17.0.13-1598551706563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33974,DS-9a8d5d1e-20c0-46d4-8b11-5478564d16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-6747732c-d6c1-42e2-849d-0dbad86bbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-1e7d771f-bfe1-4a88-b57c-03140a2b8068,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-d80bf061-f464-44a8-a7c6-0de25ec50e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-393e6a5e-dd7a-498e-a7c1-ed8d65652493,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-e41382cd-1b64-492b-a2a9-fd71ff3bb8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b7ec33f2-9119-48de-a400-423de54e5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-cd3adad2-2c4b-4233-b516-f8d1f7a15e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110871774-172.17.0.13-1598551706563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33974,DS-9a8d5d1e-20c0-46d4-8b11-5478564d16d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-6747732c-d6c1-42e2-849d-0dbad86bbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-1e7d771f-bfe1-4a88-b57c-03140a2b8068,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-d80bf061-f464-44a8-a7c6-0de25ec50e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-393e6a5e-dd7a-498e-a7c1-ed8d65652493,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-e41382cd-1b64-492b-a2a9-fd71ff3bb8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b7ec33f2-9119-48de-a400-423de54e5fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-cd3adad2-2c4b-4233-b516-f8d1f7a15e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020729698-172.17.0.13-1598551740186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-e67cec22-2f99-446c-b094-63e2896065e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-329fffc5-6f5d-496d-b410-7cd1d9559af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-00161c47-192f-46de-9b34-7920e53ea97b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-b12cd1b2-c731-4e31-9727-1673fa557184,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-23f6b402-3fbf-4757-b625-254ddb8f7df8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-cf6b48c3-6fd9-46b4-9941-5be68d42f736,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-c0310899-c48c-4fb4-b5ed-d025f59dfc05,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-c975b07e-5234-49e8-b143-dd638c2794f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020729698-172.17.0.13-1598551740186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45038,DS-e67cec22-2f99-446c-b094-63e2896065e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-329fffc5-6f5d-496d-b410-7cd1d9559af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-00161c47-192f-46de-9b34-7920e53ea97b,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-b12cd1b2-c731-4e31-9727-1673fa557184,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-23f6b402-3fbf-4757-b625-254ddb8f7df8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-cf6b48c3-6fd9-46b4-9941-5be68d42f736,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-c0310899-c48c-4fb4-b5ed-d025f59dfc05,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-c975b07e-5234-49e8-b143-dd638c2794f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709442442-172.17.0.13-1598551811218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-68a65004-1438-4806-832f-0c6979c48360,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-536ab4d5-3833-4045-8d8d-644b2b5d4667,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-01bde5e2-2680-4a4d-b833-9945ce6eb390,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-753a4984-81a0-414c-a7f4-704c53312fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-7e89b22d-3581-4895-a503-df88e5d28273,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-f4727d6d-7943-4c0c-9111-12b1e3356355,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d4b20d6a-4661-4a3e-a14d-9b82b2b687da,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-f25c5cd9-3682-4971-963c-1050fb2a102f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709442442-172.17.0.13-1598551811218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-68a65004-1438-4806-832f-0c6979c48360,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-536ab4d5-3833-4045-8d8d-644b2b5d4667,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-01bde5e2-2680-4a4d-b833-9945ce6eb390,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-753a4984-81a0-414c-a7f4-704c53312fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-7e89b22d-3581-4895-a503-df88e5d28273,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-f4727d6d-7943-4c0c-9111-12b1e3356355,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d4b20d6a-4661-4a3e-a14d-9b82b2b687da,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-f25c5cd9-3682-4971-963c-1050fb2a102f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426092497-172.17.0.13-1598552133011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-af133abc-c461-4e9c-aaf0-c5797edea403,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-b2b096bf-c723-46e1-85ef-f4346aa63b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-e56d91ae-3d16-4790-8b1c-50d7a3e956cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-67710f5c-4f8e-4ed8-9344-a77b22f17e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-f58d668f-83fd-4ffc-b9b1-121bc6e67242,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-ecd8bcd9-c271-42be-8561-d084bfa00456,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1f240393-f8e8-470e-9f90-fa608127ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b88c034f-50da-4a0e-ac94-0666c32b8b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426092497-172.17.0.13-1598552133011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-af133abc-c461-4e9c-aaf0-c5797edea403,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-b2b096bf-c723-46e1-85ef-f4346aa63b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-e56d91ae-3d16-4790-8b1c-50d7a3e956cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-67710f5c-4f8e-4ed8-9344-a77b22f17e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-f58d668f-83fd-4ffc-b9b1-121bc6e67242,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-ecd8bcd9-c271-42be-8561-d084bfa00456,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1f240393-f8e8-470e-9f90-fa608127ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-b88c034f-50da-4a0e-ac94-0666c32b8b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547768992-172.17.0.13-1598552410150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-a2f9f61e-ae0f-422f-a069-c09248ee2032,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d2d61de0-4656-4634-afa7-37e28c8310cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-23eac813-4e77-4569-ad90-ddece93af6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-7bb29380-d8b3-4ef5-ba0d-bbcec49f6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-6a15ae2d-8357-4d4a-9982-d3723569a534,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-3dc70688-763d-49d0-9e7c-1a851b2731c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-71dd70fd-8d02-4652-a593-27b2fcb2cc31,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-22f487fc-53aa-42ad-81f7-d37ae3e7ad5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547768992-172.17.0.13-1598552410150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-a2f9f61e-ae0f-422f-a069-c09248ee2032,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d2d61de0-4656-4634-afa7-37e28c8310cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-23eac813-4e77-4569-ad90-ddece93af6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-7bb29380-d8b3-4ef5-ba0d-bbcec49f6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-6a15ae2d-8357-4d4a-9982-d3723569a534,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-3dc70688-763d-49d0-9e7c-1a851b2731c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-71dd70fd-8d02-4652-a593-27b2fcb2cc31,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-22f487fc-53aa-42ad-81f7-d37ae3e7ad5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634719153-172.17.0.13-1598552449633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-1471e811-9765-4889-9c30-998165bf26bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-ea94ab00-57b0-407a-a59e-17edc8b89cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-aada75bd-73b1-4271-8a49-f3ce929de6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3f3fa0be-40ce-4e43-9be6-08c56a9e2e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4c8ca47e-ef97-4ad8-9337-a7eb47b4c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8186703e-857d-4467-ae26-bb49f4407b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-6a39f071-5d9b-4920-ac10-e48f5e0b76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-a2ab839d-095e-47dc-9ae8-3286a9205734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634719153-172.17.0.13-1598552449633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-1471e811-9765-4889-9c30-998165bf26bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-ea94ab00-57b0-407a-a59e-17edc8b89cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-aada75bd-73b1-4271-8a49-f3ce929de6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-3f3fa0be-40ce-4e43-9be6-08c56a9e2e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-4c8ca47e-ef97-4ad8-9337-a7eb47b4c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8186703e-857d-4467-ae26-bb49f4407b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-6a39f071-5d9b-4920-ac10-e48f5e0b76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-a2ab839d-095e-47dc-9ae8-3286a9205734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:NameNode
v1: 67108864
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35571300-172.17.0.13-1598552967755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-831257ee-a5ef-449c-8ba6-2e890050b848,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-7a60e4a0-7c65-423b-9a7f-173a56059678,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-9ea3832f-2503-4e06-af53-bd808e1c2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-53098190-b624-4eee-b3ca-700985699b55,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-61acea7b-5ab3-4d37-a448-a16e60fabfab,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-8f9879ab-df0d-4f8d-be3a-2df484886671,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ad8f2c58-f3b0-4b34-920c-9f503b8322ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-56924ca7-8891-4e0c-95af-958fad45ad23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35571300-172.17.0.13-1598552967755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-831257ee-a5ef-449c-8ba6-2e890050b848,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-7a60e4a0-7c65-423b-9a7f-173a56059678,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-9ea3832f-2503-4e06-af53-bd808e1c2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-53098190-b624-4eee-b3ca-700985699b55,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-61acea7b-5ab3-4d37-a448-a16e60fabfab,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-8f9879ab-df0d-4f8d-be3a-2df484886671,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ad8f2c58-f3b0-4b34-920c-9f503b8322ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-56924ca7-8891-4e0c-95af-958fad45ad23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4956
