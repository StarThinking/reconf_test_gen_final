reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713368904-172.17.0.18-1598677462004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-8e520777-4155-4465-89a1-274fb065e1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-9ce1960c-38a4-4886-8d91-4b1ca34ad99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fcc38452-8315-41b6-b812-fb79280f1449,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-f624b907-55e8-48b1-ad2f-15a99f254088,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-0b2471d5-94b0-4839-821f-40adac569ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-92149bc8-e396-4726-b052-acb444fcf1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-6951f23c-7609-492b-8937-ace63920ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-3a42255c-c3e0-4a09-9870-c7d79c7dc357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713368904-172.17.0.18-1598677462004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42518,DS-8e520777-4155-4465-89a1-274fb065e1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-9ce1960c-38a4-4886-8d91-4b1ca34ad99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fcc38452-8315-41b6-b812-fb79280f1449,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-f624b907-55e8-48b1-ad2f-15a99f254088,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-0b2471d5-94b0-4839-821f-40adac569ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-92149bc8-e396-4726-b052-acb444fcf1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-6951f23c-7609-492b-8937-ace63920ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-3a42255c-c3e0-4a09-9870-c7d79c7dc357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169025307-172.17.0.18-1598677502157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36264,DS-1c4cf57d-cca7-474a-89ec-f230488580bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-105b656b-f229-4962-87fd-45d747070742,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-23242ccc-c1c4-4559-9b2f-0ad8acf6d072,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-5e7ef1d6-4af9-45fd-a2b5-290d98d84d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6da50bee-33fd-4408-9f98-e8c1f4a846be,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-174fac6c-5540-44b5-80ba-37ae941cdae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-84daa9eb-85a6-4c5c-87da-c9a71095c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-97c5fc98-29e5-4907-a1da-0963558ab9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169025307-172.17.0.18-1598677502157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36264,DS-1c4cf57d-cca7-474a-89ec-f230488580bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-105b656b-f229-4962-87fd-45d747070742,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-23242ccc-c1c4-4559-9b2f-0ad8acf6d072,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-5e7ef1d6-4af9-45fd-a2b5-290d98d84d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-6da50bee-33fd-4408-9f98-e8c1f4a846be,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-174fac6c-5540-44b5-80ba-37ae941cdae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-84daa9eb-85a6-4c5c-87da-c9a71095c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-97c5fc98-29e5-4907-a1da-0963558ab9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772291781-172.17.0.18-1598678544592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-4d9662cd-95f3-47c9-b524-33ba0f8d6214,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-a03bdf1a-28ff-4ff6-96d2-7dc7a65a5383,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d927c77e-f002-435e-877c-90b23ff1dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-0568b3d0-43ea-4d31-9279-54efbe7c7770,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-284d198b-7e17-47ce-b2ad-49969cf0d596,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-d01e06aa-ccda-437a-b038-0dbbd710b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-536ff724-5b9b-45b2-a13f-0f132e886c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f6f5d494-bab8-4867-b6fa-645a381e1e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772291781-172.17.0.18-1598678544592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-4d9662cd-95f3-47c9-b524-33ba0f8d6214,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-a03bdf1a-28ff-4ff6-96d2-7dc7a65a5383,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d927c77e-f002-435e-877c-90b23ff1dd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-0568b3d0-43ea-4d31-9279-54efbe7c7770,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-284d198b-7e17-47ce-b2ad-49969cf0d596,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-d01e06aa-ccda-437a-b038-0dbbd710b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-536ff724-5b9b-45b2-a13f-0f132e886c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f6f5d494-bab8-4867-b6fa-645a381e1e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515180120-172.17.0.18-1598678693943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-7fa2d588-5b7c-4824-a9a2-7342b0ed72ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-444519b1-efa6-408a-8fa2-c9779257c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-2090dd84-50b4-4f6b-b62b-ef69554b381d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d5286a5e-8706-4d40-b738-7e64339eca83,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-41dd0be2-8fde-417b-ac7d-c73cc3522dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a9dd9f52-38a4-4be7-aa11-d22f4af7325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-7206022c-4161-4e73-81c9-49fe22fa1e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4c7bf588-0549-42f4-a732-8c872b28c615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515180120-172.17.0.18-1598678693943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-7fa2d588-5b7c-4824-a9a2-7342b0ed72ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-444519b1-efa6-408a-8fa2-c9779257c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-2090dd84-50b4-4f6b-b62b-ef69554b381d,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d5286a5e-8706-4d40-b738-7e64339eca83,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-41dd0be2-8fde-417b-ac7d-c73cc3522dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a9dd9f52-38a4-4be7-aa11-d22f4af7325d,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-7206022c-4161-4e73-81c9-49fe22fa1e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4c7bf588-0549-42f4-a732-8c872b28c615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93977294-172.17.0.18-1598678908319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-54b4082e-e3d9-4a16-82ad-3a33617780f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-7a87a76f-4ad8-475e-b85b-d8b473923c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b7574c01-41e7-4c0d-8bde-5422cfe5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-f3193e76-13e1-4e06-a6c6-77cabea38153,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-f895d293-01f2-420a-bd99-67d249a3f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-c8f3aa55-ba84-4ebf-8937-f5b120dd19c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-48e6cbbf-1eff-4d9e-ba3b-25c4e5f40e39,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-99e18cdf-190d-494e-9491-4b53d65fc20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93977294-172.17.0.18-1598678908319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-54b4082e-e3d9-4a16-82ad-3a33617780f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-7a87a76f-4ad8-475e-b85b-d8b473923c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b7574c01-41e7-4c0d-8bde-5422cfe5bb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-f3193e76-13e1-4e06-a6c6-77cabea38153,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-f895d293-01f2-420a-bd99-67d249a3f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-c8f3aa55-ba84-4ebf-8937-f5b120dd19c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-48e6cbbf-1eff-4d9e-ba3b-25c4e5f40e39,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-99e18cdf-190d-494e-9491-4b53d65fc20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228203799-172.17.0.18-1598679523334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-ee781965-d96e-45ba-b161-06372fa8f854,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-33955bac-3969-4970-8006-c02c88e57902,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-bedf51aa-29d1-4601-b03a-4268629cc074,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-59d8aac8-5f64-414f-8d4b-95e7a2b6e583,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-363f7c8e-bc1a-4f82-8c94-30e8e051424b,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-7fe403b2-33e7-41f3-bdc4-4cbd6732e694,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-0403cb45-0c53-4137-aeb7-2a8f263eb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-a06c98d3-b377-458e-a092-8daf14d58b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228203799-172.17.0.18-1598679523334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-ee781965-d96e-45ba-b161-06372fa8f854,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-33955bac-3969-4970-8006-c02c88e57902,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-bedf51aa-29d1-4601-b03a-4268629cc074,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-59d8aac8-5f64-414f-8d4b-95e7a2b6e583,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-363f7c8e-bc1a-4f82-8c94-30e8e051424b,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-7fe403b2-33e7-41f3-bdc4-4cbd6732e694,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-0403cb45-0c53-4137-aeb7-2a8f263eb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-a06c98d3-b377-458e-a092-8daf14d58b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949202322-172.17.0.18-1598679894084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-c029b35b-e527-4c75-8381-875f41956fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-bff1ce03-f7e3-491a-8ac8-45c9e2f8435d,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-59d28547-b61d-449c-a51c-16dba9b52461,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-7e89a47c-46fe-414f-bbc5-20dff09aaf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-7b5b9a09-3c2b-42e2-a740-d6925995e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-dc9b811d-3e43-4dc5-867e-1b44762c5c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-607d40cc-b599-4e03-ae52-b271a3cd13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-3dfdbba2-55d8-4069-9322-b0976028c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949202322-172.17.0.18-1598679894084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-c029b35b-e527-4c75-8381-875f41956fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-bff1ce03-f7e3-491a-8ac8-45c9e2f8435d,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-59d28547-b61d-449c-a51c-16dba9b52461,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-7e89a47c-46fe-414f-bbc5-20dff09aaf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-7b5b9a09-3c2b-42e2-a740-d6925995e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-dc9b811d-3e43-4dc5-867e-1b44762c5c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-607d40cc-b599-4e03-ae52-b271a3cd13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-3dfdbba2-55d8-4069-9322-b0976028c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087421746-172.17.0.18-1598679932991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43010,DS-376f572d-1198-419c-9508-08f0d193709e,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-533ce63c-1f02-4a75-bb29-2a0ce2e9f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-8da9e772-64a4-45dd-9a8b-e2a54e5bba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-7524a618-ca75-4087-8f11-f3f757552664,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-3b844755-9a7a-4a1d-b35b-7e0d534b2719,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-3dccdd8b-538c-488a-bef2-1bfe6409b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-7e6380eb-5003-42e5-b823-70c3a9726748,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-520b3bdf-a1b7-496b-8d38-7bf02a8dde43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087421746-172.17.0.18-1598679932991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43010,DS-376f572d-1198-419c-9508-08f0d193709e,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-533ce63c-1f02-4a75-bb29-2a0ce2e9f00d,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-8da9e772-64a4-45dd-9a8b-e2a54e5bba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-7524a618-ca75-4087-8f11-f3f757552664,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-3b844755-9a7a-4a1d-b35b-7e0d534b2719,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-3dccdd8b-538c-488a-bef2-1bfe6409b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-7e6380eb-5003-42e5-b823-70c3a9726748,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-520b3bdf-a1b7-496b-8d38-7bf02a8dde43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903002946-172.17.0.18-1598679965996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-41559a5a-e6a7-4f84-9215-82b236e16eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-0596f544-7cde-450e-b4bf-894544a8ef23,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-a16e74de-68d4-4f62-900c-ea5f122b53d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-9317bd16-a482-40be-a5e6-88ed09047fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-7233ce9a-6ee0-481b-8782-4fd1475f6484,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d3364793-d11e-4fca-a42d-3ae3637ddb32,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6d6bbd63-ca8c-4f34-ba57-609b491b7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5222eb2e-e3e0-421f-805f-20fee25ea268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903002946-172.17.0.18-1598679965996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-41559a5a-e6a7-4f84-9215-82b236e16eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-0596f544-7cde-450e-b4bf-894544a8ef23,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-a16e74de-68d4-4f62-900c-ea5f122b53d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-9317bd16-a482-40be-a5e6-88ed09047fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-7233ce9a-6ee0-481b-8782-4fd1475f6484,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d3364793-d11e-4fca-a42d-3ae3637ddb32,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6d6bbd63-ca8c-4f34-ba57-609b491b7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5222eb2e-e3e0-421f-805f-20fee25ea268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787840567-172.17.0.18-1598680183994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-0b44466b-2539-45c7-9ca2-b973abc0d7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-4e5156c8-3554-447a-868f-5f49e366a179,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-939bbf96-0e4f-4fec-b5fb-258ccacf254e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ee7b8986-64a3-4ae6-b9af-fdc6b6ff2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-252d5479-f418-4062-8b12-6dace1badeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-b5716c78-8fc5-4548-bff6-f4da85cf7805,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-cb53a909-b1f0-42ec-846d-4f682846057d,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-3328f6db-01ae-40b1-8cab-562d98174e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787840567-172.17.0.18-1598680183994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37295,DS-0b44466b-2539-45c7-9ca2-b973abc0d7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-4e5156c8-3554-447a-868f-5f49e366a179,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-939bbf96-0e4f-4fec-b5fb-258ccacf254e,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ee7b8986-64a3-4ae6-b9af-fdc6b6ff2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-252d5479-f418-4062-8b12-6dace1badeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-b5716c78-8fc5-4548-bff6-f4da85cf7805,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-cb53a909-b1f0-42ec-846d-4f682846057d,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-3328f6db-01ae-40b1-8cab-562d98174e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355241735-172.17.0.18-1598680568128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-07df76d7-105f-4387-819a-f7c7fd1645e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-1b22ee61-b576-4649-a5e9-d1933e8ab837,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-68a77ea4-122d-4504-a7a3-7da2404f7cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-34ee90f1-1cc7-49fd-a16c-dd9e54a729bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-249401db-7332-4e24-972a-fc66c3391e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-c535dab3-a3f1-4b0c-997b-3bafd45d269f,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-e3f4d178-55a5-4af3-ae31-baca1858b823,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d516dc19-29bf-44f7-8a0d-7fd3cf513e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355241735-172.17.0.18-1598680568128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-07df76d7-105f-4387-819a-f7c7fd1645e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-1b22ee61-b576-4649-a5e9-d1933e8ab837,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-68a77ea4-122d-4504-a7a3-7da2404f7cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-34ee90f1-1cc7-49fd-a16c-dd9e54a729bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-249401db-7332-4e24-972a-fc66c3391e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-c535dab3-a3f1-4b0c-997b-3bafd45d269f,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-e3f4d178-55a5-4af3-ae31-baca1858b823,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-d516dc19-29bf-44f7-8a0d-7fd3cf513e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422713964-172.17.0.18-1598680865060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-f62f08ec-7212-47d5-b47c-d27b1cb13c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-f4df01e1-ecbd-4629-8613-af864dfa3596,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d8afb434-a7ae-40ad-996e-9d4f0acaf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-2bfed9d8-d5e4-457d-ac73-9412afc396ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-3cfa47d4-1e98-45f7-9f52-998c64d6c5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-0556f944-4d90-4f9e-a9e3-fe9b74237eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-e114e611-4bae-465f-b524-558e62af4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-a2e638ca-5112-4f84-a4b3-eac76fd85c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422713964-172.17.0.18-1598680865060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-f62f08ec-7212-47d5-b47c-d27b1cb13c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-f4df01e1-ecbd-4629-8613-af864dfa3596,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d8afb434-a7ae-40ad-996e-9d4f0acaf0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-2bfed9d8-d5e4-457d-ac73-9412afc396ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-3cfa47d4-1e98-45f7-9f52-998c64d6c5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-0556f944-4d90-4f9e-a9e3-fe9b74237eae,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-e114e611-4bae-465f-b524-558e62af4d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-a2e638ca-5112-4f84-a4b3-eac76fd85c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498595005-172.17.0.18-1598681015111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-93f9eae7-07c1-41c8-831c-27f31a0f14ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-24710337-fc22-4cc3-b500-23011cba53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-8f122f94-a90e-49d1-afd3-1acdd2c9bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-dce3fd2b-67c3-406f-b390-437939cd529e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-f2b9e780-beab-4815-8453-dbdb77fa2f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-0ad21577-2071-40a2-9a7c-da67c3963d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-055c3c5c-56f4-4a1e-9f1c-f2bd1321667e,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6fc721e9-a188-4c92-a096-6ab51a0cfc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498595005-172.17.0.18-1598681015111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-93f9eae7-07c1-41c8-831c-27f31a0f14ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-24710337-fc22-4cc3-b500-23011cba53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-8f122f94-a90e-49d1-afd3-1acdd2c9bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-dce3fd2b-67c3-406f-b390-437939cd529e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-f2b9e780-beab-4815-8453-dbdb77fa2f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-0ad21577-2071-40a2-9a7c-da67c3963d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-055c3c5c-56f4-4a1e-9f1c-f2bd1321667e,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6fc721e9-a188-4c92-a096-6ab51a0cfc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352603051-172.17.0.18-1598681156649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-cedffdd5-4a9f-4856-ad0d-1f187270b6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-e8f33eb9-1dac-4314-abe6-f051a02b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-a2c1a18a-7f0c-4076-a083-bb53ab1cc6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-75142d40-cc78-46dc-913a-04e7547dc0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-0c7e6af0-fdc3-4778-bc20-5888ca98a842,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-00c88db1-6fa3-4acb-b1ba-54b0e0c1d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-b432dfc0-3f81-429d-aa20-8b81153bfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-ba978e2a-c6a1-43bb-9511-8179420f825a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352603051-172.17.0.18-1598681156649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-cedffdd5-4a9f-4856-ad0d-1f187270b6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-e8f33eb9-1dac-4314-abe6-f051a02b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-a2c1a18a-7f0c-4076-a083-bb53ab1cc6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-75142d40-cc78-46dc-913a-04e7547dc0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-0c7e6af0-fdc3-4778-bc20-5888ca98a842,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-00c88db1-6fa3-4acb-b1ba-54b0e0c1d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-b432dfc0-3f81-429d-aa20-8b81153bfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-ba978e2a-c6a1-43bb-9511-8179420f825a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022393698-172.17.0.18-1598681628490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-d0bd8c7c-0135-4502-9d63-79a109294b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-a745963b-68f8-4daf-9d09-07109d9dd9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-72f05042-963d-4ea4-9c4b-aff0a84d8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-77e0054e-b016-4e30-964e-9ef2bf98da35,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-89e3ee38-d0a7-4439-841d-e758dccefe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-4c0ed71e-5be2-4ec4-a939-74bdac468a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-8e0ee438-8627-4beb-89c3-56d507c60d68,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-e44fd229-4a43-4ff6-ad70-23b6da32be06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022393698-172.17.0.18-1598681628490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-d0bd8c7c-0135-4502-9d63-79a109294b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-a745963b-68f8-4daf-9d09-07109d9dd9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-72f05042-963d-4ea4-9c4b-aff0a84d8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-77e0054e-b016-4e30-964e-9ef2bf98da35,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-89e3ee38-d0a7-4439-841d-e758dccefe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-4c0ed71e-5be2-4ec4-a939-74bdac468a58,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-8e0ee438-8627-4beb-89c3-56d507c60d68,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-e44fd229-4a43-4ff6-ad70-23b6da32be06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067909057-172.17.0.18-1598681733335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-f18edc66-ee5d-4f25-b98f-4bc327d34e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-48089d09-ac0c-422b-b474-9df4a7073377,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-9e1f5e11-0724-4246-981e-a85679c78fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-a0045d4d-583c-4ff8-95b8-594485688bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8a765358-0d20-4c5a-8208-ab5dcdb61b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-d2e9ee70-0e35-4632-ab74-39e423889e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-9ae243db-8086-4bd3-8e37-4902e946a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-262254f6-ffeb-4369-af80-55ee97a4edec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067909057-172.17.0.18-1598681733335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-f18edc66-ee5d-4f25-b98f-4bc327d34e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-48089d09-ac0c-422b-b474-9df4a7073377,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-9e1f5e11-0724-4246-981e-a85679c78fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-a0045d4d-583c-4ff8-95b8-594485688bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8a765358-0d20-4c5a-8208-ab5dcdb61b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-d2e9ee70-0e35-4632-ab74-39e423889e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-9ae243db-8086-4bd3-8e37-4902e946a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-262254f6-ffeb-4369-af80-55ee97a4edec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038004317-172.17.0.18-1598681845487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-5e7a6c8c-6c40-4481-8e9b-3e310c481b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4cc4a017-5793-4648-bbdf-f272f707a072,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d1cd0cb4-ab9f-4a7b-92ba-b34e1569ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-3567ccfd-8298-4c5a-b009-675e051f7c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0500eaa6-7397-4081-98ba-82ec8ccc43e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-16130278-8ab2-4eb1-ba48-84c132f1d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-9c27c0e0-2c7a-4c3a-83fe-aad71b0ca454,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-7c875661-feb7-4d9b-9fb1-a49db7c3b3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038004317-172.17.0.18-1598681845487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-5e7a6c8c-6c40-4481-8e9b-3e310c481b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4cc4a017-5793-4648-bbdf-f272f707a072,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d1cd0cb4-ab9f-4a7b-92ba-b34e1569ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-3567ccfd-8298-4c5a-b009-675e051f7c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-0500eaa6-7397-4081-98ba-82ec8ccc43e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-16130278-8ab2-4eb1-ba48-84c132f1d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-9c27c0e0-2c7a-4c3a-83fe-aad71b0ca454,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-7c875661-feb7-4d9b-9fb1-a49db7c3b3ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400435289-172.17.0.18-1598682128819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-27522082-e065-4b99-93fe-165cabf97f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-9721ddd6-adf8-4d38-a37b-22b0fcb3a9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-19ce8e10-8b48-4d6b-bf96-9d3bb59fc222,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-2b8a230c-2dfc-4b13-91e3-0ef65b09215e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-1a024d7a-70be-4b01-a1b6-38564ce91578,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f7d89e23-a986-4b6e-a7ea-300b510ed59f,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-1b5e2d61-293f-495a-8f25-4557b7978bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-b788d910-5d52-47b4-8f8a-bc91e4e29c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400435289-172.17.0.18-1598682128819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-27522082-e065-4b99-93fe-165cabf97f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-9721ddd6-adf8-4d38-a37b-22b0fcb3a9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-19ce8e10-8b48-4d6b-bf96-9d3bb59fc222,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-2b8a230c-2dfc-4b13-91e3-0ef65b09215e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-1a024d7a-70be-4b01-a1b6-38564ce91578,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-f7d89e23-a986-4b6e-a7ea-300b510ed59f,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-1b5e2d61-293f-495a-8f25-4557b7978bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-b788d910-5d52-47b4-8f8a-bc91e4e29c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876982215-172.17.0.18-1598682166813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-d9dd4114-3ad9-42cb-8546-988fcbe2aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3acf53b3-27a5-416a-9fe0-bc9a2a387e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-74c47a21-65ee-47bb-af60-2720a4618af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-3b586dee-b396-4a6c-b91e-2e11c54cacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-328ec3f2-e417-4630-a1c6-008971cd50aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-1c9f4b6a-129f-4216-aeef-eda3fcb16e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-6bcab0c7-76bd-4199-8c5c-f582214064d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-060a1d0c-ebe7-41ee-b1e5-1318409ab870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876982215-172.17.0.18-1598682166813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-d9dd4114-3ad9-42cb-8546-988fcbe2aa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3acf53b3-27a5-416a-9fe0-bc9a2a387e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-74c47a21-65ee-47bb-af60-2720a4618af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-3b586dee-b396-4a6c-b91e-2e11c54cacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-328ec3f2-e417-4630-a1c6-008971cd50aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-1c9f4b6a-129f-4216-aeef-eda3fcb16e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-6bcab0c7-76bd-4199-8c5c-f582214064d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-060a1d0c-ebe7-41ee-b1e5-1318409ab870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472229067-172.17.0.18-1598682318601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-9822b5aa-5519-4ce0-82e6-1f4a5b37524d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-47a4f348-51a2-4fc7-9269-b3e5ec41ba74,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-9acf9be8-d84d-4f38-b1f1-98319e0a17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-a86d319c-f8f6-45b7-8403-e06ad529278d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-ad897c98-3e56-4c97-b3b0-ef806cd7c859,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-d0493373-b77a-47f9-b97d-d892a2caac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-f10241c4-c35c-4755-b876-f9bb0302a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-dcbf34a2-7d6e-4cb6-89c8-3787ab33a148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472229067-172.17.0.18-1598682318601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-9822b5aa-5519-4ce0-82e6-1f4a5b37524d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-47a4f348-51a2-4fc7-9269-b3e5ec41ba74,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-9acf9be8-d84d-4f38-b1f1-98319e0a17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-a86d319c-f8f6-45b7-8403-e06ad529278d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-ad897c98-3e56-4c97-b3b0-ef806cd7c859,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-d0493373-b77a-47f9-b97d-d892a2caac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-f10241c4-c35c-4755-b876-f9bb0302a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-dcbf34a2-7d6e-4cb6-89c8-3787ab33a148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111835653-172.17.0.18-1598682353513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-432c9feb-0c1e-4c8d-87a3-b87aac0dcfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-9f2524e3-189b-4d15-8ab4-1695a0da43a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-06d08283-b2de-4359-bb1d-b3a112cf8c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-69151e6f-40ac-46d1-aafc-1158b3ebfc80,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-0c5cc24b-bf43-4055-a8a1-af185d5e6be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-1b1199e1-070a-4c5a-9f09-aa2e549d4922,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-34b442fb-e60d-42b2-aa0e-9fecccf87129,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-7603a605-76c5-461a-9250-1eb558d66ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111835653-172.17.0.18-1598682353513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36215,DS-432c9feb-0c1e-4c8d-87a3-b87aac0dcfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-9f2524e3-189b-4d15-8ab4-1695a0da43a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-06d08283-b2de-4359-bb1d-b3a112cf8c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-69151e6f-40ac-46d1-aafc-1158b3ebfc80,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-0c5cc24b-bf43-4055-a8a1-af185d5e6be7,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-1b1199e1-070a-4c5a-9f09-aa2e549d4922,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-34b442fb-e60d-42b2-aa0e-9fecccf87129,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-7603a605-76c5-461a-9250-1eb558d66ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987434721-172.17.0.18-1598682433798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39910,DS-ddc41bee-ec40-43b1-8359-504cf8afdf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-b2fbe7a1-50fe-4608-a6b4-cf9fb778d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-67538580-c9be-4445-a372-1fc50188dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-5de5cd05-7f7e-41ca-9247-778bf882ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-2d8d8b44-3fc3-42a0-ac85-45ab8e423c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-9bf93520-03d5-49aa-be2e-706e65ff9090,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-a62da81a-638d-44a6-905e-5b45bbcd0095,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-95baf408-a145-4add-b52e-c9441b7e83ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987434721-172.17.0.18-1598682433798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39910,DS-ddc41bee-ec40-43b1-8359-504cf8afdf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-b2fbe7a1-50fe-4608-a6b4-cf9fb778d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-67538580-c9be-4445-a372-1fc50188dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-5de5cd05-7f7e-41ca-9247-778bf882ab5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-2d8d8b44-3fc3-42a0-ac85-45ab8e423c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-9bf93520-03d5-49aa-be2e-706e65ff9090,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-a62da81a-638d-44a6-905e-5b45bbcd0095,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-95baf408-a145-4add-b52e-c9441b7e83ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705446607-172.17.0.18-1598682593207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-c76f572f-d7c5-45b2-8752-3a031fb7ebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-0394785d-3ac5-440a-b917-123ba94e065c,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-70655418-dc4c-445c-adac-0f9acd505f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-74845d89-63bd-4e98-b9be-faa4239ead95,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-225d8275-b864-4648-8e08-dc772444d429,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-03826bc2-6891-4e1c-bdf0-51aa186641de,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-70aba538-ed9e-4d1f-916e-2584d62e0177,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-276c6283-af97-4799-b80c-d8a62eeb4590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705446607-172.17.0.18-1598682593207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-c76f572f-d7c5-45b2-8752-3a031fb7ebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-0394785d-3ac5-440a-b917-123ba94e065c,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-70655418-dc4c-445c-adac-0f9acd505f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-74845d89-63bd-4e98-b9be-faa4239ead95,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-225d8275-b864-4648-8e08-dc772444d429,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-03826bc2-6891-4e1c-bdf0-51aa186641de,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-70aba538-ed9e-4d1f-916e-2584d62e0177,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-276c6283-af97-4799-b80c-d8a62eeb4590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80644439-172.17.0.18-1598682715750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-794012fc-6c35-417d-b109-ba25906acadb,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-f64edf58-4a2c-427d-b1b0-7492d44f3c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-3140488e-c8ef-428d-b647-6ef2c740ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-afbe1967-2cdb-46df-aeb3-d727000b975b,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-7896460d-b1a0-4df2-995a-5cfce450913e,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-5fb23f9a-e139-4ee6-8a13-d96e1dcbdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-337b68c0-daee-49d8-aa30-45652943a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8cb49513-8026-45be-af1c-8c6791185769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80644439-172.17.0.18-1598682715750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-794012fc-6c35-417d-b109-ba25906acadb,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-f64edf58-4a2c-427d-b1b0-7492d44f3c84,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-3140488e-c8ef-428d-b647-6ef2c740ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-afbe1967-2cdb-46df-aeb3-d727000b975b,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-7896460d-b1a0-4df2-995a-5cfce450913e,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-5fb23f9a-e139-4ee6-8a13-d96e1dcbdb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-337b68c0-daee-49d8-aa30-45652943a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8cb49513-8026-45be-af1c-8c6791185769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835353275-172.17.0.18-1598682792027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40124,DS-93c0dba5-9fc9-460d-8eb1-72ddb21a221f,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-26e8cb20-f428-4c50-9eef-085540630f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-7949100f-0ee9-414c-a965-c9139aaf29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-45c3fe69-6ee1-4af8-a493-4bb3def07118,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-94e8f03d-925a-495b-9224-4a9c6a4e7fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-1269b184-1d70-4abc-98ee-bdbe03d8554a,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-269f8a71-d307-4784-b8f4-511f1e254ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-d1e3af49-ae16-44ab-955e-eac559b2856d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835353275-172.17.0.18-1598682792027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40124,DS-93c0dba5-9fc9-460d-8eb1-72ddb21a221f,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-26e8cb20-f428-4c50-9eef-085540630f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-7949100f-0ee9-414c-a965-c9139aaf29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-45c3fe69-6ee1-4af8-a493-4bb3def07118,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-94e8f03d-925a-495b-9224-4a9c6a4e7fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-1269b184-1d70-4abc-98ee-bdbe03d8554a,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-269f8a71-d307-4784-b8f4-511f1e254ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-d1e3af49-ae16-44ab-955e-eac559b2856d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5525
