reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003478376-172.17.0.11-1598521610790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-72ead23a-ec84-4533-99ed-98f1e29885c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-7042d084-50dc-441f-ad1d-ea0cd0408f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-28ce77a1-476f-4971-ac1d-c77f5e07486c,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-ced78152-affd-4350-a25e-20e1ebe61e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-fd97a19b-bb95-4135-bcd2-135a65ccdd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-6a5b8b0c-5c10-41be-b37a-6bdd0d59474c,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-71a6155e-1f5d-4555-9cb4-d80505c4b823,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-8ab66c67-3bef-4408-9fa0-7ca58220ca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003478376-172.17.0.11-1598521610790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-72ead23a-ec84-4533-99ed-98f1e29885c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-7042d084-50dc-441f-ad1d-ea0cd0408f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-28ce77a1-476f-4971-ac1d-c77f5e07486c,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-ced78152-affd-4350-a25e-20e1ebe61e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-fd97a19b-bb95-4135-bcd2-135a65ccdd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-6a5b8b0c-5c10-41be-b37a-6bdd0d59474c,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-71a6155e-1f5d-4555-9cb4-d80505c4b823,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-8ab66c67-3bef-4408-9fa0-7ca58220ca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586548343-172.17.0.11-1598523469089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-cdcaa50f-3d84-4278-9f7d-14a05c44476c,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-5250f9cd-38b3-499b-9cda-d0992e315676,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-df234312-b10d-46be-8bf3-2533ae148469,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-01050ca7-247b-49e8-93cd-766f3703e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-df199119-6b08-4463-b380-03c5068e7768,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-351f40ba-2984-4f4b-9dce-5e905a19866a,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-01245e5f-6f8e-4619-a172-5d59f43c47fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-3b1a7fad-bbcf-422e-bd6f-8be3a992b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586548343-172.17.0.11-1598523469089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-cdcaa50f-3d84-4278-9f7d-14a05c44476c,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-5250f9cd-38b3-499b-9cda-d0992e315676,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-df234312-b10d-46be-8bf3-2533ae148469,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-01050ca7-247b-49e8-93cd-766f3703e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-df199119-6b08-4463-b380-03c5068e7768,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-351f40ba-2984-4f4b-9dce-5e905a19866a,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-01245e5f-6f8e-4619-a172-5d59f43c47fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-3b1a7fad-bbcf-422e-bd6f-8be3a992b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806372811-172.17.0.11-1598523543347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-66d0b9fb-a4c9-47af-b0c4-9559589435e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-e37623fb-7290-4754-9f81-dbe676c5a221,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-2626cda4-dc64-48d8-8daf-e27c9e862851,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-489c8b9d-7a72-46bd-aa9c-9cb634a454db,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-dd7833a5-905b-4ff0-a0e4-c7747e3b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-c6a2b8cf-df42-47af-a7b9-b33d9878ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-516768f9-003a-461e-92d0-c116b6b5ee72,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ea8fd9e5-9291-45e6-a462-b86b03c3bedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806372811-172.17.0.11-1598523543347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-66d0b9fb-a4c9-47af-b0c4-9559589435e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-e37623fb-7290-4754-9f81-dbe676c5a221,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-2626cda4-dc64-48d8-8daf-e27c9e862851,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-489c8b9d-7a72-46bd-aa9c-9cb634a454db,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-dd7833a5-905b-4ff0-a0e4-c7747e3b2781,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-c6a2b8cf-df42-47af-a7b9-b33d9878ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-516768f9-003a-461e-92d0-c116b6b5ee72,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-ea8fd9e5-9291-45e6-a462-b86b03c3bedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012251091-172.17.0.11-1598523759371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-039a218f-0aed-46ea-bfb7-513efc3347d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-97eec3fe-b752-4e3c-b274-691b5bbc3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-5e57a744-8d44-4ecd-9b3b-1f6e8f47bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-24aa1b1d-bbaa-46c6-99ca-b34d1bea176f,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1b29a7aa-a7c5-4885-a8c9-49af190f5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-34c3d918-f0e1-4298-9bab-6c51c5010938,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-7a373623-623a-463d-86f9-b4a97ad56079,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-58d2dcbb-f427-4147-b254-880eb70c4881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012251091-172.17.0.11-1598523759371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-039a218f-0aed-46ea-bfb7-513efc3347d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-97eec3fe-b752-4e3c-b274-691b5bbc3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-5e57a744-8d44-4ecd-9b3b-1f6e8f47bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-24aa1b1d-bbaa-46c6-99ca-b34d1bea176f,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1b29a7aa-a7c5-4885-a8c9-49af190f5fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-34c3d918-f0e1-4298-9bab-6c51c5010938,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-7a373623-623a-463d-86f9-b4a97ad56079,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-58d2dcbb-f427-4147-b254-880eb70c4881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474024629-172.17.0.11-1598523797347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-26c679f8-8cb0-4bbc-a2e1-a114983d3967,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-7ae7f1d8-7b02-48b4-92f4-e4d3aa83c657,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-f202f562-f56d-4d86-abdd-a8c8cfad0c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-ac5ea765-34df-49e2-94c6-13f19e137b82,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-a0dafb74-8f76-41e2-99d2-6e8bed59de82,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-4fbae826-1f27-4b2f-b49c-a20f67a24c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-2eb9cff0-e390-4162-aaa1-9af726fbb096,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-6babe0d5-e995-4518-b7ac-c6ae07df0484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474024629-172.17.0.11-1598523797347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-26c679f8-8cb0-4bbc-a2e1-a114983d3967,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-7ae7f1d8-7b02-48b4-92f4-e4d3aa83c657,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-f202f562-f56d-4d86-abdd-a8c8cfad0c99,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-ac5ea765-34df-49e2-94c6-13f19e137b82,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-a0dafb74-8f76-41e2-99d2-6e8bed59de82,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-4fbae826-1f27-4b2f-b49c-a20f67a24c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-2eb9cff0-e390-4162-aaa1-9af726fbb096,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-6babe0d5-e995-4518-b7ac-c6ae07df0484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354851266-172.17.0.11-1598523963361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-acaf900a-5b48-4b68-a4e8-607a894af220,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7cd54e02-cd94-4fab-9122-305793974e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ef122526-90ac-47b0-9666-5ea42b6e4936,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-33ec0248-499a-4db3-8535-5316ca837f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-93c0ef05-f8c9-4187-803e-2aed791e8457,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-21f13589-1534-439b-abc1-db99fb31f82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-f166c56f-cde6-425b-9e79-0d9d544d6607,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-33e28a8b-d5c2-4427-9ef2-4410db531f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354851266-172.17.0.11-1598523963361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-acaf900a-5b48-4b68-a4e8-607a894af220,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-7cd54e02-cd94-4fab-9122-305793974e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-ef122526-90ac-47b0-9666-5ea42b6e4936,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-33ec0248-499a-4db3-8535-5316ca837f44,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-93c0ef05-f8c9-4187-803e-2aed791e8457,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-21f13589-1534-439b-abc1-db99fb31f82e,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-f166c56f-cde6-425b-9e79-0d9d544d6607,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-33e28a8b-d5c2-4427-9ef2-4410db531f3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218784354-172.17.0.11-1598524005860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-feef3e8c-a6ae-45a9-be79-7d9c9dd4349e,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-03df8dc0-5656-406b-ac6a-4f4392c363f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-9212aa16-ab3a-40a2-a2ec-5e5a6fe2e889,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-231cef0d-4479-4ed6-97d8-22c6938a4071,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-7f571e0a-3971-4db7-a31d-255f93be3c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-f0102fb6-e4f6-49b0-8b0d-54361c4a5c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-090b12c6-428f-4944-a809-5be15d5935bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-12dd9461-7c0e-4038-b4f8-a332d2c0e898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218784354-172.17.0.11-1598524005860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45841,DS-feef3e8c-a6ae-45a9-be79-7d9c9dd4349e,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-03df8dc0-5656-406b-ac6a-4f4392c363f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-9212aa16-ab3a-40a2-a2ec-5e5a6fe2e889,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-231cef0d-4479-4ed6-97d8-22c6938a4071,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-7f571e0a-3971-4db7-a31d-255f93be3c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-f0102fb6-e4f6-49b0-8b0d-54361c4a5c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-090b12c6-428f-4944-a809-5be15d5935bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-12dd9461-7c0e-4038-b4f8-a332d2c0e898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311868038-172.17.0.11-1598524046951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c4ecf606-0fab-49e3-8e4e-e97aadf85180,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-662041d5-0ea8-47f8-9dfb-b9ae7e78585e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-6d1b6a2d-f93d-4145-a515-2ca9756dc312,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-06d206f8-93df-4a38-93b9-1c68ead835c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-92fc036f-bd8d-49b9-94b7-84c0111e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-eb9628aa-6edb-4330-9c67-fbd0ee7f277a,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-cad0ffbb-8d5d-4ac9-aead-bb0ee4924401,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-142eb444-e1af-451a-88f2-01361a476bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311868038-172.17.0.11-1598524046951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-c4ecf606-0fab-49e3-8e4e-e97aadf85180,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-662041d5-0ea8-47f8-9dfb-b9ae7e78585e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-6d1b6a2d-f93d-4145-a515-2ca9756dc312,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-06d206f8-93df-4a38-93b9-1c68ead835c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-92fc036f-bd8d-49b9-94b7-84c0111e7256,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-eb9628aa-6edb-4330-9c67-fbd0ee7f277a,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-cad0ffbb-8d5d-4ac9-aead-bb0ee4924401,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-142eb444-e1af-451a-88f2-01361a476bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873916262-172.17.0.11-1598524222038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-333df5e2-2693-4047-b1cb-ca26d526a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-b11f7b26-3bd1-4e22-86f2-e3c0f370ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-08673d90-d567-453d-b8a1-8e2579390cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-f1fec09d-46b3-4bea-a3d7-9e52b991a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f35fea2e-d00a-43ad-9478-14b387566962,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-76c4b149-e0c0-4358-ba40-e2c4716ebcda,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-4a2750a7-5437-4e0d-b89a-3f42af4cf20b,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-48fc9984-76c1-44a4-9d2f-123ee0ca2fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873916262-172.17.0.11-1598524222038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-333df5e2-2693-4047-b1cb-ca26d526a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-b11f7b26-3bd1-4e22-86f2-e3c0f370ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-08673d90-d567-453d-b8a1-8e2579390cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-f1fec09d-46b3-4bea-a3d7-9e52b991a6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f35fea2e-d00a-43ad-9478-14b387566962,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-76c4b149-e0c0-4358-ba40-e2c4716ebcda,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-4a2750a7-5437-4e0d-b89a-3f42af4cf20b,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-48fc9984-76c1-44a4-9d2f-123ee0ca2fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550975764-172.17.0.11-1598524262441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-32c7cd99-ec0e-4b26-ae8e-38c34f9caace,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-9c4c1d2b-a008-4b28-881b-363fed4d3f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-0ffbf114-896e-422e-8c6f-423c3fa13e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f02d5f85-69e4-409c-b315-226d9de1119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-a8efbd1e-26da-4e9a-8e55-fcea68b29c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-bb328958-8b07-46b4-b38a-f201d1e1811e,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-320a66d7-1d40-4174-a4c0-76618129a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-735c4fcd-14ca-4599-88aa-563cb316a5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550975764-172.17.0.11-1598524262441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-32c7cd99-ec0e-4b26-ae8e-38c34f9caace,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-9c4c1d2b-a008-4b28-881b-363fed4d3f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-0ffbf114-896e-422e-8c6f-423c3fa13e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f02d5f85-69e4-409c-b315-226d9de1119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-a8efbd1e-26da-4e9a-8e55-fcea68b29c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-bb328958-8b07-46b4-b38a-f201d1e1811e,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-320a66d7-1d40-4174-a4c0-76618129a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-735c4fcd-14ca-4599-88aa-563cb316a5d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463801540-172.17.0.11-1598524478497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-cec19b56-a609-49fa-a053-a6d16b7c5547,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-2bfa8cff-db88-4b75-bab8-41398fed32ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-906ed49d-615e-4585-a9b3-86df508b624d,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5484b153-4516-4664-810b-7c64990d5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-19f4aae1-c3b0-43fb-9cab-e2bad041bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-e38bac10-d29d-48f9-be9c-30fdad579768,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-be0b8e65-8c9b-41b1-947e-dc941ba20263,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-387bdb59-3faf-482f-b766-48289c8a3575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463801540-172.17.0.11-1598524478497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-cec19b56-a609-49fa-a053-a6d16b7c5547,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-2bfa8cff-db88-4b75-bab8-41398fed32ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-906ed49d-615e-4585-a9b3-86df508b624d,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-5484b153-4516-4664-810b-7c64990d5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-19f4aae1-c3b0-43fb-9cab-e2bad041bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-e38bac10-d29d-48f9-be9c-30fdad579768,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-be0b8e65-8c9b-41b1-947e-dc941ba20263,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-387bdb59-3faf-482f-b766-48289c8a3575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086932517-172.17.0.11-1598524587313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-7707cb6e-c3bb-4580-94bc-1cf66b92b362,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-cbe994a3-25fe-4d09-a54a-7f991d57bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-44bd7a26-058f-473f-95bf-9711935f17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-a156d8a3-bdbf-42c5-9518-53e0615bddef,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-6459fea7-25e9-43f6-8d7a-4cdee64d4d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-fdb503d9-932e-44cc-b04c-123c49d9409d,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-09156012-a445-4977-8523-eac7457f69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-a38cf6ab-a577-403b-b5d6-159e105da937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086932517-172.17.0.11-1598524587313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-7707cb6e-c3bb-4580-94bc-1cf66b92b362,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-cbe994a3-25fe-4d09-a54a-7f991d57bc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-44bd7a26-058f-473f-95bf-9711935f17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-a156d8a3-bdbf-42c5-9518-53e0615bddef,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-6459fea7-25e9-43f6-8d7a-4cdee64d4d60,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-fdb503d9-932e-44cc-b04c-123c49d9409d,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-09156012-a445-4977-8523-eac7457f69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-a38cf6ab-a577-403b-b5d6-159e105da937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122615752-172.17.0.11-1598525232004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-a729f45c-af22-4284-80cc-37296f88e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-5b541f46-f98f-4935-9cba-ed8331a4c995,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-0b7bfded-a775-494e-8d9a-4ecc5d71591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-c544d39d-af71-4dcf-bb82-db7afce47620,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-166fa7c5-b096-4979-bdb0-aec66f5584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-ec24cc00-d4ed-4922-a6a6-5ef7dd4a4431,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-83ca33b7-d4ab-4359-8307-54b92a87d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-5e07b175-f7db-409e-9404-a012e7497f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122615752-172.17.0.11-1598525232004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-a729f45c-af22-4284-80cc-37296f88e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-5b541f46-f98f-4935-9cba-ed8331a4c995,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-0b7bfded-a775-494e-8d9a-4ecc5d71591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-c544d39d-af71-4dcf-bb82-db7afce47620,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-166fa7c5-b096-4979-bdb0-aec66f5584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-ec24cc00-d4ed-4922-a6a6-5ef7dd4a4431,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-83ca33b7-d4ab-4359-8307-54b92a87d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-5e07b175-f7db-409e-9404-a012e7497f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643330879-172.17.0.11-1598525377373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-c3b11388-6779-44ce-941a-b3dd52834e13,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-a8c49cec-e441-4699-b2d4-681ecf655ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-dcc2278e-b067-4c00-a534-43d303bfdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8b060ef3-920f-4aa5-ae2f-92d9da2b9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-77f323bd-df5c-48a1-94d3-4e02fd742bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-79f37bce-f408-4b3f-8c1b-9758e47cf3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-493157f1-fa40-4c3b-8667-28f50156b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-440f7d01-cd59-44e2-910f-ffd6eb2844b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643330879-172.17.0.11-1598525377373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-c3b11388-6779-44ce-941a-b3dd52834e13,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-a8c49cec-e441-4699-b2d4-681ecf655ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-dcc2278e-b067-4c00-a534-43d303bfdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8b060ef3-920f-4aa5-ae2f-92d9da2b9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-77f323bd-df5c-48a1-94d3-4e02fd742bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-79f37bce-f408-4b3f-8c1b-9758e47cf3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-493157f1-fa40-4c3b-8667-28f50156b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-440f7d01-cd59-44e2-910f-ffd6eb2844b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875261931-172.17.0.11-1598525630510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-f1d98234-8a3b-4c12-9d2f-f22202d3be5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-64a58759-bd99-4487-9bb3-257545c35ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-054cf62e-e80a-4ff1-86fe-580824762295,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-78353d7a-3da2-49ac-9fa6-118dcd0f9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-88c1baff-921b-4b7d-b554-9cba562284fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-af322379-d19c-48ee-a684-92c8e09eae93,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-8ec6f136-d138-4781-8ec4-fb99b8977763,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-219b110b-d85e-4211-ab83-46b9849e5489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875261931-172.17.0.11-1598525630510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-f1d98234-8a3b-4c12-9d2f-f22202d3be5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-64a58759-bd99-4487-9bb3-257545c35ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-054cf62e-e80a-4ff1-86fe-580824762295,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-78353d7a-3da2-49ac-9fa6-118dcd0f9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-88c1baff-921b-4b7d-b554-9cba562284fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-af322379-d19c-48ee-a684-92c8e09eae93,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-8ec6f136-d138-4781-8ec4-fb99b8977763,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-219b110b-d85e-4211-ab83-46b9849e5489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388222761-172.17.0.11-1598525660425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-4f57bf53-9759-49cc-ae25-cab70ef80308,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-c845665f-b55a-43f7-acf0-42f67e3fb50c,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-d2ea4571-a6e1-4c07-9945-a5213d8aed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-2964fb29-52a8-464f-a1f8-ca5516270ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-9d818222-dd71-4f1f-af7e-9e3bd9ab58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-abb83c05-adc7-426d-b5e1-fbb48bef8f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-04f9ee05-7baa-4c6a-8487-12c35cc5f965,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-7caba7ab-7799-49de-b30f-c9f6d1089a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388222761-172.17.0.11-1598525660425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41472,DS-4f57bf53-9759-49cc-ae25-cab70ef80308,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-c845665f-b55a-43f7-acf0-42f67e3fb50c,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-d2ea4571-a6e1-4c07-9945-a5213d8aed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-2964fb29-52a8-464f-a1f8-ca5516270ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-9d818222-dd71-4f1f-af7e-9e3bd9ab58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-abb83c05-adc7-426d-b5e1-fbb48bef8f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-04f9ee05-7baa-4c6a-8487-12c35cc5f965,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-7caba7ab-7799-49de-b30f-c9f6d1089a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96221168-172.17.0.11-1598526471409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-483b1ad6-7a2d-4666-a8c7-15192cb83fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-d704e147-e592-4f73-b293-0003d18256ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-8b0ef1d3-e611-464e-a219-224d689cead2,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-30b90006-0435-4cef-9f33-3a70bcafe4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-499bbd89-f2ac-4a0e-894f-84a69ac90527,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-61cfaa19-8def-4459-8921-94650c346767,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-9ca6217e-8672-4e19-ad82-816116646e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-dedaa853-ea77-4636-a463-1b5d58cdde00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96221168-172.17.0.11-1598526471409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-483b1ad6-7a2d-4666-a8c7-15192cb83fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-d704e147-e592-4f73-b293-0003d18256ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-8b0ef1d3-e611-464e-a219-224d689cead2,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-30b90006-0435-4cef-9f33-3a70bcafe4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-499bbd89-f2ac-4a0e-894f-84a69ac90527,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-61cfaa19-8def-4459-8921-94650c346767,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-9ca6217e-8672-4e19-ad82-816116646e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-dedaa853-ea77-4636-a463-1b5d58cdde00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858227477-172.17.0.11-1598526666556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-6cad40da-f8de-4061-a450-8f6bd2b94bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-d2a08967-24be-4893-9eb6-ee6443a65919,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-00c6528d-30dd-433c-8245-7890b6224bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a058b049-5579-4022-9227-4d88743ba3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-202d6430-f383-4b71-9031-4431a3e67dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-27ee5618-a817-484b-ab81-dc029b453f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-183f9665-949c-44f9-8b01-dab3a8e40e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-4310af5c-25c1-49cd-9832-dd160669e966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858227477-172.17.0.11-1598526666556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-6cad40da-f8de-4061-a450-8f6bd2b94bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-d2a08967-24be-4893-9eb6-ee6443a65919,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-00c6528d-30dd-433c-8245-7890b6224bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a058b049-5579-4022-9227-4d88743ba3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-202d6430-f383-4b71-9031-4431a3e67dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-27ee5618-a817-484b-ab81-dc029b453f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-183f9665-949c-44f9-8b01-dab3a8e40e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-4310af5c-25c1-49cd-9832-dd160669e966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 5000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49384437-172.17.0.11-1598526706942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39529,DS-56b121c1-b3a7-4d25-b1a3-8ebb692d4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-0af95720-4ddb-4070-a84f-066f148aac62,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-882a8821-dc25-4bca-aa4a-cbd23fb14d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-02a92d07-0de1-4e27-a03c-beefdde87ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-5a1898e2-a645-401b-9bab-214ebf5225e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-ae96428a-0483-441d-9f93-34d2e43e976a,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-678e103f-ea13-401a-8a32-e620d55b0048,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-7504757b-327c-4066-a568-d08814b4ad46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49384437-172.17.0.11-1598526706942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39529,DS-56b121c1-b3a7-4d25-b1a3-8ebb692d4d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-0af95720-4ddb-4070-a84f-066f148aac62,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-882a8821-dc25-4bca-aa4a-cbd23fb14d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-02a92d07-0de1-4e27-a03c-beefdde87ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-5a1898e2-a645-401b-9bab-214ebf5225e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-ae96428a-0483-441d-9f93-34d2e43e976a,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-678e103f-ea13-401a-8a32-e620d55b0048,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-7504757b-327c-4066-a568-d08814b4ad46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5410
