reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840143732-172.17.0.8-1598545995106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-a1ef996d-c15c-4012-812a-aa4cfb186c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a5ef0042-6384-418c-a72b-bfd867fdccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-26b14606-434b-47fe-8fa9-0ca04596ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-a93d5668-e86f-4cea-b15f-9174393e8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-80a5f3ec-a2c0-45ff-93e6-99315bd434bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-e6738db9-a0ab-4aca-b820-c37c7461d474,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-8724a802-6331-443f-9046-4fffd1dcbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-da0c0c3c-ed81-404f-a33d-176652b1163c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840143732-172.17.0.8-1598545995106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-a1ef996d-c15c-4012-812a-aa4cfb186c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-a5ef0042-6384-418c-a72b-bfd867fdccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-26b14606-434b-47fe-8fa9-0ca04596ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-a93d5668-e86f-4cea-b15f-9174393e8d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-80a5f3ec-a2c0-45ff-93e6-99315bd434bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-e6738db9-a0ab-4aca-b820-c37c7461d474,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-8724a802-6331-443f-9046-4fffd1dcbd77,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-da0c0c3c-ed81-404f-a33d-176652b1163c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998972790-172.17.0.8-1598546168371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-ad65c88c-240f-494a-bbbd-38a100a93b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-da80f2a4-273a-4e93-937f-0f009440bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-7fbd9189-075d-4062-bd8c-0ba104d3c230,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-460203ad-ed7b-4e4c-8567-c7cf761888f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-a56b5704-8b0f-4929-9240-473af67adbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c454ccf4-3e62-428d-be32-1bac79c632a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-ec4db87d-2f2f-47e9-8f07-97cdb7cc5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-98320b0e-a987-4845-ba5a-ba056ea1f9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998972790-172.17.0.8-1598546168371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-ad65c88c-240f-494a-bbbd-38a100a93b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-da80f2a4-273a-4e93-937f-0f009440bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-7fbd9189-075d-4062-bd8c-0ba104d3c230,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-460203ad-ed7b-4e4c-8567-c7cf761888f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-a56b5704-8b0f-4929-9240-473af67adbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c454ccf4-3e62-428d-be32-1bac79c632a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-ec4db87d-2f2f-47e9-8f07-97cdb7cc5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-98320b0e-a987-4845-ba5a-ba056ea1f9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003555934-172.17.0.8-1598546197301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-d95f7def-0679-47fe-8517-78534c3a1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2056d251-dc84-4285-ab50-b3e722b86a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-5f76af55-a28f-441d-ad86-ab95254cf378,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-6eae2c4a-655f-4320-9121-c5253a343cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-703fe182-9e26-44b0-af53-87d016497ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-f0ef5992-9194-4dbb-bef1-4bdf1a4fe129,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5c5bbc2e-d712-4f3a-a26a-83aadde05e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-754c8840-e8ba-495a-9ac1-c715a7814c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003555934-172.17.0.8-1598546197301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-d95f7def-0679-47fe-8517-78534c3a1c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2056d251-dc84-4285-ab50-b3e722b86a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-5f76af55-a28f-441d-ad86-ab95254cf378,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-6eae2c4a-655f-4320-9121-c5253a343cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-703fe182-9e26-44b0-af53-87d016497ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-f0ef5992-9194-4dbb-bef1-4bdf1a4fe129,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5c5bbc2e-d712-4f3a-a26a-83aadde05e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-754c8840-e8ba-495a-9ac1-c715a7814c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757073876-172.17.0.8-1598546474433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-d21ab620-58fa-4ba5-a449-054e39ec9c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-e4ad83c8-bf18-4572-9bbe-91f71204d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-a4e3ab55-101f-461a-a002-307ba0adcfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9b49e07e-fc73-46b7-90f1-3975e3d8c735,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-b40a7ce6-0c62-4d2b-b727-96a0f0c7450b,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-262137d2-887c-498e-9aa4-6af9c9aaac09,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-169a9103-b50f-4639-ab63-410de863ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-e6b7323c-253e-4052-bc5c-a6e484d7c4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757073876-172.17.0.8-1598546474433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-d21ab620-58fa-4ba5-a449-054e39ec9c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-e4ad83c8-bf18-4572-9bbe-91f71204d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-a4e3ab55-101f-461a-a002-307ba0adcfae,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9b49e07e-fc73-46b7-90f1-3975e3d8c735,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-b40a7ce6-0c62-4d2b-b727-96a0f0c7450b,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-262137d2-887c-498e-9aa4-6af9c9aaac09,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-169a9103-b50f-4639-ab63-410de863ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-e6b7323c-253e-4052-bc5c-a6e484d7c4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471762422-172.17.0.8-1598546549888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35535,DS-671a29b9-8dc6-4680-909f-6e7e0c64dc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-b52f174c-feb8-4fc5-a594-e21b5d82b397,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-69cae8f0-2a28-49c2-95b5-560a384db4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-aff5fcde-21a7-4c85-bb7c-cd65517f1bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-49622155-7a8e-4dd1-9519-b83759f50bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c5fcd951-19da-445b-84b0-50cbb700aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5b442334-9a73-43c3-9430-67e907881493,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-3b5b4e11-caa1-4f62-80fa-23f3c629bf61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471762422-172.17.0.8-1598546549888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35535,DS-671a29b9-8dc6-4680-909f-6e7e0c64dc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-b52f174c-feb8-4fc5-a594-e21b5d82b397,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-69cae8f0-2a28-49c2-95b5-560a384db4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-aff5fcde-21a7-4c85-bb7c-cd65517f1bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-49622155-7a8e-4dd1-9519-b83759f50bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c5fcd951-19da-445b-84b0-50cbb700aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5b442334-9a73-43c3-9430-67e907881493,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-3b5b4e11-caa1-4f62-80fa-23f3c629bf61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652564159-172.17.0.8-1598546923494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-f4747e5e-a16a-43ad-bb88-7eac546b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-c3485756-29a1-483c-b2ac-0b2655a5db31,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-8bab6870-c1ad-4153-a547-e7e452a0959a,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-8961ddd4-0e2a-4b26-9be2-d8f809c8a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4fec979a-2ec7-4281-8b92-f36d17f6949c,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9c31bfa5-440c-4ba9-b810-c971cb2caeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-10efeda0-59e2-46ce-9783-0a3a3c1a921a,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-a6287666-c00a-4976-9eac-cc87e72ea402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652564159-172.17.0.8-1598546923494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-f4747e5e-a16a-43ad-bb88-7eac546b1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-c3485756-29a1-483c-b2ac-0b2655a5db31,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-8bab6870-c1ad-4153-a547-e7e452a0959a,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-8961ddd4-0e2a-4b26-9be2-d8f809c8a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-4fec979a-2ec7-4281-8b92-f36d17f6949c,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9c31bfa5-440c-4ba9-b810-c971cb2caeea,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-10efeda0-59e2-46ce-9783-0a3a3c1a921a,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-a6287666-c00a-4976-9eac-cc87e72ea402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74053683-172.17.0.8-1598547115572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-1b7a994f-12e9-4dfb-986a-ffd58a12b737,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-3821f01a-95aa-44da-948f-ca4a2ca1c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-0e006c92-b411-4643-81d2-875c9ceb9850,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-1a7662e9-0a9a-404c-87c6-db042c517f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-b51e6c2f-3b11-4e4a-990f-d97dd27cdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-aca0bf1e-9fd7-4392-935c-b7cdb7776878,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-7c554ba3-7bc8-4645-9acb-81dd4c0fc4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-834cff85-62f8-45f6-9d11-01e08160c38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74053683-172.17.0.8-1598547115572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-1b7a994f-12e9-4dfb-986a-ffd58a12b737,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-3821f01a-95aa-44da-948f-ca4a2ca1c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-0e006c92-b411-4643-81d2-875c9ceb9850,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-1a7662e9-0a9a-404c-87c6-db042c517f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-b51e6c2f-3b11-4e4a-990f-d97dd27cdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-aca0bf1e-9fd7-4392-935c-b7cdb7776878,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-7c554ba3-7bc8-4645-9acb-81dd4c0fc4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-834cff85-62f8-45f6-9d11-01e08160c38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737917423-172.17.0.8-1598547412180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-d22ed02d-59ac-492d-ab35-419c36676ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-ff883b2a-35e2-4323-8c02-a53de3584db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-36c57067-c94d-41bd-80d1-52147fca8454,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e1b6fca6-d8fb-4030-9d90-18a3bd5fa3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-054175e7-e60b-4111-9891-c9722a5f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a26adfc3-bc2e-4180-b9ea-b1fda634dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-558b5def-08bf-4470-9e51-1d3191b999e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-3a4bb9c1-fe72-455a-a4f9-32cb66996f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737917423-172.17.0.8-1598547412180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-d22ed02d-59ac-492d-ab35-419c36676ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-ff883b2a-35e2-4323-8c02-a53de3584db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-36c57067-c94d-41bd-80d1-52147fca8454,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e1b6fca6-d8fb-4030-9d90-18a3bd5fa3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-054175e7-e60b-4111-9891-c9722a5f6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a26adfc3-bc2e-4180-b9ea-b1fda634dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-558b5def-08bf-4470-9e51-1d3191b999e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-3a4bb9c1-fe72-455a-a4f9-32cb66996f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188431604-172.17.0.8-1598547644641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-bc5cd017-3cdf-4cb4-a45b-a9e8b79a8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-82127aec-6d43-423e-9d84-6e643697f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-a5c3971d-5d49-40cd-af01-d3feb228d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1a2de2f5-13a0-4cf5-b90c-82f1190ba667,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-055fb219-0144-4607-8215-947dc5df0be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-eefc94e1-7ff7-438e-9d5a-d8f64a096662,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-2259d4d4-a74b-4d56-94a9-f6f82c54dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c6edba4f-5851-4422-ab8b-702577765af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188431604-172.17.0.8-1598547644641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-bc5cd017-3cdf-4cb4-a45b-a9e8b79a8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-82127aec-6d43-423e-9d84-6e643697f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-a5c3971d-5d49-40cd-af01-d3feb228d3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-1a2de2f5-13a0-4cf5-b90c-82f1190ba667,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-055fb219-0144-4607-8215-947dc5df0be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-eefc94e1-7ff7-438e-9d5a-d8f64a096662,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-2259d4d4-a74b-4d56-94a9-f6f82c54dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c6edba4f-5851-4422-ab8b-702577765af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301534629-172.17.0.8-1598547794904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-4f0e8eb5-cb82-4235-bdae-649a8bb88cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c3fe1b2c-9b6c-4eee-be38-508a054a5916,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-856f27d0-a9d8-43a9-9cb2-1208821aa449,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-de8d3778-66a5-4094-9065-3daf3af3ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-fc9bdd3c-e01e-4881-81bf-40cf7bc0fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-8814db6b-6d3c-4039-b815-26d77d22a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-90906dfa-53d5-423c-b1d8-7c3dbdb3c845,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-f836519b-7024-47d9-8c6f-cffcebaaff63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301534629-172.17.0.8-1598547794904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-4f0e8eb5-cb82-4235-bdae-649a8bb88cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c3fe1b2c-9b6c-4eee-be38-508a054a5916,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-856f27d0-a9d8-43a9-9cb2-1208821aa449,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-de8d3778-66a5-4094-9065-3daf3af3ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-fc9bdd3c-e01e-4881-81bf-40cf7bc0fd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-8814db6b-6d3c-4039-b815-26d77d22a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-90906dfa-53d5-423c-b1d8-7c3dbdb3c845,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-f836519b-7024-47d9-8c6f-cffcebaaff63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214225666-172.17.0.8-1598548140798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-4c5a7717-ac0d-4c94-8da1-3805898662b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-1f9321bb-2bbe-49a1-baf5-ec953352812a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ab428f0c-35ec-4d34-90ec-c573f911295d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-eb8afbfd-81f9-40d3-a3f1-16d5e876d874,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-77e9e57b-d24b-4a90-b8dc-edc3a35859da,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-33b115bc-3e9d-45bb-b6b3-97a18eb03ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-76ba3ea6-f37d-4231-94d6-7956ece7c099,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-83650c1b-e0ba-48f3-b1bc-d6c1f0546b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214225666-172.17.0.8-1598548140798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-4c5a7717-ac0d-4c94-8da1-3805898662b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-1f9321bb-2bbe-49a1-baf5-ec953352812a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-ab428f0c-35ec-4d34-90ec-c573f911295d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-eb8afbfd-81f9-40d3-a3f1-16d5e876d874,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-77e9e57b-d24b-4a90-b8dc-edc3a35859da,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-33b115bc-3e9d-45bb-b6b3-97a18eb03ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-76ba3ea6-f37d-4231-94d6-7956ece7c099,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-83650c1b-e0ba-48f3-b1bc-d6c1f0546b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800797780-172.17.0.8-1598548443235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-9b5c659e-7a31-4956-ba4d-f7e44f0544c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-a09280ce-bbb4-44dd-9b9f-d772c2e9fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-1f7e5994-b11a-4aa1-8c63-1bcd4ec8a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-3b29af5a-32fc-4ac7-af73-7f0c7cc68a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-8d74b232-7746-4625-8521-8ef17cd57273,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-0da22ce7-3cb0-4774-b40d-91d68dad39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-b088c9d5-e297-4f41-b9c2-cfe043b0e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-9c3a04e5-a279-4da8-a8df-9ae7a169d52d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800797780-172.17.0.8-1598548443235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-9b5c659e-7a31-4956-ba4d-f7e44f0544c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-a09280ce-bbb4-44dd-9b9f-d772c2e9fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-1f7e5994-b11a-4aa1-8c63-1bcd4ec8a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-3b29af5a-32fc-4ac7-af73-7f0c7cc68a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-8d74b232-7746-4625-8521-8ef17cd57273,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-0da22ce7-3cb0-4774-b40d-91d68dad39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-b088c9d5-e297-4f41-b9c2-cfe043b0e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-9c3a04e5-a279-4da8-a8df-9ae7a169d52d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568979106-172.17.0.8-1598548521750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-1567e4b9-905e-4faf-a9dc-ec7a4e4193a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c76222a6-ee51-40d3-9347-c9587392a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fe632f6c-b61e-4921-9a17-0e5e454d3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-759b8e58-81fa-4073-b2ed-c8fb78a53ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-2d45b0b0-eec1-466b-bb0f-6f2aa76811df,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-062f5ce9-75a6-417b-ba16-b967474c5664,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-e654d540-d481-4e30-aab3-bb39dc5c68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-f8105a98-62bc-4b6d-858f-ce0733862cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568979106-172.17.0.8-1598548521750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45186,DS-1567e4b9-905e-4faf-a9dc-ec7a4e4193a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c76222a6-ee51-40d3-9347-c9587392a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-fe632f6c-b61e-4921-9a17-0e5e454d3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-759b8e58-81fa-4073-b2ed-c8fb78a53ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-2d45b0b0-eec1-466b-bb0f-6f2aa76811df,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-062f5ce9-75a6-417b-ba16-b967474c5664,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-e654d540-d481-4e30-aab3-bb39dc5c68f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-f8105a98-62bc-4b6d-858f-ce0733862cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925157694-172.17.0.8-1598549448264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-5c0855dc-2caa-43e2-9498-68e89535c655,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-91602f2a-fbec-4d4f-bfd0-9121d09f7463,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-38a32537-cfbb-4132-a76a-b5401d8b83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-22d8cdc0-39c2-42a5-a016-15c5ae8932af,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-5a2dc441-dc86-46b5-9034-3c67defac8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-848342a4-2740-4b73-b1cf-ea3b20e00ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-470c4706-8644-4305-a836-3689d8be6da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-1691cd2d-c18a-4d49-a168-9aafa67e9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925157694-172.17.0.8-1598549448264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45430,DS-5c0855dc-2caa-43e2-9498-68e89535c655,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-91602f2a-fbec-4d4f-bfd0-9121d09f7463,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-38a32537-cfbb-4132-a76a-b5401d8b83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-22d8cdc0-39c2-42a5-a016-15c5ae8932af,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-5a2dc441-dc86-46b5-9034-3c67defac8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-848342a4-2740-4b73-b1cf-ea3b20e00ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-470c4706-8644-4305-a836-3689d8be6da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-1691cd2d-c18a-4d49-a168-9aafa67e9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702156426-172.17.0.8-1598549999909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-916e9f97-17cb-4e3e-b778-3b4f51bcac65,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-6ff6b063-82ba-45d5-8d4c-94c04f268915,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-e65e33f4-5b0a-479e-a533-67c6dc50f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-52b8d468-c687-40c6-9c4d-a0f0a075f416,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-dfde1086-ffdd-4442-a616-009e0257b770,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a1a71990-99a8-45e1-a33d-37a543f1db83,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-26bdb813-1252-4d34-8776-9facd61ab68a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f46455bd-3ba6-4251-a021-80511fc4f888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702156426-172.17.0.8-1598549999909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-916e9f97-17cb-4e3e-b778-3b4f51bcac65,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-6ff6b063-82ba-45d5-8d4c-94c04f268915,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-e65e33f4-5b0a-479e-a533-67c6dc50f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-52b8d468-c687-40c6-9c4d-a0f0a075f416,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-dfde1086-ffdd-4442-a616-009e0257b770,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a1a71990-99a8-45e1-a33d-37a543f1db83,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-26bdb813-1252-4d34-8776-9facd61ab68a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f46455bd-3ba6-4251-a021-80511fc4f888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901564921-172.17.0.8-1598550152010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-6e8bba43-20e8-4b95-97b3-8caec9a2036a,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-a09789e5-fbbb-4099-adac-03442af625b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-b098b0e7-26a5-4d36-a364-bf49b91046b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-03f4c9fb-7679-4f3e-97f8-eee148139caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-4751580d-5d68-4791-9434-3c9ff22b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-e69eb615-891c-43c9-a907-4364a1ecb654,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-916042b4-0583-4a53-8ebd-67d70d8f1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-2b551410-e1cc-4262-bb7b-17adc5ed9e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901564921-172.17.0.8-1598550152010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-6e8bba43-20e8-4b95-97b3-8caec9a2036a,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-a09789e5-fbbb-4099-adac-03442af625b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-b098b0e7-26a5-4d36-a364-bf49b91046b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-03f4c9fb-7679-4f3e-97f8-eee148139caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-4751580d-5d68-4791-9434-3c9ff22b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-e69eb615-891c-43c9-a907-4364a1ecb654,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-916042b4-0583-4a53-8ebd-67d70d8f1e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-2b551410-e1cc-4262-bb7b-17adc5ed9e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209812366-172.17.0.8-1598550298202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37914,DS-5e5076d5-ded7-4a4f-bfdf-60a8c7bb9694,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-7a73e2b0-f09a-4316-bef1-678bded68842,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-9fb05930-e3e9-4a19-bb1c-df8d90b9df01,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-60e6f056-9e09-4d68-8bda-971e75f0027e,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f749026a-12c4-4c22-aede-e0ee4c58d4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-ff8f889c-4c7c-47ae-ac2b-006091eef207,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-fbde0a5e-6bb4-46f5-baab-0d7238cfe558,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-3814c4a8-52f7-4403-9c69-02801cc813b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209812366-172.17.0.8-1598550298202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37914,DS-5e5076d5-ded7-4a4f-bfdf-60a8c7bb9694,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-7a73e2b0-f09a-4316-bef1-678bded68842,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-9fb05930-e3e9-4a19-bb1c-df8d90b9df01,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-60e6f056-9e09-4d68-8bda-971e75f0027e,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-f749026a-12c4-4c22-aede-e0ee4c58d4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-ff8f889c-4c7c-47ae-ac2b-006091eef207,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-fbde0a5e-6bb4-46f5-baab-0d7238cfe558,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-3814c4a8-52f7-4403-9c69-02801cc813b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763833338-172.17.0.8-1598550712838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-31779aa6-bdce-4edb-a6dc-e412f91e3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-02b87439-3cf9-4ffc-b213-5d76b2a8fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-335e5f99-caf9-4dd8-b114-832bd2255c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-10f3fb76-e6de-4e58-9d08-bdb9036c1c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-66f460cc-a354-44ff-a92a-5534637f12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-51073780-c0c2-462b-91ce-57c4d5bd1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-bac1f277-5451-4d9b-84ad-b6833e9825b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-212df4b3-9ae9-44ac-a168-b021dd5b5f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763833338-172.17.0.8-1598550712838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-31779aa6-bdce-4edb-a6dc-e412f91e3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-02b87439-3cf9-4ffc-b213-5d76b2a8fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-335e5f99-caf9-4dd8-b114-832bd2255c41,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-10f3fb76-e6de-4e58-9d08-bdb9036c1c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-66f460cc-a354-44ff-a92a-5534637f12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-51073780-c0c2-462b-91ce-57c4d5bd1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-bac1f277-5451-4d9b-84ad-b6833e9825b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-212df4b3-9ae9-44ac-a168-b021dd5b5f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050003223-172.17.0.8-1598550792759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-d2cd592d-4aeb-4278-be60-5e05ab342a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-c9293200-4b16-482a-98ba-4c382828a610,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-5bba600b-7db1-4cd5-aea5-8c5309c38080,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-dd3af007-900a-4f78-91a9-92f93eb102cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-b0aac36f-c722-4934-8d22-8df5b2142f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-f4be264f-b7f6-446b-91a9-94540fdd44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-4a325e52-6c9e-4214-9654-3c44e34fe028,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-1bfa6a19-555e-4314-9f02-8ac0785b618e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050003223-172.17.0.8-1598550792759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34549,DS-d2cd592d-4aeb-4278-be60-5e05ab342a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-c9293200-4b16-482a-98ba-4c382828a610,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-5bba600b-7db1-4cd5-aea5-8c5309c38080,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-dd3af007-900a-4f78-91a9-92f93eb102cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-b0aac36f-c722-4934-8d22-8df5b2142f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-f4be264f-b7f6-446b-91a9-94540fdd44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-4a325e52-6c9e-4214-9654-3c44e34fe028,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-1bfa6a19-555e-4314-9f02-8ac0785b618e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074927243-172.17.0.8-1598551195568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-a2f912b4-476d-49b7-995f-3bf053456002,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d154fd0a-7ef7-4db8-a6eb-eabe645be536,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-c443a0f2-6d2c-40ac-8998-4a86bd1bb764,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-b8bd9345-b004-4fb1-8169-ed20fb6cd94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-c469cbc6-eced-4c38-ae33-9dac979653ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-f1a522f6-a143-4397-9b1d-5ac19eb6e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ac221186-49dc-43a7-8124-604a28e19f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-676b9145-7ea5-411d-aa15-ac290ba7b5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074927243-172.17.0.8-1598551195568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-a2f912b4-476d-49b7-995f-3bf053456002,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d154fd0a-7ef7-4db8-a6eb-eabe645be536,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-c443a0f2-6d2c-40ac-8998-4a86bd1bb764,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-b8bd9345-b004-4fb1-8169-ed20fb6cd94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-c469cbc6-eced-4c38-ae33-9dac979653ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-f1a522f6-a143-4397-9b1d-5ac19eb6e78c,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ac221186-49dc-43a7-8124-604a28e19f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-676b9145-7ea5-411d-aa15-ac290ba7b5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5559
