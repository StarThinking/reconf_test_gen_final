reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740034857-172.17.0.8-1598664210106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-d0ee50b9-ddad-428f-867e-d00a17696a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-995c37e2-8efc-4131-974b-9f1e019799b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-b2715559-6f24-49a7-ba77-a667dd074930,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-313ab747-6c2d-43c1-8f65-b1283123e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-6f986d94-c027-40e6-a6d9-42ed09e21933,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-d76d004c-0904-498d-94d4-3f293f7532c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-4ae8721d-379f-4302-b3bd-0d42a1a69067,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-c2741249-2309-4faf-bd7b-fa70ebc730b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740034857-172.17.0.8-1598664210106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-d0ee50b9-ddad-428f-867e-d00a17696a40,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-995c37e2-8efc-4131-974b-9f1e019799b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-b2715559-6f24-49a7-ba77-a667dd074930,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-313ab747-6c2d-43c1-8f65-b1283123e2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-6f986d94-c027-40e6-a6d9-42ed09e21933,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-d76d004c-0904-498d-94d4-3f293f7532c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-4ae8721d-379f-4302-b3bd-0d42a1a69067,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-c2741249-2309-4faf-bd7b-fa70ebc730b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855333494-172.17.0.8-1598664285697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-7dd913a5-0ddb-42e7-a748-317d1910da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d3555160-364f-4a17-81b1-7fc9e27e4749,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-f64e6031-c60a-40a6-867a-27d206973817,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-250b32f3-b816-410f-b9c5-653d129123d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-c4186712-cc28-44cb-acc7-b1d72cd77a04,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-f2f32128-3997-4237-9b9c-fb86b064dc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-7d77ebbc-5a0d-4c3f-8bf1-dab199356d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2affb801-8706-490e-8c76-b4e42e8f7ac6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855333494-172.17.0.8-1598664285697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-7dd913a5-0ddb-42e7-a748-317d1910da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d3555160-364f-4a17-81b1-7fc9e27e4749,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-f64e6031-c60a-40a6-867a-27d206973817,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-250b32f3-b816-410f-b9c5-653d129123d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-c4186712-cc28-44cb-acc7-b1d72cd77a04,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-f2f32128-3997-4237-9b9c-fb86b064dc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-7d77ebbc-5a0d-4c3f-8bf1-dab199356d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-2affb801-8706-490e-8c76-b4e42e8f7ac6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669073822-172.17.0.8-1598664316297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43004,DS-73e2c889-bf93-40a5-ae8f-a26fb798d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-279d2572-3aaa-4492-9d00-083455c8840b,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-d207442b-327f-47ba-a150-f6101fc4a30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-84c4a3c6-fc5d-4751-babc-63f8c534c086,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-45bb8052-90ed-419d-b37d-056e279c0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-e63f51d0-86e2-45be-a155-97964fac51fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-03ad9f9a-0c0b-4bf9-ba83-2a0f63399043,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-63b21a00-64a4-4093-bc87-22748eaade5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669073822-172.17.0.8-1598664316297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43004,DS-73e2c889-bf93-40a5-ae8f-a26fb798d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-279d2572-3aaa-4492-9d00-083455c8840b,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-d207442b-327f-47ba-a150-f6101fc4a30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-84c4a3c6-fc5d-4751-babc-63f8c534c086,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-45bb8052-90ed-419d-b37d-056e279c0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-e63f51d0-86e2-45be-a155-97964fac51fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-03ad9f9a-0c0b-4bf9-ba83-2a0f63399043,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-63b21a00-64a4-4093-bc87-22748eaade5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079095819-172.17.0.8-1598664425623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-74a95a9a-e651-4c2d-9da4-304a5be97429,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-64068368-21ac-4e64-8898-4a36fa5aa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-e4ee2b3c-af1e-4677-b35a-7ad4737ebead,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-3432f413-7699-4a67-ab20-158c57e98bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-9b5d9200-ed26-4591-9755-9ebefd0106aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-91bad2de-9427-4be7-9238-ba3f37868c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-45889a0b-7495-46ea-a963-7970352fcca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1b0374ef-a073-4bcd-816a-8e1ca9313392,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079095819-172.17.0.8-1598664425623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-74a95a9a-e651-4c2d-9da4-304a5be97429,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-64068368-21ac-4e64-8898-4a36fa5aa9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-e4ee2b3c-af1e-4677-b35a-7ad4737ebead,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-3432f413-7699-4a67-ab20-158c57e98bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-9b5d9200-ed26-4591-9755-9ebefd0106aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-91bad2de-9427-4be7-9238-ba3f37868c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-45889a0b-7495-46ea-a963-7970352fcca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-1b0374ef-a073-4bcd-816a-8e1ca9313392,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890791837-172.17.0.8-1598664462160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-2a842434-2c60-4fef-a84f-ba05ad10aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-a2ca8115-aad7-49a7-b612-8416396836e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-023ed22b-577c-4801-8c7d-9bc7924db74c,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-49ce752e-a3b7-48f0-9fd8-27025ae5c357,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-bd47ac65-7eb5-49dd-b567-c0a11f796e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-42e0c3c4-86be-4f8f-9abe-13d97180c211,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-c574a20e-911c-45a4-901e-3ae620445bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-1e0155c9-915d-493d-b818-137d0d212aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890791837-172.17.0.8-1598664462160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41300,DS-2a842434-2c60-4fef-a84f-ba05ad10aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-a2ca8115-aad7-49a7-b612-8416396836e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-023ed22b-577c-4801-8c7d-9bc7924db74c,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-49ce752e-a3b7-48f0-9fd8-27025ae5c357,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-bd47ac65-7eb5-49dd-b567-c0a11f796e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-42e0c3c4-86be-4f8f-9abe-13d97180c211,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-c574a20e-911c-45a4-901e-3ae620445bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-1e0155c9-915d-493d-b818-137d0d212aba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306266932-172.17.0.8-1598664939470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-79a34660-cd7e-4f42-b030-caf77ff4f891,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-6e936540-cb82-47df-a067-13ec5fd9bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-5b8a362c-02a4-4362-bc88-326e09eac83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-d834d927-bf0b-4ff2-9398-055701ac9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-92f1678a-874c-426e-96d6-67d00130fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-a9ad2892-4e48-4f4e-a4b2-42414d1fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-3e9d2497-0498-4aaa-9060-9ef49edaa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ca50eec6-4b47-4681-9b52-4c0ad125ad5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306266932-172.17.0.8-1598664939470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-79a34660-cd7e-4f42-b030-caf77ff4f891,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-6e936540-cb82-47df-a067-13ec5fd9bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-5b8a362c-02a4-4362-bc88-326e09eac83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-d834d927-bf0b-4ff2-9398-055701ac9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-92f1678a-874c-426e-96d6-67d00130fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-a9ad2892-4e48-4f4e-a4b2-42414d1fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-3e9d2497-0498-4aaa-9060-9ef49edaa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ca50eec6-4b47-4681-9b52-4c0ad125ad5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579867291-172.17.0.8-1598665344530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-d8742b6b-8bda-4906-93de-ba5b4ceb4868,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-737b8079-874f-49cb-a89a-33c82afdf510,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-8c20b058-40ab-4ce9-a644-fcfffa11abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-c2edcd71-6ec6-4ce5-a2f8-6c5f2fb9b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-be88a53b-3f00-46d3-9f48-b15d7ec878ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-774e3899-d6cc-49d8-ae26-d2cdd6471947,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-9feeade6-ce77-419b-a22c-1381e8d53e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-91572604-79e6-4297-a1e5-62cf3ecad09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579867291-172.17.0.8-1598665344530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44421,DS-d8742b6b-8bda-4906-93de-ba5b4ceb4868,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-737b8079-874f-49cb-a89a-33c82afdf510,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-8c20b058-40ab-4ce9-a644-fcfffa11abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-c2edcd71-6ec6-4ce5-a2f8-6c5f2fb9b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-be88a53b-3f00-46d3-9f48-b15d7ec878ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-774e3899-d6cc-49d8-ae26-d2cdd6471947,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-9feeade6-ce77-419b-a22c-1381e8d53e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-91572604-79e6-4297-a1e5-62cf3ecad09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265300515-172.17.0.8-1598665660249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-dd6fe13f-7146-46d5-92bb-59aa62de5275,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-b98debe8-2235-41da-b339-2cf3619d47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-fcbcc879-9444-4616-ac09-6b1cff0235b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-a254e87c-0dad-444e-a8c1-858fb93eaa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-936d365c-4ff7-4a98-9a8b-f08db0c5cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7b91290d-859f-41a1-8707-fb65dfa337ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-b972bd3a-f1b3-4ec0-accf-09f1db91efa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-37ebca3f-0b06-4e92-9ef8-1b9ecf642b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265300515-172.17.0.8-1598665660249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-dd6fe13f-7146-46d5-92bb-59aa62de5275,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-b98debe8-2235-41da-b339-2cf3619d47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-fcbcc879-9444-4616-ac09-6b1cff0235b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-a254e87c-0dad-444e-a8c1-858fb93eaa99,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-936d365c-4ff7-4a98-9a8b-f08db0c5cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-7b91290d-859f-41a1-8707-fb65dfa337ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-b972bd3a-f1b3-4ec0-accf-09f1db91efa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-37ebca3f-0b06-4e92-9ef8-1b9ecf642b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190256076-172.17.0.8-1598665693412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-58e58edc-980d-4883-b377-77562d600c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-fcbc16c4-e5ce-4179-b8d4-449334626426,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-25997e58-3bc5-45f2-90cb-6f301e33a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-2a6969c4-baf7-4859-9ee3-c412c744a538,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-49fcc797-02c8-45e8-9843-2f8b33d622ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-40b7777a-ea7a-453b-853d-648eac02ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-b355a96a-701d-42ae-bc64-27881d7bcace,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-1f45aba0-ad21-47d5-97c0-48819e14e797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190256076-172.17.0.8-1598665693412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46602,DS-58e58edc-980d-4883-b377-77562d600c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-fcbc16c4-e5ce-4179-b8d4-449334626426,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-25997e58-3bc5-45f2-90cb-6f301e33a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-2a6969c4-baf7-4859-9ee3-c412c744a538,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-49fcc797-02c8-45e8-9843-2f8b33d622ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-40b7777a-ea7a-453b-853d-648eac02ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-b355a96a-701d-42ae-bc64-27881d7bcace,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-1f45aba0-ad21-47d5-97c0-48819e14e797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836021218-172.17.0.8-1598666145387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-1f2642f3-cbc5-4060-a359-e5d1331c9fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-14f33718-8c05-4fe2-baec-7ed9a7915159,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-d870a910-b98d-4eb2-869a-7ab3a2ed11e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-c8577bb4-5f10-456c-a2f5-0fcbc87f61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-d411af72-0ecd-4579-979d-66af301c418d,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-172fbda0-62aa-42ee-b637-201ff4230e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-00674c9d-1cdb-4568-baf2-d3377df5749c,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d715a748-6934-4aea-9d01-03423536b379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836021218-172.17.0.8-1598666145387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-1f2642f3-cbc5-4060-a359-e5d1331c9fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-14f33718-8c05-4fe2-baec-7ed9a7915159,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-d870a910-b98d-4eb2-869a-7ab3a2ed11e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-c8577bb4-5f10-456c-a2f5-0fcbc87f61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-d411af72-0ecd-4579-979d-66af301c418d,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-172fbda0-62aa-42ee-b637-201ff4230e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-00674c9d-1cdb-4568-baf2-d3377df5749c,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d715a748-6934-4aea-9d01-03423536b379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870127052-172.17.0.8-1598666180340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-890e46ea-71ff-46ec-ad50-f2ce34cdbaac,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-ba28e3dc-8d9c-4239-a5af-510e19ac3874,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d05ad1e7-f3ed-4398-bcf1-ee1f01c60f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-b64cb111-3de7-40eb-8f50-614cacf26b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-f7275c5d-9e26-4c58-b966-e96e93076a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-7988494f-8711-493c-90bb-5052c1bd8535,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-9ea149a5-327e-42ee-9605-74caddf6a460,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-2bfc5651-a601-4ffc-b6f7-77e5676bbec0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870127052-172.17.0.8-1598666180340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-890e46ea-71ff-46ec-ad50-f2ce34cdbaac,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-ba28e3dc-8d9c-4239-a5af-510e19ac3874,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-d05ad1e7-f3ed-4398-bcf1-ee1f01c60f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-b64cb111-3de7-40eb-8f50-614cacf26b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-f7275c5d-9e26-4c58-b966-e96e93076a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-7988494f-8711-493c-90bb-5052c1bd8535,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-9ea149a5-327e-42ee-9605-74caddf6a460,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-2bfc5651-a601-4ffc-b6f7-77e5676bbec0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015773644-172.17.0.8-1598666291008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-6562567c-8394-4a33-a595-7f4214fab482,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1d46bff5-d0d6-485b-99d7-c29e5b165c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d689fd4f-e214-4aa3-921f-9909a6f351b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-7cdb844b-1430-4a35-8398-adb9d2bd5552,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-94cafcd9-d34e-48ef-b2ef-b1d80a2955d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-80096e96-d15f-4385-9ee2-ff6274287b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-2153e88f-4713-4227-ab35-e92d1afb1036,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-93d6571c-8dc9-4a74-8a8f-9f69aa7f3a59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015773644-172.17.0.8-1598666291008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-6562567c-8394-4a33-a595-7f4214fab482,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1d46bff5-d0d6-485b-99d7-c29e5b165c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d689fd4f-e214-4aa3-921f-9909a6f351b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-7cdb844b-1430-4a35-8398-adb9d2bd5552,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-94cafcd9-d34e-48ef-b2ef-b1d80a2955d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-80096e96-d15f-4385-9ee2-ff6274287b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-2153e88f-4713-4227-ab35-e92d1afb1036,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-93d6571c-8dc9-4a74-8a8f-9f69aa7f3a59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389539156-172.17.0.8-1598666391746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-60c978a6-febc-4e02-86a5-c93bb983c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-c19f5511-87cd-49e5-a532-a699d9945d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-bbf7508e-dcfe-480f-b5f7-7cfa9899b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-185ab32d-a9d9-4caf-a4b0-d8b874104a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-ce311fb1-545d-4218-8515-64d69f2e8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-fda58b83-3e98-4081-9bc8-61117f9a0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ca816c80-7283-4d94-a374-1f3401de3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ec9c4e42-80dc-44c2-a53c-ec203fe08f03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389539156-172.17.0.8-1598666391746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45970,DS-60c978a6-febc-4e02-86a5-c93bb983c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-c19f5511-87cd-49e5-a532-a699d9945d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-bbf7508e-dcfe-480f-b5f7-7cfa9899b31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-185ab32d-a9d9-4caf-a4b0-d8b874104a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-ce311fb1-545d-4218-8515-64d69f2e8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-fda58b83-3e98-4081-9bc8-61117f9a0b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ca816c80-7283-4d94-a374-1f3401de3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-ec9c4e42-80dc-44c2-a53c-ec203fe08f03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907125345-172.17.0.8-1598666526961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-d5ce060a-dc7c-4019-b812-044f5dbb601c,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-038c2cbd-503b-4c36-8367-b881f5e421f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8e419ec1-8582-47fb-ba6a-05acb83fa818,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-a141811f-857a-47c4-b1c2-9060115981c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1fd5884e-d012-40ae-a771-2f0184597de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-c2fc0606-fc66-41ed-bb06-6ab32bac6741,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-216e58c6-2ff0-48b0-8f8c-aa6fbd1fd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-4c74f315-38fe-4db5-a550-db08cd6f9306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907125345-172.17.0.8-1598666526961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-d5ce060a-dc7c-4019-b812-044f5dbb601c,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-038c2cbd-503b-4c36-8367-b881f5e421f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8e419ec1-8582-47fb-ba6a-05acb83fa818,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-a141811f-857a-47c4-b1c2-9060115981c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1fd5884e-d012-40ae-a771-2f0184597de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-c2fc0606-fc66-41ed-bb06-6ab32bac6741,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-216e58c6-2ff0-48b0-8f8c-aa6fbd1fd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-4c74f315-38fe-4db5-a550-db08cd6f9306,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011687738-172.17.0.8-1598666562819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-2834c0b0-8981-44ee-8441-e4f5e7714622,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-fc280caf-899d-495b-9fdb-00cdff73b317,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-9326b086-742e-4864-b5ed-a698d6f19420,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e142cb58-5084-4328-8d51-648489f4ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-c1b62aa1-4934-447c-8074-d160ea080a03,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-a5b754ce-e3bd-4470-abcc-624d1537dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-98f54965-4216-41c7-a332-16083fcf36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-30988316-d816-4c3c-b068-6c1dba909594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011687738-172.17.0.8-1598666562819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-2834c0b0-8981-44ee-8441-e4f5e7714622,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-fc280caf-899d-495b-9fdb-00cdff73b317,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-9326b086-742e-4864-b5ed-a698d6f19420,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e142cb58-5084-4328-8d51-648489f4ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-c1b62aa1-4934-447c-8074-d160ea080a03,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-a5b754ce-e3bd-4470-abcc-624d1537dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-98f54965-4216-41c7-a332-16083fcf36a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-30988316-d816-4c3c-b068-6c1dba909594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569177776-172.17.0.8-1598666777108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-55cb5ace-4f59-461c-a169-87771474fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-fbeaba50-aa91-4aba-8df0-977d32910241,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a67476c8-9b80-4bf6-befe-ceb110fc21ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-ae270c46-eeaa-47a1-bcf9-f23a65490980,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-fb276882-9ba0-42d4-9ebe-6a07bf318097,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-7539d6b5-db1d-4b5a-87b6-162d175777e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-0d3debb3-6584-4b85-a166-5ebca610a612,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c69b9f57-095b-47b7-a50a-7da725d07610,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569177776-172.17.0.8-1598666777108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-55cb5ace-4f59-461c-a169-87771474fa11,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-fbeaba50-aa91-4aba-8df0-977d32910241,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-a67476c8-9b80-4bf6-befe-ceb110fc21ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-ae270c46-eeaa-47a1-bcf9-f23a65490980,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-fb276882-9ba0-42d4-9ebe-6a07bf318097,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-7539d6b5-db1d-4b5a-87b6-162d175777e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-0d3debb3-6584-4b85-a166-5ebca610a612,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c69b9f57-095b-47b7-a50a-7da725d07610,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799398872-172.17.0.8-1598667090207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-dc8c9af2-5a90-4988-8880-7b3214cadaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-7e614721-0a76-4250-8bf8-946bce0cded2,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-01a50e5c-f80e-4368-8253-94621c66b842,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-6badfb54-150d-4a83-8088-93801a9accfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-8d4d8987-2a62-4c18-aeb0-f9419339c620,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-d66011f2-2327-4003-90e0-a14aee5b6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-28d76c2c-94af-420b-b3dd-7a63e0656890,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-c986af80-9319-480c-938a-8db427e64976,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799398872-172.17.0.8-1598667090207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-dc8c9af2-5a90-4988-8880-7b3214cadaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-7e614721-0a76-4250-8bf8-946bce0cded2,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-01a50e5c-f80e-4368-8253-94621c66b842,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-6badfb54-150d-4a83-8088-93801a9accfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-8d4d8987-2a62-4c18-aeb0-f9419339c620,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-d66011f2-2327-4003-90e0-a14aee5b6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-28d76c2c-94af-420b-b3dd-7a63e0656890,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-c986af80-9319-480c-938a-8db427e64976,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933841556-172.17.0.8-1598667338144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-bbd11749-aabd-445f-8745-46335c57627e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-bdf6acfc-9dd6-44b5-bf8b-ac0e9da5c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-158e26ee-85cd-4b6c-a5bb-edaba5f7c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-6a3921d6-6c00-445d-b7e9-2c5768637cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4af79733-d011-488c-856a-bbe41e2fa282,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-68dce407-f2b1-4891-a5aa-e62ea9422bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-3baa11fa-9aaa-463f-91b7-ac5f010395a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-d609bc07-7368-4677-87d0-851e3f1b72eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933841556-172.17.0.8-1598667338144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-bbd11749-aabd-445f-8745-46335c57627e,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-bdf6acfc-9dd6-44b5-bf8b-ac0e9da5c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-158e26ee-85cd-4b6c-a5bb-edaba5f7c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-6a3921d6-6c00-445d-b7e9-2c5768637cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4af79733-d011-488c-856a-bbe41e2fa282,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-68dce407-f2b1-4891-a5aa-e62ea9422bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-3baa11fa-9aaa-463f-91b7-ac5f010395a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-d609bc07-7368-4677-87d0-851e3f1b72eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004540359-172.17.0.8-1598667699643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-3db2e167-1c47-472f-a556-ee2a78d23260,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-dc5ee496-c043-4f9e-ab8d-a309d6d6d63a,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-8ced64c5-c153-4b5e-8416-392490ea7627,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-874177f8-627a-42d1-8a02-ce90afc589da,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f546cef4-5052-4c83-8bb7-b3f696e4b385,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-5c4ccc29-0553-4a66-b1c7-66062c30d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-ce01be27-7743-425e-af4b-5c51330670cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-de3449f6-ccb5-4932-b7db-7e46b9f47b6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004540359-172.17.0.8-1598667699643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-3db2e167-1c47-472f-a556-ee2a78d23260,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-dc5ee496-c043-4f9e-ab8d-a309d6d6d63a,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-8ced64c5-c153-4b5e-8416-392490ea7627,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-874177f8-627a-42d1-8a02-ce90afc589da,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f546cef4-5052-4c83-8bb7-b3f696e4b385,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-5c4ccc29-0553-4a66-b1c7-66062c30d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-ce01be27-7743-425e-af4b-5c51330670cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-de3449f6-ccb5-4932-b7db-7e46b9f47b6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651032879-172.17.0.8-1598667764784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44528,DS-f8cf15a3-bcf8-4113-9d48-a4809638a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4d8449f7-c13f-47b6-983f-b581e3324f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-ab36d3d2-6684-4c8b-9f34-8baeb41b3746,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8bbd4f3b-5d01-4d7d-94df-865b8ad6ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-f6b9a066-d579-45d8-b2a5-37dcb4fcac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f40a9089-3146-4b8c-88dd-eb8a6ad78050,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-eb7bfd6f-f295-43b1-aa9c-e7be9d1ca4be,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-7ec2e893-d230-40da-8969-cd1bc2a297a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651032879-172.17.0.8-1598667764784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44528,DS-f8cf15a3-bcf8-4113-9d48-a4809638a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4d8449f7-c13f-47b6-983f-b581e3324f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-ab36d3d2-6684-4c8b-9f34-8baeb41b3746,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-8bbd4f3b-5d01-4d7d-94df-865b8ad6ba59,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-f6b9a066-d579-45d8-b2a5-37dcb4fcac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f40a9089-3146-4b8c-88dd-eb8a6ad78050,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-eb7bfd6f-f295-43b1-aa9c-e7be9d1ca4be,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-7ec2e893-d230-40da-8969-cd1bc2a297a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836352311-172.17.0.8-1598667895696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-1778a70b-724c-46ec-82a3-0493bc68f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-73763db0-a14f-4751-9683-95a9354c2c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2014b118-58c8-4ff0-ad07-e38924271eda,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-79d09f5c-0ac3-4fa0-977d-1ae4a6b56337,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-90ba17d1-cf38-4d49-a691-41e4b0e8a038,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-0ba38b1f-39e6-4d92-85a2-1556402b2fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-c6c57f0b-eb5e-477f-94c4-7a6911a2b896,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-6680864b-51a2-4e51-b137-67dff91f84ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836352311-172.17.0.8-1598667895696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-1778a70b-724c-46ec-82a3-0493bc68f2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-73763db0-a14f-4751-9683-95a9354c2c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2014b118-58c8-4ff0-ad07-e38924271eda,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-79d09f5c-0ac3-4fa0-977d-1ae4a6b56337,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-90ba17d1-cf38-4d49-a691-41e4b0e8a038,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-0ba38b1f-39e6-4d92-85a2-1556402b2fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-c6c57f0b-eb5e-477f-94c4-7a6911a2b896,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-6680864b-51a2-4e51-b137-67dff91f84ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38633798-172.17.0.8-1598667959881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-30143535-3bee-4405-8f60-9f4e36a00571,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-f600876d-ce14-46c2-a6d4-8ee297c7c517,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-651330b1-cc50-43fd-9984-f1f28c16d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-7e852264-b718-488c-9e60-a2deb8459434,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-6a3b0a70-f082-4790-8e91-aa11a0740153,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-0d3ae2bd-bf5f-4a1b-9c57-dc478fdbcf35,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-297084b3-f015-4cdc-9a06-86765c4a23aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-d7158b2f-677b-4bf6-9129-f8f3b3f22829,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38633798-172.17.0.8-1598667959881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-30143535-3bee-4405-8f60-9f4e36a00571,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-f600876d-ce14-46c2-a6d4-8ee297c7c517,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-651330b1-cc50-43fd-9984-f1f28c16d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-7e852264-b718-488c-9e60-a2deb8459434,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-6a3b0a70-f082-4790-8e91-aa11a0740153,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-0d3ae2bd-bf5f-4a1b-9c57-dc478fdbcf35,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-297084b3-f015-4cdc-9a06-86765c4a23aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-d7158b2f-677b-4bf6-9129-f8f3b3f22829,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271020658-172.17.0.8-1598668051014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-4e71d102-258b-4b16-a749-824a0c13f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-8c9335b2-da6c-4a86-b1c4-06097ae17a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-bf59ba26-1fba-4f41-928f-3be046ddcb90,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-6661e9e7-1aff-4799-b9b0-d725e7496824,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-5eec7b09-655b-4cb0-8829-da7422d21ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-fd34582f-3d18-4907-a5eb-da9634700353,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-dd91077d-1092-40a8-ac1e-673f938ddc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-d18d362a-1d42-4767-adaa-5fbd4803ec1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271020658-172.17.0.8-1598668051014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-4e71d102-258b-4b16-a749-824a0c13f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-8c9335b2-da6c-4a86-b1c4-06097ae17a23,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-bf59ba26-1fba-4f41-928f-3be046ddcb90,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-6661e9e7-1aff-4799-b9b0-d725e7496824,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-5eec7b09-655b-4cb0-8829-da7422d21ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-fd34582f-3d18-4907-a5eb-da9634700353,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-dd91077d-1092-40a8-ac1e-673f938ddc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-d18d362a-1d42-4767-adaa-5fbd4803ec1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68441711-172.17.0.8-1598668083456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-2d8412b1-8198-4dc0-9be0-a77f883e4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9f92dab5-7dd7-4505-b80c-0e53fb9934ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-00bd5fe4-4e87-4109-9223-6a261ed397ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-3f64ed17-3fdb-4e6b-822e-c1327cb95015,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-c7c6fefb-d661-403e-b250-6b70c7f25458,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-8da448a0-b1e5-488b-9881-2c068dd5c579,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-e5fe31d6-40bb-4999-9273-a5089454c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-6a171c57-8b6f-49c8-b376-820760561d9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68441711-172.17.0.8-1598668083456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-2d8412b1-8198-4dc0-9be0-a77f883e4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9f92dab5-7dd7-4505-b80c-0e53fb9934ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-00bd5fe4-4e87-4109-9223-6a261ed397ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-3f64ed17-3fdb-4e6b-822e-c1327cb95015,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-c7c6fefb-d661-403e-b250-6b70c7f25458,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-8da448a0-b1e5-488b-9881-2c068dd5c579,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-e5fe31d6-40bb-4999-9273-a5089454c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-6a171c57-8b6f-49c8-b376-820760561d9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325839108-172.17.0.8-1598668242151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-88869271-e2e6-43c0-91b5-2cc6ad556f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-e49de99d-a61d-4897-ab96-80ce8559bbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-452a4283-bd2d-407d-a315-3d8554c1951a,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-529fbfe7-b611-4493-9321-79e41e7f126a,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-4d21b6bc-2f37-4948-adee-481928a0d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-d02c40a9-bbc4-495d-92eb-08e6fb333a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-67a3c0be-a94a-4ad3-900f-3d72b211b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-b67d35b1-72a1-46cc-bd4d-760dc3a4bda4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325839108-172.17.0.8-1598668242151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-88869271-e2e6-43c0-91b5-2cc6ad556f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-e49de99d-a61d-4897-ab96-80ce8559bbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-452a4283-bd2d-407d-a315-3d8554c1951a,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-529fbfe7-b611-4493-9321-79e41e7f126a,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-4d21b6bc-2f37-4948-adee-481928a0d7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-d02c40a9-bbc4-495d-92eb-08e6fb333a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-67a3c0be-a94a-4ad3-900f-3d72b211b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-b67d35b1-72a1-46cc-bd4d-760dc3a4bda4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326732588-172.17.0.8-1598668398720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-7e21dbe5-0329-4c29-a461-b3afc78f5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-34b10943-65e5-46d3-a0d2-e7d865a052e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-86c909c9-b0e8-4881-abdd-0b9eb3d963cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-df7b4eff-06d3-404b-ab65-b05a133f6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-7fe182bd-5671-4a1e-9b73-9452446eaf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-05ca0378-a0aa-483e-a199-f26ceb82cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-f5d871b8-8a41-466e-b620-13e9327ee6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-bdf53846-3b94-49f4-a984-93cb6287597c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326732588-172.17.0.8-1598668398720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-7e21dbe5-0329-4c29-a461-b3afc78f5dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-34b10943-65e5-46d3-a0d2-e7d865a052e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-86c909c9-b0e8-4881-abdd-0b9eb3d963cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-df7b4eff-06d3-404b-ab65-b05a133f6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-7fe182bd-5671-4a1e-9b73-9452446eaf79,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-05ca0378-a0aa-483e-a199-f26ceb82cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-f5d871b8-8a41-466e-b620-13e9327ee6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-bdf53846-3b94-49f4-a984-93cb6287597c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257036768-172.17.0.8-1598668432087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33062,DS-832c60c7-76f4-4ca7-8d75-3db2ccebe231,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-83f049f2-1466-455e-9b10-0c0468c780c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-33e0c84a-eeb4-40ea-98f2-3340934d9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-993cc546-af48-435f-b16f-fe2607968c19,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-6837caa4-7138-4e78-9a4a-fe2d4b575b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-6ae1bf40-cf00-4a3a-b667-26bae5378db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-ca3ba9de-a166-4de1-b7cd-f1fd287e6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-8f268e79-aa1f-47a8-aa91-a14538aedbfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257036768-172.17.0.8-1598668432087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33062,DS-832c60c7-76f4-4ca7-8d75-3db2ccebe231,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-83f049f2-1466-455e-9b10-0c0468c780c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-33e0c84a-eeb4-40ea-98f2-3340934d9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-993cc546-af48-435f-b16f-fe2607968c19,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-6837caa4-7138-4e78-9a4a-fe2d4b575b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-6ae1bf40-cf00-4a3a-b667-26bae5378db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-ca3ba9de-a166-4de1-b7cd-f1fd287e6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-8f268e79-aa1f-47a8-aa91-a14538aedbfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672262162-172.17.0.8-1598668502634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-f8e1ffc5-35b7-4d45-b4a8-281f62d113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-757e445a-0e85-44b8-a4aa-167cfb7b6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-da801795-a021-475d-84df-da13a9f41d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-fa6bc635-bbc1-4cb2-96d1-6e8f95605081,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-7e4232dc-7a99-4907-abd2-b886e2853985,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-ecf8c909-cba8-43aa-94c1-0983a6cbffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-8c86e9ed-dc51-44c1-b2e7-f42a11463645,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-62f7c758-14db-4461-aa53-93d54bb490fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672262162-172.17.0.8-1598668502634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-f8e1ffc5-35b7-4d45-b4a8-281f62d113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-757e445a-0e85-44b8-a4aa-167cfb7b6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-da801795-a021-475d-84df-da13a9f41d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-fa6bc635-bbc1-4cb2-96d1-6e8f95605081,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-7e4232dc-7a99-4907-abd2-b886e2853985,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-ecf8c909-cba8-43aa-94c1-0983a6cbffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-8c86e9ed-dc51-44c1-b2e7-f42a11463645,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-62f7c758-14db-4461-aa53-93d54bb490fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463167203-172.17.0.8-1598668571683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-acedecf9-da22-4339-bd48-67a9d2b1a304,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-c841bc43-222f-40e2-aa2f-723fdaa41ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-8d4dfe29-2d9e-4480-974f-2afe4f437b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-a8673bd5-735c-4f60-a6c4-7e4d64ccdb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-53bbcd55-24a3-4119-a517-604ec30fff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-e9e80c4d-20c9-441e-9cb1-943e1bf8e711,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-eb91ebc0-00a1-4f01-989a-f11fe8d2c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-a2b48e11-412e-42f5-9038-87db0cf00a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463167203-172.17.0.8-1598668571683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-acedecf9-da22-4339-bd48-67a9d2b1a304,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-c841bc43-222f-40e2-aa2f-723fdaa41ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-8d4dfe29-2d9e-4480-974f-2afe4f437b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-a8673bd5-735c-4f60-a6c4-7e4d64ccdb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-53bbcd55-24a3-4119-a517-604ec30fff8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-e9e80c4d-20c9-441e-9cb1-943e1bf8e711,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-eb91ebc0-00a1-4f01-989a-f11fe8d2c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-a2b48e11-412e-42f5-9038-87db0cf00a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570329082-172.17.0.8-1598668608396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-2a90ce14-866c-4c3c-9cd5-f3ebb9074587,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-3ae993c6-bd94-43f3-91b0-7623b0c4df5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-1c27bc27-5fd8-4990-9ee0-06da36be296d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-b3d0c5af-0e5d-4bea-9a49-e3614a3a3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-f88351c1-3c7f-478b-8ac2-d551ba49beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-942f2d80-a68f-4d2a-8de7-3aa346a2f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-6cb59b9d-e37f-485e-b10b-2985aadff08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-3e39439d-eb1d-41f9-9774-f1692aa4eb86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570329082-172.17.0.8-1598668608396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42511,DS-2a90ce14-866c-4c3c-9cd5-f3ebb9074587,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-3ae993c6-bd94-43f3-91b0-7623b0c4df5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-1c27bc27-5fd8-4990-9ee0-06da36be296d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-b3d0c5af-0e5d-4bea-9a49-e3614a3a3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-f88351c1-3c7f-478b-8ac2-d551ba49beaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-942f2d80-a68f-4d2a-8de7-3aa346a2f39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-6cb59b9d-e37f-485e-b10b-2985aadff08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-3e39439d-eb1d-41f9-9774-f1692aa4eb86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023284927-172.17.0.8-1598668750183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-6fb61b16-1bec-431a-91f6-4abe45791ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-777cd400-6703-4b1d-a523-c694f5fc0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-bf16ccfd-15de-45b2-8a92-95a6fc514c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-38d989d0-4157-4e6f-b861-7e338c192893,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-fbe250bf-426c-4b5c-ada7-3f3546e7e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-43113423-6654-476d-a323-61aebc68f537,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-4c99a192-b79a-43c8-8355-b7e123715c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-d42b969e-b5bb-4569-86fd-ca93107d4f08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023284927-172.17.0.8-1598668750183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-6fb61b16-1bec-431a-91f6-4abe45791ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-777cd400-6703-4b1d-a523-c694f5fc0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-bf16ccfd-15de-45b2-8a92-95a6fc514c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-38d989d0-4157-4e6f-b861-7e338c192893,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-fbe250bf-426c-4b5c-ada7-3f3546e7e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-43113423-6654-476d-a323-61aebc68f537,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-4c99a192-b79a-43c8-8355-b7e123715c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-d42b969e-b5bb-4569-86fd-ca93107d4f08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136664899-172.17.0.8-1598668928238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-e2898d0e-b59a-42e3-8cce-53e4122f9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-99342e2e-0d52-47ab-8cee-88cb0040b634,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-1365956d-6dc3-411f-a92c-7d0a04e945ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b942abc6-0698-41d1-b31e-9bb4a040353c,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-ae51b7e3-f919-4a1a-b47f-2bfa61cbaab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-f45ff0ca-4e5b-4a06-99f8-aa2e5603afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-2dc8a955-2008-4e7c-8c47-8c14786decca,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-21fb9ab6-62f9-4c23-b5d8-35043efd0a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136664899-172.17.0.8-1598668928238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-e2898d0e-b59a-42e3-8cce-53e4122f9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-99342e2e-0d52-47ab-8cee-88cb0040b634,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-1365956d-6dc3-411f-a92c-7d0a04e945ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b942abc6-0698-41d1-b31e-9bb4a040353c,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-ae51b7e3-f919-4a1a-b47f-2bfa61cbaab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-f45ff0ca-4e5b-4a06-99f8-aa2e5603afbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-2dc8a955-2008-4e7c-8c47-8c14786decca,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-21fb9ab6-62f9-4c23-b5d8-35043efd0a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257595642-172.17.0.8-1598669054981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-9fe600b3-2a87-441c-a400-369cf83f9ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-45650fe8-025a-4285-94f6-6c6a4ec244bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-e56d72dd-09e4-4207-861d-d3bdf7675f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-527e4703-a2b8-492e-8770-1292b08cfc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-c6ea9fe0-8b66-44b7-b3d4-f9198bcfa3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8bc8a51a-1419-4b6a-807e-e680c79283d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-7e65adfe-8db0-4bae-95dc-ada098ad2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-29da9f42-46b7-4352-876f-e88bdaa491b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257595642-172.17.0.8-1598669054981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-9fe600b3-2a87-441c-a400-369cf83f9ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-45650fe8-025a-4285-94f6-6c6a4ec244bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-e56d72dd-09e4-4207-861d-d3bdf7675f94,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-527e4703-a2b8-492e-8770-1292b08cfc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-c6ea9fe0-8b66-44b7-b3d4-f9198bcfa3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8bc8a51a-1419-4b6a-807e-e680c79283d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-7e65adfe-8db0-4bae-95dc-ada098ad2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-29da9f42-46b7-4352-876f-e88bdaa491b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772667459-172.17.0.8-1598669136539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-8d28b506-32bc-4451-9317-ec918f5d65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-0bac2a94-fac5-4630-a3a3-0713d7cc9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-1ea2b283-a16a-4e1e-95cf-bac06eb7e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-6a686984-b6a0-4464-8363-3a84ac7f4272,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-37208df1-a4bd-42c7-962e-ad75e2cf8e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-7a7ef6b4-d630-4032-9856-9ff66884f623,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-0361dc2f-5f8c-4544-be4d-648057be66ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-39105cf7-4e92-49ab-a8da-fe11cf93cace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772667459-172.17.0.8-1598669136539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-8d28b506-32bc-4451-9317-ec918f5d65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-0bac2a94-fac5-4630-a3a3-0713d7cc9be9,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-1ea2b283-a16a-4e1e-95cf-bac06eb7e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-6a686984-b6a0-4464-8363-3a84ac7f4272,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-37208df1-a4bd-42c7-962e-ad75e2cf8e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-7a7ef6b4-d630-4032-9856-9ff66884f623,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-0361dc2f-5f8c-4544-be4d-648057be66ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-39105cf7-4e92-49ab-a8da-fe11cf93cace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369457129-172.17.0.8-1598669284558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-0adb10a7-73b2-4a13-b739-ebc5a2762e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-e103b93a-f568-4ca0-b165-86dfc00f1207,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-84c9a666-a6cb-498c-b52c-cc404d4cf1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-366c2944-b236-49d4-9a12-0ecbc93ca57f,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-896a19e8-30a6-4ac6-af47-6ef37f31d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-eee4eaf2-c4d1-46e5-8803-24440c71fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-678ee39d-e6e8-4032-8396-277d80c47232,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-dbb8ce13-852f-4438-a9a4-9e99c77fcbca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369457129-172.17.0.8-1598669284558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-0adb10a7-73b2-4a13-b739-ebc5a2762e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-e103b93a-f568-4ca0-b165-86dfc00f1207,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-84c9a666-a6cb-498c-b52c-cc404d4cf1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-366c2944-b236-49d4-9a12-0ecbc93ca57f,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-896a19e8-30a6-4ac6-af47-6ef37f31d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-eee4eaf2-c4d1-46e5-8803-24440c71fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-678ee39d-e6e8-4032-8396-277d80c47232,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-dbb8ce13-852f-4438-a9a4-9e99c77fcbca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5287
