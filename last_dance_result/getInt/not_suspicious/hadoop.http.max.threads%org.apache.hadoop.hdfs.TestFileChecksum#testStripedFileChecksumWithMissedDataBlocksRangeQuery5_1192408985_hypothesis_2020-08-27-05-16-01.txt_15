reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77347193-172.17.0.8-1598505684988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-c730bae2-aea4-43ba-876f-9f71aab7a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-8167189f-d2bc-40ad-9f53-03b21ea08a05,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-0e8a022f-da52-4fd1-b6fe-9482444d878f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-c41b4f7a-44f0-4af3-bfe2-ec46a80b9b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-ef137f7a-8a5f-4626-b934-e8591f1fbd99,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-1b576aa1-05f6-49d5-b31f-c0b034186e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-d85eb84a-79fb-46ef-89a4-c946215c6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6b0e1eb3-95a3-4339-89ca-44fca8e859cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77347193-172.17.0.8-1598505684988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-c730bae2-aea4-43ba-876f-9f71aab7a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-8167189f-d2bc-40ad-9f53-03b21ea08a05,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-0e8a022f-da52-4fd1-b6fe-9482444d878f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-c41b4f7a-44f0-4af3-bfe2-ec46a80b9b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-ef137f7a-8a5f-4626-b934-e8591f1fbd99,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-1b576aa1-05f6-49d5-b31f-c0b034186e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-d85eb84a-79fb-46ef-89a4-c946215c6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6b0e1eb3-95a3-4339-89ca-44fca8e859cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685072958-172.17.0.8-1598505754141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42396,DS-439498e4-8197-4ff6-945c-88311b57f415,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-a41a89ea-f756-4b2a-9deb-ef14a8ce6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-91a62396-0849-4f4c-819a-584202f501d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-4f74e3b8-bb9b-44ad-ab5d-8fcba483f929,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-8b4cf758-65a5-4e10-a1bb-533ad6e84ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-1ee025cf-251c-43d9-88ad-1c67a776e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-1ca77b88-3b26-41a6-ad54-792f0f61417e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c2c5d18b-f017-4126-90c8-6f61c68bec9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685072958-172.17.0.8-1598505754141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42396,DS-439498e4-8197-4ff6-945c-88311b57f415,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-a41a89ea-f756-4b2a-9deb-ef14a8ce6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-91a62396-0849-4f4c-819a-584202f501d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-4f74e3b8-bb9b-44ad-ab5d-8fcba483f929,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-8b4cf758-65a5-4e10-a1bb-533ad6e84ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-1ee025cf-251c-43d9-88ad-1c67a776e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-1ca77b88-3b26-41a6-ad54-792f0f61417e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-c2c5d18b-f017-4126-90c8-6f61c68bec9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956808328-172.17.0.8-1598505813901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-8f60342c-479c-4a84-ae03-a74d32e07a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-d5e00aac-6966-4f5e-a775-21b0718d6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-86b0a7b6-3f6e-4b44-90e3-ec40bc3a6c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-61309a82-ce38-47bc-82f5-588bf9cdc041,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-53072d37-b234-4a1b-9c34-7a01ad895b91,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-3c9924bb-86ec-440e-b923-29397d410a81,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-78937b48-c3a2-4bc2-af7c-fe7bd98a912d,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-37961d1a-a75c-4cae-8883-ab9ab16b64b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956808328-172.17.0.8-1598505813901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-8f60342c-479c-4a84-ae03-a74d32e07a50,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-d5e00aac-6966-4f5e-a775-21b0718d6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-86b0a7b6-3f6e-4b44-90e3-ec40bc3a6c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-61309a82-ce38-47bc-82f5-588bf9cdc041,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-53072d37-b234-4a1b-9c34-7a01ad895b91,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-3c9924bb-86ec-440e-b923-29397d410a81,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-78937b48-c3a2-4bc2-af7c-fe7bd98a912d,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-37961d1a-a75c-4cae-8883-ab9ab16b64b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671832844-172.17.0.8-1598506224212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-112c304f-2314-4cf8-ac7a-01657910aabd,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a8046844-8850-45e4-8dc5-80743921eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-98fd264b-b30a-471b-9151-a7b158b67855,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5127f3b5-9f45-4027-87b3-cb7ada082edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-10d28064-4c16-4091-ac44-08c9455c5957,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-093b2cf1-bbd0-4d75-a881-dea0cd471e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-5c28be9c-d34c-4c54-b6c1-c5cda51c1454,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-04b41aea-79ca-4f93-a577-cb6dc07251c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671832844-172.17.0.8-1598506224212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-112c304f-2314-4cf8-ac7a-01657910aabd,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a8046844-8850-45e4-8dc5-80743921eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-98fd264b-b30a-471b-9151-a7b158b67855,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5127f3b5-9f45-4027-87b3-cb7ada082edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-10d28064-4c16-4091-ac44-08c9455c5957,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-093b2cf1-bbd0-4d75-a881-dea0cd471e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-5c28be9c-d34c-4c54-b6c1-c5cda51c1454,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-04b41aea-79ca-4f93-a577-cb6dc07251c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340002942-172.17.0.8-1598506251379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-9edfa585-d403-4eaf-85c8-f626e57055f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-847c0897-ec78-4a41-a62d-0a0844bbf693,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-1c4a482b-ea57-4092-a7b1-2b5c3b486b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-a7e4ebf8-76e6-474c-99c4-040ef18ee1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-3aa4812d-27ee-40ba-9e70-1ee9d827f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-02790453-b23f-4d1d-86c4-230927aebfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-c666715f-3a91-4e9b-8687-3c54c184cef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-df36df3b-b861-493e-aae2-a8f0d5ac7d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340002942-172.17.0.8-1598506251379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-9edfa585-d403-4eaf-85c8-f626e57055f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-847c0897-ec78-4a41-a62d-0a0844bbf693,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-1c4a482b-ea57-4092-a7b1-2b5c3b486b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-a7e4ebf8-76e6-474c-99c4-040ef18ee1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-3aa4812d-27ee-40ba-9e70-1ee9d827f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-02790453-b23f-4d1d-86c4-230927aebfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-c666715f-3a91-4e9b-8687-3c54c184cef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-df36df3b-b861-493e-aae2-a8f0d5ac7d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721427867-172.17.0.8-1598506941744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-fff46d80-c3d2-476b-a811-1092daef70be,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-6ba0539c-9369-438c-bcd7-490833a6945f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-e5e159a9-6a57-4750-bb3d-af8d78ab609b,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-a6f87c1f-f09f-476b-a35a-7b0d72c6bc16,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-73a6026b-5e5a-41ea-b092-f56c23e646d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-f06d1a43-7414-4aba-aa1b-fd3c1f641299,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-b6d48ea1-a59e-4609-92df-32b54371ed96,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-b5fc77e2-6d19-4cf8-9584-a79020f36c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721427867-172.17.0.8-1598506941744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-fff46d80-c3d2-476b-a811-1092daef70be,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-6ba0539c-9369-438c-bcd7-490833a6945f,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-e5e159a9-6a57-4750-bb3d-af8d78ab609b,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-a6f87c1f-f09f-476b-a35a-7b0d72c6bc16,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-73a6026b-5e5a-41ea-b092-f56c23e646d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-f06d1a43-7414-4aba-aa1b-fd3c1f641299,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-b6d48ea1-a59e-4609-92df-32b54371ed96,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-b5fc77e2-6d19-4cf8-9584-a79020f36c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351709248-172.17.0.8-1598507022042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-bf3c42ec-040b-4758-b6ff-c7de26d09319,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-c8848351-9152-4318-8ffc-6adc118dc9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-73da9914-9d65-4dee-bdbc-60bd6167e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-e03bff9e-eac4-4dcb-9afc-890c326b4295,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-f1d21b68-8c23-4b13-a7ef-d38bbfe87fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-adba5ef1-4e98-45fb-a6c9-9b3f60376325,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-9c81e45e-e235-4bcf-a3a0-86ff22abe740,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-a23f7876-b067-4374-a936-dc88050b06a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351709248-172.17.0.8-1598507022042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-bf3c42ec-040b-4758-b6ff-c7de26d09319,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-c8848351-9152-4318-8ffc-6adc118dc9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-73da9914-9d65-4dee-bdbc-60bd6167e0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-e03bff9e-eac4-4dcb-9afc-890c326b4295,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-f1d21b68-8c23-4b13-a7ef-d38bbfe87fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-adba5ef1-4e98-45fb-a6c9-9b3f60376325,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-9c81e45e-e235-4bcf-a3a0-86ff22abe740,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-a23f7876-b067-4374-a936-dc88050b06a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551572620-172.17.0.8-1598507629265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-37a15179-e75a-4087-b71d-b144ad69839d,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-55500fc8-714e-4617-a937-3ae4ee4f85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-5c66347b-b390-47f7-a5b9-4e4671b52648,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-c2f421bd-d7e6-4f59-b048-2c06bfc6a431,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-9033ef07-9ff1-4f9c-8e21-63b4d693ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-cc5fbb49-4ea7-4144-9e18-604b9a69a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0bd7ab69-7c28-42a2-911c-3201249f8c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-adeb9001-68ff-4f25-b766-192086d13273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551572620-172.17.0.8-1598507629265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-37a15179-e75a-4087-b71d-b144ad69839d,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-55500fc8-714e-4617-a937-3ae4ee4f85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-5c66347b-b390-47f7-a5b9-4e4671b52648,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-c2f421bd-d7e6-4f59-b048-2c06bfc6a431,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-9033ef07-9ff1-4f9c-8e21-63b4d693ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-cc5fbb49-4ea7-4144-9e18-604b9a69a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0bd7ab69-7c28-42a2-911c-3201249f8c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-adeb9001-68ff-4f25-b766-192086d13273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476282377-172.17.0.8-1598508389017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-ae84f6b0-b22d-4746-9dfd-bff671d72821,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-71d4abce-7cf0-4ba3-8339-7b06813b219b,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-a3ee8eb4-8651-466c-b816-af1a2bd9c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-69700d51-9763-45dc-aa26-d8098111da52,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-1d1aff4b-00b4-44fb-b49f-e76615c4e9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1b9ffa85-cb6c-412a-a354-f02b6f75c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-4f69cfc0-58f9-4cc5-a56d-3c154377560f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f12a49ce-0792-499c-8840-87b70a5bb2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476282377-172.17.0.8-1598508389017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-ae84f6b0-b22d-4746-9dfd-bff671d72821,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-71d4abce-7cf0-4ba3-8339-7b06813b219b,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-a3ee8eb4-8651-466c-b816-af1a2bd9c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-69700d51-9763-45dc-aa26-d8098111da52,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-1d1aff4b-00b4-44fb-b49f-e76615c4e9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1b9ffa85-cb6c-412a-a354-f02b6f75c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-4f69cfc0-58f9-4cc5-a56d-3c154377560f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f12a49ce-0792-499c-8840-87b70a5bb2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259251510-172.17.0.8-1598508596242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46376,DS-23d82b1c-bd31-44e4-a940-d14211b3284e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-80156731-99df-4964-a36c-737f4851b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e7c054d7-d32d-4a1b-989c-85fb3e36b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-d9b7fd49-68d8-4864-b249-9a8bd14033f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-99084bc8-ba8b-4b4a-91e3-a05031ef3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-77042683-976b-4064-bb03-0a6628cfbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-6dd5b848-eab3-4cb0-9726-e0aeeea35f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-567662f4-26b6-446a-b45c-3405eb500d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259251510-172.17.0.8-1598508596242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46376,DS-23d82b1c-bd31-44e4-a940-d14211b3284e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-80156731-99df-4964-a36c-737f4851b5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e7c054d7-d32d-4a1b-989c-85fb3e36b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-d9b7fd49-68d8-4864-b249-9a8bd14033f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-99084bc8-ba8b-4b4a-91e3-a05031ef3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-77042683-976b-4064-bb03-0a6628cfbc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-6dd5b848-eab3-4cb0-9726-e0aeeea35f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-567662f4-26b6-446a-b45c-3405eb500d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822046166-172.17.0.8-1598508629308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-b6c6e35c-bbe4-4569-855f-94a1b3d1d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-393eacbf-2a5c-4844-94e7-1ae5e4707bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-c22004e5-2fe8-42a6-a7b7-20941fd27f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-da94d73f-e352-4e09-a5a4-3ff2780b851f,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-ba5470be-7e98-4dc5-ab8e-9926d848b353,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-84865c75-0e35-4dc2-837a-3b049516e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-75b678a2-8793-4371-8e95-607c0633e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-7a8521e4-7769-451c-8dff-41abf6e01c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822046166-172.17.0.8-1598508629308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41623,DS-b6c6e35c-bbe4-4569-855f-94a1b3d1d4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-393eacbf-2a5c-4844-94e7-1ae5e4707bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-c22004e5-2fe8-42a6-a7b7-20941fd27f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-da94d73f-e352-4e09-a5a4-3ff2780b851f,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-ba5470be-7e98-4dc5-ab8e-9926d848b353,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-84865c75-0e35-4dc2-837a-3b049516e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-75b678a2-8793-4371-8e95-607c0633e9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-7a8521e4-7769-451c-8dff-41abf6e01c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18498061-172.17.0.8-1598508776901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-a22dcffc-03bd-4b76-9377-f5d1d6dfca19,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-3ee35471-3746-4485-8a0e-f766e4a0a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-643282d2-f308-4e54-b809-bb1911ea5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-25f74f0b-48c9-4db1-8359-b55d8d418a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-e906a208-55a1-4ebd-8dde-516bf6b1b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-63b63a34-9061-47e6-8133-37a72d177621,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-dbbcadf5-3b2e-4d74-9ddf-241b0c0ebed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-ae703d92-22b5-4bbc-8972-ea7cbf9891fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18498061-172.17.0.8-1598508776901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-a22dcffc-03bd-4b76-9377-f5d1d6dfca19,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-3ee35471-3746-4485-8a0e-f766e4a0a8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-643282d2-f308-4e54-b809-bb1911ea5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-25f74f0b-48c9-4db1-8359-b55d8d418a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-e906a208-55a1-4ebd-8dde-516bf6b1b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-63b63a34-9061-47e6-8133-37a72d177621,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-dbbcadf5-3b2e-4d74-9ddf-241b0c0ebed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-ae703d92-22b5-4bbc-8972-ea7cbf9891fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414243038-172.17.0.8-1598509076812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-eb3f55bd-05cb-42de-b379-ae8f23bedbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-43cb1296-0b76-4a85-a465-29a9b19c5564,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-19195b5f-4256-4a85-8913-53c44bdd88ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-f35e071c-4350-4353-b678-ed59e93e3e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-309abdfc-c4d9-4b47-82b2-60afb822e9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-d4413d60-b6e1-40bc-8913-720c7705258e,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-aed239a5-6671-4d84-8353-1384cf4d5da1,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-eed3a143-e72a-4ded-bfe1-ea4283e34505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414243038-172.17.0.8-1598509076812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35045,DS-eb3f55bd-05cb-42de-b379-ae8f23bedbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-43cb1296-0b76-4a85-a465-29a9b19c5564,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-19195b5f-4256-4a85-8913-53c44bdd88ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-f35e071c-4350-4353-b678-ed59e93e3e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-309abdfc-c4d9-4b47-82b2-60afb822e9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-d4413d60-b6e1-40bc-8913-720c7705258e,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-aed239a5-6671-4d84-8353-1384cf4d5da1,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-eed3a143-e72a-4ded-bfe1-ea4283e34505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556557752-172.17.0.8-1598509556718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-cba1d226-396d-4dbf-94cd-ac33e5185766,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9d4c2a70-4780-4527-ad33-543a8fadd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-dacfdafc-fb51-4b1e-8235-78351d9fdcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-3635d8ed-5cb5-447a-9a54-4c6d83bb2fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-1c2d2da3-5507-40fc-96ec-36e66f5bdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-2e2a521e-e102-4e32-839a-5499be7e2708,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-844106e5-0657-4c4a-8e07-1ff51ce4cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-a118d006-08bf-43e7-be80-9e088e21aa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556557752-172.17.0.8-1598509556718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-cba1d226-396d-4dbf-94cd-ac33e5185766,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9d4c2a70-4780-4527-ad33-543a8fadd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-dacfdafc-fb51-4b1e-8235-78351d9fdcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-3635d8ed-5cb5-447a-9a54-4c6d83bb2fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-1c2d2da3-5507-40fc-96ec-36e66f5bdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-2e2a521e-e102-4e32-839a-5499be7e2708,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-844106e5-0657-4c4a-8e07-1ff51ce4cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-a118d006-08bf-43e7-be80-9e088e21aa1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472087561-172.17.0.8-1598509859830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-a7e34514-15bd-494e-aad5-e3df0a26eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-d013ae0d-0188-4efe-84c0-f30f3436911a,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0810e856-b9f2-4e4e-b1f5-041f8e4cf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-336a21c2-f227-4119-a217-2d214b8b8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-c8c7b05d-30ec-4be4-89ce-ef976ff96415,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-403c3137-f7af-4b90-b0f1-cde9651f6b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-4c70a18e-94ce-487f-9e47-7607b10d2077,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-8348c5bf-11e1-4f06-a3e7-71dc2e4c69e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472087561-172.17.0.8-1598509859830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-a7e34514-15bd-494e-aad5-e3df0a26eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-d013ae0d-0188-4efe-84c0-f30f3436911a,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0810e856-b9f2-4e4e-b1f5-041f8e4cf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-336a21c2-f227-4119-a217-2d214b8b8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-c8c7b05d-30ec-4be4-89ce-ef976ff96415,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-403c3137-f7af-4b90-b0f1-cde9651f6b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-4c70a18e-94ce-487f-9e47-7607b10d2077,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-8348c5bf-11e1-4f06-a3e7-71dc2e4c69e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847425790-172.17.0.8-1598509930444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-0689f5b3-5801-46f2-ad7d-90125da74faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-e02e4536-5104-4e74-8c9a-67765733b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-43042747-9625-4e3c-8c9d-a3677d46b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-ea5e5e0e-eafc-4542-ab03-f827fa55c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-5b930b5b-72fa-409d-8181-3ae047b51e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ec95f2f0-3b1f-485f-95b5-4d476620c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-b156bc7e-ea3c-4c4c-bb32-550f352108c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-191efb62-889b-49fb-8d6c-3753bc407fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847425790-172.17.0.8-1598509930444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-0689f5b3-5801-46f2-ad7d-90125da74faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-e02e4536-5104-4e74-8c9a-67765733b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-43042747-9625-4e3c-8c9d-a3677d46b0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-ea5e5e0e-eafc-4542-ab03-f827fa55c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-5b930b5b-72fa-409d-8181-3ae047b51e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ec95f2f0-3b1f-485f-95b5-4d476620c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-b156bc7e-ea3c-4c4c-bb32-550f352108c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-191efb62-889b-49fb-8d6c-3753bc407fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465192877-172.17.0.8-1598510603465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-32f449ed-57bc-4534-be53-ac388943d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-32c99480-0931-4bcc-800f-d7f134d10199,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-199cd551-24c6-46ed-b1fc-6fc90f68f813,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-63a44bc1-fd79-446d-8ca2-2084e84cfef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-7d852a9f-6e8e-4599-96b8-dc3a71333b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-624ede9a-b7b0-4ed4-aed3-4811b05f7a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-26fc64a4-4555-4911-ad40-72cf0e93738a,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-4fc435c1-29ce-4d1a-b6d1-2504c73fb303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465192877-172.17.0.8-1598510603465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-32f449ed-57bc-4534-be53-ac388943d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-32c99480-0931-4bcc-800f-d7f134d10199,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-199cd551-24c6-46ed-b1fc-6fc90f68f813,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-63a44bc1-fd79-446d-8ca2-2084e84cfef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-7d852a9f-6e8e-4599-96b8-dc3a71333b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-624ede9a-b7b0-4ed4-aed3-4811b05f7a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-26fc64a4-4555-4911-ad40-72cf0e93738a,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-4fc435c1-29ce-4d1a-b6d1-2504c73fb303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5403
