reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392802759-172.17.0.13-1598617262318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-2f4d3784-0aa0-444f-84ee-2379feea791b,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-3acf3e58-1659-4e44-a271-a9044502f257,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-72d95799-bc36-4e8a-b84f-f7ca94499808,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-4820a34d-fd4f-4d59-ad6a-f1344c67cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-056e68af-54f9-4f66-9405-30ce64851ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-15b334f2-1e9e-4b6a-9a17-c46c9a064ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-e2e43811-e5ee-4b2e-b3c7-556390cba578,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-ab3c233e-cf1f-41b6-8494-dd64e38f6a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392802759-172.17.0.13-1598617262318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-2f4d3784-0aa0-444f-84ee-2379feea791b,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-3acf3e58-1659-4e44-a271-a9044502f257,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-72d95799-bc36-4e8a-b84f-f7ca94499808,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-4820a34d-fd4f-4d59-ad6a-f1344c67cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-056e68af-54f9-4f66-9405-30ce64851ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-15b334f2-1e9e-4b6a-9a17-c46c9a064ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-e2e43811-e5ee-4b2e-b3c7-556390cba578,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-ab3c233e-cf1f-41b6-8494-dd64e38f6a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283939675-172.17.0.13-1598617589208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-08dc0a10-8ce8-4aef-8b47-f1c0ceaf31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bb8e6c6a-486a-4142-8a7d-fdb6911bbcba,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ac240a06-fc5d-47ee-af12-8483a717500c,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-4f022239-0f78-42c8-9862-48a9e5c1f216,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-5b2202bf-3d75-413a-a411-44cb6bde2221,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-d19896b6-0dbc-4ebe-8dfe-07e7c142c418,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-6d9cbeeb-a37c-4930-a754-ce6d03b083f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-c56ad9e3-0592-488a-8fb2-e75479bff87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283939675-172.17.0.13-1598617589208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-08dc0a10-8ce8-4aef-8b47-f1c0ceaf31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-bb8e6c6a-486a-4142-8a7d-fdb6911bbcba,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ac240a06-fc5d-47ee-af12-8483a717500c,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-4f022239-0f78-42c8-9862-48a9e5c1f216,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-5b2202bf-3d75-413a-a411-44cb6bde2221,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-d19896b6-0dbc-4ebe-8dfe-07e7c142c418,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-6d9cbeeb-a37c-4930-a754-ce6d03b083f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-c56ad9e3-0592-488a-8fb2-e75479bff87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528722259-172.17.0.13-1598617810886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-cc5100be-7399-4146-838f-ca3ee7d1d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-c0880114-7c28-44b1-bfce-038599e9305c,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-f9233d89-4636-4335-ae61-d307ad48f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-cefd5047-6efe-4921-8de8-cdce42af5807,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-2e64dbe7-da9e-4d13-80bc-00b707b5f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-495aef4c-c801-45a5-b068-77f0096f8493,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-51013c8a-c2b7-4c03-8f88-cd5a25c29ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-fbe1c9e6-fff4-44f4-afba-9c19687805d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528722259-172.17.0.13-1598617810886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-cc5100be-7399-4146-838f-ca3ee7d1d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-c0880114-7c28-44b1-bfce-038599e9305c,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-f9233d89-4636-4335-ae61-d307ad48f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-cefd5047-6efe-4921-8de8-cdce42af5807,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-2e64dbe7-da9e-4d13-80bc-00b707b5f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-495aef4c-c801-45a5-b068-77f0096f8493,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-51013c8a-c2b7-4c03-8f88-cd5a25c29ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-fbe1c9e6-fff4-44f4-afba-9c19687805d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980439382-172.17.0.13-1598618295903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-6f06232d-816f-4aaf-86d9-2a253e1d0532,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-954e0cf6-98c8-4344-890a-35fb8df3c261,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-aed8d160-702c-4969-ad4c-0fd9ec62cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-bac3df28-da52-4e4f-8914-e702f4ab47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-25433a71-01d3-48ef-abea-070a6e3ab9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-1db45eeb-d615-4ddd-b5e1-62c3109e7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-84dbfde6-3bb2-4b61-966a-196de8127693,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-6a65ec49-9f9e-4f00-a0bc-1fed3531a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980439382-172.17.0.13-1598618295903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33674,DS-6f06232d-816f-4aaf-86d9-2a253e1d0532,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-954e0cf6-98c8-4344-890a-35fb8df3c261,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-aed8d160-702c-4969-ad4c-0fd9ec62cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-bac3df28-da52-4e4f-8914-e702f4ab47b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-25433a71-01d3-48ef-abea-070a6e3ab9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-1db45eeb-d615-4ddd-b5e1-62c3109e7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-84dbfde6-3bb2-4b61-966a-196de8127693,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-6a65ec49-9f9e-4f00-a0bc-1fed3531a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868008352-172.17.0.13-1598618443890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-48d545ee-142b-4480-8a98-6eb8065bdf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-03bc60d7-c60d-4704-994b-4335fbe51fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-af6a36f4-ccae-4cca-9053-a4490e9fccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-fba6f1a3-d4ab-4ef7-ab83-1ba38b424bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-e2d11f61-1b06-4e41-a559-dc476078266e,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-f14a4e5f-e251-475f-aeb8-a54e6294ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-a48e897c-7e05-4250-aeab-a2a324093549,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3c99823f-abf4-4d5e-b946-008b59b8f449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868008352-172.17.0.13-1598618443890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-48d545ee-142b-4480-8a98-6eb8065bdf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-03bc60d7-c60d-4704-994b-4335fbe51fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-af6a36f4-ccae-4cca-9053-a4490e9fccc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-fba6f1a3-d4ab-4ef7-ab83-1ba38b424bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-e2d11f61-1b06-4e41-a559-dc476078266e,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-f14a4e5f-e251-475f-aeb8-a54e6294ce47,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-a48e897c-7e05-4250-aeab-a2a324093549,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3c99823f-abf4-4d5e-b946-008b59b8f449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695926910-172.17.0.13-1598619249964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-57587b1c-022d-4dc4-af2e-370ae086a153,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-c82ab959-6697-4e74-8ed5-56cadb59333c,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-395ab2c0-37c3-4b84-a3d3-10286dbf110e,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-d75f429a-3ef0-4054-8f41-42ef3801378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-7db6f4df-0f46-4b69-aa56-d0834f39160f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-a7356d1d-4201-4bd7-849e-444d1682ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-723f0b53-9550-4b79-9722-42dc68ab1bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-af357a13-046b-4f74-8d9e-d86ba78442e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695926910-172.17.0.13-1598619249964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-57587b1c-022d-4dc4-af2e-370ae086a153,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-c82ab959-6697-4e74-8ed5-56cadb59333c,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-395ab2c0-37c3-4b84-a3d3-10286dbf110e,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-d75f429a-3ef0-4054-8f41-42ef3801378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-7db6f4df-0f46-4b69-aa56-d0834f39160f,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-a7356d1d-4201-4bd7-849e-444d1682ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-723f0b53-9550-4b79-9722-42dc68ab1bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-af357a13-046b-4f74-8d9e-d86ba78442e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566466338-172.17.0.13-1598619284045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-8b1c1cb4-f0c0-43a6-87d0-8dda0053dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d4b1737b-c7ad-4b93-bf15-5fe5081b331a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-1f667420-e284-4380-9903-85c310b0d7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-b3a35b16-b781-4e4a-9384-bab1273a161f,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-36e1e838-a761-4c17-9bfc-306a3ee8534d,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-f84f3d1d-cf39-48ae-8570-6e979edc6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-23c63e1c-4c64-4f2e-9655-ae012ee8ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-fd7bf7f3-a993-44ea-a151-a6b2da4c4a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566466338-172.17.0.13-1598619284045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43790,DS-8b1c1cb4-f0c0-43a6-87d0-8dda0053dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-d4b1737b-c7ad-4b93-bf15-5fe5081b331a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-1f667420-e284-4380-9903-85c310b0d7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-b3a35b16-b781-4e4a-9384-bab1273a161f,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-36e1e838-a761-4c17-9bfc-306a3ee8534d,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-f84f3d1d-cf39-48ae-8570-6e979edc6c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-23c63e1c-4c64-4f2e-9655-ae012ee8ffb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-fd7bf7f3-a993-44ea-a151-a6b2da4c4a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739813650-172.17.0.13-1598620168737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-05512178-75dd-4ccc-941d-f301b042b267,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-d6e59e43-1481-4353-8685-b8f37c40016f,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e09bc521-a444-4df3-b9d5-8e0373d0b382,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-536ea923-9663-492f-9d23-f38436050196,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-72100dbe-ebdc-484e-af10-f89e29977a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-25e6c104-b8dd-41e9-8cd2-e4e6a35ac4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-bec700f6-77d1-4cfd-a2ea-684437ad4866,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7594aeca-86f4-4019-83d2-7405d1954aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739813650-172.17.0.13-1598620168737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-05512178-75dd-4ccc-941d-f301b042b267,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-d6e59e43-1481-4353-8685-b8f37c40016f,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-e09bc521-a444-4df3-b9d5-8e0373d0b382,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-536ea923-9663-492f-9d23-f38436050196,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-72100dbe-ebdc-484e-af10-f89e29977a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-25e6c104-b8dd-41e9-8cd2-e4e6a35ac4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-bec700f6-77d1-4cfd-a2ea-684437ad4866,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-7594aeca-86f4-4019-83d2-7405d1954aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978215880-172.17.0.13-1598620481472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-d688c489-8df6-4cf7-9b79-7c1c413e4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-da6e1eea-d0a3-45e3-995e-22ce7276fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-b689410d-044c-4e21-a79e-ea76b3f43b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-dc7477e9-0699-44bc-9431-bbf28f0ba544,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-06c57f3c-d2ca-48ad-b1ef-5b0a709d4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-85e287f9-00e8-4c64-8278-851b618bcb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-cef0455e-015d-418f-8f17-a2add1554a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-6e15cd9c-8bd5-4d05-8624-2849b19db18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978215880-172.17.0.13-1598620481472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-d688c489-8df6-4cf7-9b79-7c1c413e4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-da6e1eea-d0a3-45e3-995e-22ce7276fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-b689410d-044c-4e21-a79e-ea76b3f43b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-dc7477e9-0699-44bc-9431-bbf28f0ba544,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-06c57f3c-d2ca-48ad-b1ef-5b0a709d4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-85e287f9-00e8-4c64-8278-851b618bcb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-cef0455e-015d-418f-8f17-a2add1554a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-6e15cd9c-8bd5-4d05-8624-2849b19db18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25850659-172.17.0.13-1598620813914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-cfdebb0c-e66c-41ee-abeb-fbe0bdfc2788,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-e4889674-dc2e-4885-a2d2-938c6016ea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-4dd852cd-5307-4338-811c-eeb8509c04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-c0dc9e5a-6464-4071-8e17-c75fa41ab07d,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-5ac29464-1f99-4961-a30e-f805bbdb87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-2000679c-ae41-4899-a13e-a330dbe0207b,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-9a3711f2-27e0-4be9-8bf6-dc9d09435a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-2d11f336-826c-46ed-b2c9-6919a93a39a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25850659-172.17.0.13-1598620813914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-cfdebb0c-e66c-41ee-abeb-fbe0bdfc2788,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-e4889674-dc2e-4885-a2d2-938c6016ea9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-4dd852cd-5307-4338-811c-eeb8509c04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-c0dc9e5a-6464-4071-8e17-c75fa41ab07d,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-5ac29464-1f99-4961-a30e-f805bbdb87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-2000679c-ae41-4899-a13e-a330dbe0207b,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-9a3711f2-27e0-4be9-8bf6-dc9d09435a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-2d11f336-826c-46ed-b2c9-6919a93a39a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806254605-172.17.0.13-1598621043504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-d77237b4-2370-4ff5-9858-5a67dee57a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-0387502d-0e70-4c47-a47d-a56492669bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-bc9ce0d4-26b1-4f52-9a05-24ff4e88ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-6bc6277f-f87c-470b-98e9-62642cdef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-8600f80f-a381-4a28-9527-f39c7f3e551c,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-db62684f-3a5a-4328-9177-545b2c64b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-09cd879e-6466-45c2-a9b9-f458819aae09,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-8ff18982-9c68-41a3-ab1a-9c9cef8665f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806254605-172.17.0.13-1598621043504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-d77237b4-2370-4ff5-9858-5a67dee57a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-0387502d-0e70-4c47-a47d-a56492669bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-bc9ce0d4-26b1-4f52-9a05-24ff4e88ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-6bc6277f-f87c-470b-98e9-62642cdef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-8600f80f-a381-4a28-9527-f39c7f3e551c,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-db62684f-3a5a-4328-9177-545b2c64b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-09cd879e-6466-45c2-a9b9-f458819aae09,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-8ff18982-9c68-41a3-ab1a-9c9cef8665f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328540510-172.17.0.13-1598621462935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-67876c04-1151-4626-b83c-654f7dbbc057,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-2a2a8a94-e750-462e-8075-3960c4ec4e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-ff876e22-90fd-4f59-939b-4b66e06f8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-3e5b10ee-3d1b-40a9-b4ae-53762dac82da,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-7a148f93-126a-490f-88ba-66ea4fa6ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-2be48687-03db-495e-a138-f3c8bbfa98f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-c06913a7-5d93-40f3-985e-1ab9811fbb40,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-84621247-3dc9-4111-a837-16fc1f257674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328540510-172.17.0.13-1598621462935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-67876c04-1151-4626-b83c-654f7dbbc057,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-2a2a8a94-e750-462e-8075-3960c4ec4e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-ff876e22-90fd-4f59-939b-4b66e06f8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-3e5b10ee-3d1b-40a9-b4ae-53762dac82da,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-7a148f93-126a-490f-88ba-66ea4fa6ec7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-2be48687-03db-495e-a138-f3c8bbfa98f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-c06913a7-5d93-40f3-985e-1ab9811fbb40,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-84621247-3dc9-4111-a837-16fc1f257674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982007355-172.17.0.13-1598621604049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-cbca54e1-d043-4c8e-bb86-921b63b394c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-6cb41980-a958-40ea-82dd-1337ed311b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-dd2dd25b-8e21-4654-8e6b-1fb2e25b3572,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-a3f2f3b9-6946-4204-a982-3d1ad3754d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-bd71406a-7ddc-4070-a2ed-c41d25b9f211,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-20e271c0-dbbb-499b-be7d-ec22d183befa,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-e425f047-d37e-4c3f-a032-9e958af677b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-360d603f-50f8-446c-a162-f981601c4527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982007355-172.17.0.13-1598621604049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-cbca54e1-d043-4c8e-bb86-921b63b394c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-6cb41980-a958-40ea-82dd-1337ed311b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-dd2dd25b-8e21-4654-8e6b-1fb2e25b3572,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-a3f2f3b9-6946-4204-a982-3d1ad3754d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-bd71406a-7ddc-4070-a2ed-c41d25b9f211,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-20e271c0-dbbb-499b-be7d-ec22d183befa,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-e425f047-d37e-4c3f-a032-9e958af677b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-360d603f-50f8-446c-a162-f981601c4527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329867448-172.17.0.13-1598622088311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43752,DS-b0bf4b6b-9afd-4f50-8871-01739a643c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-73591925-c8a2-4d44-8388-7edb348aa474,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-838f8776-baed-4a0c-91e0-362d8cc476f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-8840b2d0-dabd-4c62-8acc-6ac935bcb017,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-5c6e26fe-2f78-467f-9f19-2671566a9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7f2a6460-0871-4bbb-b3c5-e6f65a250e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-31597d7e-9975-4753-a51f-57c0e9f41571,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3435df54-5dbf-4cb4-a5ec-ec6de7b5113e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329867448-172.17.0.13-1598622088311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43752,DS-b0bf4b6b-9afd-4f50-8871-01739a643c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-73591925-c8a2-4d44-8388-7edb348aa474,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-838f8776-baed-4a0c-91e0-362d8cc476f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-8840b2d0-dabd-4c62-8acc-6ac935bcb017,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-5c6e26fe-2f78-467f-9f19-2671566a9e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-7f2a6460-0871-4bbb-b3c5-e6f65a250e41,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-31597d7e-9975-4753-a51f-57c0e9f41571,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3435df54-5dbf-4cb4-a5ec-ec6de7b5113e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66736570-172.17.0.13-1598622166410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-716d86f9-7436-436e-ba2e-b83720c2f978,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-ac272cd8-dd19-4042-b0d9-9df99a73d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-13ffab69-3d18-4425-b431-b3b30c0f047c,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-ece265f5-d067-4193-ae6d-aad65366a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-e3212aab-4cd7-4f04-866f-ba9508c8043d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d13ff218-c746-49e8-9fe3-d59b43f141b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-bb643d48-e367-49a5-8468-b50acc43373c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-411cb4f6-196e-4bb5-b1ce-e915b7f0f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66736570-172.17.0.13-1598622166410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38686,DS-716d86f9-7436-436e-ba2e-b83720c2f978,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-ac272cd8-dd19-4042-b0d9-9df99a73d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-13ffab69-3d18-4425-b431-b3b30c0f047c,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-ece265f5-d067-4193-ae6d-aad65366a4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-e3212aab-4cd7-4f04-866f-ba9508c8043d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d13ff218-c746-49e8-9fe3-d59b43f141b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-bb643d48-e367-49a5-8468-b50acc43373c,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-411cb4f6-196e-4bb5-b1ce-e915b7f0f36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206664443-172.17.0.13-1598622343209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-8e8af833-d0c0-436c-90ec-b81030e8b496,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-9a327620-ed0f-4f46-865f-cc6ed4a60358,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-bff6e87a-fdb4-4541-92bb-c8bd1770e656,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-f64d1a29-d8cf-4328-bec3-acb066d2ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-492d9657-277d-412e-813c-1af25405045c,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-5de24c7a-0809-4f98-b0f6-27d524a622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-f73eddc1-e93d-40d6-9006-1175c4941bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-63ad56ad-1b28-48a1-9c8e-44993fe1677a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206664443-172.17.0.13-1598622343209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-8e8af833-d0c0-436c-90ec-b81030e8b496,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-9a327620-ed0f-4f46-865f-cc6ed4a60358,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-bff6e87a-fdb4-4541-92bb-c8bd1770e656,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-f64d1a29-d8cf-4328-bec3-acb066d2ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-492d9657-277d-412e-813c-1af25405045c,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-5de24c7a-0809-4f98-b0f6-27d524a622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-f73eddc1-e93d-40d6-9006-1175c4941bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-63ad56ad-1b28-48a1-9c8e-44993fe1677a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.openfiles.num.responses
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779243163-172.17.0.13-1598622461788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-be0c9077-12e0-4d1e-bebc-d9604b11b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-d6e8e4d2-a2b3-4024-b7c3-5f5a28f61e96,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2c67a547-3173-48ea-b3cd-16007b564ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2d3613d0-a16c-4b49-9453-4969552ad1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4f7832c0-963d-4073-b76d-7ee911116856,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-3cd1bbe3-d5c0-4562-a90f-0f9ab627481b,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-8b1d3f28-0d98-4175-9f8f-641e9c43ab45,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-358db4e6-8f8c-4093-a8a0-d101f2f3895c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779243163-172.17.0.13-1598622461788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-be0c9077-12e0-4d1e-bebc-d9604b11b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-d6e8e4d2-a2b3-4024-b7c3-5f5a28f61e96,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2c67a547-3173-48ea-b3cd-16007b564ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2d3613d0-a16c-4b49-9453-4969552ad1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4f7832c0-963d-4073-b76d-7ee911116856,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-3cd1bbe3-d5c0-4562-a90f-0f9ab627481b,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-8b1d3f28-0d98-4175-9f8f-641e9c43ab45,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-358db4e6-8f8c-4093-a8a0-d101f2f3895c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5421
