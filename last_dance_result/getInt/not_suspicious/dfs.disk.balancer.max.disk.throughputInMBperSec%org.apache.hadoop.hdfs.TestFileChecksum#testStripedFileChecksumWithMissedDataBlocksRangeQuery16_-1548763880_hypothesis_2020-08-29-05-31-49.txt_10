reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703357560-172.17.0.15-1598679909961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-a7f16dc7-5968-4c4c-bc39-5b80c8ba6c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-0e66006a-3c65-4ba6-a783-5c7904aacb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-942605f4-b1bb-4f07-8496-cd545ed33fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-8b98daee-57c0-4a94-89e9-b6b874978e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-2a4a555f-37cc-4afd-ad1b-2218bb4d42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-cf224544-7019-47f7-830a-5748cd711ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-cfeabec6-8e0e-4a1d-9526-0fd065364c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-950405a0-a5f3-4f9f-b7e5-ac4e96fe1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703357560-172.17.0.15-1598679909961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-a7f16dc7-5968-4c4c-bc39-5b80c8ba6c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-0e66006a-3c65-4ba6-a783-5c7904aacb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-942605f4-b1bb-4f07-8496-cd545ed33fef,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-8b98daee-57c0-4a94-89e9-b6b874978e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-2a4a555f-37cc-4afd-ad1b-2218bb4d42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-cf224544-7019-47f7-830a-5748cd711ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-cfeabec6-8e0e-4a1d-9526-0fd065364c58,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-950405a0-a5f3-4f9f-b7e5-ac4e96fe1c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176868186-172.17.0.15-1598680120728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-a4ccdb44-5b17-4916-aad4-3dec76f1a336,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-7a0a4714-ac65-40eb-9303-638266ab3792,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-a8728665-1ae6-4020-88e7-b6883012478a,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-28f4c321-124c-4aec-a728-75869ff850dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-27ec9a2d-2e06-49d8-9558-5edf25b46117,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-61fd085d-e91c-4e79-9714-ca3bca18fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-6ca135c6-349b-4aef-b94f-43109a83a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e34bcf85-4e9a-4ef6-8060-7434a1cdb586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176868186-172.17.0.15-1598680120728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-a4ccdb44-5b17-4916-aad4-3dec76f1a336,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-7a0a4714-ac65-40eb-9303-638266ab3792,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-a8728665-1ae6-4020-88e7-b6883012478a,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-28f4c321-124c-4aec-a728-75869ff850dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-27ec9a2d-2e06-49d8-9558-5edf25b46117,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-61fd085d-e91c-4e79-9714-ca3bca18fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-6ca135c6-349b-4aef-b94f-43109a83a6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-e34bcf85-4e9a-4ef6-8060-7434a1cdb586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187851602-172.17.0.15-1598680873377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-547e4160-7877-4a71-ad17-1dcd8892a1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-490b7fc2-b6bd-4f14-9b4a-47bfc29a34c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-c77de918-004f-4452-98fc-31c99963e870,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-76e7b70a-fddf-4bd9-8832-6ac1c8fede46,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-be8125f1-cf62-4f29-8321-bead96ee800b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-48ee5843-485b-4059-bac4-88bf4298e005,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-92badc66-c108-43c3-a7c9-30b9a9a7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-50d5aa54-8a51-4e35-84ca-ff51946a366a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187851602-172.17.0.15-1598680873377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-547e4160-7877-4a71-ad17-1dcd8892a1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-490b7fc2-b6bd-4f14-9b4a-47bfc29a34c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-c77de918-004f-4452-98fc-31c99963e870,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-76e7b70a-fddf-4bd9-8832-6ac1c8fede46,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-be8125f1-cf62-4f29-8321-bead96ee800b,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-48ee5843-485b-4059-bac4-88bf4298e005,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-92badc66-c108-43c3-a7c9-30b9a9a7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-50d5aa54-8a51-4e35-84ca-ff51946a366a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240532462-172.17.0.15-1598681611679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-3d5d0ada-5291-4fba-9449-6c90a5d37a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-ebc8af6b-5d49-46c1-9315-b0761f3f629f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1a0869b8-c47a-4a15-8b3b-6e877df0d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b14a65c6-f883-4362-bdc2-9da3105d0b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9c28e429-fe2e-4c18-ab39-1c176e11bb06,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-d6792093-153a-4b1b-95b4-34bb986396ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-6c20c1ae-7fa7-462f-ac9b-b9ff42031ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-cb3e3359-8135-4760-8d2c-f994f405c3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240532462-172.17.0.15-1598681611679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-3d5d0ada-5291-4fba-9449-6c90a5d37a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-ebc8af6b-5d49-46c1-9315-b0761f3f629f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1a0869b8-c47a-4a15-8b3b-6e877df0d42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b14a65c6-f883-4362-bdc2-9da3105d0b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9c28e429-fe2e-4c18-ab39-1c176e11bb06,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-d6792093-153a-4b1b-95b4-34bb986396ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-6c20c1ae-7fa7-462f-ac9b-b9ff42031ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-cb3e3359-8135-4760-8d2c-f994f405c3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316023640-172.17.0.15-1598681678577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-9c1ff2a6-946b-41b1-ba01-ccc82d23ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-090ea86a-f59f-4a9d-b57a-21f4ab656946,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-c5296295-c466-49f2-90ae-1f1640331f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-a975eb4f-f1e8-45f2-9447-2f2aff304cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-97994a95-f98d-49c9-8ae1-aae3852f2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-9b586059-c2ab-4049-9c41-3d62968a0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-d66fdae0-08c2-42f5-a9fe-8c6b0ad12a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-78a35591-3767-4769-9e0a-54db8fab60b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316023640-172.17.0.15-1598681678577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-9c1ff2a6-946b-41b1-ba01-ccc82d23ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-090ea86a-f59f-4a9d-b57a-21f4ab656946,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-c5296295-c466-49f2-90ae-1f1640331f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-a975eb4f-f1e8-45f2-9447-2f2aff304cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-97994a95-f98d-49c9-8ae1-aae3852f2e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-9b586059-c2ab-4049-9c41-3d62968a0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-d66fdae0-08c2-42f5-a9fe-8c6b0ad12a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-78a35591-3767-4769-9e0a-54db8fab60b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241351810-172.17.0.15-1598682166788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-90d66480-b979-4025-9b42-d313e71ec2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-f42d2094-ef6f-4c1e-9048-72875baeffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-cb6d8fe1-b284-49d8-8190-1bb0865b741a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-1d59c768-9a4c-4281-9142-40ac3d6f5fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-aa21ed91-3a07-49eb-b1c8-c048ffee1178,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4e714b8c-bcf8-438f-8173-8ec8322df328,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-2b1ce0c1-1be2-4bc7-8718-f4ff0d8f1758,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-87163d23-ff28-4883-99f7-addcff547bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241351810-172.17.0.15-1598682166788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-90d66480-b979-4025-9b42-d313e71ec2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-f42d2094-ef6f-4c1e-9048-72875baeffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-cb6d8fe1-b284-49d8-8190-1bb0865b741a,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-1d59c768-9a4c-4281-9142-40ac3d6f5fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-aa21ed91-3a07-49eb-b1c8-c048ffee1178,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4e714b8c-bcf8-438f-8173-8ec8322df328,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-2b1ce0c1-1be2-4bc7-8718-f4ff0d8f1758,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-87163d23-ff28-4883-99f7-addcff547bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226429683-172.17.0.15-1598682375287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-a66b1765-ac94-460f-a9d5-f92cbe6f6516,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-e187f3d0-4f53-434d-8b28-419d2a3e07da,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-ad5ada0d-bf09-41cf-ac4b-4387df37ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-cb3df6a9-3936-40df-8ab7-9cce94df7906,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-bf25a42c-225c-4267-b0f8-375123d8d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-7a49196c-16c9-48a4-bbd2-ed7225cb1725,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-79bb52ad-1787-43a3-b87d-c738004df06e,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-cb940cae-7c4e-45c9-8c74-1d5b699f60ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226429683-172.17.0.15-1598682375287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-a66b1765-ac94-460f-a9d5-f92cbe6f6516,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-e187f3d0-4f53-434d-8b28-419d2a3e07da,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-ad5ada0d-bf09-41cf-ac4b-4387df37ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-cb3df6a9-3936-40df-8ab7-9cce94df7906,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-bf25a42c-225c-4267-b0f8-375123d8d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-7a49196c-16c9-48a4-bbd2-ed7225cb1725,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-79bb52ad-1787-43a3-b87d-c738004df06e,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-cb940cae-7c4e-45c9-8c74-1d5b699f60ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212024550-172.17.0.15-1598682399374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-90e87005-f412-4976-bcd9-a3f7dafb2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-f9b5696c-a0fc-4b7f-8ee3-0eb9d4cd6098,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-42981750-2f4a-4364-8183-9a6e4b4662e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-d864abc5-2b0f-49f1-b21e-854e52cab360,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-98214e37-4237-48a4-8933-bdef9489647d,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-b4baafc3-2d6e-4831-8783-ee3de1c72755,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-e926437a-a511-4813-9868-6a97f2d05506,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-5d0191b8-d027-42a9-b109-a11088777e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212024550-172.17.0.15-1598682399374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-90e87005-f412-4976-bcd9-a3f7dafb2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-f9b5696c-a0fc-4b7f-8ee3-0eb9d4cd6098,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-42981750-2f4a-4364-8183-9a6e4b4662e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-d864abc5-2b0f-49f1-b21e-854e52cab360,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-98214e37-4237-48a4-8933-bdef9489647d,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-b4baafc3-2d6e-4831-8783-ee3de1c72755,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-e926437a-a511-4813-9868-6a97f2d05506,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-5d0191b8-d027-42a9-b109-a11088777e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283060296-172.17.0.15-1598683528972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b7adde61-8d7a-4d92-a899-619f76b08ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-01cf8312-aff1-4044-8ab4-6a2fc5a9ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-0cc53fdc-48b9-42ea-9513-08e648570752,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-92355c9c-000f-4837-bf9a-7ca6d3af3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-1cf17ccd-4e35-47aa-a890-5ae9cc7e4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-898e6ea7-35d4-4ad0-a528-e6b1699714d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5152d122-c9c4-4391-87e1-414fd08f1220,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-ebeaac5a-46b5-4df2-a979-9597317013fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283060296-172.17.0.15-1598683528972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-b7adde61-8d7a-4d92-a899-619f76b08ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-01cf8312-aff1-4044-8ab4-6a2fc5a9ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-0cc53fdc-48b9-42ea-9513-08e648570752,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-92355c9c-000f-4837-bf9a-7ca6d3af3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-1cf17ccd-4e35-47aa-a890-5ae9cc7e4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-898e6ea7-35d4-4ad0-a528-e6b1699714d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-5152d122-c9c4-4391-87e1-414fd08f1220,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-ebeaac5a-46b5-4df2-a979-9597317013fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765643694-172.17.0.15-1598683862441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-b0831055-3bcc-42e6-825e-306d2875857d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-31326970-8f7d-4a3d-b09c-792605c5d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-d6e61461-796e-4ccb-975f-52e8112b8c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-bf654978-2df1-4366-9e94-4b4edf6d6bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-26c54c2a-d581-47eb-b079-589f81a09107,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-c4b57bb4-366f-45a5-9fea-e64f2f19db20,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-466e50dd-01f0-41d5-bb3e-080781e6a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-390799ad-0848-4fd4-a6ff-2200118a9ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765643694-172.17.0.15-1598683862441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-b0831055-3bcc-42e6-825e-306d2875857d,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-31326970-8f7d-4a3d-b09c-792605c5d4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-d6e61461-796e-4ccb-975f-52e8112b8c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-bf654978-2df1-4366-9e94-4b4edf6d6bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-26c54c2a-d581-47eb-b079-589f81a09107,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-c4b57bb4-366f-45a5-9fea-e64f2f19db20,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-466e50dd-01f0-41d5-bb3e-080781e6a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-390799ad-0848-4fd4-a6ff-2200118a9ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5184
