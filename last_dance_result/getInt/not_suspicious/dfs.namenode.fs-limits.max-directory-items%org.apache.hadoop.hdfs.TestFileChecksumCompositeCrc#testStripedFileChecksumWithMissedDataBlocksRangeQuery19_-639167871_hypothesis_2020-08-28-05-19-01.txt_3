reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114794759-172.17.0.15-1598592401353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-2dec9af9-ff1e-4f90-a8aa-2cb0f09219f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-d453615b-ba71-4b4c-b417-8b779d861544,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-6092abdc-8c69-4d44-b23d-c633531bae9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-abecd124-d617-4afe-977a-cfa58b8499a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-3fe91e30-cae3-4c5d-8c76-3559cc09a800,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-eb533f80-5eee-4638-858c-c32b7927fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-560ed26f-cd4e-406b-bb52-3426252cf58e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-daa83ba0-0fd1-4e84-ac88-88ec97216211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114794759-172.17.0.15-1598592401353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46163,DS-2dec9af9-ff1e-4f90-a8aa-2cb0f09219f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-d453615b-ba71-4b4c-b417-8b779d861544,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-6092abdc-8c69-4d44-b23d-c633531bae9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-abecd124-d617-4afe-977a-cfa58b8499a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-3fe91e30-cae3-4c5d-8c76-3559cc09a800,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-eb533f80-5eee-4638-858c-c32b7927fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-560ed26f-cd4e-406b-bb52-3426252cf58e,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-daa83ba0-0fd1-4e84-ac88-88ec97216211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025338615-172.17.0.15-1598592760013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-7a10c5d5-62a6-425e-a211-47565bf70bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-8ed66afe-fdb2-4b9a-abab-e499ca7d6303,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-7e9f83df-f810-43ed-9814-523465e3edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-2e94056b-f5cb-4ee9-84ae-db47cd5728cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-8b685ec7-0de5-4ad1-b2ba-ee5b638c896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-f1b031eb-76a8-48f9-9af9-a8bd4d5fb993,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2b682165-904d-4e97-a96b-baa8835617d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2f457e44-7dca-4291-9bfd-09948ca37938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025338615-172.17.0.15-1598592760013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-7a10c5d5-62a6-425e-a211-47565bf70bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-8ed66afe-fdb2-4b9a-abab-e499ca7d6303,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-7e9f83df-f810-43ed-9814-523465e3edd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-2e94056b-f5cb-4ee9-84ae-db47cd5728cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-8b685ec7-0de5-4ad1-b2ba-ee5b638c896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-f1b031eb-76a8-48f9-9af9-a8bd4d5fb993,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2b682165-904d-4e97-a96b-baa8835617d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2f457e44-7dca-4291-9bfd-09948ca37938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520508291-172.17.0.15-1598592992470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39193,DS-85779932-9aab-4b39-9c51-d1f09231ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-0c2e6d0b-5748-4164-856f-357b98deb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-19854525-1008-4acd-a9d9-7f1a0fceb8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-7180141f-0dbb-48c4-ad07-e22c4d190dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-5d7d52a5-17c7-47b3-af6f-2d0e8eef3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-4647ef20-9ced-4616-94cf-68579b29ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f5830c24-0410-43fd-b944-1b04c31ff09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-b59f3084-9330-4eb8-a548-62b48f1d5b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520508291-172.17.0.15-1598592992470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39193,DS-85779932-9aab-4b39-9c51-d1f09231ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-0c2e6d0b-5748-4164-856f-357b98deb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-19854525-1008-4acd-a9d9-7f1a0fceb8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-7180141f-0dbb-48c4-ad07-e22c4d190dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-5d7d52a5-17c7-47b3-af6f-2d0e8eef3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-4647ef20-9ced-4616-94cf-68579b29ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-f5830c24-0410-43fd-b944-1b04c31ff09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-b59f3084-9330-4eb8-a548-62b48f1d5b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516625648-172.17.0.15-1598593146682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-fde3420c-3253-45ab-80ce-c9be5c551259,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-54d867c1-df93-4e2c-a3d5-b6c4ecba6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-e4ccfc94-86ee-456d-b129-e6c996e4ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-613e8d0c-7204-4671-b73c-fcbadc4626a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-1e4eb7c8-34a2-475d-a0fd-cae950b780b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-09f8075f-10a4-478c-bde8-f90b3ceee779,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c9e5f70f-19aa-4ab5-983a-81c95ac4df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-12558bd8-a8b7-4924-b008-0243715df820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516625648-172.17.0.15-1598593146682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-fde3420c-3253-45ab-80ce-c9be5c551259,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-54d867c1-df93-4e2c-a3d5-b6c4ecba6db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-e4ccfc94-86ee-456d-b129-e6c996e4ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-613e8d0c-7204-4671-b73c-fcbadc4626a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-1e4eb7c8-34a2-475d-a0fd-cae950b780b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-09f8075f-10a4-478c-bde8-f90b3ceee779,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c9e5f70f-19aa-4ab5-983a-81c95ac4df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-12558bd8-a8b7-4924-b008-0243715df820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451432543-172.17.0.15-1598593326660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-bfc62302-154e-4f5f-bb29-e45ca5e7aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-403bf299-5a65-4304-a029-488b016549b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-be77c2d8-ba13-4ad9-98ea-215d9d955b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-7074fee9-3d08-49ea-bf4e-09874161fd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-ae17d77b-5b84-469a-b8a7-1129e472d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-06eb8b9a-5554-44dc-abc0-f719009e8561,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-5a2b7021-1324-4f5a-a7f8-10ec4288243f,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-f4246aa3-db54-4009-86cd-14090fff3c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451432543-172.17.0.15-1598593326660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-bfc62302-154e-4f5f-bb29-e45ca5e7aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-403bf299-5a65-4304-a029-488b016549b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-be77c2d8-ba13-4ad9-98ea-215d9d955b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-7074fee9-3d08-49ea-bf4e-09874161fd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-ae17d77b-5b84-469a-b8a7-1129e472d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-06eb8b9a-5554-44dc-abc0-f719009e8561,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-5a2b7021-1324-4f5a-a7f8-10ec4288243f,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-f4246aa3-db54-4009-86cd-14090fff3c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121622975-172.17.0.15-1598593387507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-ea86032a-d58a-40b8-99c2-0bf9be7979f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-4b2d3ab3-eb46-4198-ac71-9e95de19b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-1822daa9-92d0-459f-b4e4-04e9ef8ab072,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-7ba61f39-19fb-4e38-9c5d-6447d752ccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-0bb598a2-43f6-4744-b380-d5c8290c2fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-fbe235c7-b11c-4e23-922f-b39b2663e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-ec32cd8c-85a9-4a3b-9703-93879370e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48123f49-1856-4a4b-8065-c253b1fbae31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121622975-172.17.0.15-1598593387507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-ea86032a-d58a-40b8-99c2-0bf9be7979f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-4b2d3ab3-eb46-4198-ac71-9e95de19b2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-1822daa9-92d0-459f-b4e4-04e9ef8ab072,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-7ba61f39-19fb-4e38-9c5d-6447d752ccfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-0bb598a2-43f6-4744-b380-d5c8290c2fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-fbe235c7-b11c-4e23-922f-b39b2663e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-ec32cd8c-85a9-4a3b-9703-93879370e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48123f49-1856-4a4b-8065-c253b1fbae31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114429098-172.17.0.15-1598593763085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-6073afa5-1aaf-407c-9e96-1a1a5db9e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-1f76ca63-9d40-4283-ad34-d530f696e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-2a73344b-80d4-47bb-b28f-81a49e7b6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-6a3cfeca-7af1-4bbe-b90b-cfacf3c660f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-8473edf0-1246-4f03-bad3-b7a191281dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-1d8e9444-523a-4722-92c7-9c0b03eb55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9bedc3aa-c85a-4bb6-80ff-24d57068830c,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-14133a98-18d2-4e93-a32b-4d4c6dd24d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114429098-172.17.0.15-1598593763085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44471,DS-6073afa5-1aaf-407c-9e96-1a1a5db9e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-1f76ca63-9d40-4283-ad34-d530f696e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-2a73344b-80d4-47bb-b28f-81a49e7b6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-6a3cfeca-7af1-4bbe-b90b-cfacf3c660f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-8473edf0-1246-4f03-bad3-b7a191281dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-1d8e9444-523a-4722-92c7-9c0b03eb55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9bedc3aa-c85a-4bb6-80ff-24d57068830c,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-14133a98-18d2-4e93-a32b-4d4c6dd24d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003254542-172.17.0.15-1598594623732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-eb837e1a-a53a-4d51-a88c-0318b663712c,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9205ad42-00e9-44f3-a99a-5e162d48ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-71e2bc2e-4726-44cb-9639-79d5be17414d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-fb3a451c-266c-4bca-9b44-033c4588d352,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-7deef65f-0176-49f2-accb-05ab08d4e8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-5d39cbd7-dc97-48a4-84b0-4db7eaa62323,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-c58ffe35-e5e8-4ec7-b4ce-ad121f5a760e,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-7fc3285e-54a4-4165-822b-c2254c0c317e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003254542-172.17.0.15-1598594623732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-eb837e1a-a53a-4d51-a88c-0318b663712c,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-9205ad42-00e9-44f3-a99a-5e162d48ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-71e2bc2e-4726-44cb-9639-79d5be17414d,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-fb3a451c-266c-4bca-9b44-033c4588d352,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-7deef65f-0176-49f2-accb-05ab08d4e8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-5d39cbd7-dc97-48a4-84b0-4db7eaa62323,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-c58ffe35-e5e8-4ec7-b4ce-ad121f5a760e,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-7fc3285e-54a4-4165-822b-c2254c0c317e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208315177-172.17.0.15-1598595309292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32963,DS-1bfd6152-ad87-441d-ace2-077ba848bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-8ab158a2-1802-41a9-a7a7-e0f5386f6d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-117fd8b0-2a66-4ae6-94e5-7c8d89416078,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-60522a4d-bebc-4af6-b0d9-eee70751ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-10f824c4-ff2b-452b-8105-2c60aa3fced7,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-9fd76988-7e6d-4336-8aad-2c7e946a3027,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-c1ade7a3-29a2-4cf7-a78c-ee72e9758837,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-9fd6d804-6b46-46b8-ae8b-cdcf0a26bfc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208315177-172.17.0.15-1598595309292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32963,DS-1bfd6152-ad87-441d-ace2-077ba848bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-8ab158a2-1802-41a9-a7a7-e0f5386f6d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-117fd8b0-2a66-4ae6-94e5-7c8d89416078,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-60522a4d-bebc-4af6-b0d9-eee70751ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-10f824c4-ff2b-452b-8105-2c60aa3fced7,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-9fd76988-7e6d-4336-8aad-2c7e946a3027,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-c1ade7a3-29a2-4cf7-a78c-ee72e9758837,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-9fd6d804-6b46-46b8-ae8b-cdcf0a26bfc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669351365-172.17.0.15-1598595509339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-957dc937-82b5-4df3-a254-c918da137e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-0dc8904f-d0ec-4954-8a03-07b263e0d385,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b701a891-89cc-4a58-a7ad-ac3a7abb714e,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-43b352c8-1b90-45c5-8041-7d92179e81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-92b0ee1c-c2c4-4080-9522-eab34c565f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-b29bc222-a97d-4c51-8c76-4ce446665f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-cf9a7c29-1f46-4c4c-8c27-b719426e53a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-1356a435-0cda-4626-8ddc-df494ea4fdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669351365-172.17.0.15-1598595509339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-957dc937-82b5-4df3-a254-c918da137e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-0dc8904f-d0ec-4954-8a03-07b263e0d385,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b701a891-89cc-4a58-a7ad-ac3a7abb714e,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-43b352c8-1b90-45c5-8041-7d92179e81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-92b0ee1c-c2c4-4080-9522-eab34c565f38,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-b29bc222-a97d-4c51-8c76-4ce446665f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-cf9a7c29-1f46-4c4c-8c27-b719426e53a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-1356a435-0cda-4626-8ddc-df494ea4fdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192604438-172.17.0.15-1598595695887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-f555b6ea-ac26-4c16-b266-002bb083e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-a72ff398-856f-4cf5-a139-0ee29091f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-abc76810-687d-4a4c-bc1a-5d621a7b6732,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-26c14521-f440-4371-bf6e-eee755c8a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-0c55114c-78bf-4a44-a80f-75d48325e596,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-da6b88c6-5f39-49fb-8ba4-689b2d902b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-5b20516d-716d-4a5b-8b2d-9e2015aa2603,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-a3f60655-2532-4684-b94e-9a2f2f9266cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192604438-172.17.0.15-1598595695887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-f555b6ea-ac26-4c16-b266-002bb083e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-a72ff398-856f-4cf5-a139-0ee29091f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-abc76810-687d-4a4c-bc1a-5d621a7b6732,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-26c14521-f440-4371-bf6e-eee755c8a7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-0c55114c-78bf-4a44-a80f-75d48325e596,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-da6b88c6-5f39-49fb-8ba4-689b2d902b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-5b20516d-716d-4a5b-8b2d-9e2015aa2603,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-a3f60655-2532-4684-b94e-9a2f2f9266cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461530848-172.17.0.15-1598596459109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-20d72c5e-e0d2-4856-bde4-c5884771be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1c208040-93c4-41d6-b567-9ba9eddfe785,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ac5e5ad4-8f8a-4c43-8359-17456c1ca331,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-4bb85179-fbb5-4022-8d6a-81718ced0632,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-067fca62-b69f-4031-ad80-99b2f71cd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-dc9e1ac1-d360-4ba0-a552-7b06369ab7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-3bdafe57-e49a-44fc-834b-a0ce2023638a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-d5aed24d-6f5f-4c2c-8e0a-5c09358a6973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461530848-172.17.0.15-1598596459109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-20d72c5e-e0d2-4856-bde4-c5884771be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1c208040-93c4-41d6-b567-9ba9eddfe785,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ac5e5ad4-8f8a-4c43-8359-17456c1ca331,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-4bb85179-fbb5-4022-8d6a-81718ced0632,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-067fca62-b69f-4031-ad80-99b2f71cd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-dc9e1ac1-d360-4ba0-a552-7b06369ab7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-3bdafe57-e49a-44fc-834b-a0ce2023638a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-d5aed24d-6f5f-4c2c-8e0a-5c09358a6973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15832621-172.17.0.15-1598596522797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-30592591-450e-46dd-8de5-35aca5058baf,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-20e3a63b-6a21-418a-94e3-62d301b94f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-150ec871-786c-4272-bc9b-43469c72401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e0b1a59f-495b-487e-ae78-cc41a8db07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-73a0f065-0515-48f2-aa5f-250b91696063,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-203f3848-e706-4736-bbb8-059b0c390316,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-bac173a0-a08a-43a5-9071-8a358e48e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c57be444-945a-456c-9ba5-030e78d205d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15832621-172.17.0.15-1598596522797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36663,DS-30592591-450e-46dd-8de5-35aca5058baf,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-20e3a63b-6a21-418a-94e3-62d301b94f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-150ec871-786c-4272-bc9b-43469c72401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-e0b1a59f-495b-487e-ae78-cc41a8db07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-73a0f065-0515-48f2-aa5f-250b91696063,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-203f3848-e706-4736-bbb8-059b0c390316,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-bac173a0-a08a-43a5-9071-8a358e48e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c57be444-945a-456c-9ba5-030e78d205d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134344999-172.17.0.15-1598596552213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-36f7a03f-3119-48e9-b07c-84936f7478c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-a5036dba-a92f-4767-a653-280e1f3de9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-67832f60-3e41-494b-81c1-feaf788c8586,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-a8932188-0ea3-45f8-913d-a078acde95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-ad8b33cb-74f2-43cd-b353-d4813f39d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-05fdfc3e-6c93-4d4f-958a-72daf13f2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-50783d50-b1c5-4167-973b-fb28507da122,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-98a33b64-b8b3-404f-957d-ad3235bd6a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134344999-172.17.0.15-1598596552213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-36f7a03f-3119-48e9-b07c-84936f7478c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-a5036dba-a92f-4767-a653-280e1f3de9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-67832f60-3e41-494b-81c1-feaf788c8586,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-a8932188-0ea3-45f8-913d-a078acde95fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-ad8b33cb-74f2-43cd-b353-d4813f39d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-05fdfc3e-6c93-4d4f-958a-72daf13f2a79,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-50783d50-b1c5-4167-973b-fb28507da122,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-98a33b64-b8b3-404f-957d-ad3235bd6a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 4
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856169996-172.17.0.15-1598596581320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-40cbbee2-a6f9-4d3a-93b5-92de052cca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-aa0bfe14-a748-4fa6-832f-50de4c4c8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9b033bc2-bc40-40a8-ba08-0397ff32558f,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-f49ba09e-4462-421f-92cc-032cd573e420,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-b213c756-4cde-4765-8d33-687e389708db,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-c8c1d2b4-3c51-4340-9085-4e57e960be04,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-3be76577-e95a-440d-a51c-db5ce8d94f24,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-dcc9ac93-9f37-4c32-bf3b-ed16e49097b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856169996-172.17.0.15-1598596581320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-40cbbee2-a6f9-4d3a-93b5-92de052cca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-aa0bfe14-a748-4fa6-832f-50de4c4c8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9b033bc2-bc40-40a8-ba08-0397ff32558f,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-f49ba09e-4462-421f-92cc-032cd573e420,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-b213c756-4cde-4765-8d33-687e389708db,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-c8c1d2b4-3c51-4340-9085-4e57e960be04,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-3be76577-e95a-440d-a51c-db5ce8d94f24,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-dcc9ac93-9f37-4c32-bf3b-ed16e49097b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4768
