reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376133143-172.17.0.18-1598616181423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-bd90a3c0-de8b-4540-b36b-6815547ae212,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-5c7cf401-7472-4dc4-ba20-e254a6cc2f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-65a8d99d-d8c6-4176-bf74-970267dca182,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-4fe5ea8a-6610-4d44-9607-bc2465adee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-50e336b8-e18f-4f41-813a-62ba4624a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-822460cf-b10b-4568-926b-cdae6f750e50,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4ff7f0f6-2dc0-48c6-a68c-7b914f2c9fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-27f50a6e-b0a4-474e-84c1-dd1887388bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376133143-172.17.0.18-1598616181423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-bd90a3c0-de8b-4540-b36b-6815547ae212,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-5c7cf401-7472-4dc4-ba20-e254a6cc2f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-65a8d99d-d8c6-4176-bf74-970267dca182,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-4fe5ea8a-6610-4d44-9607-bc2465adee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-50e336b8-e18f-4f41-813a-62ba4624a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-822460cf-b10b-4568-926b-cdae6f750e50,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4ff7f0f6-2dc0-48c6-a68c-7b914f2c9fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-27f50a6e-b0a4-474e-84c1-dd1887388bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489249053-172.17.0.18-1598616405470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-2b4478c0-adf5-4d98-8d08-0531f70368ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-c9f4021d-3d3a-4674-a026-cd5e051b5604,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-7f0c2875-b329-480c-856b-060d64de3c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-0a81d7cb-cb36-41d4-8635-4c7b4036d735,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-0b46e3a5-c257-47cb-a0a4-09b7483df894,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-34350d84-04ec-4ee1-9891-ee3e31af1154,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c5782bac-5d89-444b-a7ec-26e6ee61bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-126fccdc-7e80-4733-ad3d-2842fdcbef0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489249053-172.17.0.18-1598616405470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-2b4478c0-adf5-4d98-8d08-0531f70368ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-c9f4021d-3d3a-4674-a026-cd5e051b5604,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-7f0c2875-b329-480c-856b-060d64de3c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-0a81d7cb-cb36-41d4-8635-4c7b4036d735,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-0b46e3a5-c257-47cb-a0a4-09b7483df894,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-34350d84-04ec-4ee1-9891-ee3e31af1154,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-c5782bac-5d89-444b-a7ec-26e6ee61bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-126fccdc-7e80-4733-ad3d-2842fdcbef0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303990320-172.17.0.18-1598616552361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f0d0ae10-b05f-49cd-b1b9-5cecc8be50d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-809108e4-80c3-42ca-9b4a-0a8991cf3f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-8bbf75a7-2ac7-4f64-b7d1-31297e56986a,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-35b05bd1-f535-4a45-8bee-4279c84393f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-25c30c7a-ae98-4dc7-a18c-e7527e248d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-c15596bd-f6a4-4b45-85c9-07755a394fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-dc94c1af-2bfb-42bb-9542-783025f30268,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-77415644-d80d-4482-a406-28b7e1c122b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303990320-172.17.0.18-1598616552361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-f0d0ae10-b05f-49cd-b1b9-5cecc8be50d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-809108e4-80c3-42ca-9b4a-0a8991cf3f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-8bbf75a7-2ac7-4f64-b7d1-31297e56986a,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-35b05bd1-f535-4a45-8bee-4279c84393f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-25c30c7a-ae98-4dc7-a18c-e7527e248d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-c15596bd-f6a4-4b45-85c9-07755a394fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-dc94c1af-2bfb-42bb-9542-783025f30268,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-77415644-d80d-4482-a406-28b7e1c122b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653663777-172.17.0.18-1598617227838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-e58cd339-eaaf-484c-8545-1a1d5511f1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-337439eb-a13f-4401-85b8-13abdd7b82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-7e71e041-24dd-4a85-ae60-fff1266abf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-c6f91692-f6e7-4b97-85b1-eada7ba7eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-fceb1114-6be8-4e16-ace1-9c3e2370af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-ba9867ab-a122-42da-94ac-056da93e8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-c2d1aea7-7748-47ab-a2ce-8ea1af0633de,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-92b47954-5404-402c-b88d-f4077c2e7afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653663777-172.17.0.18-1598617227838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-e58cd339-eaaf-484c-8545-1a1d5511f1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-337439eb-a13f-4401-85b8-13abdd7b82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-7e71e041-24dd-4a85-ae60-fff1266abf94,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-c6f91692-f6e7-4b97-85b1-eada7ba7eeed,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-fceb1114-6be8-4e16-ace1-9c3e2370af5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-ba9867ab-a122-42da-94ac-056da93e8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-c2d1aea7-7748-47ab-a2ce-8ea1af0633de,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-92b47954-5404-402c-b88d-f4077c2e7afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643786328-172.17.0.18-1598617495620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-66eb245a-bfe0-4d91-b267-bbbd78080dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-af77c947-2037-4d83-989a-90fbff56b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d88c0080-e7cf-461c-8d23-0da4cef183b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-314c66ef-3ee8-4df8-85d4-9f10a5251b17,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-b5539dad-09a3-4672-a7f7-27c374d28f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8eb70c6d-bbcf-4376-9a8b-316061f8ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-9fc4ed36-ad4c-4386-b9d9-03410d7c229a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-8a33a51f-e857-49c1-97c5-7e65d920b6e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643786328-172.17.0.18-1598617495620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-66eb245a-bfe0-4d91-b267-bbbd78080dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-af77c947-2037-4d83-989a-90fbff56b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-d88c0080-e7cf-461c-8d23-0da4cef183b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-314c66ef-3ee8-4df8-85d4-9f10a5251b17,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-b5539dad-09a3-4672-a7f7-27c374d28f84,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8eb70c6d-bbcf-4376-9a8b-316061f8ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-9fc4ed36-ad4c-4386-b9d9-03410d7c229a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-8a33a51f-e857-49c1-97c5-7e65d920b6e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43133263-172.17.0.18-1598618205027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-8c425c42-8990-4c33-a813-bd1c4f16a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-ff1878ad-626a-41ba-9e14-8ba6e80bee47,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-1c8a9dbd-29df-4967-a89f-eddf51b98705,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-be0e7774-d8e0-40ac-8ad5-d277f3d4ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-79df2156-6197-4c52-8e96-797900e9dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-aab20cd1-ee0a-4eba-9883-3b82556e789e,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-362d96c4-0cb2-4d88-b46a-dbda6dcf5398,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-a4b698a9-aaa4-449c-9502-f4642c2c0f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43133263-172.17.0.18-1598618205027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-8c425c42-8990-4c33-a813-bd1c4f16a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-ff1878ad-626a-41ba-9e14-8ba6e80bee47,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-1c8a9dbd-29df-4967-a89f-eddf51b98705,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-be0e7774-d8e0-40ac-8ad5-d277f3d4ba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-79df2156-6197-4c52-8e96-797900e9dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-aab20cd1-ee0a-4eba-9883-3b82556e789e,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-362d96c4-0cb2-4d88-b46a-dbda6dcf5398,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-a4b698a9-aaa4-449c-9502-f4642c2c0f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160913573-172.17.0.18-1598618665936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34786,DS-732b0bf6-aab5-4438-a100-ab3a96a8f299,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-db08ae9a-eb7a-45c5-ac23-2586eb49c572,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-6950cd1e-1256-4d51-8699-ed423c4e436d,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ffe93556-d000-4b8e-a336-588217bd9ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-7463e3f1-a23a-498a-ad66-b5d3517776e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5dbf0033-928b-4d92-9b49-7bc0e5b9709a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-b09bd475-fa95-4cff-9b48-712267549afe,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-d137d74b-80f0-443b-b777-3858619c90a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160913573-172.17.0.18-1598618665936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34786,DS-732b0bf6-aab5-4438-a100-ab3a96a8f299,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-db08ae9a-eb7a-45c5-ac23-2586eb49c572,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-6950cd1e-1256-4d51-8699-ed423c4e436d,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ffe93556-d000-4b8e-a336-588217bd9ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-7463e3f1-a23a-498a-ad66-b5d3517776e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-5dbf0033-928b-4d92-9b49-7bc0e5b9709a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-b09bd475-fa95-4cff-9b48-712267549afe,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-d137d74b-80f0-443b-b777-3858619c90a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638309680-172.17.0.18-1598618988580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-3fae92d4-c105-438b-a21f-644afab28ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-599f552d-d3df-466e-b1c7-fbb35f85efa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-315a10ab-c8bc-4e38-8871-932486d112b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-c8b54e33-c17d-4685-8b4e-cfd9b1fc68b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-d82e3c89-3669-489c-a190-47e58cad8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-d05fcbab-97fc-4df2-ae29-87b1782e5578,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-c4b8c196-90f5-49a0-8f2c-42d36757ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-d48e9cb8-a500-40a6-808d-641c7a64f67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638309680-172.17.0.18-1598618988580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-3fae92d4-c105-438b-a21f-644afab28ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-599f552d-d3df-466e-b1c7-fbb35f85efa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-315a10ab-c8bc-4e38-8871-932486d112b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-c8b54e33-c17d-4685-8b4e-cfd9b1fc68b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-d82e3c89-3669-489c-a190-47e58cad8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-d05fcbab-97fc-4df2-ae29-87b1782e5578,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-c4b8c196-90f5-49a0-8f2c-42d36757ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-d48e9cb8-a500-40a6-808d-641c7a64f67a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130169342-172.17.0.18-1598619556865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-cdf1b09a-a55a-4c6f-9083-3dbab7c2226a,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a88c699e-1fb0-4272-9930-ea8b015ccd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-814cae42-0a62-4b63-85ea-a4a31af2afef,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-e26b622c-8281-487e-884b-efe513fd89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a4cc4c94-db54-4449-9e86-089ffc59ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-2008ae71-56a2-48cc-ad4d-c81ade375d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-91285a59-4af0-4a6e-bf7c-597895cecfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-18164b44-f09d-40f4-b7fd-8aeef0a47d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130169342-172.17.0.18-1598619556865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-cdf1b09a-a55a-4c6f-9083-3dbab7c2226a,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a88c699e-1fb0-4272-9930-ea8b015ccd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-814cae42-0a62-4b63-85ea-a4a31af2afef,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-e26b622c-8281-487e-884b-efe513fd89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-a4cc4c94-db54-4449-9e86-089ffc59ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-2008ae71-56a2-48cc-ad4d-c81ade375d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-91285a59-4af0-4a6e-bf7c-597895cecfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-18164b44-f09d-40f4-b7fd-8aeef0a47d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706798500-172.17.0.18-1598619644290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-1e964092-0fbe-4181-83f5-b73ac8b2b122,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-98bd2e67-e9ed-4709-b282-363cecc2a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-1b84c07d-5fb6-48be-8deb-2f7d0a201aca,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-a57bd696-f924-44e5-979f-f5a1dda564f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-f1f1e658-7f5b-44fe-8d99-2fb5caf179b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-dce904f5-a1a7-4171-857b-507d9e2bcce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-18fe666d-f1e7-43a7-996e-fc53ddfc08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5552f49f-a2da-4341-8053-2728e41ea602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706798500-172.17.0.18-1598619644290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-1e964092-0fbe-4181-83f5-b73ac8b2b122,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-98bd2e67-e9ed-4709-b282-363cecc2a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-1b84c07d-5fb6-48be-8deb-2f7d0a201aca,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-a57bd696-f924-44e5-979f-f5a1dda564f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-f1f1e658-7f5b-44fe-8d99-2fb5caf179b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-dce904f5-a1a7-4171-857b-507d9e2bcce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-18fe666d-f1e7-43a7-996e-fc53ddfc08ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5552f49f-a2da-4341-8053-2728e41ea602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916595220-172.17.0.18-1598620042447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35810,DS-956d9121-4f40-4758-884c-49719da59b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-957e042b-0fb3-44d9-bff5-36fd434e30b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-c7a9e383-042c-4f9d-bbf4-35bcb5e72ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-5643f95c-16fe-4704-81c7-4091c8c72f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-35a8d638-c267-4b0c-9013-06167bc621ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-facf202e-ed87-4516-9fd8-07a70855109b,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-41984818-0d78-42d7-a9a9-067a1fe65a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-8a82d21c-94ae-402a-951b-7fa1634d7de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916595220-172.17.0.18-1598620042447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35810,DS-956d9121-4f40-4758-884c-49719da59b96,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-957e042b-0fb3-44d9-bff5-36fd434e30b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-c7a9e383-042c-4f9d-bbf4-35bcb5e72ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-5643f95c-16fe-4704-81c7-4091c8c72f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-35a8d638-c267-4b0c-9013-06167bc621ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-facf202e-ed87-4516-9fd8-07a70855109b,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-41984818-0d78-42d7-a9a9-067a1fe65a76,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-8a82d21c-94ae-402a-951b-7fa1634d7de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41317357-172.17.0.18-1598620606910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-1ba67dda-0454-4d8c-97d2-ba57334d9684,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-a8c9751e-ea36-4f97-b286-169c4ad3b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5a717ca8-1514-468b-97c2-ef8296b88b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-2a330cf9-200b-4266-90c8-8de32a00983e,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ebd87660-a7cf-4451-b74f-d4e867536835,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-46cbe979-154f-4c72-92aa-5a95a5895831,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7665cfea-3549-45e9-8ddb-7e36d450c157,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-f79ac07d-a535-4f69-a67a-ef2bf6e9805a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41317357-172.17.0.18-1598620606910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41449,DS-1ba67dda-0454-4d8c-97d2-ba57334d9684,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-a8c9751e-ea36-4f97-b286-169c4ad3b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-5a717ca8-1514-468b-97c2-ef8296b88b98,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-2a330cf9-200b-4266-90c8-8de32a00983e,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ebd87660-a7cf-4451-b74f-d4e867536835,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-46cbe979-154f-4c72-92aa-5a95a5895831,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7665cfea-3549-45e9-8ddb-7e36d450c157,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-f79ac07d-a535-4f69-a67a-ef2bf6e9805a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708215405-172.17.0.18-1598620676419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42340,DS-1c9d3fd2-35cc-4db2-af28-ca628c94c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-40f2638c-42e7-45f3-975f-93126186abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-51a6a7ee-1edc-4507-aaed-0ad8be70e473,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-2294e1d8-000a-4947-ace8-57d8dbc8a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-d95dfe47-a460-4630-88c2-87cb8247f367,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-9bf1a05b-2b1b-4f02-818e-191b150d9239,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-64ea7d69-cd48-4681-aa0b-adaaf7553d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-ab722e60-07c8-4c74-a6d7-8135c79d835f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708215405-172.17.0.18-1598620676419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42340,DS-1c9d3fd2-35cc-4db2-af28-ca628c94c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-40f2638c-42e7-45f3-975f-93126186abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-51a6a7ee-1edc-4507-aaed-0ad8be70e473,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-2294e1d8-000a-4947-ace8-57d8dbc8a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-d95dfe47-a460-4630-88c2-87cb8247f367,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-9bf1a05b-2b1b-4f02-818e-191b150d9239,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-64ea7d69-cd48-4681-aa0b-adaaf7553d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-ab722e60-07c8-4c74-a6d7-8135c79d835f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5742
