reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585502096-172.17.0.9-1598615243024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-5403c93a-58a2-4f6e-9afe-c407236db088,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f0386fb8-0305-467a-86f3-491d0a721976,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c5cca562-5e1e-4fae-af9e-8b2aa6f95200,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-3166b90e-f8d8-492e-ae33-f775eb27eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-6a5355b0-31e7-495a-a7da-d47dfcc0b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-7ff29b0f-4ddb-46eb-a9c5-957d4c395c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-d359cfa8-ae17-4818-a550-4af1f7b84292,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-4696d6cf-fcc6-4148-89ce-e0a9c64aff66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585502096-172.17.0.9-1598615243024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-5403c93a-58a2-4f6e-9afe-c407236db088,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f0386fb8-0305-467a-86f3-491d0a721976,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c5cca562-5e1e-4fae-af9e-8b2aa6f95200,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-3166b90e-f8d8-492e-ae33-f775eb27eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-6a5355b0-31e7-495a-a7da-d47dfcc0b3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-7ff29b0f-4ddb-46eb-a9c5-957d4c395c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-d359cfa8-ae17-4818-a550-4af1f7b84292,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-4696d6cf-fcc6-4148-89ce-e0a9c64aff66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744103828-172.17.0.9-1598615434979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-495683e3-c5fe-4d7c-83eb-f284fb208f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-f869dcc5-c5b6-4a49-9740-c811ca79f52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-c739d6c4-98f7-4714-a41e-edd51fada7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-a3ed2229-9e6b-4922-a2af-b14458c8c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-de932953-46b4-4ac6-aaf1-4f9c2893aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-840ad7ec-92b4-4bd0-beb7-c189dec84e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-6fb4ab1d-4ec7-4972-a0b8-ae483db37c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-3a66e8c7-a8da-4887-a869-4fed8ece3474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744103828-172.17.0.9-1598615434979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-495683e3-c5fe-4d7c-83eb-f284fb208f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-f869dcc5-c5b6-4a49-9740-c811ca79f52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-c739d6c4-98f7-4714-a41e-edd51fada7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-a3ed2229-9e6b-4922-a2af-b14458c8c2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-de932953-46b4-4ac6-aaf1-4f9c2893aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-840ad7ec-92b4-4bd0-beb7-c189dec84e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-6fb4ab1d-4ec7-4972-a0b8-ae483db37c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-3a66e8c7-a8da-4887-a869-4fed8ece3474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728201759-172.17.0.9-1598615502285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-308dda3e-31ff-4355-8632-083532f789be,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-09169529-227d-4093-8048-864df3a429aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-751e9167-b9e9-410e-b952-8216480e04c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-d8d6d895-df5f-495e-9ae1-9778e91a745a,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-22b629d8-06c7-45a5-a8e3-a8e00cb3d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-52689166-7c89-4ff1-b9dd-ab9d98c6bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-02b70241-cf2d-4f38-bda2-58e0180e7836,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-e6c29a8b-f05b-4aa8-8141-0238a32c5023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728201759-172.17.0.9-1598615502285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-308dda3e-31ff-4355-8632-083532f789be,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-09169529-227d-4093-8048-864df3a429aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-751e9167-b9e9-410e-b952-8216480e04c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-d8d6d895-df5f-495e-9ae1-9778e91a745a,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-22b629d8-06c7-45a5-a8e3-a8e00cb3d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-52689166-7c89-4ff1-b9dd-ab9d98c6bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-02b70241-cf2d-4f38-bda2-58e0180e7836,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-e6c29a8b-f05b-4aa8-8141-0238a32c5023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681076049-172.17.0.9-1598615545103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-0ce4084a-8136-4588-b33a-40ed5d4dfa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-704a2e6f-aaf6-4f05-9070-5c32c6f1945d,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-9c14ba26-ffe9-40d3-a3c9-b5e7bf9a1e80,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9bb74897-29b4-4a28-85fd-846b0670fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-d6b644c7-9b8e-46c6-af01-a75e53e0448e,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-6c7c89a2-6be6-431f-b483-dd9da5b5ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d3099ec6-be94-4e0d-83d8-473f961e4f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-b6eb60b1-64b9-4725-89d2-49e1148fcc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681076049-172.17.0.9-1598615545103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-0ce4084a-8136-4588-b33a-40ed5d4dfa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-704a2e6f-aaf6-4f05-9070-5c32c6f1945d,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-9c14ba26-ffe9-40d3-a3c9-b5e7bf9a1e80,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9bb74897-29b4-4a28-85fd-846b0670fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-d6b644c7-9b8e-46c6-af01-a75e53e0448e,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-6c7c89a2-6be6-431f-b483-dd9da5b5ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-d3099ec6-be94-4e0d-83d8-473f961e4f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-b6eb60b1-64b9-4725-89d2-49e1148fcc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493079138-172.17.0.9-1598615932314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-00399a34-6fd0-4601-bd39-c7dedaf8b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-e96ae4fc-406b-4071-9095-d3146d92fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-7f87fde0-0d6e-4559-a78a-958970cdad98,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-03352eb0-7ae2-4106-8b25-6a26c9794162,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-9c0ac13b-8d29-4887-ab98-b4b851204414,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-22e7b145-c6ed-436a-aa72-9faaba9d8f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-22635473-4ed1-417e-9b5c-82532ba011da,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-53c2108a-d94e-4309-b132-59c384641976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493079138-172.17.0.9-1598615932314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-00399a34-6fd0-4601-bd39-c7dedaf8b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-e96ae4fc-406b-4071-9095-d3146d92fe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-7f87fde0-0d6e-4559-a78a-958970cdad98,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-03352eb0-7ae2-4106-8b25-6a26c9794162,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-9c0ac13b-8d29-4887-ab98-b4b851204414,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-22e7b145-c6ed-436a-aa72-9faaba9d8f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-22635473-4ed1-417e-9b5c-82532ba011da,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-53c2108a-d94e-4309-b132-59c384641976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745464321-172.17.0.9-1598615963463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40958,DS-86aa4e6e-e628-4def-aa98-25339b702e68,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-2e227cf2-24a9-4016-9a50-06537a0666fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-41139385-cc1c-4c94-977e-aaf44dbf9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-5a4bc8cd-f0de-4843-bd35-35958801d000,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-a616c2e0-3c4b-48e7-9c5c-59d97e51f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-1f4b0b2a-7d94-4dca-a0b3-873f89d1c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-69928076-a31a-4bc8-8742-28f2013d68e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-f1e75274-985e-4311-b406-d4fa5029a79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745464321-172.17.0.9-1598615963463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40958,DS-86aa4e6e-e628-4def-aa98-25339b702e68,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-2e227cf2-24a9-4016-9a50-06537a0666fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-41139385-cc1c-4c94-977e-aaf44dbf9c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-5a4bc8cd-f0de-4843-bd35-35958801d000,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-a616c2e0-3c4b-48e7-9c5c-59d97e51f6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-1f4b0b2a-7d94-4dca-a0b3-873f89d1c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-69928076-a31a-4bc8-8742-28f2013d68e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-f1e75274-985e-4311-b406-d4fa5029a79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600257904-172.17.0.9-1598616378898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-0bb286ca-913b-4ade-949d-67b6edad29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-382502fd-8797-416a-a845-b26525e9bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-f1f9bea0-a03f-4f53-bded-03a12ad6c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2dd21561-60bf-4303-9d8a-8b6cdca28adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-38146e22-077f-443d-a535-01bcfe08111b,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-734c8c7c-5171-4919-afd9-40aa670a696e,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-55745db0-ec9f-4084-927a-d66d00ff0d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-e85096de-64fa-4ac9-9c07-2a1338d49eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600257904-172.17.0.9-1598616378898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-0bb286ca-913b-4ade-949d-67b6edad29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-382502fd-8797-416a-a845-b26525e9bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-f1f9bea0-a03f-4f53-bded-03a12ad6c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2dd21561-60bf-4303-9d8a-8b6cdca28adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-38146e22-077f-443d-a535-01bcfe08111b,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-734c8c7c-5171-4919-afd9-40aa670a696e,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-55745db0-ec9f-4084-927a-d66d00ff0d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-e85096de-64fa-4ac9-9c07-2a1338d49eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894577149-172.17.0.9-1598616928441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-207d2093-efaa-4111-9d92-2d9dfd5f518b,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-cbc365d3-2cc9-4350-88c2-fbd14586bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-e510816b-691e-4e63-bd3e-336a20962a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8e4fc2e6-5d69-4aca-bb5f-d81807f99b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cd48425a-5b96-4517-85d0-61b117575cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ac7677ba-7fe0-41af-a390-491a571b46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e231bc70-0188-47ce-b9fd-7fdd44bc0b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-7baa43e7-1ef7-44a4-8773-18594d11c471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894577149-172.17.0.9-1598616928441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-207d2093-efaa-4111-9d92-2d9dfd5f518b,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-cbc365d3-2cc9-4350-88c2-fbd14586bdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-e510816b-691e-4e63-bd3e-336a20962a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-8e4fc2e6-5d69-4aca-bb5f-d81807f99b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-cd48425a-5b96-4517-85d0-61b117575cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ac7677ba-7fe0-41af-a390-491a571b46b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e231bc70-0188-47ce-b9fd-7fdd44bc0b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-7baa43e7-1ef7-44a4-8773-18594d11c471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389821061-172.17.0.9-1598617022116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-1e592c67-c4a4-45c3-ac5c-dbccd053210b,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d9301ede-845d-4fbb-928c-bcdf5d34b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-9a9dda98-7e42-484c-8493-a4bee8049ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-eeb9652c-0db3-4055-87a2-bf3678aeca60,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-7f32823b-19ea-4bc1-8003-43ad5021eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-9ccd8f98-5243-409e-b61e-fd8a70febb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-457505ea-17ac-4a7e-a4f5-8eb555bdb3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f7fbaf11-2a3f-4d43-9888-0d350cf1c8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389821061-172.17.0.9-1598617022116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44813,DS-1e592c67-c4a4-45c3-ac5c-dbccd053210b,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d9301ede-845d-4fbb-928c-bcdf5d34b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-9a9dda98-7e42-484c-8493-a4bee8049ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-eeb9652c-0db3-4055-87a2-bf3678aeca60,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-7f32823b-19ea-4bc1-8003-43ad5021eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-9ccd8f98-5243-409e-b61e-fd8a70febb79,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-457505ea-17ac-4a7e-a4f5-8eb555bdb3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-f7fbaf11-2a3f-4d43-9888-0d350cf1c8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409786021-172.17.0.9-1598617457598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-3550449a-4fcd-469b-a949-fb04cab13909,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-e5bccd40-2f33-4970-bd19-62451610a595,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-94f84c29-9703-4363-99f5-462cdfa86390,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-550b6857-a7bc-4cae-a81c-e73222211fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-2553ddbd-052b-4faa-be87-c7c57e194fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-cbd5bbe5-e075-4c2c-99da-509adbe34a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-45ff2df5-6370-46ff-a84a-365d1dd432a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-b90dafa6-53dc-4cd8-bb43-0abd5f76f72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409786021-172.17.0.9-1598617457598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-3550449a-4fcd-469b-a949-fb04cab13909,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-e5bccd40-2f33-4970-bd19-62451610a595,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-94f84c29-9703-4363-99f5-462cdfa86390,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-550b6857-a7bc-4cae-a81c-e73222211fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-2553ddbd-052b-4faa-be87-c7c57e194fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-cbd5bbe5-e075-4c2c-99da-509adbe34a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-45ff2df5-6370-46ff-a84a-365d1dd432a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-b90dafa6-53dc-4cd8-bb43-0abd5f76f72f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914181552-172.17.0.9-1598617901219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-726382e0-94a8-407f-89ea-5315cabe5f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-57f81b09-2f55-4e23-91aa-9be98493e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-e20c716d-9d92-4546-9cc4-d8cb140a8206,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-90318a39-cfee-4ace-84fb-a7b2f418ddda,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-82ad19a8-9ed3-43af-a735-1d56c47f7e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a434e8e1-bf5f-4f0e-ad57-7251ffe1e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-231eaf8b-e098-4e45-948d-05c78eb9711d,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-63f4c46d-c380-47bb-89a0-aa66519424d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914181552-172.17.0.9-1598617901219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38483,DS-726382e0-94a8-407f-89ea-5315cabe5f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-57f81b09-2f55-4e23-91aa-9be98493e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-e20c716d-9d92-4546-9cc4-d8cb140a8206,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-90318a39-cfee-4ace-84fb-a7b2f418ddda,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-82ad19a8-9ed3-43af-a735-1d56c47f7e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a434e8e1-bf5f-4f0e-ad57-7251ffe1e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-231eaf8b-e098-4e45-948d-05c78eb9711d,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-63f4c46d-c380-47bb-89a0-aa66519424d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654602698-172.17.0.9-1598618296456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-050234e5-8fa0-4fd9-bffe-40d9e0e02642,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-a17f38ec-e722-4416-a9f3-398c82ac8d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-b7e33f82-fbab-4fca-a13c-461bf8112f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-9a97281f-9811-41f6-bdd5-8acd1737f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-320fd58f-39cc-48c8-b584-f9cfdbb159fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-d500e718-ae03-498a-9fb2-98662e46626e,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-bbbe6292-9f54-4d1d-93a4-e7ef0a00f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-97be9abe-993c-47c7-960d-6d318bfc769b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654602698-172.17.0.9-1598618296456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-050234e5-8fa0-4fd9-bffe-40d9e0e02642,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-a17f38ec-e722-4416-a9f3-398c82ac8d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-b7e33f82-fbab-4fca-a13c-461bf8112f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-9a97281f-9811-41f6-bdd5-8acd1737f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-320fd58f-39cc-48c8-b584-f9cfdbb159fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-d500e718-ae03-498a-9fb2-98662e46626e,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-bbbe6292-9f54-4d1d-93a4-e7ef0a00f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-97be9abe-993c-47c7-960d-6d318bfc769b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563940235-172.17.0.9-1598618820796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34652,DS-8cf050f0-7c0f-4712-bda1-49bbfc08b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-325deacc-3e70-44d8-8629-5a8798cb7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-9ed4d89d-a1ec-4b31-a958-3b84352397fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-e19491c7-dbb5-459c-aaf1-1a38a2a40f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-ca45084b-6d1c-4133-90a8-e888d3cdd871,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c17cd155-ecf6-46d5-990f-4da937a1fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b3097843-e1b0-4aed-8533-a6ed3d536812,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-1a66f511-806d-4dfa-9c32-b5681acc72dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563940235-172.17.0.9-1598618820796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34652,DS-8cf050f0-7c0f-4712-bda1-49bbfc08b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-325deacc-3e70-44d8-8629-5a8798cb7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-9ed4d89d-a1ec-4b31-a958-3b84352397fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-e19491c7-dbb5-459c-aaf1-1a38a2a40f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-ca45084b-6d1c-4133-90a8-e888d3cdd871,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c17cd155-ecf6-46d5-990f-4da937a1fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-b3097843-e1b0-4aed-8533-a6ed3d536812,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-1a66f511-806d-4dfa-9c32-b5681acc72dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077714982-172.17.0.9-1598619161529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34757,DS-5de0011a-e3e4-4855-8165-09028be08e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b979b741-a5ba-4574-b2d7-c403c10f69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-5b7d0a59-1dc6-41ff-8913-5ef42569fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-db4951e9-688a-41ed-9491-9abaf9ea8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-81a12cd0-67be-4462-9009-8f7a5f7e3836,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-28d881db-cba1-49b7-8df3-adff7938f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-97732cdb-5dad-4983-9ca9-a09dd672767a,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-9cdb044c-8468-4ad6-9791-475441960dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077714982-172.17.0.9-1598619161529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34757,DS-5de0011a-e3e4-4855-8165-09028be08e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b979b741-a5ba-4574-b2d7-c403c10f69ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-5b7d0a59-1dc6-41ff-8913-5ef42569fa79,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-db4951e9-688a-41ed-9491-9abaf9ea8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-81a12cd0-67be-4462-9009-8f7a5f7e3836,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-28d881db-cba1-49b7-8df3-adff7938f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-97732cdb-5dad-4983-9ca9-a09dd672767a,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-9cdb044c-8468-4ad6-9791-475441960dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986101172-172.17.0.9-1598619285017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-6985a3b3-c998-4c8a-a0f7-0f90bd94c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-d6e09487-05dd-4c54-82fe-cca7a1d0c028,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-f19a4d0e-c82a-466c-a1ee-7e5383869a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-7455d2c2-005f-4b82-a72d-c5b89a897ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-44acd401-8fd0-4b92-9318-dfe9505c3afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-279fb8c4-e4fe-4467-bd57-530d1251e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-355be2bd-0089-49b9-8ff8-493fe357a683,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-f9f72c20-7645-41ea-a267-02723cf179fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986101172-172.17.0.9-1598619285017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-6985a3b3-c998-4c8a-a0f7-0f90bd94c8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-d6e09487-05dd-4c54-82fe-cca7a1d0c028,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-f19a4d0e-c82a-466c-a1ee-7e5383869a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-7455d2c2-005f-4b82-a72d-c5b89a897ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-44acd401-8fd0-4b92-9318-dfe9505c3afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-279fb8c4-e4fe-4467-bd57-530d1251e2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-355be2bd-0089-49b9-8ff8-493fe357a683,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-f9f72c20-7645-41ea-a267-02723cf179fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460657241-172.17.0.9-1598619374855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-69cbd235-2bcf-496d-ab90-45e354df4b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-a73a6cf4-f0aa-4b9b-a02f-b96d792cfbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-71a70e59-e2fa-4dca-a919-40f2eb5e80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-e796b3cb-0986-4fde-be98-997d05f5f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-0c684e87-791a-494a-90bd-0607d792875e,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-8d8f34d5-1975-4da8-9843-dcdadea632d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-32ee5f06-fba6-4fce-96d5-a698c018fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-93cbad92-4b55-48e4-83d9-aa859c7de588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460657241-172.17.0.9-1598619374855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-69cbd235-2bcf-496d-ab90-45e354df4b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-a73a6cf4-f0aa-4b9b-a02f-b96d792cfbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-71a70e59-e2fa-4dca-a919-40f2eb5e80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-e796b3cb-0986-4fde-be98-997d05f5f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-0c684e87-791a-494a-90bd-0607d792875e,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-8d8f34d5-1975-4da8-9843-dcdadea632d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-32ee5f06-fba6-4fce-96d5-a698c018fa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-93cbad92-4b55-48e4-83d9-aa859c7de588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159395797-172.17.0.9-1598619445236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-48756d64-51c9-442d-9678-9282454b3857,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-e5c5aa20-91bd-48f4-807a-d5020c645585,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-ea739697-3aec-46ac-8f2d-ddb4eb767c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-8fe90cc9-ea90-451a-9424-5c3da020da95,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-44735b81-8215-4b40-be61-697592d6116b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-fc538254-96ce-4fed-be15-0c14f1ba966e,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-dc737c8a-c027-4a11-92f4-d6fddca5c239,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-cdd18847-a3db-4050-8e38-829f5718f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159395797-172.17.0.9-1598619445236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-48756d64-51c9-442d-9678-9282454b3857,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-e5c5aa20-91bd-48f4-807a-d5020c645585,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-ea739697-3aec-46ac-8f2d-ddb4eb767c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-8fe90cc9-ea90-451a-9424-5c3da020da95,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-44735b81-8215-4b40-be61-697592d6116b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-fc538254-96ce-4fed-be15-0c14f1ba966e,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-dc737c8a-c027-4a11-92f4-d6fddca5c239,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-cdd18847-a3db-4050-8e38-829f5718f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824734013-172.17.0.9-1598619586779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-f6a9eeae-577a-4bba-b2b1-71f33a3eb646,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-63795646-5311-4880-a0eb-cac4cbba0cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-418621ef-f568-4e1a-a021-5be1c34cef30,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-5ac7f496-2b51-4702-977c-eac3d7e9aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-434f5b5f-924d-41fe-89f0-ced69b116f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-1e91a67e-5c2f-4271-a9ea-e93646237c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-3c09c18d-5ea2-4883-a216-476e98192b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-12009d0f-01b2-4dbc-9969-0e4e00aca0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824734013-172.17.0.9-1598619586779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-f6a9eeae-577a-4bba-b2b1-71f33a3eb646,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-63795646-5311-4880-a0eb-cac4cbba0cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-418621ef-f568-4e1a-a021-5be1c34cef30,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-5ac7f496-2b51-4702-977c-eac3d7e9aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-434f5b5f-924d-41fe-89f0-ced69b116f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-1e91a67e-5c2f-4271-a9ea-e93646237c43,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-3c09c18d-5ea2-4883-a216-476e98192b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-12009d0f-01b2-4dbc-9969-0e4e00aca0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475333836-172.17.0.9-1598619707109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-450355fc-f3a9-4660-85b2-5837c3ae0430,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-d610d33c-9985-4dbd-8e22-58dd882a3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-80a15857-cf22-4380-8eee-cd4c222d5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-7ae40ed4-4058-4035-85d9-044ac659980e,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-48cdd7df-cd1b-41b1-a774-1556278b9427,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-0547b929-0032-490f-8aab-8b2554443f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-9a4896cd-08a3-4c58-883f-238ef47254c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-a9e39246-7e44-4d2d-a59c-e141740e92e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475333836-172.17.0.9-1598619707109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44283,DS-450355fc-f3a9-4660-85b2-5837c3ae0430,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-d610d33c-9985-4dbd-8e22-58dd882a3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-80a15857-cf22-4380-8eee-cd4c222d5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-7ae40ed4-4058-4035-85d9-044ac659980e,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-48cdd7df-cd1b-41b1-a774-1556278b9427,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-0547b929-0032-490f-8aab-8b2554443f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-9a4896cd-08a3-4c58-883f-238ef47254c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-a9e39246-7e44-4d2d-a59c-e141740e92e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4800
