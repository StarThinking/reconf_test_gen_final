reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350976961-172.17.0.19-1598486334778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-f7523a00-dbbe-47bc-a32c-5ecb3a033907,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b0039b01-4c24-4148-a229-22d3f22a307a,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-af09e3d4-1e10-46ef-ab39-4a887a3a7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-8446f4f6-3696-4c06-9a17-f4515011c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-bf741c5b-1373-4afb-9514-96b5ba822669,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4c958c10-525c-4d7d-9063-39a63c7ded1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-b479e11b-bf21-4a84-8547-a6a16206e520,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-030e9c83-a99e-40ec-b7d6-7037ca0b818f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350976961-172.17.0.19-1598486334778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-f7523a00-dbbe-47bc-a32c-5ecb3a033907,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b0039b01-4c24-4148-a229-22d3f22a307a,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-af09e3d4-1e10-46ef-ab39-4a887a3a7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-8446f4f6-3696-4c06-9a17-f4515011c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-bf741c5b-1373-4afb-9514-96b5ba822669,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4c958c10-525c-4d7d-9063-39a63c7ded1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-b479e11b-bf21-4a84-8547-a6a16206e520,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-030e9c83-a99e-40ec-b7d6-7037ca0b818f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779225680-172.17.0.19-1598486441147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-62ca7d36-2ff1-4b07-95c2-8b7d37217da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-8e3016a1-3594-4186-b9a4-c6d6e69d97f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-dfd9c861-6482-407a-ae68-4ef771391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-aca8c91a-9e4e-49c3-b0a6-2b4a076f6928,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e0d12d9e-454e-4643-9fa6-603bc935b131,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-5fdb7b7e-2aaa-4883-a1d5-0cf3a93d1fab,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-b067e496-b345-44e1-a70e-b638772400db,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-37316673-ac3e-4431-aa7c-64d0ca904c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779225680-172.17.0.19-1598486441147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-62ca7d36-2ff1-4b07-95c2-8b7d37217da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-8e3016a1-3594-4186-b9a4-c6d6e69d97f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-dfd9c861-6482-407a-ae68-4ef771391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-aca8c91a-9e4e-49c3-b0a6-2b4a076f6928,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e0d12d9e-454e-4643-9fa6-603bc935b131,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-5fdb7b7e-2aaa-4883-a1d5-0cf3a93d1fab,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-b067e496-b345-44e1-a70e-b638772400db,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-37316673-ac3e-4431-aa7c-64d0ca904c30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095243015-172.17.0.19-1598486542916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-93215058-3390-4f22-9439-b50554d30379,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-13211091-cc7f-4451-8416-ec31e27d87e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-a659d6b4-c0f4-478a-98a3-aa7f14491061,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2da09de7-4afe-44cf-9b8a-d571b6ee277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-090f921c-3d43-49ef-8366-564cec4b7e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-143836a5-6eee-43f4-9844-c84ea2cb14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-56e5a4ef-c1a4-4d03-bd96-dfb8102a4f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-3c660a8f-8907-416e-b421-987014ca36ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095243015-172.17.0.19-1598486542916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-93215058-3390-4f22-9439-b50554d30379,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-13211091-cc7f-4451-8416-ec31e27d87e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-a659d6b4-c0f4-478a-98a3-aa7f14491061,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-2da09de7-4afe-44cf-9b8a-d571b6ee277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-090f921c-3d43-49ef-8366-564cec4b7e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-143836a5-6eee-43f4-9844-c84ea2cb14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-56e5a4ef-c1a4-4d03-bd96-dfb8102a4f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-3c660a8f-8907-416e-b421-987014ca36ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569402802-172.17.0.19-1598486853211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-dd0b47fa-0499-4f2f-aefc-0adadc30a860,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-9890202e-0d25-4934-9635-11e2d372b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-e99fda52-e7bb-451e-b295-43b969a8a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-0d01555d-baa1-4f52-bbd9-862c602383e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-c6ca97ab-de7b-409c-aaf2-ba51db75e779,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-38fe9c5a-5589-4931-a23a-e6320a1a758a,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e0522a0b-b625-46d9-ad82-7c5ed32a3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-6b826a55-1b28-462a-9988-6c03663b8b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569402802-172.17.0.19-1598486853211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-dd0b47fa-0499-4f2f-aefc-0adadc30a860,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-9890202e-0d25-4934-9635-11e2d372b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-e99fda52-e7bb-451e-b295-43b969a8a5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-0d01555d-baa1-4f52-bbd9-862c602383e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-c6ca97ab-de7b-409c-aaf2-ba51db75e779,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-38fe9c5a-5589-4931-a23a-e6320a1a758a,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-e0522a0b-b625-46d9-ad82-7c5ed32a3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-6b826a55-1b28-462a-9988-6c03663b8b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339207480-172.17.0.19-1598486922240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-a889f47c-45bf-4320-b2eb-be834b40cf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-8f7f0528-6255-4431-8c9e-8d135d7dc30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-23d941d8-0ba0-48fb-9c82-19fb2f251854,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-2e238f2c-76c3-4fb1-b01f-1496d891a493,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1f4a1aed-99bf-48e2-8d22-7f6c9cd32883,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-3d9938c7-97cf-48f8-8f63-355efff2535f,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-17e855a3-a44a-4c87-a764-fae2c77e3569,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-6f435e18-5d45-4136-840d-0d2a2a061744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339207480-172.17.0.19-1598486922240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-a889f47c-45bf-4320-b2eb-be834b40cf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-8f7f0528-6255-4431-8c9e-8d135d7dc30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-23d941d8-0ba0-48fb-9c82-19fb2f251854,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-2e238f2c-76c3-4fb1-b01f-1496d891a493,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1f4a1aed-99bf-48e2-8d22-7f6c9cd32883,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-3d9938c7-97cf-48f8-8f63-355efff2535f,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-17e855a3-a44a-4c87-a764-fae2c77e3569,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-6f435e18-5d45-4136-840d-0d2a2a061744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752183099-172.17.0.19-1598487106380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38796,DS-22d087e4-e8bc-4b50-a1d5-be24d4b81a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-91eb68ba-1350-42b3-b94d-d10cd477f389,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-d13680ee-bf66-42d5-b529-9c3be4257f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-d7ba5aa4-d988-4ec0-bcaf-d8d0f2ee8135,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-86e5fa1c-81c4-4d68-bff8-a6aa416556a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-940f4e71-c266-42c3-b894-a3022f95293f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-4ff434a7-9b0d-4148-a33c-1ddb85d239da,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-a16956c2-5677-4731-a3e3-caa1ca0d506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752183099-172.17.0.19-1598487106380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38796,DS-22d087e4-e8bc-4b50-a1d5-be24d4b81a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-91eb68ba-1350-42b3-b94d-d10cd477f389,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-d13680ee-bf66-42d5-b529-9c3be4257f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-d7ba5aa4-d988-4ec0-bcaf-d8d0f2ee8135,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-86e5fa1c-81c4-4d68-bff8-a6aa416556a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-940f4e71-c266-42c3-b894-a3022f95293f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-4ff434a7-9b0d-4148-a33c-1ddb85d239da,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-a16956c2-5677-4731-a3e3-caa1ca0d506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080725415-172.17.0.19-1598487434666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-2bf2e5f1-ad5d-4d33-9b59-c0ff748fdff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-41ee70a9-3e09-478e-8b5b-696d651e3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b727f50c-6d96-444a-ab89-47c4a1f9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-d40f932a-5658-4fc7-a4e1-65a749537f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-c8e7b87c-0be5-45dc-b113-b569104d9675,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-343a063b-28a2-4a7a-91c0-ad56029b7499,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-10edae5c-858e-4831-a067-d9b1e7d1cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-c28c3623-48ca-4886-b6f6-6735ef2904be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080725415-172.17.0.19-1598487434666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-2bf2e5f1-ad5d-4d33-9b59-c0ff748fdff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-41ee70a9-3e09-478e-8b5b-696d651e3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-b727f50c-6d96-444a-ab89-47c4a1f9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-d40f932a-5658-4fc7-a4e1-65a749537f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-c8e7b87c-0be5-45dc-b113-b569104d9675,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-343a063b-28a2-4a7a-91c0-ad56029b7499,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-10edae5c-858e-4831-a067-d9b1e7d1cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-c28c3623-48ca-4886-b6f6-6735ef2904be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404152146-172.17.0.19-1598488017905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39349,DS-d52674d2-86db-431c-b137-fc05ab41e974,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-a7db0a8a-ac2b-474d-ba58-7cdc7418d4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-07854ddc-6e7f-432e-94d7-3648cdfa6415,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-06c03aa1-9e66-4001-a3d9-108813f77598,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-6bd20ae7-da1e-49f4-94d8-c169137ae709,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-53a5f01e-c931-442f-bb22-4890694869ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-ca6a93e6-c052-445d-be1d-75f89193278f,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-6e41ca70-5575-4704-b765-ac4f99f367da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404152146-172.17.0.19-1598488017905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39349,DS-d52674d2-86db-431c-b137-fc05ab41e974,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-a7db0a8a-ac2b-474d-ba58-7cdc7418d4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-07854ddc-6e7f-432e-94d7-3648cdfa6415,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-06c03aa1-9e66-4001-a3d9-108813f77598,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-6bd20ae7-da1e-49f4-94d8-c169137ae709,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-53a5f01e-c931-442f-bb22-4890694869ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-ca6a93e6-c052-445d-be1d-75f89193278f,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-6e41ca70-5575-4704-b765-ac4f99f367da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486150313-172.17.0.19-1598488243601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-c274492b-85f4-4b44-adc4-04eaac786e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-370953f3-acb2-4c92-a3c3-0993dfadd30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-b9b7fdd9-42d4-4dcf-ae1b-c8a2cb591782,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-f02b452d-f940-49b9-81dc-bbf641a8c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-94c963d2-793e-445e-bfdd-5412e207193b,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-fae3a549-2b24-497c-9cdd-35ad989b00e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-8588d61d-4c80-4b3e-9dc9-a90da5b1acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-fe4111fa-a24b-4c62-ba23-0675fb41cc28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486150313-172.17.0.19-1598488243601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-c274492b-85f4-4b44-adc4-04eaac786e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-370953f3-acb2-4c92-a3c3-0993dfadd30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-b9b7fdd9-42d4-4dcf-ae1b-c8a2cb591782,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-f02b452d-f940-49b9-81dc-bbf641a8c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-94c963d2-793e-445e-bfdd-5412e207193b,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-fae3a549-2b24-497c-9cdd-35ad989b00e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-8588d61d-4c80-4b3e-9dc9-a90da5b1acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-fe4111fa-a24b-4c62-ba23-0675fb41cc28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391856518-172.17.0.19-1598488447346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-5c7e58f7-4b21-4b4b-a74b-b186aff54a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-02a23a7c-d340-43f6-b7cc-54c13a21ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-697385d6-09c6-41d7-a0ed-f8305af2c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-72e92d59-777a-4394-aede-6477d395406f,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-77f449ee-3629-4003-9de4-5b24140429d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-637d7f41-4398-46d7-afd2-1788e41470d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-46dd6756-e997-4343-bf4f-5f393e0eb851,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-21b17e81-b84d-4a0a-be80-d5cb86a8e3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391856518-172.17.0.19-1598488447346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-5c7e58f7-4b21-4b4b-a74b-b186aff54a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-02a23a7c-d340-43f6-b7cc-54c13a21ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-697385d6-09c6-41d7-a0ed-f8305af2c1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-72e92d59-777a-4394-aede-6477d395406f,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-77f449ee-3629-4003-9de4-5b24140429d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-637d7f41-4398-46d7-afd2-1788e41470d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-46dd6756-e997-4343-bf4f-5f393e0eb851,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-21b17e81-b84d-4a0a-be80-d5cb86a8e3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480208572-172.17.0.19-1598488537843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-18604804-794b-41c7-845d-530092e7e2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-a0dcde9e-0183-4103-9e36-bfaadb7db529,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-b05e7804-027c-431d-bd40-66596dac2451,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-695de2dc-20d0-4a05-a56a-ce95360058a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-87829e55-ad50-4233-a4ea-d6b09a366dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-6fa468e8-cf69-4b61-9cbd-f7cf11e2a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-18fb797f-5d0c-4a85-9547-18ae682eec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-72fcfedd-3b29-47c0-8e05-d8d37f947342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480208572-172.17.0.19-1598488537843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-18604804-794b-41c7-845d-530092e7e2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-a0dcde9e-0183-4103-9e36-bfaadb7db529,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-b05e7804-027c-431d-bd40-66596dac2451,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-695de2dc-20d0-4a05-a56a-ce95360058a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-87829e55-ad50-4233-a4ea-d6b09a366dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-6fa468e8-cf69-4b61-9cbd-f7cf11e2a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-18fb797f-5d0c-4a85-9547-18ae682eec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-72fcfedd-3b29-47c0-8e05-d8d37f947342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417432133-172.17.0.19-1598489554897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-d530e363-c8b3-490a-859b-272569387bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-e32a4571-cf27-45cd-81fa-4997a39b73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-b57b93d9-931b-4bfa-895b-fd3fb910778e,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-3dac5458-cb78-4da2-a370-1ae3a9008fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ff18b5c1-1095-41c8-87b4-e72f77aef502,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-86b548fe-98f4-40e3-857d-50d33477c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-e263d1bc-3fa8-47c1-9a91-7b36d8448dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-777ab614-1648-4ccf-8cdc-49ecaf57da6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417432133-172.17.0.19-1598489554897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-d530e363-c8b3-490a-859b-272569387bac,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-e32a4571-cf27-45cd-81fa-4997a39b73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-b57b93d9-931b-4bfa-895b-fd3fb910778e,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-3dac5458-cb78-4da2-a370-1ae3a9008fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ff18b5c1-1095-41c8-87b4-e72f77aef502,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-86b548fe-98f4-40e3-857d-50d33477c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-e263d1bc-3fa8-47c1-9a91-7b36d8448dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-777ab614-1648-4ccf-8cdc-49ecaf57da6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328372010-172.17.0.19-1598490338590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-9fee99d9-6295-4bc0-a6be-5c252be3768f,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-87b0c769-da6d-4f27-b461-526edcc293c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-9f667108-2e98-492a-848d-ef3672ac0497,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-e15fea9a-133c-4645-bba4-d2d697d75053,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-5421050c-3741-48c5-a001-80ab7da9b210,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-da0f25ee-6b21-4afd-a5e8-349263a6ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f3649707-a867-4506-b308-5b701a2d77d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-2d8d16fe-2599-4f56-9173-435b1d32fa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328372010-172.17.0.19-1598490338590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39110,DS-9fee99d9-6295-4bc0-a6be-5c252be3768f,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-87b0c769-da6d-4f27-b461-526edcc293c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-9f667108-2e98-492a-848d-ef3672ac0497,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-e15fea9a-133c-4645-bba4-d2d697d75053,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-5421050c-3741-48c5-a001-80ab7da9b210,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-da0f25ee-6b21-4afd-a5e8-349263a6ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f3649707-a867-4506-b308-5b701a2d77d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-2d8d16fe-2599-4f56-9173-435b1d32fa2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256621981-172.17.0.19-1598490823848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-e0c6be15-55cd-45c0-a768-61246b6313a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-6227ee72-70da-48b8-be20-85af8b0a3c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-dbab8acc-181b-424d-9007-21d39846e446,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-8a8c7f90-7290-4d47-af6d-d3ae4fd54670,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8b858380-437e-4769-b42b-c3cc97168529,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-9c7151bd-e0a9-4517-a351-4b3df680e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-0ecfd37e-64b8-4ef4-a987-c01b6e5f8151,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4159f30e-caaa-48e0-804c-2e442dc1b211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256621981-172.17.0.19-1598490823848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-e0c6be15-55cd-45c0-a768-61246b6313a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-6227ee72-70da-48b8-be20-85af8b0a3c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-dbab8acc-181b-424d-9007-21d39846e446,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-8a8c7f90-7290-4d47-af6d-d3ae4fd54670,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8b858380-437e-4769-b42b-c3cc97168529,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-9c7151bd-e0a9-4517-a351-4b3df680e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-0ecfd37e-64b8-4ef4-a987-c01b6e5f8151,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4159f30e-caaa-48e0-804c-2e442dc1b211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723523975-172.17.0.19-1598490887219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-4fc1b9a8-638d-46c6-9434-7ec6eaad506f,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-db756aa3-f4ae-4381-8812-75f7b0f025fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a17d5f5c-2be3-4efa-87d7-4646254f3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-42d102ed-2079-487c-85b6-3f03a927c845,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-5f19f50e-192e-4d89-85c6-8ba41a71bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-66e693d0-24f7-4425-a55b-dc5116cb4b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-5583c482-9628-4603-97b7-00fdd1f8abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-475cc1c4-926e-4bc2-ad26-12989c2da207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723523975-172.17.0.19-1598490887219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-4fc1b9a8-638d-46c6-9434-7ec6eaad506f,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-db756aa3-f4ae-4381-8812-75f7b0f025fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a17d5f5c-2be3-4efa-87d7-4646254f3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-42d102ed-2079-487c-85b6-3f03a927c845,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-5f19f50e-192e-4d89-85c6-8ba41a71bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-66e693d0-24f7-4425-a55b-dc5116cb4b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-5583c482-9628-4603-97b7-00fdd1f8abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-475cc1c4-926e-4bc2-ad26-12989c2da207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045619052-172.17.0.19-1598490954821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-203eb448-789c-4861-8e39-07edb457a896,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-544bc089-770c-4d18-a73f-8a313952d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-d8ad1f31-4ad2-470f-bc55-7f769a90e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-455dd29f-286c-470f-9c67-1d1a8f436ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b84a6f08-c7ef-4400-a23e-1f04fa0b1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-5a0ea199-736c-495f-9d4b-4fada25a7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-806a6093-7574-465e-919b-accd4f9e2490,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2cf5014a-6084-4865-9ca6-e47fd53e28b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045619052-172.17.0.19-1598490954821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46391,DS-203eb448-789c-4861-8e39-07edb457a896,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-544bc089-770c-4d18-a73f-8a313952d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-d8ad1f31-4ad2-470f-bc55-7f769a90e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-455dd29f-286c-470f-9c67-1d1a8f436ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b84a6f08-c7ef-4400-a23e-1f04fa0b1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-5a0ea199-736c-495f-9d4b-4fada25a7c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-806a6093-7574-465e-919b-accd4f9e2490,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2cf5014a-6084-4865-9ca6-e47fd53e28b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599984956-172.17.0.19-1598491027827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-b57ee88a-335f-45ab-894a-03afaf9e45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-3d639b05-d31e-43ff-bdfb-e2e9529520f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-9c8b4303-eabe-4688-a794-25cfad23c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-38c684ab-6676-4f69-b020-e14669180150,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-e74b047b-9600-410a-b9f2-e85a3f74cce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-443bbb6b-1483-474d-99e6-461584d816bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0b363b25-6a84-4eb3-90d2-0514ff8e377e,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-5c380993-5aba-4c32-b1b5-89e3b2c9267f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599984956-172.17.0.19-1598491027827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-b57ee88a-335f-45ab-894a-03afaf9e45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-3d639b05-d31e-43ff-bdfb-e2e9529520f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-9c8b4303-eabe-4688-a794-25cfad23c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-38c684ab-6676-4f69-b020-e14669180150,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-e74b047b-9600-410a-b9f2-e85a3f74cce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-443bbb6b-1483-474d-99e6-461584d816bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-0b363b25-6a84-4eb3-90d2-0514ff8e377e,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-5c380993-5aba-4c32-b1b5-89e3b2c9267f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5231
