reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731630568-172.17.0.15-1598494648919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43340,DS-9c5cf5b4-ea1f-4a30-872c-02383a0b1c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-de031c69-46f4-4d46-96db-1e5e15a075bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-89b86d36-f977-4b95-b180-13b54882d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-0eb481a5-d2f9-42d8-adbf-87ae9d5b8bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9cc974ce-1ab1-4386-bcc7-876a6cc75bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-ef3f4ad2-9b19-4b83-806b-558344c25cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-e0b41205-2adb-42c5-aaca-b598407d09f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-aff12545-652c-40fd-b4d6-0209fcf5ba29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731630568-172.17.0.15-1598494648919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43340,DS-9c5cf5b4-ea1f-4a30-872c-02383a0b1c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-de031c69-46f4-4d46-96db-1e5e15a075bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-89b86d36-f977-4b95-b180-13b54882d8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-0eb481a5-d2f9-42d8-adbf-87ae9d5b8bed,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-9cc974ce-1ab1-4386-bcc7-876a6cc75bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-ef3f4ad2-9b19-4b83-806b-558344c25cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-e0b41205-2adb-42c5-aaca-b598407d09f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-aff12545-652c-40fd-b4d6-0209fcf5ba29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897158180-172.17.0.15-1598495143971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-8c5874a5-d071-449e-ae28-7fcc4fe10267,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-928a45cc-c648-43c0-ae24-08a3c86c0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-2a3a5a55-5a33-4abf-8534-44a9ecd33a77,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-4a0314e6-c7bf-4093-8510-e11042b48d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-c50fee0d-7ec0-4da6-a318-082ceb675930,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-b44585cd-4c1b-458e-9d4b-d238500a70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d788b315-397b-432e-af25-64d1107b28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-fef0c146-48e1-4cef-be34-994010ee6f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897158180-172.17.0.15-1598495143971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-8c5874a5-d071-449e-ae28-7fcc4fe10267,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-928a45cc-c648-43c0-ae24-08a3c86c0b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-2a3a5a55-5a33-4abf-8534-44a9ecd33a77,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-4a0314e6-c7bf-4093-8510-e11042b48d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-c50fee0d-7ec0-4da6-a318-082ceb675930,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-b44585cd-4c1b-458e-9d4b-d238500a70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d788b315-397b-432e-af25-64d1107b28eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-fef0c146-48e1-4cef-be34-994010ee6f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202987808-172.17.0.15-1598495460201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-34e9e968-347b-4df9-ac20-f9e6aed61637,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-7cd38d25-cfa1-45a1-ac09-04cdc52838ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-61a55d67-43ff-473e-992e-0146ecf9244a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-96247168-2003-47b2-9d8e-f34415c4614e,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-0d760a79-1d4e-446c-8505-896aeaccd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-0b84e4ad-4ac6-4086-aca1-eaa7e67d4560,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-19da5855-0c92-4d80-8258-a0b65fcbc9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-26157040-865b-415c-a2a1-c37b500e7be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202987808-172.17.0.15-1598495460201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-34e9e968-347b-4df9-ac20-f9e6aed61637,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-7cd38d25-cfa1-45a1-ac09-04cdc52838ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-61a55d67-43ff-473e-992e-0146ecf9244a,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-96247168-2003-47b2-9d8e-f34415c4614e,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-0d760a79-1d4e-446c-8505-896aeaccd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-0b84e4ad-4ac6-4086-aca1-eaa7e67d4560,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-19da5855-0c92-4d80-8258-a0b65fcbc9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-26157040-865b-415c-a2a1-c37b500e7be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519215203-172.17.0.15-1598495533590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-271bf2d4-2326-49bc-98f7-4258b5456391,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-a309578b-b27a-4385-a70b-a81991ad0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-071cc3ab-6ba2-4f69-a70b-7e24941a7028,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d2fee861-2ee4-4b7d-9ad6-551d1ea9c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d2b733f3-988a-436d-bf15-bf7635271b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-4e632c9f-3717-4620-b0fb-a661a6cadabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2dc1aa2e-4e8b-40d8-87af-f962ffb0dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-46fee8d5-f722-48b4-b32c-df488cf86dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519215203-172.17.0.15-1598495533590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-271bf2d4-2326-49bc-98f7-4258b5456391,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-a309578b-b27a-4385-a70b-a81991ad0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-071cc3ab-6ba2-4f69-a70b-7e24941a7028,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-d2fee861-2ee4-4b7d-9ad6-551d1ea9c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d2b733f3-988a-436d-bf15-bf7635271b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-4e632c9f-3717-4620-b0fb-a661a6cadabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2dc1aa2e-4e8b-40d8-87af-f962ffb0dfec,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-46fee8d5-f722-48b4-b32c-df488cf86dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212398181-172.17.0.15-1598495649880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-406cb984-f45c-4a45-ad5d-3e07e927f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c966e4e7-43c2-4f7f-aef7-033d00702d92,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-bb01e8e8-af46-494b-92c3-3474c36ea40b,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-4b25b1be-c38a-4c0d-9b03-a3207ce2e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-89bf1ed4-4af6-425b-b4fb-4e5e2a45efff,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-bb884f8b-8ce3-42d1-9f45-59038cf069da,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-9b8f4d3d-4bca-4228-b6de-28c512267c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-934b2d97-eecc-4c69-a64f-e207f8706af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212398181-172.17.0.15-1598495649880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-406cb984-f45c-4a45-ad5d-3e07e927f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-c966e4e7-43c2-4f7f-aef7-033d00702d92,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-bb01e8e8-af46-494b-92c3-3474c36ea40b,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-4b25b1be-c38a-4c0d-9b03-a3207ce2e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-89bf1ed4-4af6-425b-b4fb-4e5e2a45efff,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-bb884f8b-8ce3-42d1-9f45-59038cf069da,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-9b8f4d3d-4bca-4228-b6de-28c512267c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-934b2d97-eecc-4c69-a64f-e207f8706af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858236279-172.17.0.15-1598496452499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-ab5ce038-d7cf-45fa-b35d-af138ddf0f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-4982e165-0516-4601-bb4e-015734c57880,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-203a0b6d-47e4-41e1-813b-68a290cfeba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-380e3740-33d4-4beb-89a9-2894060d281e,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e6bd625b-abc0-47a7-a86f-106670512224,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-6b692ad7-028d-4b32-bb7c-a5db6f09be54,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-2d2b4502-c979-4c53-af26-1c2e9db8cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-fa9e3177-0cf3-4fdf-9702-fdb40f946021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858236279-172.17.0.15-1598496452499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-ab5ce038-d7cf-45fa-b35d-af138ddf0f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-4982e165-0516-4601-bb4e-015734c57880,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-203a0b6d-47e4-41e1-813b-68a290cfeba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-380e3740-33d4-4beb-89a9-2894060d281e,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e6bd625b-abc0-47a7-a86f-106670512224,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-6b692ad7-028d-4b32-bb7c-a5db6f09be54,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-2d2b4502-c979-4c53-af26-1c2e9db8cb00,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-fa9e3177-0cf3-4fdf-9702-fdb40f946021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424953924-172.17.0.15-1598496629511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-1945e8d7-d709-4c56-9c55-fbd0fa28cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-8b7242e9-d2fa-4c5b-946a-99c0ce2441d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-c30551af-8ff3-41f9-9277-ec798b00cab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-62e42b69-7180-4808-b095-be642e0f6d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-6b4b441a-a3bc-42b2-9f33-943f55df6f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-3e5250cd-2b56-4456-a540-bbe8bf283f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-cf1d438f-6478-4a7d-97ae-68dcd3b9adef,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-26e03bde-fc51-4e49-85c7-60faf75fd2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424953924-172.17.0.15-1598496629511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-1945e8d7-d709-4c56-9c55-fbd0fa28cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-8b7242e9-d2fa-4c5b-946a-99c0ce2441d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-c30551af-8ff3-41f9-9277-ec798b00cab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-62e42b69-7180-4808-b095-be642e0f6d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-6b4b441a-a3bc-42b2-9f33-943f55df6f50,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-3e5250cd-2b56-4456-a540-bbe8bf283f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-cf1d438f-6478-4a7d-97ae-68dcd3b9adef,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-26e03bde-fc51-4e49-85c7-60faf75fd2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020671020-172.17.0.15-1598497287128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34903,DS-cd359ad1-1412-4809-bd2e-4ce6b6426b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09330705-c89a-4b4c-bc2b-15767df0eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-46049c71-98ca-49c6-9771-45f7b6ae2479,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-3821898b-5459-4e3d-8923-5eb805692cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-64e315a6-8eb5-4076-b687-72545e876051,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-40c7fe4e-f37c-45cb-84ae-f946b7163afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-c4c2a545-6fae-4efd-a49e-4338577b6b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-d881b928-d782-44a3-b2d7-55af90df53b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020671020-172.17.0.15-1598497287128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34903,DS-cd359ad1-1412-4809-bd2e-4ce6b6426b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-09330705-c89a-4b4c-bc2b-15767df0eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-46049c71-98ca-49c6-9771-45f7b6ae2479,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-3821898b-5459-4e3d-8923-5eb805692cac,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-64e315a6-8eb5-4076-b687-72545e876051,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-40c7fe4e-f37c-45cb-84ae-f946b7163afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-c4c2a545-6fae-4efd-a49e-4338577b6b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-d881b928-d782-44a3-b2d7-55af90df53b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501352030-172.17.0.15-1598497537788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-c7923aa9-1cdd-4fa3-aadd-1b20928d29fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e2ce2a0a-0dca-4726-b73c-e29ec42a3ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-48d78b10-8b95-4cfa-850b-c8351c69fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-010ea0f1-e775-4e10-a05c-f7316c6cbb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-041e8d02-aec3-4774-866b-b2cbd3758513,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b23fcb0c-9289-4f90-801c-59dd856636cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-9450c9b4-7ae2-4f13-895e-26bba79b3529,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-39ddbff3-02ed-4bb9-8dbe-637d03a0d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501352030-172.17.0.15-1598497537788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-c7923aa9-1cdd-4fa3-aadd-1b20928d29fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e2ce2a0a-0dca-4726-b73c-e29ec42a3ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-48d78b10-8b95-4cfa-850b-c8351c69fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-010ea0f1-e775-4e10-a05c-f7316c6cbb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-041e8d02-aec3-4774-866b-b2cbd3758513,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b23fcb0c-9289-4f90-801c-59dd856636cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-9450c9b4-7ae2-4f13-895e-26bba79b3529,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-39ddbff3-02ed-4bb9-8dbe-637d03a0d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719185326-172.17.0.15-1598498357006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-9a9a1276-41a9-44a9-a739-8dc9e666389b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-ce5dfe4a-1ab3-4fe3-abe8-ac5c790dd4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-7cb1ddf5-27fa-42fb-8814-a62809332de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-96effb9f-7507-4b37-ba0e-a42f09cf2e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-892b6bcf-81c7-4c69-a067-e41c682aeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-f75352a4-5e34-4cc9-b6c0-561cdb30596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-b7850c57-639f-41ab-9788-fad2d6211792,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-91104e93-4454-46fd-b9b9-4b279269efe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719185326-172.17.0.15-1598498357006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-9a9a1276-41a9-44a9-a739-8dc9e666389b,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-ce5dfe4a-1ab3-4fe3-abe8-ac5c790dd4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-7cb1ddf5-27fa-42fb-8814-a62809332de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-96effb9f-7507-4b37-ba0e-a42f09cf2e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-892b6bcf-81c7-4c69-a067-e41c682aeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-f75352a4-5e34-4cc9-b6c0-561cdb30596f,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-b7850c57-639f-41ab-9788-fad2d6211792,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-91104e93-4454-46fd-b9b9-4b279269efe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654494577-172.17.0.15-1598498386212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-33de02d9-8fcc-42d5-8f3b-5d92973210ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-0a2e415f-120f-4b9f-abe0-2316d6e7daec,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-491c4db8-cf87-48f9-b3a9-cc46d2ec07a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-e767191c-9e67-4330-a12f-563b2d5677b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-6926fb0d-32d0-4d1d-b799-558db9c3e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-16074093-97a5-4ffa-9e28-cfbeda5d2704,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-db79636f-ed0f-4488-bd55-bbfc54af7655,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-1c538164-a561-4bc4-9846-f786580466ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654494577-172.17.0.15-1598498386212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-33de02d9-8fcc-42d5-8f3b-5d92973210ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-0a2e415f-120f-4b9f-abe0-2316d6e7daec,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-491c4db8-cf87-48f9-b3a9-cc46d2ec07a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-e767191c-9e67-4330-a12f-563b2d5677b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-6926fb0d-32d0-4d1d-b799-558db9c3e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-16074093-97a5-4ffa-9e28-cfbeda5d2704,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-db79636f-ed0f-4488-bd55-bbfc54af7655,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-1c538164-a561-4bc4-9846-f786580466ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411520022-172.17.0.15-1598498560352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-0f01dd3d-daf7-4983-9d1f-b20c549ad1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-846e877c-01a0-4179-9b82-88cce5b83d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-c43a74c4-ae84-42a6-9b6a-fe72bedf5f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-a9e5eece-b0cb-4ab8-91da-06d106cd9c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-a1476628-6a34-47db-b431-cf40c966e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-ff69579b-b676-4e42-aa86-868e85dccaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3072c506-2b99-46f9-b9c6-8365b32fcbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-0bed769a-1d37-4c72-843d-70eecbf4c4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411520022-172.17.0.15-1598498560352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36668,DS-0f01dd3d-daf7-4983-9d1f-b20c549ad1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-846e877c-01a0-4179-9b82-88cce5b83d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-c43a74c4-ae84-42a6-9b6a-fe72bedf5f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-a9e5eece-b0cb-4ab8-91da-06d106cd9c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-a1476628-6a34-47db-b431-cf40c966e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-ff69579b-b676-4e42-aa86-868e85dccaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-3072c506-2b99-46f9-b9c6-8365b32fcbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-0bed769a-1d37-4c72-843d-70eecbf4c4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862828264-172.17.0.15-1598499647808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-60a81f84-9b28-4d64-86c8-3e3a0017397d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-9710a81e-d8ab-48ac-b067-3e0ed0bd47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-740f33a9-5297-473d-bbdd-664753fd473f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-99601e57-e74a-434b-aa58-76df9d9b9d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-959759b9-459c-409c-b4bf-428a539fb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-8c379409-4f6f-4907-a9fb-d0955e626444,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-ee2bcb4d-6d5e-4363-9fbd-89f3be4085b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-3521843f-a582-4b94-b457-2079ab24e510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862828264-172.17.0.15-1598499647808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-60a81f84-9b28-4d64-86c8-3e3a0017397d,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-9710a81e-d8ab-48ac-b067-3e0ed0bd47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-740f33a9-5297-473d-bbdd-664753fd473f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-99601e57-e74a-434b-aa58-76df9d9b9d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-959759b9-459c-409c-b4bf-428a539fb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-8c379409-4f6f-4907-a9fb-d0955e626444,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-ee2bcb4d-6d5e-4363-9fbd-89f3be4085b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-3521843f-a582-4b94-b457-2079ab24e510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492136147-172.17.0.15-1598499759054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38925,DS-e8dd34b0-040d-47b5-ae26-4b42c203caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-aad7068f-fb92-4fea-85cd-155f41348528,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-95f3175b-a8cf-4350-b0a1-8c90c1986205,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-1538bd3e-da30-46a7-af72-6480bf16c8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-278ca426-889a-42ca-8c0a-403d003f3c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-47f68a96-f14d-4e9a-9c19-078dfce65e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-400c1bba-79af-4024-bf35-3026fe11f500,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-157bb1b6-ad20-45c5-b7e6-d6401c7d1e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492136147-172.17.0.15-1598499759054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38925,DS-e8dd34b0-040d-47b5-ae26-4b42c203caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-aad7068f-fb92-4fea-85cd-155f41348528,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-95f3175b-a8cf-4350-b0a1-8c90c1986205,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-1538bd3e-da30-46a7-af72-6480bf16c8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-278ca426-889a-42ca-8c0a-403d003f3c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-47f68a96-f14d-4e9a-9c19-078dfce65e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-400c1bba-79af-4024-bf35-3026fe11f500,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-157bb1b6-ad20-45c5-b7e6-d6401c7d1e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5415
