reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741580911-172.17.0.6-1598498743174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43414,DS-450b9489-8efb-4e0b-86b3-6bd522da90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-aa6d9890-d990-4626-b853-475e9d5cd3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-60237015-2594-45cd-a33c-5e3a67ca41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-09184543-6a26-433f-91f0-ada4b44591b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-2606bff7-6a73-450a-91e2-87f7b6da4579,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-a0797ab1-303c-4a50-a755-be83d9ac97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3920a1c6-5ff6-4f35-9357-4c1fce7a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-26a3c945-cc47-4220-8533-f9b6c1f902e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1741580911-172.17.0.6-1598498743174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43414,DS-450b9489-8efb-4e0b-86b3-6bd522da90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-aa6d9890-d990-4626-b853-475e9d5cd3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-60237015-2594-45cd-a33c-5e3a67ca41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-09184543-6a26-433f-91f0-ada4b44591b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-2606bff7-6a73-450a-91e2-87f7b6da4579,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-a0797ab1-303c-4a50-a755-be83d9ac97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3920a1c6-5ff6-4f35-9357-4c1fce7a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-26a3c945-cc47-4220-8533-f9b6c1f902e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568270505-172.17.0.6-1598498774415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-6b90e6a6-d045-4ad2-8cc9-b827d452458c,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-7f904969-2a38-4937-865f-b7389ff22051,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-553c11cd-99f8-44a4-9add-5f88b8cbf89a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-56824cc3-1ae1-4646-973a-79d634565cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b665f7a7-83ea-42b8-b4ee-dd4e49f06d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-5fbf3f5d-e793-40a5-a366-39766036a115,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-50336143-b9e0-4635-bd10-11316837e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-7329b0ba-c6ef-4e40-9938-85808ab0c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568270505-172.17.0.6-1598498774415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-6b90e6a6-d045-4ad2-8cc9-b827d452458c,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-7f904969-2a38-4937-865f-b7389ff22051,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-553c11cd-99f8-44a4-9add-5f88b8cbf89a,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-56824cc3-1ae1-4646-973a-79d634565cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-b665f7a7-83ea-42b8-b4ee-dd4e49f06d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-5fbf3f5d-e793-40a5-a366-39766036a115,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-50336143-b9e0-4635-bd10-11316837e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-7329b0ba-c6ef-4e40-9938-85808ab0c3de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906009087-172.17.0.6-1598498840709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-867ac12e-8624-4b70-8ade-8247c9619b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-af9d7bea-3196-45ae-b1c4-2d8e5cc21005,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-daa44f0a-d837-483b-98e7-156e7ad93e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-071621bc-da57-4e3c-8486-79f55b6cb01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-e60104bd-6b31-41ed-ad34-78f3dfe69e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-1e679d63-ddf9-44b4-a439-9251bae8cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-0f8391fa-fcc9-4b20-9b55-324b44fb6469,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b0643da2-2051-4342-9d8e-3629601d318a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906009087-172.17.0.6-1598498840709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-867ac12e-8624-4b70-8ade-8247c9619b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-af9d7bea-3196-45ae-b1c4-2d8e5cc21005,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-daa44f0a-d837-483b-98e7-156e7ad93e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-071621bc-da57-4e3c-8486-79f55b6cb01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-e60104bd-6b31-41ed-ad34-78f3dfe69e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-1e679d63-ddf9-44b4-a439-9251bae8cc05,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-0f8391fa-fcc9-4b20-9b55-324b44fb6469,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b0643da2-2051-4342-9d8e-3629601d318a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697633078-172.17.0.6-1598499459773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-a802e4ce-4aca-4c65-ab92-67bf1a23db24,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e656947-d6d8-48ae-8af9-4c6e1a6a2db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-4bd5853b-ef74-4472-9023-9d56c8bf768f,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-1c0ff0fb-51b2-4429-bebc-21f651216986,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-66f72c69-26be-43a4-8072-e8a75da57e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-e6ae1d63-3db1-4ae1-8872-22ed92de73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-54554c37-79ab-43b4-bac2-0fd8dd874a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-9840c6af-d93f-4c7b-9ee5-cdad4d2c9e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697633078-172.17.0.6-1598499459773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-a802e4ce-4aca-4c65-ab92-67bf1a23db24,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e656947-d6d8-48ae-8af9-4c6e1a6a2db9,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-4bd5853b-ef74-4472-9023-9d56c8bf768f,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-1c0ff0fb-51b2-4429-bebc-21f651216986,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-66f72c69-26be-43a4-8072-e8a75da57e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-e6ae1d63-3db1-4ae1-8872-22ed92de73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-54554c37-79ab-43b4-bac2-0fd8dd874a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-9840c6af-d93f-4c7b-9ee5-cdad4d2c9e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162305506-172.17.0.6-1598500085621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-9f401a71-9272-4169-81b1-f98cb7b896e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-940d823e-a3c7-4867-b735-053612a15550,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8095b6b4-738d-44ed-92d3-e9b026a60f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-f381c983-5df6-4074-a1c8-4670aabf6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-fa26f5bf-09f9-4277-8179-f665885d54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-bae1db44-98de-4764-abba-2abc5f26ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-df5d5db8-b8e0-4565-91c8-85c2b02ee310,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-edc38d7f-fb05-4124-81f7-73dcd953988f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162305506-172.17.0.6-1598500085621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-9f401a71-9272-4169-81b1-f98cb7b896e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-940d823e-a3c7-4867-b735-053612a15550,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8095b6b4-738d-44ed-92d3-e9b026a60f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-f381c983-5df6-4074-a1c8-4670aabf6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-fa26f5bf-09f9-4277-8179-f665885d54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-bae1db44-98de-4764-abba-2abc5f26ac02,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-df5d5db8-b8e0-4565-91c8-85c2b02ee310,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-edc38d7f-fb05-4124-81f7-73dcd953988f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133163131-172.17.0.6-1598500183106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-005eeea2-4f13-4ee7-bd9f-f086bf5253ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-bae05016-d006-4f46-bbcb-969efcc136e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-8c5d358e-9f36-4ce3-9142-efbb1dcc709a,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-6d812133-4094-420a-933e-ee670555be81,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-815a2a21-0c9e-4f07-a359-ea15ca15ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-87670a18-47c8-4e9a-b711-09340ed4f549,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-f70ee29a-868a-46f0-9989-244520154e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-bc6b6cda-5385-4ab9-9622-473f9be2b541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133163131-172.17.0.6-1598500183106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-005eeea2-4f13-4ee7-bd9f-f086bf5253ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-bae05016-d006-4f46-bbcb-969efcc136e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-8c5d358e-9f36-4ce3-9142-efbb1dcc709a,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-6d812133-4094-420a-933e-ee670555be81,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-815a2a21-0c9e-4f07-a359-ea15ca15ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-87670a18-47c8-4e9a-b711-09340ed4f549,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-f70ee29a-868a-46f0-9989-244520154e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-bc6b6cda-5385-4ab9-9622-473f9be2b541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138991559-172.17.0.6-1598500578419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45720,DS-d1b90bf5-63dc-4889-bf37-74c2f75bfb18,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-c90c89f2-47d1-4fbe-ba3a-6567b9a5f63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d55dcf5b-80d0-454a-b202-58380f4b22e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5eb9e59f-0745-4f51-8c0f-f30ae5e3bd63,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-3ce1e0e1-325d-42c2-b434-4615805dba38,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-b9fda598-fa99-4eeb-9736-e3c621d8b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-2295fdaf-deda-4c64-82d1-8aae440c34d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-976a884b-7e19-4c59-ac9a-16b49d6c55d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138991559-172.17.0.6-1598500578419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45720,DS-d1b90bf5-63dc-4889-bf37-74c2f75bfb18,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-c90c89f2-47d1-4fbe-ba3a-6567b9a5f63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d55dcf5b-80d0-454a-b202-58380f4b22e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-5eb9e59f-0745-4f51-8c0f-f30ae5e3bd63,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-3ce1e0e1-325d-42c2-b434-4615805dba38,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-b9fda598-fa99-4eeb-9736-e3c621d8b94d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-2295fdaf-deda-4c64-82d1-8aae440c34d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-976a884b-7e19-4c59-ac9a-16b49d6c55d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713450178-172.17.0.6-1598500725057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-09a1876e-f8af-48af-8d39-6b9acbe18287,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-ed7bc39e-46b7-4ebb-afa0-151b7bdfbff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-d559ddf0-6e3b-4e03-8948-1d706c008dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-2bcebd78-a500-47b3-a30b-ca864afb5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c42098e1-af1c-4255-995f-05f2b4e7dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-3453a627-07e8-423f-a21c-b8ad8e115e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-2d4d2670-538b-46e0-b29e-640cd6403b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-24410388-ed8e-4c5f-aa9f-3d10ca83f476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713450178-172.17.0.6-1598500725057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-09a1876e-f8af-48af-8d39-6b9acbe18287,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-ed7bc39e-46b7-4ebb-afa0-151b7bdfbff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-d559ddf0-6e3b-4e03-8948-1d706c008dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-2bcebd78-a500-47b3-a30b-ca864afb5d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c42098e1-af1c-4255-995f-05f2b4e7dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-3453a627-07e8-423f-a21c-b8ad8e115e20,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-2d4d2670-538b-46e0-b29e-640cd6403b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-24410388-ed8e-4c5f-aa9f-3d10ca83f476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784353415-172.17.0.6-1598502938936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33065,DS-d82fb0fa-ed4d-48c4-a744-2169181b50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f8931862-b4f8-477f-b56a-a4ec9c5e8791,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-c5e36158-945e-4258-a38e-b488da10f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-077cbb75-aa90-4082-b590-32a10379bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-a65576a8-3e3c-4265-a699-6d3bea2041ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-afa2a248-9135-43a7-a7bb-9d93bbecb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-bc7f46f0-e025-4c58-a043-4f12406eec54,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-2ae22df1-d053-4999-8e58-9fd5540189ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784353415-172.17.0.6-1598502938936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33065,DS-d82fb0fa-ed4d-48c4-a744-2169181b50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f8931862-b4f8-477f-b56a-a4ec9c5e8791,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-c5e36158-945e-4258-a38e-b488da10f1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-077cbb75-aa90-4082-b590-32a10379bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-a65576a8-3e3c-4265-a699-6d3bea2041ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-afa2a248-9135-43a7-a7bb-9d93bbecb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-bc7f46f0-e025-4c58-a043-4f12406eec54,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-2ae22df1-d053-4999-8e58-9fd5540189ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380971416-172.17.0.6-1598503012210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-10f9bbd6-40ce-4eda-98f2-715c0213accd,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-da03355a-fb17-462a-8e72-55cef04e7cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-2f77bc76-9abf-4ff4-ae98-b6296552095c,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-677d077f-1609-4ac5-bd95-4e14b7d02702,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-681a0702-945e-4630-bac2-91b324bd5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-8bc4dd6a-c637-47b9-8d4f-ebcaa9b7bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-5cb8997b-c045-499d-a7bc-5ded1ee4ddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-2ba1c9e4-64a6-437c-850e-38a43e752224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380971416-172.17.0.6-1598503012210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38970,DS-10f9bbd6-40ce-4eda-98f2-715c0213accd,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-da03355a-fb17-462a-8e72-55cef04e7cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-2f77bc76-9abf-4ff4-ae98-b6296552095c,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-677d077f-1609-4ac5-bd95-4e14b7d02702,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-681a0702-945e-4630-bac2-91b324bd5a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-8bc4dd6a-c637-47b9-8d4f-ebcaa9b7bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-5cb8997b-c045-499d-a7bc-5ded1ee4ddc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-2ba1c9e4-64a6-437c-850e-38a43e752224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721125297-172.17.0.6-1598503050980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43249,DS-c5bd60b9-1b4c-44dc-9dd6-38aaaf63b317,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-9cba6b94-0c21-48d0-8711-8ad208a9d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-f51b5356-ea73-42ff-92eb-5d06073e2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-24e074c5-e413-46a7-b87c-5c95176692b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-27368cf4-23c4-410a-b365-53dc5b093f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-9642bdaa-07b1-4715-89c5-b3339f01e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-00648b06-911d-45da-904b-9ce7ed29dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-580d75cd-2962-40e2-b02e-f0e592bf3d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721125297-172.17.0.6-1598503050980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43249,DS-c5bd60b9-1b4c-44dc-9dd6-38aaaf63b317,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-9cba6b94-0c21-48d0-8711-8ad208a9d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-f51b5356-ea73-42ff-92eb-5d06073e2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-24e074c5-e413-46a7-b87c-5c95176692b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-27368cf4-23c4-410a-b365-53dc5b093f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-9642bdaa-07b1-4715-89c5-b3339f01e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-00648b06-911d-45da-904b-9ce7ed29dfde,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-580d75cd-2962-40e2-b02e-f0e592bf3d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:NameNode
v1: 10000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227427803-172.17.0.6-1598503298088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-72353ebf-e170-4b39-8438-f8ccdb1b511a,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-6d8db385-4dd8-430e-8beb-82b39a08726b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f3817495-ec79-41a6-8df3-f276ff6a42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-5e06a57a-7b61-41fc-887d-8b33e2a1ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-79adaa8c-bb90-4383-b057-4d68354f68db,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ff3ee012-41e3-460c-aa9d-ae854451bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-dbc4d952-0a04-48b7-9f6f-4a8878e9ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-7c8be046-51f3-4f5f-a9c7-a8ed87120dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227427803-172.17.0.6-1598503298088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-72353ebf-e170-4b39-8438-f8ccdb1b511a,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-6d8db385-4dd8-430e-8beb-82b39a08726b,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f3817495-ec79-41a6-8df3-f276ff6a42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-5e06a57a-7b61-41fc-887d-8b33e2a1ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-79adaa8c-bb90-4383-b057-4d68354f68db,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ff3ee012-41e3-460c-aa9d-ae854451bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-dbc4d952-0a04-48b7-9f6f-4a8878e9ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-7c8be046-51f3-4f5f-a9c7-a8ed87120dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 0 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: v1v2 failure didn't occur
Total execution time in seconds : 5378
