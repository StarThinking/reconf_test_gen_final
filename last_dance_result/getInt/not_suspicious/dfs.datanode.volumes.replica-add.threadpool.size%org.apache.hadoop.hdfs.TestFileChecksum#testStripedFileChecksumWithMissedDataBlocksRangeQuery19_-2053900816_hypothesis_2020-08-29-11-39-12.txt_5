reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737532020-172.17.0.2-1598701168023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-ddc8fd19-3801-4c70-a58f-c06ae4b184ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-b2eaa864-0a6a-43a2-bd7d-14fab0eb3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0e2d0a18-b2bc-4992-be91-82c3b93fae20,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-7464bded-5e0e-49b7-ba03-3d15d7257270,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-34c4d5cf-d986-4636-a6e3-fb5930975f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-534105df-a760-4d61-ab0c-ce4e306464eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-d2776711-fe36-4127-b524-6498f19fc474,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-4d346f25-f8bf-4694-a211-8edaccf26b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737532020-172.17.0.2-1598701168023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-ddc8fd19-3801-4c70-a58f-c06ae4b184ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-b2eaa864-0a6a-43a2-bd7d-14fab0eb3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0e2d0a18-b2bc-4992-be91-82c3b93fae20,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-7464bded-5e0e-49b7-ba03-3d15d7257270,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-34c4d5cf-d986-4636-a6e3-fb5930975f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-534105df-a760-4d61-ab0c-ce4e306464eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-d2776711-fe36-4127-b524-6498f19fc474,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-4d346f25-f8bf-4694-a211-8edaccf26b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581309282-172.17.0.2-1598701767531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-7b267258-a9c1-48a9-af16-554107a0cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-51526d46-a1ea-42cf-a237-7a3c80ff3d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-47fe2c21-2baa-41de-b8e5-84ab82ce55d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-fe2ddbae-a5b3-4d7a-aad9-66b0ba270d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-0fe67967-695c-4e99-91b0-fd7ae3ee7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-c3aff059-2964-48f5-8f1e-a8b0aad79a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-68c445ce-3b61-4770-91ad-1bc1ca6caa63,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-b321e2fc-bf58-4b0b-9aaa-4de6c571d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581309282-172.17.0.2-1598701767531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-7b267258-a9c1-48a9-af16-554107a0cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-51526d46-a1ea-42cf-a237-7a3c80ff3d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-47fe2c21-2baa-41de-b8e5-84ab82ce55d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-fe2ddbae-a5b3-4d7a-aad9-66b0ba270d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-0fe67967-695c-4e99-91b0-fd7ae3ee7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-c3aff059-2964-48f5-8f1e-a8b0aad79a15,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-68c445ce-3b61-4770-91ad-1bc1ca6caa63,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-b321e2fc-bf58-4b0b-9aaa-4de6c571d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951611331-172.17.0.2-1598701830759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-2077ae21-de04-4424-9017-3c1027cc1ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-2dca715e-66c6-4e45-a1b6-e5ff7a294265,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-c508e7a4-148a-4dd0-bf7b-94385fe857cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-221cc7e6-aa2a-41a6-8e76-2cd617cd5190,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-7d81db01-e41c-4f85-9770-48b62b9fe15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-9d24e767-5eca-461f-8f31-4904864bf9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-5a300555-7ac9-4cc7-8466-e28741abbc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-acb53fdf-b1f7-4199-9b7b-98ba2c24cee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951611331-172.17.0.2-1598701830759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-2077ae21-de04-4424-9017-3c1027cc1ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-2dca715e-66c6-4e45-a1b6-e5ff7a294265,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-c508e7a4-148a-4dd0-bf7b-94385fe857cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-221cc7e6-aa2a-41a6-8e76-2cd617cd5190,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-7d81db01-e41c-4f85-9770-48b62b9fe15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-9d24e767-5eca-461f-8f31-4904864bf9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-5a300555-7ac9-4cc7-8466-e28741abbc83,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-acb53fdf-b1f7-4199-9b7b-98ba2c24cee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561164744-172.17.0.2-1598701916550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-da2c6c8c-2650-4495-b7e9-bb6aed572204,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-cc5d578e-714f-4aff-81a2-432e07590410,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c018fe9f-53a7-437c-8070-125d3c0fcb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8708ba7e-764e-4b52-8fee-4f12cffbbb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-53cffd3f-7924-42f0-afc7-8de84c4133c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3af52bd4-f20b-4ce5-821c-6662b764273c,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-6070af89-7ff1-4a4a-b8c5-7eab89173125,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-32f7c9ad-1043-4947-81ac-fcd5211256b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561164744-172.17.0.2-1598701916550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41538,DS-da2c6c8c-2650-4495-b7e9-bb6aed572204,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-cc5d578e-714f-4aff-81a2-432e07590410,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-c018fe9f-53a7-437c-8070-125d3c0fcb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-8708ba7e-764e-4b52-8fee-4f12cffbbb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-53cffd3f-7924-42f0-afc7-8de84c4133c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3af52bd4-f20b-4ce5-821c-6662b764273c,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-6070af89-7ff1-4a4a-b8c5-7eab89173125,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-32f7c9ad-1043-4947-81ac-fcd5211256b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205629926-172.17.0.2-1598702074115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-db9f7980-b038-4e18-8c78-0b1bba3c1896,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-8fa39bcf-35dc-4639-9e5f-609bcc583386,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-88154b33-7443-409a-b643-8e17fc6252d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-e4cf3124-2ac1-4ebc-a451-64fd75a0b62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-562c1fab-0f2b-4958-9720-b50987775ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-37adc1ab-304f-408d-bf47-e38a0245262a,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-dd6c5589-ebf7-4e6f-99e6-9173d071596f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-4b5f2475-c781-4482-84d6-072782d230b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205629926-172.17.0.2-1598702074115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46183,DS-db9f7980-b038-4e18-8c78-0b1bba3c1896,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-8fa39bcf-35dc-4639-9e5f-609bcc583386,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-88154b33-7443-409a-b643-8e17fc6252d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-e4cf3124-2ac1-4ebc-a451-64fd75a0b62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-562c1fab-0f2b-4958-9720-b50987775ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-37adc1ab-304f-408d-bf47-e38a0245262a,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-dd6c5589-ebf7-4e6f-99e6-9173d071596f,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-4b5f2475-c781-4482-84d6-072782d230b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382694785-172.17.0.2-1598702470977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-36daba03-72d8-4c36-89e9-09b9fb05aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-1205526d-5fe2-4ac6-bdf4-7a382ed04538,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-498178d8-b358-4947-b674-02e3f8d1d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-8766bb99-0e2e-4616-822a-363a3ef2eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-11e5a567-fefa-4f39-b236-a6485a3d138d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-ec5f6ca8-9ace-4969-bb63-c52d2abb4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-61ce1a8e-ad0b-4339-931f-e5c7a46eefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-7d7c3e6c-a3ce-46a8-b8cc-227e0fbfee36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382694785-172.17.0.2-1598702470977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-36daba03-72d8-4c36-89e9-09b9fb05aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-1205526d-5fe2-4ac6-bdf4-7a382ed04538,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-498178d8-b358-4947-b674-02e3f8d1d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-8766bb99-0e2e-4616-822a-363a3ef2eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-11e5a567-fefa-4f39-b236-a6485a3d138d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-ec5f6ca8-9ace-4969-bb63-c52d2abb4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-61ce1a8e-ad0b-4339-931f-e5c7a46eefd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-7d7c3e6c-a3ce-46a8-b8cc-227e0fbfee36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329878680-172.17.0.2-1598702577831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-9929e1e6-3893-4c84-bf04-15357d8cc9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-a2088ff1-dad0-44aa-9409-38846bb3695b,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-0a48e7d2-ed0e-4a99-81ea-666a92c6f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2acbb7bf-ae79-4114-83d1-550c170977fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4299c4aa-c226-4525-a854-8e424729466a,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-62cc6d8d-1fde-4ec2-b1b6-7224a4be926a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-4c0bca11-bc21-4b26-b1b9-7fbdf71dc74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-8b1f4388-7538-4942-952d-8b9c5bfa15c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329878680-172.17.0.2-1598702577831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40865,DS-9929e1e6-3893-4c84-bf04-15357d8cc9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-a2088ff1-dad0-44aa-9409-38846bb3695b,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-0a48e7d2-ed0e-4a99-81ea-666a92c6f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2acbb7bf-ae79-4114-83d1-550c170977fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4299c4aa-c226-4525-a854-8e424729466a,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-62cc6d8d-1fde-4ec2-b1b6-7224a4be926a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-4c0bca11-bc21-4b26-b1b9-7fbdf71dc74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-8b1f4388-7538-4942-952d-8b9c5bfa15c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165085706-172.17.0.2-1598702672378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-04910e27-2444-4381-83bc-ed8e868a9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-0657d83d-64a2-4b0e-bc72-3c9873f0d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-f5649f74-ccdf-4819-8083-7cce276fe499,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-0b2e0e1c-d9aa-48fa-8b3d-983a80c0e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-e51c0977-3930-4136-9f81-c03da1a70a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-6797fc6f-90d3-4e53-8e76-ffbac966af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-eee73193-e737-4b24-87c3-9c533af529a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-67be5871-746a-456b-a9fb-fd6807bf10e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165085706-172.17.0.2-1598702672378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-04910e27-2444-4381-83bc-ed8e868a9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-0657d83d-64a2-4b0e-bc72-3c9873f0d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-f5649f74-ccdf-4819-8083-7cce276fe499,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-0b2e0e1c-d9aa-48fa-8b3d-983a80c0e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-e51c0977-3930-4136-9f81-c03da1a70a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-6797fc6f-90d3-4e53-8e76-ffbac966af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-eee73193-e737-4b24-87c3-9c533af529a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-67be5871-746a-456b-a9fb-fd6807bf10e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461907408-172.17.0.2-1598702832481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-b1877495-3dbf-4764-86bf-8926911566a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-2e7fb5f1-df81-4adc-a09b-59b0692a6063,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-2cc510e3-747d-4530-81b9-c98cd1c74efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-3bea261d-0f02-453f-a163-1d0a6dcad900,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-239918f6-cfc7-4d23-8b42-e4e6c2b98720,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-c51304c9-b1f6-474b-aef5-c30df8710bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-fac5cd4e-9ef9-4cf2-af43-935a0ea50707,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-27b3c9d4-b88c-4828-8a35-1176c997adc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461907408-172.17.0.2-1598702832481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-b1877495-3dbf-4764-86bf-8926911566a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-2e7fb5f1-df81-4adc-a09b-59b0692a6063,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-2cc510e3-747d-4530-81b9-c98cd1c74efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-3bea261d-0f02-453f-a163-1d0a6dcad900,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-239918f6-cfc7-4d23-8b42-e4e6c2b98720,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-c51304c9-b1f6-474b-aef5-c30df8710bab,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-fac5cd4e-9ef9-4cf2-af43-935a0ea50707,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-27b3c9d4-b88c-4828-8a35-1176c997adc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235891378-172.17.0.2-1598702897775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-ce555807-f17c-44b3-9c45-30b238e998f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-9d33f43f-5cc2-4fed-836b-2fac757a9522,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-ec39f900-b450-46a8-a9a6-0e2539cce87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-79e4e91d-655b-45a1-b71f-415a8247327c,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-d848338a-b95a-433e-8f4e-b7e2de2c874b,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-130dc9b2-9431-420b-b71c-a7ba67f3436d,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c22886cc-afb0-43a9-8816-253805b18473,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b53fe007-5145-4bfe-9d44-d9019a6e3639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235891378-172.17.0.2-1598702897775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-ce555807-f17c-44b3-9c45-30b238e998f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-9d33f43f-5cc2-4fed-836b-2fac757a9522,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-ec39f900-b450-46a8-a9a6-0e2539cce87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-79e4e91d-655b-45a1-b71f-415a8247327c,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-d848338a-b95a-433e-8f4e-b7e2de2c874b,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-130dc9b2-9431-420b-b71c-a7ba67f3436d,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-c22886cc-afb0-43a9-8816-253805b18473,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-b53fe007-5145-4bfe-9d44-d9019a6e3639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365807898-172.17.0.2-1598702991374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36395,DS-c9c66b3d-6679-4429-b44f-77470118f233,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-e45bd30c-18a6-482e-887b-7040727c935c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2849b35a-bc9c-4e3b-bdf9-6ee486737158,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-69163302-c94a-4af7-b213-1dd46748a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-c670f437-6e59-4631-9366-8fa8eed5c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-4daeeaca-a25d-4fbc-8c5f-ba4f9d55660b,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-b059fb7d-cbf0-4337-9ab7-a4f5f35d18be,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-38f117bd-1f64-4541-a522-ad53aa395ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365807898-172.17.0.2-1598702991374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36395,DS-c9c66b3d-6679-4429-b44f-77470118f233,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-e45bd30c-18a6-482e-887b-7040727c935c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2849b35a-bc9c-4e3b-bdf9-6ee486737158,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-69163302-c94a-4af7-b213-1dd46748a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-c670f437-6e59-4631-9366-8fa8eed5c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-4daeeaca-a25d-4fbc-8c5f-ba4f9d55660b,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-b059fb7d-cbf0-4337-9ab7-a4f5f35d18be,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-38f117bd-1f64-4541-a522-ad53aa395ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92878601-172.17.0.2-1598703029249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-01d74412-f964-4063-8443-ba57da20c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-980a4ba5-2d91-4cb0-9859-73acb4d46432,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-633256c9-ca9d-4548-aaf2-681dc8f893f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-b6161fb4-734b-46b3-a1c7-3708eb1bbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-49e257ff-2ab1-43fa-b5c7-59c773340092,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-942052e0-8291-4668-b5d1-ac02cf2f5f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a8e7da11-a4c0-4f3d-ba51-e0f48d1d8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-f95c4ab1-d5a8-4e29-933a-8c3ddd1971d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92878601-172.17.0.2-1598703029249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-01d74412-f964-4063-8443-ba57da20c8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-980a4ba5-2d91-4cb0-9859-73acb4d46432,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-633256c9-ca9d-4548-aaf2-681dc8f893f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-b6161fb4-734b-46b3-a1c7-3708eb1bbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-49e257ff-2ab1-43fa-b5c7-59c773340092,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-942052e0-8291-4668-b5d1-ac02cf2f5f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-a8e7da11-a4c0-4f3d-ba51-e0f48d1d8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-f95c4ab1-d5a8-4e29-933a-8c3ddd1971d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521902475-172.17.0.2-1598703201201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-288c2804-6445-43c6-a566-05c6a70a02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-af599b8e-e004-4670-a647-a257f37689ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-254b5322-da78-41f4-bde5-ba346816ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-205bd3f5-d60f-4aad-bced-402120826613,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-881fd3ce-6e83-44dd-b0e8-0b0e1c18b91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-6345bae7-22ca-4c0e-bba2-1c18289ce984,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b6dd75f3-9d04-45af-ac2a-fabe94f4fcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-f7619400-6d19-4118-8881-ece405f40ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521902475-172.17.0.2-1598703201201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36526,DS-288c2804-6445-43c6-a566-05c6a70a02f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-af599b8e-e004-4670-a647-a257f37689ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-254b5322-da78-41f4-bde5-ba346816ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-205bd3f5-d60f-4aad-bced-402120826613,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-881fd3ce-6e83-44dd-b0e8-0b0e1c18b91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-6345bae7-22ca-4c0e-bba2-1c18289ce984,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b6dd75f3-9d04-45af-ac2a-fabe94f4fcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-f7619400-6d19-4118-8881-ece405f40ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103234439-172.17.0.2-1598703409672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-8e38adf5-8c80-4b9d-8f95-94bae18bdf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-ccda5fd0-e0d3-4fe0-8a13-e39b7d022ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-b94bd73d-cf30-44e2-9b83-c0c46f5a8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-85ff5865-3465-44ac-9b66-c20a6f8c2659,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e9f6c758-a216-471f-ad59-ea2dfa92a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-0c8d9afb-58fb-4a78-8fd5-318c5bf74297,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ea206566-c5a9-4c4f-b4fe-284ec07f4fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d930d7d1-3857-437e-880d-38c6ebcdb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103234439-172.17.0.2-1598703409672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-8e38adf5-8c80-4b9d-8f95-94bae18bdf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-ccda5fd0-e0d3-4fe0-8a13-e39b7d022ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-b94bd73d-cf30-44e2-9b83-c0c46f5a8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-85ff5865-3465-44ac-9b66-c20a6f8c2659,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e9f6c758-a216-471f-ad59-ea2dfa92a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-0c8d9afb-58fb-4a78-8fd5-318c5bf74297,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ea206566-c5a9-4c4f-b4fe-284ec07f4fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d930d7d1-3857-437e-880d-38c6ebcdb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167616303-172.17.0.2-1598703549417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-3e373a69-aad2-47f0-862a-9f8b8d8c21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-bb37ccf3-267a-4a8d-a2b4-12507296190a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-af2df54f-72d9-407b-92f4-6bbc91bf726c,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-b7621e99-b3ae-4175-98fd-82af289044a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-2e2b11c5-4c6c-40ac-8627-13d3ed7c70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-783180f9-ab57-4018-80f5-284831b49a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-0a7c51c0-b341-4661-b2c7-a76bc17b30a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-182bcfe9-22cd-4a76-8656-da0f3e09128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167616303-172.17.0.2-1598703549417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40085,DS-3e373a69-aad2-47f0-862a-9f8b8d8c21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-bb37ccf3-267a-4a8d-a2b4-12507296190a,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-af2df54f-72d9-407b-92f4-6bbc91bf726c,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-b7621e99-b3ae-4175-98fd-82af289044a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-2e2b11c5-4c6c-40ac-8627-13d3ed7c70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-783180f9-ab57-4018-80f5-284831b49a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-0a7c51c0-b341-4661-b2c7-a76bc17b30a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-182bcfe9-22cd-4a76-8656-da0f3e09128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031091705-172.17.0.2-1598703643529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-09ae3ccd-b66c-41fb-9e52-2a6b95f16996,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-c410c39e-f042-4092-be7a-62b34e020e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-06ca5bf8-516b-45d1-80f8-b2cbf4b438db,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-0884c9fc-8051-4d42-8000-9210b82d6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-9568d39b-638e-457c-a1c8-ca198d95ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-cb3789ac-a6ea-4fdc-9faf-5b43f90c2879,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-8f5b2072-2cf4-45b9-8056-af73f6f55fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-bf0c6436-829c-4b6d-8b95-3eb34629a3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031091705-172.17.0.2-1598703643529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36196,DS-09ae3ccd-b66c-41fb-9e52-2a6b95f16996,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-c410c39e-f042-4092-be7a-62b34e020e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-06ca5bf8-516b-45d1-80f8-b2cbf4b438db,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-0884c9fc-8051-4d42-8000-9210b82d6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-9568d39b-638e-457c-a1c8-ca198d95ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-cb3789ac-a6ea-4fdc-9faf-5b43f90c2879,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-8f5b2072-2cf4-45b9-8056-af73f6f55fff,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-bf0c6436-829c-4b6d-8b95-3eb34629a3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019420451-172.17.0.2-1598703935388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-8a2225f3-5a7b-4118-bcfd-964785a05e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-6b46e5ea-581a-4531-93ed-35167a150559,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-b4bff99d-fe80-4b69-8650-7a056385d823,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-3ddee3b8-99c5-42b7-acc5-b868b94ab3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-35513bef-ad4b-4fe3-9786-f46b105a43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6cb28734-63fc-44e7-b6b1-82760ca36f94,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-acc613f6-15d6-413b-974e-b7bb2bedbead,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-f0e42c7e-4581-4cc4-98e0-c8f18ecff44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019420451-172.17.0.2-1598703935388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-8a2225f3-5a7b-4118-bcfd-964785a05e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-6b46e5ea-581a-4531-93ed-35167a150559,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-b4bff99d-fe80-4b69-8650-7a056385d823,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-3ddee3b8-99c5-42b7-acc5-b868b94ab3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-35513bef-ad4b-4fe3-9786-f46b105a43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6cb28734-63fc-44e7-b6b1-82760ca36f94,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-acc613f6-15d6-413b-974e-b7bb2bedbead,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-f0e42c7e-4581-4cc4-98e0-c8f18ecff44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267927471-172.17.0.2-1598703999194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4b2bf900-1de5-44a2-8792-f859331b6270,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-ef95a5dd-e8a2-4283-9c01-53e760d23b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-793433da-889e-413c-93ad-5345f5fd673b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-9d4fe377-cb77-4a16-a141-e1af3c421144,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-96d66546-3a9e-4afc-8520-3b423e544283,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-c5311565-1db3-48fd-91a5-f121002d95d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-893935e1-b50e-4519-b411-b12fb22678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-4ba2ab13-dc49-439d-8498-258dd745b182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267927471-172.17.0.2-1598703999194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4b2bf900-1de5-44a2-8792-f859331b6270,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-ef95a5dd-e8a2-4283-9c01-53e760d23b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-793433da-889e-413c-93ad-5345f5fd673b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-9d4fe377-cb77-4a16-a141-e1af3c421144,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-96d66546-3a9e-4afc-8520-3b423e544283,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-c5311565-1db3-48fd-91a5-f121002d95d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-893935e1-b50e-4519-b411-b12fb22678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-4ba2ab13-dc49-439d-8498-258dd745b182,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094137940-172.17.0.2-1598704100532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-d349bd41-182a-4035-8b20-2df8f1379429,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-4a6302f8-bbed-4129-bdd9-b00e6a13e9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c58cba1b-562a-4e94-8728-b86393f34800,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-45f26c58-5ba6-4624-8797-52a162d53e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-fa2611d4-0708-4191-8578-c353a8ae0459,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-d8e9d0bd-0ed2-4342-bf51-308664da216c,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-a7b5aab6-a2f0-4879-bff8-118ab0b4b63d,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-e22ffa31-aa80-43d4-bed9-ac04102413d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094137940-172.17.0.2-1598704100532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-d349bd41-182a-4035-8b20-2df8f1379429,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-4a6302f8-bbed-4129-bdd9-b00e6a13e9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c58cba1b-562a-4e94-8728-b86393f34800,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-45f26c58-5ba6-4624-8797-52a162d53e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-fa2611d4-0708-4191-8578-c353a8ae0459,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-d8e9d0bd-0ed2-4342-bf51-308664da216c,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-a7b5aab6-a2f0-4879-bff8-118ab0b4b63d,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-e22ffa31-aa80-43d4-bed9-ac04102413d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236332439-172.17.0.2-1598704292043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-cfbdf34e-4b37-41a0-b149-e66748ac3bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-c5798007-46ec-4b22-bba9-b93dfd93fa38,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-8f9a7836-948d-43a7-b37e-9f0a789a715d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-32ba350a-10bc-41bd-bf40-63d2654abe92,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6384f42-91e0-4d6f-abb0-e7426ccc3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-bfd754f3-5e4e-4369-bb2b-055af0855ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-0b1b92e7-6c61-43cd-a04f-8c0235880b62,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-b40c4d4f-fcf4-4468-8111-716725b87dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236332439-172.17.0.2-1598704292043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-cfbdf34e-4b37-41a0-b149-e66748ac3bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-c5798007-46ec-4b22-bba9-b93dfd93fa38,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-8f9a7836-948d-43a7-b37e-9f0a789a715d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-32ba350a-10bc-41bd-bf40-63d2654abe92,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b6384f42-91e0-4d6f-abb0-e7426ccc3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-bfd754f3-5e4e-4369-bb2b-055af0855ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-0b1b92e7-6c61-43cd-a04f-8c0235880b62,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-b40c4d4f-fcf4-4468-8111-716725b87dcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332689973-172.17.0.2-1598704320564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36456,DS-77dde703-9c8c-409a-a37f-717c0f6f945a,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-cdefae28-41eb-4b0b-aa64-ce8841a66962,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-dcb49954-82de-4588-aa96-489ffc606982,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d4d8f554-6516-4e01-ac79-82aa72c6effd,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-26ecbedd-4653-48ff-9967-b0ef0c3a9b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-82d731c5-5da2-4c7f-8b3c-32fc52f517a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-8fdd61f6-8d9f-414f-bef6-00049e4e8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-e4777f87-30ef-4f45-ae2c-da1cd8c3d25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332689973-172.17.0.2-1598704320564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36456,DS-77dde703-9c8c-409a-a37f-717c0f6f945a,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-cdefae28-41eb-4b0b-aa64-ce8841a66962,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-dcb49954-82de-4588-aa96-489ffc606982,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d4d8f554-6516-4e01-ac79-82aa72c6effd,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-26ecbedd-4653-48ff-9967-b0ef0c3a9b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-82d731c5-5da2-4c7f-8b3c-32fc52f517a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-8fdd61f6-8d9f-414f-bef6-00049e4e8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-e4777f87-30ef-4f45-ae2c-da1cd8c3d25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774792023-172.17.0.2-1598704401240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-66bbefb4-9c3f-4e9a-9726-bb2f2488bdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-25917c51-9ab5-4e77-82e8-57167ccf9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-20133830-ef0c-47e3-ab2c-8f5343d190d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-7b5169cf-86b1-40be-8972-08faebb19cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-f554e351-ea24-4217-8c39-f54aeee37f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-34479405-5106-4de0-8c62-41dec2643ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-d78e026d-8e20-46f6-8482-e9020ad294ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-5781d0aa-d5aa-4480-a7ad-86d3a079fb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774792023-172.17.0.2-1598704401240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-66bbefb4-9c3f-4e9a-9726-bb2f2488bdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-25917c51-9ab5-4e77-82e8-57167ccf9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-20133830-ef0c-47e3-ab2c-8f5343d190d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-7b5169cf-86b1-40be-8972-08faebb19cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-f554e351-ea24-4217-8c39-f54aeee37f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-34479405-5106-4de0-8c62-41dec2643ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-d78e026d-8e20-46f6-8482-e9020ad294ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-5781d0aa-d5aa-4480-a7ad-86d3a079fb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892676173-172.17.0.2-1598704417666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-cd7e86fd-cc5f-4cbb-aeef-ba906eb911dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2b407567-b752-4dd7-8a5e-cd234d7e5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-a3e5d81a-70b1-4917-8107-9ae1ed503218,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-7c9fadfd-a857-401c-b902-789c00ccaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-fdbfa7f5-652c-46bc-948b-25bdd79f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-e6a1eb6f-970e-454d-ac03-1f450c932b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-4eeb9257-df24-40e1-93f5-d141e2440b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-7770b6f5-5566-4a03-9ad6-e6b982f5c236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892676173-172.17.0.2-1598704417666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-cd7e86fd-cc5f-4cbb-aeef-ba906eb911dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2b407567-b752-4dd7-8a5e-cd234d7e5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-a3e5d81a-70b1-4917-8107-9ae1ed503218,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-7c9fadfd-a857-401c-b902-789c00ccaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-fdbfa7f5-652c-46bc-948b-25bdd79f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-e6a1eb6f-970e-454d-ac03-1f450c932b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-4eeb9257-df24-40e1-93f5-d141e2440b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-7770b6f5-5566-4a03-9ad6-e6b982f5c236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542264463-172.17.0.2-1598704534456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-9a2bfcd8-5ce3-4955-a344-3f8cfc8b9c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-0331efc0-5e37-4b2b-be06-0ba372d1e920,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-08bdfba2-3c61-4f64-8b7d-54a5fcbc519d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-5fd3938f-eba7-4eeb-b407-92144f692991,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-a539eec7-9f67-451f-9fe6-9caa83d0b20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-8c67a4b5-df6b-482e-be15-ea0b81f76fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-6d382f06-f285-4a27-9cf3-d10cdc968628,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-579d5fc9-b15c-4893-b387-d49c8e0e648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542264463-172.17.0.2-1598704534456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-9a2bfcd8-5ce3-4955-a344-3f8cfc8b9c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-0331efc0-5e37-4b2b-be06-0ba372d1e920,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-08bdfba2-3c61-4f64-8b7d-54a5fcbc519d,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-5fd3938f-eba7-4eeb-b407-92144f692991,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-a539eec7-9f67-451f-9fe6-9caa83d0b20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-8c67a4b5-df6b-482e-be15-ea0b81f76fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-6d382f06-f285-4a27-9cf3-d10cdc968628,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-579d5fc9-b15c-4893-b387-d49c8e0e648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911751237-172.17.0.2-1598704583257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-ffc30906-65b2-4609-a3cf-5f439e96c657,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-040419b4-d297-4f78-9492-7d3c30c846d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2875164a-3c48-4b1c-b8de-88507a3fd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-db1cfa3d-7e40-4d6b-9fc6-771cc706ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-5687b8c4-973d-4c44-809b-b05bb224296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-ba1969a1-b9c5-46ca-a5ce-56dbd80fdc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f2f4813f-52b5-43c9-80de-5c83dbf9b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-122397d2-fe10-4c41-bab3-2472dcd5b257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911751237-172.17.0.2-1598704583257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44597,DS-ffc30906-65b2-4609-a3cf-5f439e96c657,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-040419b4-d297-4f78-9492-7d3c30c846d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-2875164a-3c48-4b1c-b8de-88507a3fd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-db1cfa3d-7e40-4d6b-9fc6-771cc706ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-5687b8c4-973d-4c44-809b-b05bb224296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-ba1969a1-b9c5-46ca-a5ce-56dbd80fdc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f2f4813f-52b5-43c9-80de-5c83dbf9b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-122397d2-fe10-4c41-bab3-2472dcd5b257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143579109-172.17.0.2-1598704842993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-df72d15c-73aa-48c3-92dc-e25cbf35f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b66835b4-0a6f-4bee-95ee-977763a95ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-1a9dc35c-a028-4e50-afa4-0e9fbbafab56,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-822c243d-d835-4a63-a5d9-7bc4629557f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d1bcef44-13e9-4534-ab27-933979634290,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-f25908e5-bc19-4425-9114-5d0e9278c312,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-ff364b3f-2b52-49e0-8120-7742e1cb1d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b9419ed8-43d5-4d70-b4bd-4ba8b6e625b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143579109-172.17.0.2-1598704842993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-df72d15c-73aa-48c3-92dc-e25cbf35f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-b66835b4-0a6f-4bee-95ee-977763a95ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-1a9dc35c-a028-4e50-afa4-0e9fbbafab56,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-822c243d-d835-4a63-a5d9-7bc4629557f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-d1bcef44-13e9-4534-ab27-933979634290,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-f25908e5-bc19-4425-9114-5d0e9278c312,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-ff364b3f-2b52-49e0-8120-7742e1cb1d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-b9419ed8-43d5-4d70-b4bd-4ba8b6e625b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082148300-172.17.0.2-1598704923000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44556,DS-a82de48b-7425-49f1-8dcc-0a8494be886d,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-5aa75d59-43b5-4f6b-9e34-a87218cde97e,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-45c927ec-f6f9-4f64-9fc0-c8f1386e6de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b77dca0e-5dcf-4450-9ec7-4c28147d2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a5778577-4ee6-4d53-b29c-fc8e38740d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f6a95e15-038e-4475-8df1-b9f7105350a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-0cf44c9b-cdf6-472c-aa73-2428c81ad882,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-453f1aae-e0d2-4351-82ad-fb8083030da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082148300-172.17.0.2-1598704923000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44556,DS-a82de48b-7425-49f1-8dcc-0a8494be886d,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-5aa75d59-43b5-4f6b-9e34-a87218cde97e,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-45c927ec-f6f9-4f64-9fc0-c8f1386e6de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b77dca0e-5dcf-4450-9ec7-4c28147d2f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-a5778577-4ee6-4d53-b29c-fc8e38740d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f6a95e15-038e-4475-8df1-b9f7105350a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-0cf44c9b-cdf6-472c-aa73-2428c81ad882,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-453f1aae-e0d2-4351-82ad-fb8083030da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369048538-172.17.0.2-1598705118921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-479c2bbc-a4aa-4d48-9c05-afe874f61be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-a82f4d0a-f35d-422c-9740-9afa5b078a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-e5f28459-014e-4732-ac66-7eda0ba1dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a00d4473-b277-433a-8ff3-ee3f205dce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-b8c1a55b-7861-4cc1-9455-7caeda3397c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-65a6a79f-06b9-48af-b94e-8ef31d25df65,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-5851b688-7b78-4ffe-8d2c-dcf7709a1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-e4092a01-178e-4493-a84a-d7708ec16329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369048538-172.17.0.2-1598705118921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-479c2bbc-a4aa-4d48-9c05-afe874f61be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-a82f4d0a-f35d-422c-9740-9afa5b078a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-e5f28459-014e-4732-ac66-7eda0ba1dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a00d4473-b277-433a-8ff3-ee3f205dce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-b8c1a55b-7861-4cc1-9455-7caeda3397c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-65a6a79f-06b9-48af-b94e-8ef31d25df65,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-5851b688-7b78-4ffe-8d2c-dcf7709a1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-e4092a01-178e-4493-a84a-d7708ec16329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831884594-172.17.0.2-1598705134760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-003d3b7d-6d2d-4c9c-acae-e29f5d785900,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-ae2383bf-c005-4bea-b9dd-de07eb836077,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-d6610020-2f9b-4a15-9f0f-7bd7d39e9352,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-1eb20138-3b70-4e59-9a6e-9c5640f84f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d937130a-b609-48d6-8d28-c4bf93394616,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-ed03357a-ee37-4099-9af7-05c44dab7423,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-e8a31a48-fac2-41d4-ac8e-094b7bcbcdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-aeff3434-4cff-44ad-83e4-1acbf73bf07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831884594-172.17.0.2-1598705134760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-003d3b7d-6d2d-4c9c-acae-e29f5d785900,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-ae2383bf-c005-4bea-b9dd-de07eb836077,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-d6610020-2f9b-4a15-9f0f-7bd7d39e9352,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-1eb20138-3b70-4e59-9a6e-9c5640f84f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d937130a-b609-48d6-8d28-c4bf93394616,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-ed03357a-ee37-4099-9af7-05c44dab7423,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-e8a31a48-fac2-41d4-ac8e-094b7bcbcdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-aeff3434-4cff-44ad-83e4-1acbf73bf07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 4041
