reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540265318-172.17.0.13-1598667213671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-41ceb625-1071-4123-8bce-533541d7f753,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-52e838c5-edbf-4ba6-b2f6-7a8acf192176,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-45c0a128-a10d-497c-9a25-fcf4a1ab4676,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-4bd01140-039d-4180-a42c-1b345c1698d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-0d1a3122-f8d0-4709-a75b-6d7ee5d5ea3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-0ec39ca1-9c2c-4fac-b658-ddc0ba7d6ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-62ab3ae5-7459-4ce8-aec7-d09191d9161d,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-7d99bb8f-2f48-4177-94f7-d3b9092565af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540265318-172.17.0.13-1598667213671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42171,DS-41ceb625-1071-4123-8bce-533541d7f753,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-52e838c5-edbf-4ba6-b2f6-7a8acf192176,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-45c0a128-a10d-497c-9a25-fcf4a1ab4676,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-4bd01140-039d-4180-a42c-1b345c1698d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-0d1a3122-f8d0-4709-a75b-6d7ee5d5ea3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-0ec39ca1-9c2c-4fac-b658-ddc0ba7d6ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-62ab3ae5-7459-4ce8-aec7-d09191d9161d,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-7d99bb8f-2f48-4177-94f7-d3b9092565af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262262303-172.17.0.13-1598668303946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5d73bee8-ceb2-463a-8372-5a0437adcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-cd5010e1-4693-4e91-b35a-3c08e877d934,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-fdfa6170-e081-4ff9-bf84-9f9fdecdc2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-8d7c3988-7142-492c-85d0-bcb3133e2640,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-a69865cb-ac9f-47a8-97ca-a51b989cf457,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-d191304e-f5e5-44fc-9a0b-80cae252dd72,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-4dc6c5cb-3703-4498-9444-c4f3eb6c5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-efb30419-d9fc-4a9b-b759-ee829cb8029d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262262303-172.17.0.13-1598668303946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45318,DS-5d73bee8-ceb2-463a-8372-5a0437adcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-cd5010e1-4693-4e91-b35a-3c08e877d934,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-fdfa6170-e081-4ff9-bf84-9f9fdecdc2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-8d7c3988-7142-492c-85d0-bcb3133e2640,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-a69865cb-ac9f-47a8-97ca-a51b989cf457,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-d191304e-f5e5-44fc-9a0b-80cae252dd72,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-4dc6c5cb-3703-4498-9444-c4f3eb6c5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-efb30419-d9fc-4a9b-b759-ee829cb8029d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196027982-172.17.0.13-1598668342360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-574cc67c-bb79-4983-ad6b-461ac7aa3be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-a79c4f1a-af17-49c4-9ba6-56875dd19212,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-1bba1fba-bef1-46c1-83fd-a9408d0ceccb,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-b3c70053-f39d-479b-97e6-c0a1e419d547,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-21c7d51c-e445-43c0-8933-7eb2be86b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-83429bdf-236a-4f89-9ff7-725c61b9e104,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-f92c0fd3-03a9-4149-a1b8-4d1f010eea83,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-e52191b8-838f-4c45-aba8-52d43ba87df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196027982-172.17.0.13-1598668342360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-574cc67c-bb79-4983-ad6b-461ac7aa3be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-a79c4f1a-af17-49c4-9ba6-56875dd19212,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-1bba1fba-bef1-46c1-83fd-a9408d0ceccb,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-b3c70053-f39d-479b-97e6-c0a1e419d547,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-21c7d51c-e445-43c0-8933-7eb2be86b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-83429bdf-236a-4f89-9ff7-725c61b9e104,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-f92c0fd3-03a9-4149-a1b8-4d1f010eea83,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-e52191b8-838f-4c45-aba8-52d43ba87df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140339247-172.17.0.13-1598668382634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-7a85301e-a22f-4fd0-8ff2-f7c7867799d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-68a707f5-e617-47de-9a30-0424464af6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-e42201a0-5e8e-4fab-ae64-579290533f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-707ae2e1-11c9-40bf-bd16-ca7b1e1cae53,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-d5d30f66-52bf-4934-9a68-104bbafeb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-dcd57638-4df8-45e1-b283-b78602f840f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-6a290165-8f88-4759-a0a7-b65c0f26062b,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-91dec6ce-d501-40f1-aee7-a8375d46e7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140339247-172.17.0.13-1598668382634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-7a85301e-a22f-4fd0-8ff2-f7c7867799d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-68a707f5-e617-47de-9a30-0424464af6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-e42201a0-5e8e-4fab-ae64-579290533f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-707ae2e1-11c9-40bf-bd16-ca7b1e1cae53,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-d5d30f66-52bf-4934-9a68-104bbafeb5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-dcd57638-4df8-45e1-b283-b78602f840f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-6a290165-8f88-4759-a0a7-b65c0f26062b,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-91dec6ce-d501-40f1-aee7-a8375d46e7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252563190-172.17.0.13-1598668611942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-1fddcb9a-02dc-40f3-a634-aa486c375fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-1a6fb407-8fb8-44e8-8a07-8240cec022ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ae9140f6-2e33-4298-afc3-6cf76dc77655,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-91a66544-2cb7-4b1f-8f6c-8964bb3f50e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-fcf74b61-b94c-4c8a-995c-8ae991b1abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-4e319429-109c-4cec-8d93-1c5ec78118a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-b390d7d6-c06a-4c4b-a5e2-84b600a9c8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-fd2b68ce-f62f-4c5a-9c55-bf482d4cf805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252563190-172.17.0.13-1598668611942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-1fddcb9a-02dc-40f3-a634-aa486c375fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-1a6fb407-8fb8-44e8-8a07-8240cec022ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-ae9140f6-2e33-4298-afc3-6cf76dc77655,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-91a66544-2cb7-4b1f-8f6c-8964bb3f50e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-fcf74b61-b94c-4c8a-995c-8ae991b1abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-4e319429-109c-4cec-8d93-1c5ec78118a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-b390d7d6-c06a-4c4b-a5e2-84b600a9c8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-fd2b68ce-f62f-4c5a-9c55-bf482d4cf805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361088188-172.17.0.13-1598669567744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-2832ccdd-bba9-40b5-8620-9da5a2714fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-6e4baba3-0f1a-4b9f-836a-966018a86d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-7c3ce7cb-ef62-491a-a17f-182cc50664be,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-4a3905f0-a62b-447d-91d3-66e449dadfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-95a2e669-9659-4f10-885f-b7ff5aaf1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-29172b48-0723-4369-b0fb-44d1ce39c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-e6c52475-edea-44b3-86e1-2ec33b4e71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-1e5e1b9c-de6f-4d9b-8d2d-d4233f5a3edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361088188-172.17.0.13-1598669567744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-2832ccdd-bba9-40b5-8620-9da5a2714fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-6e4baba3-0f1a-4b9f-836a-966018a86d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-7c3ce7cb-ef62-491a-a17f-182cc50664be,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-4a3905f0-a62b-447d-91d3-66e449dadfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-95a2e669-9659-4f10-885f-b7ff5aaf1e55,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-29172b48-0723-4369-b0fb-44d1ce39c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-e6c52475-edea-44b3-86e1-2ec33b4e71f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-1e5e1b9c-de6f-4d9b-8d2d-d4233f5a3edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888879837-172.17.0.13-1598669859075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46679,DS-b85228c0-090b-4d36-829e-d47b5a5832e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-e128747c-47e7-4e2d-a69c-be036770cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-9c05eadc-94b9-4d1b-bb06-67007fcdda6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-9f371c6e-1c86-4f63-bf4f-38eee0555ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-40f480a1-8df0-4423-aed4-e0527c21f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0e2272d9-5538-40d4-ae76-65147759da94,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-5fa2278b-422d-4231-87dd-424ad77bb2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-e6f9e4e6-f658-4d76-872d-06b5237db7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888879837-172.17.0.13-1598669859075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46679,DS-b85228c0-090b-4d36-829e-d47b5a5832e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-e128747c-47e7-4e2d-a69c-be036770cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-9c05eadc-94b9-4d1b-bb06-67007fcdda6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-9f371c6e-1c86-4f63-bf4f-38eee0555ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-40f480a1-8df0-4423-aed4-e0527c21f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0e2272d9-5538-40d4-ae76-65147759da94,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-5fa2278b-422d-4231-87dd-424ad77bb2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-e6f9e4e6-f658-4d76-872d-06b5237db7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677259876-172.17.0.13-1598670420405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-0d6150fb-fea0-486c-a1a9-ded32f236cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-9e57dde9-4eab-411a-80df-c294cacd0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-c3ece0ac-8630-48d3-8dcb-fda09c5804d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-81d99c7a-291f-4c50-bc43-4db58f05000d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-bd442749-40ad-4fbf-8619-b620b37f4a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9cee66b0-4738-48bd-9653-b658b4ae8134,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-d853b3c5-6da4-44a2-9521-e981b95fd448,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-64978c07-85a3-4e53-a8f7-adeccab81aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677259876-172.17.0.13-1598670420405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-0d6150fb-fea0-486c-a1a9-ded32f236cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-9e57dde9-4eab-411a-80df-c294cacd0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-c3ece0ac-8630-48d3-8dcb-fda09c5804d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-81d99c7a-291f-4c50-bc43-4db58f05000d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-bd442749-40ad-4fbf-8619-b620b37f4a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-9cee66b0-4738-48bd-9653-b658b4ae8134,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-d853b3c5-6da4-44a2-9521-e981b95fd448,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-64978c07-85a3-4e53-a8f7-adeccab81aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478453104-172.17.0.13-1598670455820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40405,DS-b413903a-a2bc-4c67-b6dd-031deec47dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-2fe78e80-9145-49ef-8e6f-829cb0aad202,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-05a51d34-bbe1-4559-9283-dcefca9aef58,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-d240ce94-4a15-4e14-a0d1-03bf4f2c4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-459f6cda-5a0e-4ff9-b9dc-0dd8e29a21b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-fe7cd4da-d13a-4d5e-8283-fb39ecd03396,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-a02eb3ec-9467-4ed6-a72d-73dd8948059a,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c5f8a3fd-c9ea-4b97-bc76-02b5ddf19a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478453104-172.17.0.13-1598670455820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40405,DS-b413903a-a2bc-4c67-b6dd-031deec47dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-2fe78e80-9145-49ef-8e6f-829cb0aad202,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-05a51d34-bbe1-4559-9283-dcefca9aef58,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-d240ce94-4a15-4e14-a0d1-03bf4f2c4b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-459f6cda-5a0e-4ff9-b9dc-0dd8e29a21b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-fe7cd4da-d13a-4d5e-8283-fb39ecd03396,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-a02eb3ec-9467-4ed6-a72d-73dd8948059a,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c5f8a3fd-c9ea-4b97-bc76-02b5ddf19a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320845267-172.17.0.13-1598670532675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-8945f401-d70f-4f7d-9260-e71b551714e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-acf1d923-60a1-454f-8c61-d7f55483411c,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-b0fd0363-a6ff-4bd6-8c36-5b5252ba8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ecb5e03b-06b1-4564-9421-1d804211f781,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-16b42552-74a1-496b-a0fa-12c6099aa1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7483e60a-baf7-4f8a-862a-3b99131ad5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-748dea34-88ff-499d-a391-39b3194bb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-99d55c41-eaa4-48d9-85e1-12ac3d498e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320845267-172.17.0.13-1598670532675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-8945f401-d70f-4f7d-9260-e71b551714e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-acf1d923-60a1-454f-8c61-d7f55483411c,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-b0fd0363-a6ff-4bd6-8c36-5b5252ba8a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ecb5e03b-06b1-4564-9421-1d804211f781,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-16b42552-74a1-496b-a0fa-12c6099aa1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-7483e60a-baf7-4f8a-862a-3b99131ad5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-748dea34-88ff-499d-a391-39b3194bb8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-99d55c41-eaa4-48d9-85e1-12ac3d498e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988323169-172.17.0.13-1598670680152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-1867a438-7d6a-47ee-9e40-b8b751bcd302,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-07adbec7-ad47-4552-9b29-0e3a8aaeb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-86361ae1-d87a-4990-8199-e62f7936717b,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-85de4390-cf09-4f11-860f-3640cb1a721f,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-3f13a786-6cb4-4c22-a9fd-0ecab09b57bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-21f31ebd-9200-4885-983f-539620de78f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fbd5c9e2-b1fd-414e-b9df-3ce844a40df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-9f561162-7fc9-43d1-8a22-6edb5ed7a2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988323169-172.17.0.13-1598670680152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-1867a438-7d6a-47ee-9e40-b8b751bcd302,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-07adbec7-ad47-4552-9b29-0e3a8aaeb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-86361ae1-d87a-4990-8199-e62f7936717b,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-85de4390-cf09-4f11-860f-3640cb1a721f,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-3f13a786-6cb4-4c22-a9fd-0ecab09b57bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-21f31ebd-9200-4885-983f-539620de78f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-fbd5c9e2-b1fd-414e-b9df-3ce844a40df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-9f561162-7fc9-43d1-8a22-6edb5ed7a2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233484978-172.17.0.13-1598670719112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-6e65620c-4998-4bf9-bda2-a01bb4de4643,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-ec5bd0f4-8cee-4669-9130-222f09224194,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c92d7f96-5977-4b74-9a89-ab996ee8bb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-0cb53a58-cb31-49d2-aaf4-683e4df1e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-68b93c75-636b-4d1a-8d2a-37d768060921,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-51136837-c11e-4530-86c8-168d936f9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-7097e436-cc00-49fe-8c19-488c585ba95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-1309cc3e-5937-438d-a272-49d178e2fadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233484978-172.17.0.13-1598670719112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38793,DS-6e65620c-4998-4bf9-bda2-a01bb4de4643,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-ec5bd0f4-8cee-4669-9130-222f09224194,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c92d7f96-5977-4b74-9a89-ab996ee8bb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-0cb53a58-cb31-49d2-aaf4-683e4df1e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-68b93c75-636b-4d1a-8d2a-37d768060921,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-51136837-c11e-4530-86c8-168d936f9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-7097e436-cc00-49fe-8c19-488c585ba95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-1309cc3e-5937-438d-a272-49d178e2fadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542322648-172.17.0.13-1598671855608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37299,DS-8692129f-6b85-45a2-85bf-76ae3668c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-1d3350e1-8720-480d-a11b-5a1ac0655236,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-773d1e4b-40c0-49b6-af67-1171c3ecd719,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-13384842-23c8-4ea1-b5eb-4bc463d8966d,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-00a5e5ab-42eb-4f6f-be23-0696bcc546cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-1ae260b7-7a07-42f7-a247-ac3c7a49fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-f25704dd-a21b-47a4-8d7f-85036641b657,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-b51519bd-ba0b-4373-9275-22948f76e510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542322648-172.17.0.13-1598671855608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37299,DS-8692129f-6b85-45a2-85bf-76ae3668c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-1d3350e1-8720-480d-a11b-5a1ac0655236,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-773d1e4b-40c0-49b6-af67-1171c3ecd719,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-13384842-23c8-4ea1-b5eb-4bc463d8966d,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-00a5e5ab-42eb-4f6f-be23-0696bcc546cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-1ae260b7-7a07-42f7-a247-ac3c7a49fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-f25704dd-a21b-47a4-8d7f-85036641b657,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-b51519bd-ba0b-4373-9275-22948f76e510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393951213-172.17.0.13-1598671968189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-aaeb4b12-b1ea-494b-a34b-ce13694bf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-7ca25530-4a6b-45db-bd82-5f5d2f27d035,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-3cd1afe5-335f-439b-b200-a7056477f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-b610a6ed-cdc2-4d33-a94c-a73d44e61a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-aff888f8-b155-461d-8fbb-23b1933228fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-14a9486b-dce8-4a89-a960-ab24bffcd9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-7b5a6b40-521a-4470-832d-ea931e22d491,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-20e1cbdd-9c97-409b-a4e1-61c2be8745d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393951213-172.17.0.13-1598671968189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-aaeb4b12-b1ea-494b-a34b-ce13694bf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-7ca25530-4a6b-45db-bd82-5f5d2f27d035,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-3cd1afe5-335f-439b-b200-a7056477f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-b610a6ed-cdc2-4d33-a94c-a73d44e61a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-aff888f8-b155-461d-8fbb-23b1933228fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-14a9486b-dce8-4a89-a960-ab24bffcd9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-7b5a6b40-521a-4470-832d-ea931e22d491,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-20e1cbdd-9c97-409b-a4e1-61c2be8745d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846001094-172.17.0.13-1598672129363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-b0de6b1d-bbdc-48ea-80da-0b6cd51a5e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-b29a7126-60f3-43a1-933a-eb21e331e078,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-1d97e239-6692-42b1-8784-09bb4f5b731c,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0ea07978-11c6-40ef-bb15-c4f180677573,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-377adde4-50bb-4da9-8abd-bb9134fe1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-7f7674ae-f03e-4cd5-8855-3ab8fd70abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8295ae4b-3e5f-4bcf-92e9-1b436a7e1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-ea4850bd-971e-4ffc-8d2c-e9d929fa2e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846001094-172.17.0.13-1598672129363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39842,DS-b0de6b1d-bbdc-48ea-80da-0b6cd51a5e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-b29a7126-60f3-43a1-933a-eb21e331e078,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-1d97e239-6692-42b1-8784-09bb4f5b731c,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0ea07978-11c6-40ef-bb15-c4f180677573,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-377adde4-50bb-4da9-8abd-bb9134fe1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-7f7674ae-f03e-4cd5-8855-3ab8fd70abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8295ae4b-3e5f-4bcf-92e9-1b436a7e1a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-ea4850bd-971e-4ffc-8d2c-e9d929fa2e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528235939-172.17.0.13-1598672554373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-dd7d97c5-8c8d-4df2-a564-65fa4356f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-a9428cc3-63a0-46a7-9243-ddd0527aa28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-17942736-589a-4b0e-851e-7c876b485738,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-cd06ddcb-1754-4581-ad00-eda7abdffe37,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-78f6b84d-4288-45ae-93ee-762564071bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-33001dfc-2f06-485b-8872-bfaff9ef10cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-8cec580a-58a7-473f-a0ff-fb501177bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-19426a26-5cdb-496d-ad07-a1c320ecf655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528235939-172.17.0.13-1598672554373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-dd7d97c5-8c8d-4df2-a564-65fa4356f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-a9428cc3-63a0-46a7-9243-ddd0527aa28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-17942736-589a-4b0e-851e-7c876b485738,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-cd06ddcb-1754-4581-ad00-eda7abdffe37,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-78f6b84d-4288-45ae-93ee-762564071bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-33001dfc-2f06-485b-8872-bfaff9ef10cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-8cec580a-58a7-473f-a0ff-fb501177bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-19426a26-5cdb-496d-ad07-a1c320ecf655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825551834-172.17.0.13-1598672635610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-4065f00a-b1f7-434e-8b43-cb7d4ff2cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-eab8fdfb-0bf0-4c0e-bbff-b3a25c3d498b,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-a4d8522b-ce9a-427e-9b4f-b437934e4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-370077b2-7e75-4603-be0b-2c60f33ed938,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-157e3b69-dab5-4e3f-a94f-a7288cc52d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-90f88dde-c089-4c2c-9331-8d9af5f95ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8cb31274-8833-40fc-b41d-4991144cefe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-afab66a7-b72d-47b8-adbe-36f9368ffbe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825551834-172.17.0.13-1598672635610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-4065f00a-b1f7-434e-8b43-cb7d4ff2cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-eab8fdfb-0bf0-4c0e-bbff-b3a25c3d498b,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-a4d8522b-ce9a-427e-9b4f-b437934e4ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-370077b2-7e75-4603-be0b-2c60f33ed938,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-157e3b69-dab5-4e3f-a94f-a7288cc52d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-90f88dde-c089-4c2c-9331-8d9af5f95ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8cb31274-8833-40fc-b41d-4991144cefe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-afab66a7-b72d-47b8-adbe-36f9368ffbe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5603
