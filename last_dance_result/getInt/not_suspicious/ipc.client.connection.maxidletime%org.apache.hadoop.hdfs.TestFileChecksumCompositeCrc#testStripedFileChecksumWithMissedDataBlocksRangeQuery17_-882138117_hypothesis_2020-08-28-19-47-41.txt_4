reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939931846-172.17.0.3-1598644114343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-7483aeba-4b38-4d6b-8d34-7bf8fac5f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-4c6ea586-95bd-429e-bc36-a655c82a967b,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-fb7faa3b-409e-46e0-ba6b-c2dc5ab3598b,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-8cf159ff-2f3e-4332-9dec-435ae4c50edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-2e939709-b87b-4421-9f8a-dad6f4cd172c,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-1b6d69f9-d6e0-4c18-8797-541cd513bbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-fda7d4b6-8593-49ad-8962-74790f80a449,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e1ef075a-8a97-4375-b73b-13ffbc3f020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939931846-172.17.0.3-1598644114343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-7483aeba-4b38-4d6b-8d34-7bf8fac5f8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-4c6ea586-95bd-429e-bc36-a655c82a967b,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-fb7faa3b-409e-46e0-ba6b-c2dc5ab3598b,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-8cf159ff-2f3e-4332-9dec-435ae4c50edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-2e939709-b87b-4421-9f8a-dad6f4cd172c,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-1b6d69f9-d6e0-4c18-8797-541cd513bbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-fda7d4b6-8593-49ad-8962-74790f80a449,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e1ef075a-8a97-4375-b73b-13ffbc3f020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024856640-172.17.0.3-1598644144229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-125be79e-9740-4b30-b884-1f72eae7214a,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-476ebaf1-705d-40a6-8bde-151456cc39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-072c7dbf-1c00-4663-94a1-45c79b6f9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ec65029b-66b6-4746-97c1-f0a1110a2dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-1016c179-d943-475e-a6f1-dc9e3ab8ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d90725b8-8bd7-41a2-ab2f-7aca0d243bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-22d5d40f-64ab-490b-a698-6601029124d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c8b38a56-e54f-4cbc-8757-e027658a7b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024856640-172.17.0.3-1598644144229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-125be79e-9740-4b30-b884-1f72eae7214a,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-476ebaf1-705d-40a6-8bde-151456cc39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-072c7dbf-1c00-4663-94a1-45c79b6f9d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ec65029b-66b6-4746-97c1-f0a1110a2dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-1016c179-d943-475e-a6f1-dc9e3ab8ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d90725b8-8bd7-41a2-ab2f-7aca0d243bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-22d5d40f-64ab-490b-a698-6601029124d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c8b38a56-e54f-4cbc-8757-e027658a7b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452012451-172.17.0.3-1598644461087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-bb75e298-98cf-45ae-9d20-1224791b4fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-42841283-ea07-48ad-97d0-3bfabdb8bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-b52f1afc-12db-4399-bf4a-7e69c9f524e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-abc478df-9440-4216-82be-66f2792497ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-4ab55a84-e62c-48e0-8c9c-5ece8df9ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-2d314443-383e-424f-830a-e2d137ccb17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c0a2c95d-dc98-452a-966a-f536bf3a1f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-9983b1b1-97eb-4086-a288-eb4c91271c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452012451-172.17.0.3-1598644461087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-bb75e298-98cf-45ae-9d20-1224791b4fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-42841283-ea07-48ad-97d0-3bfabdb8bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-b52f1afc-12db-4399-bf4a-7e69c9f524e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-abc478df-9440-4216-82be-66f2792497ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-4ab55a84-e62c-48e0-8c9c-5ece8df9ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-2d314443-383e-424f-830a-e2d137ccb17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c0a2c95d-dc98-452a-966a-f536bf3a1f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-9983b1b1-97eb-4086-a288-eb4c91271c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890355907-172.17.0.3-1598644500052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33958,DS-4184e2c5-0234-4202-8ef9-84dd52b877de,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-de7add0a-9ea5-45a3-b4d7-a822769a8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-40328f5e-6b6e-4f51-899b-897660bfaa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-3c42562c-6a31-415c-ac7a-faa85ada7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c92d7a9b-7f6a-4eeb-9f11-9bade762251f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-6e504d5a-cdd8-439f-8873-d4b10c385379,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-3d6b2310-bcd9-4309-9497-b91cf30bbeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-2fd1d5b6-fb1e-4461-a1a6-f03dc7666457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890355907-172.17.0.3-1598644500052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33958,DS-4184e2c5-0234-4202-8ef9-84dd52b877de,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-de7add0a-9ea5-45a3-b4d7-a822769a8eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-40328f5e-6b6e-4f51-899b-897660bfaa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-3c42562c-6a31-415c-ac7a-faa85ada7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-c92d7a9b-7f6a-4eeb-9f11-9bade762251f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-6e504d5a-cdd8-439f-8873-d4b10c385379,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-3d6b2310-bcd9-4309-9497-b91cf30bbeac,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-2fd1d5b6-fb1e-4461-a1a6-f03dc7666457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43879340-172.17.0.3-1598644697837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-a6e98284-ed89-4767-840a-ec294fb3bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-3d0e313a-9238-4ccb-885d-bec19ed8fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-3f291bfe-cd50-440f-9b67-733e0c2183b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-765989e8-57d7-460c-82b8-fb17378637d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-a1d77495-3f88-4fb9-bfd6-c5b1c55bb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-cd2e0260-a21d-4150-9942-8ceb1eb0d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-7dc55eac-803a-4f85-a5cf-11f3b3f33df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-f230161b-7deb-4507-9752-4f02fe93bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43879340-172.17.0.3-1598644697837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-a6e98284-ed89-4767-840a-ec294fb3bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-3d0e313a-9238-4ccb-885d-bec19ed8fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-3f291bfe-cd50-440f-9b67-733e0c2183b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-765989e8-57d7-460c-82b8-fb17378637d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-a1d77495-3f88-4fb9-bfd6-c5b1c55bb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-cd2e0260-a21d-4150-9942-8ceb1eb0d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-7dc55eac-803a-4f85-a5cf-11f3b3f33df3,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-f230161b-7deb-4507-9752-4f02fe93bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747387113-172.17.0.3-1598644931037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-3b6010c8-f85c-418d-b7a0-5ae9771a54af,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-4071f665-40ab-48e8-93a0-96dded2e6e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-ea359a53-581b-45eb-ad2a-161410ef7585,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-9da30446-3d32-455d-ab1f-6a0aa896431d,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-808be582-7568-49e3-83c8-0c56f2ca2609,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-b562abc8-4f5f-427a-b6e3-d931bf2e0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-a3ec4f04-9502-4a61-b740-eafc9b41959b,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-a1cbf0de-57c7-475a-b24f-bd61600803e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747387113-172.17.0.3-1598644931037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-3b6010c8-f85c-418d-b7a0-5ae9771a54af,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-4071f665-40ab-48e8-93a0-96dded2e6e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-ea359a53-581b-45eb-ad2a-161410ef7585,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-9da30446-3d32-455d-ab1f-6a0aa896431d,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-808be582-7568-49e3-83c8-0c56f2ca2609,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-b562abc8-4f5f-427a-b6e3-d931bf2e0d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-a3ec4f04-9502-4a61-b740-eafc9b41959b,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-a1cbf0de-57c7-475a-b24f-bd61600803e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485574281-172.17.0.3-1598644991727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-099a38fe-9cd2-4b13-a99d-aa7dc13fa1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f41141c2-d82b-483a-a4eb-e771c987affc,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-84045edc-d4cb-40a3-b237-ade1873a380d,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-314ff80f-40ce-4ddf-9000-3ccf4ffecf00,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ca740c3d-9658-4919-b082-394613fef429,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-ac7bf818-92c4-404b-ae7b-ef1324ce0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-af9c70e1-6db6-4c2c-b420-f2124d123d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2027535d-7e81-4acb-a4f5-7f2cd3667ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485574281-172.17.0.3-1598644991727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-099a38fe-9cd2-4b13-a99d-aa7dc13fa1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f41141c2-d82b-483a-a4eb-e771c987affc,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-84045edc-d4cb-40a3-b237-ade1873a380d,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-314ff80f-40ce-4ddf-9000-3ccf4ffecf00,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ca740c3d-9658-4919-b082-394613fef429,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-ac7bf818-92c4-404b-ae7b-ef1324ce0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-af9c70e1-6db6-4c2c-b420-f2124d123d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-2027535d-7e81-4acb-a4f5-7f2cd3667ddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272820241-172.17.0.3-1598645343579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-6a1339d4-6755-4479-9f1a-8eed7ca30029,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-fd0f0704-64c5-45c8-93b9-f9f0a541bedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f330c8a5-3003-46cc-b4bf-c9b546820f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-9a6f5216-01e8-4662-9a0d-82a11ad36bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-c8cdfcb8-d46a-48ff-aed8-3c47de94479a,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-107e752a-cf40-41f6-b04a-df5899fff001,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-0ab2829d-b611-4ecc-a52c-f5bd88142c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-5a3037bb-c3ec-4dca-b268-817ab40396f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272820241-172.17.0.3-1598645343579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-6a1339d4-6755-4479-9f1a-8eed7ca30029,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-fd0f0704-64c5-45c8-93b9-f9f0a541bedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f330c8a5-3003-46cc-b4bf-c9b546820f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-9a6f5216-01e8-4662-9a0d-82a11ad36bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-c8cdfcb8-d46a-48ff-aed8-3c47de94479a,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-107e752a-cf40-41f6-b04a-df5899fff001,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-0ab2829d-b611-4ecc-a52c-f5bd88142c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-5a3037bb-c3ec-4dca-b268-817ab40396f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668016614-172.17.0.3-1598645410411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-f0a7750f-2103-44e3-8cc0-bce5fe56e879,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-3b7d027d-421d-4453-9ae4-ce2fbcd5153a,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-bec66c36-8af4-4bca-8e40-e8731457c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-8c1bd1c4-4577-4059-99a0-e1880d3675cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ad713b16-091f-4f38-9246-c083a7ff32af,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-d8d90912-45b7-4669-8144-f56b4d51e596,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-181b8977-fe75-4811-81f1-7afa858073ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2f3681c8-b735-481d-9cb4-b8ca28d033ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668016614-172.17.0.3-1598645410411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-f0a7750f-2103-44e3-8cc0-bce5fe56e879,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-3b7d027d-421d-4453-9ae4-ce2fbcd5153a,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-bec66c36-8af4-4bca-8e40-e8731457c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-8c1bd1c4-4577-4059-99a0-e1880d3675cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ad713b16-091f-4f38-9246-c083a7ff32af,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-d8d90912-45b7-4669-8144-f56b4d51e596,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-181b8977-fe75-4811-81f1-7afa858073ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-2f3681c8-b735-481d-9cb4-b8ca28d033ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982735182-172.17.0.3-1598645477133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34742,DS-1e8c75ea-5222-4fb1-9b6f-27645e846b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-aae68b28-9ab4-446b-b70a-73aa2276e608,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ce221342-ec93-4c3d-943e-d5286025ed9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-8b6e1c7c-32e4-43a8-b67b-59834e982031,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-a50ebb1e-01d9-49d2-ad6d-a1a17a6d632e,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-d843a021-9530-47cb-b3b0-807b8356a9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-2181adbb-3717-4e14-b3e0-76e6cde6d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-61794829-f7db-499b-9bdc-9deb9cca1336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982735182-172.17.0.3-1598645477133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34742,DS-1e8c75ea-5222-4fb1-9b6f-27645e846b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-aae68b28-9ab4-446b-b70a-73aa2276e608,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ce221342-ec93-4c3d-943e-d5286025ed9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-8b6e1c7c-32e4-43a8-b67b-59834e982031,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-a50ebb1e-01d9-49d2-ad6d-a1a17a6d632e,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-d843a021-9530-47cb-b3b0-807b8356a9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-2181adbb-3717-4e14-b3e0-76e6cde6d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-61794829-f7db-499b-9bdc-9deb9cca1336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642863244-172.17.0.3-1598645615263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-86ddb08a-addb-41db-b827-e71e9f5e125f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-bb58cc23-1a8b-4196-804e-3645f7380099,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-222a6bc6-0216-4ea5-acce-be077f47158d,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-1ff3671c-772f-46a7-8e4c-f0c68d62b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-614bd267-31cc-47f3-a912-a264d1261204,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-ee173fff-09ac-467f-a7ff-8d48ce729a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-f490a952-3096-4a59-9fa3-726fbbe43967,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-c9a235fa-2608-4086-b5e7-f23bcfacc357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642863244-172.17.0.3-1598645615263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-86ddb08a-addb-41db-b827-e71e9f5e125f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-bb58cc23-1a8b-4196-804e-3645f7380099,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-222a6bc6-0216-4ea5-acce-be077f47158d,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-1ff3671c-772f-46a7-8e4c-f0c68d62b42a,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-614bd267-31cc-47f3-a912-a264d1261204,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-ee173fff-09ac-467f-a7ff-8d48ce729a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-f490a952-3096-4a59-9fa3-726fbbe43967,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-c9a235fa-2608-4086-b5e7-f23bcfacc357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869098126-172.17.0.3-1598645720312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-615437ed-d0dc-4da3-8c1b-ff940f14f414,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-9677a723-7668-4dc9-8c3c-285bb96a7503,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-499efe1f-e08f-4d07-b991-51f471c19ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-efbf7c11-e5ff-4d9b-bc33-d5af1c5678cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-5687fe68-1587-4507-8a53-11ceb208e522,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c12addea-39fe-42a2-bdc6-52a0ba843aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-991dd5dc-38c4-4598-baa9-5ee1d3a120a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-529f0023-245e-47d2-a662-5e3d25dee783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869098126-172.17.0.3-1598645720312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-615437ed-d0dc-4da3-8c1b-ff940f14f414,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-9677a723-7668-4dc9-8c3c-285bb96a7503,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-499efe1f-e08f-4d07-b991-51f471c19ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-efbf7c11-e5ff-4d9b-bc33-d5af1c5678cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-5687fe68-1587-4507-8a53-11ceb208e522,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c12addea-39fe-42a2-bdc6-52a0ba843aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-991dd5dc-38c4-4598-baa9-5ee1d3a120a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-529f0023-245e-47d2-a662-5e3d25dee783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119406645-172.17.0.3-1598645758314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-a8715804-3dbc-448b-8945-e4166848739d,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-e2625fe5-7ee7-487e-8caf-a10b0fb6b592,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-83898034-49aa-4fbf-a0ee-746ce62caa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-20d33c1d-b8cf-4f5e-99c9-1dd0cc65a351,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-2edac1b4-c099-42ce-bc57-229e20f1940f,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e7daab0d-5bb5-4d9a-ae2d-e3e2c54f5394,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-a9a140c1-5645-47d9-9f1c-8f19edb090c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-391ae4a5-7096-441d-8225-a45632d4b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119406645-172.17.0.3-1598645758314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-a8715804-3dbc-448b-8945-e4166848739d,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-e2625fe5-7ee7-487e-8caf-a10b0fb6b592,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-83898034-49aa-4fbf-a0ee-746ce62caa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-20d33c1d-b8cf-4f5e-99c9-1dd0cc65a351,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-2edac1b4-c099-42ce-bc57-229e20f1940f,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e7daab0d-5bb5-4d9a-ae2d-e3e2c54f5394,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-a9a140c1-5645-47d9-9f1c-8f19edb090c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-391ae4a5-7096-441d-8225-a45632d4b066,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101976899-172.17.0.3-1598645913426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-d0796257-fab1-4dd4-835a-ba2164938e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-874b91cf-d7f8-4627-8280-73b368e8c19b,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-8accf610-754e-4cca-b519-5d0f1bc6933f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-758da820-1390-4d79-a377-e1049ff8f582,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-2c5ef2bb-67f0-469a-8ce1-4849eac531b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-5a64253f-dc95-4950-b363-b71e6a5ec7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-b6ccc328-fe32-40ed-9c5d-c2e98e20f56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-85c5d7e8-ba7c-4775-b601-661c03db6883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101976899-172.17.0.3-1598645913426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-d0796257-fab1-4dd4-835a-ba2164938e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-874b91cf-d7f8-4627-8280-73b368e8c19b,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-8accf610-754e-4cca-b519-5d0f1bc6933f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-758da820-1390-4d79-a377-e1049ff8f582,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-2c5ef2bb-67f0-469a-8ce1-4849eac531b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-5a64253f-dc95-4950-b363-b71e6a5ec7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-b6ccc328-fe32-40ed-9c5d-c2e98e20f56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-85c5d7e8-ba7c-4775-b601-661c03db6883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340815253-172.17.0.3-1598647608550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-7236c05c-7c9c-439e-abe6-b24b96627338,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-95cc3b1a-9419-4b79-aa1e-d64667f56913,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-c90c8335-2006-4174-b97b-ebea55351b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-9ddc53a1-fd58-4717-ba49-7205f34ef0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-96af8b9d-f27a-40e2-96ce-23782824b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-f17b4ee2-8440-4148-93f7-900d4fd9ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-3e6633bd-c459-44e4-96e4-65d175206248,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-16f82c33-f4e3-4291-a2b8-12c4c2b7f148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340815253-172.17.0.3-1598647608550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-7236c05c-7c9c-439e-abe6-b24b96627338,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-95cc3b1a-9419-4b79-aa1e-d64667f56913,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-c90c8335-2006-4174-b97b-ebea55351b41,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-9ddc53a1-fd58-4717-ba49-7205f34ef0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-96af8b9d-f27a-40e2-96ce-23782824b2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-f17b4ee2-8440-4148-93f7-900d4fd9ffbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-3e6633bd-c459-44e4-96e4-65d175206248,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-16f82c33-f4e3-4291-a2b8-12c4c2b7f148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393602092-172.17.0.3-1598647914450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-783ced70-46e7-4713-ae9a-d447795a63e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a0713983-eca0-4219-b13f-2d61e3cd579c,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fda85021-940b-4f32-a5c0-91b45951a934,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-872ea08e-9b74-449a-9ac6-2fdd337f08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-537bca1f-c897-49d2-9bd7-9383d28014c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-39d2dc13-d9d3-4735-b828-561cbca41e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-5c3ab49f-088d-45b9-a327-6825e743f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-651c425b-2115-4f95-a6d2-a074b15909b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393602092-172.17.0.3-1598647914450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39212,DS-783ced70-46e7-4713-ae9a-d447795a63e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a0713983-eca0-4219-b13f-2d61e3cd579c,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fda85021-940b-4f32-a5c0-91b45951a934,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-872ea08e-9b74-449a-9ac6-2fdd337f08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-537bca1f-c897-49d2-9bd7-9383d28014c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-39d2dc13-d9d3-4735-b828-561cbca41e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-5c3ab49f-088d-45b9-a327-6825e743f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-651c425b-2115-4f95-a6d2-a074b15909b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48659036-172.17.0.3-1598648025028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-8b5f9d24-9a0d-40ae-82ec-965e8188cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-e3daec45-ccbf-4274-bb69-97045b097efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-e6fe81de-d909-4855-a0c4-59a406ddf18b,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-a91fec19-6365-4b05-ac75-5df191ebb301,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-d5c15643-1d7a-46de-9405-a755359d2669,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-305319fd-9493-4f2d-b7ab-79589a48019c,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-1de31e65-c2bd-441a-9115-536975c48af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-1991b7d5-0082-44ef-96c7-954db6d71afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48659036-172.17.0.3-1598648025028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-8b5f9d24-9a0d-40ae-82ec-965e8188cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-e3daec45-ccbf-4274-bb69-97045b097efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-e6fe81de-d909-4855-a0c4-59a406ddf18b,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-a91fec19-6365-4b05-ac75-5df191ebb301,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-d5c15643-1d7a-46de-9405-a755359d2669,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-305319fd-9493-4f2d-b7ab-79589a48019c,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-1de31e65-c2bd-441a-9115-536975c48af3,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-1991b7d5-0082-44ef-96c7-954db6d71afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174847008-172.17.0.3-1598648647906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-2ffb94fd-e626-4f33-9ea6-72dd6db5ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-0dfce12a-29fb-4588-b47d-73c5e0bde1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-dd6d2a6c-05be-4cfd-b5db-1da62bc1fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-d47cced9-e7a6-4294-9aa2-4c57806ef74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-622a0b17-3671-4548-bfff-3b15174a8f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-451b737c-9504-49d8-890d-07cfafd979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-9fb46306-5c21-415f-b5bb-7683552d9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-bd33609d-c562-4102-9ceb-67d63dec000d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174847008-172.17.0.3-1598648647906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-2ffb94fd-e626-4f33-9ea6-72dd6db5ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-0dfce12a-29fb-4588-b47d-73c5e0bde1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-dd6d2a6c-05be-4cfd-b5db-1da62bc1fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-d47cced9-e7a6-4294-9aa2-4c57806ef74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-622a0b17-3671-4548-bfff-3b15174a8f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-451b737c-9504-49d8-890d-07cfafd979a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-9fb46306-5c21-415f-b5bb-7683552d9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-bd33609d-c562-4102-9ceb-67d63dec000d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4969
