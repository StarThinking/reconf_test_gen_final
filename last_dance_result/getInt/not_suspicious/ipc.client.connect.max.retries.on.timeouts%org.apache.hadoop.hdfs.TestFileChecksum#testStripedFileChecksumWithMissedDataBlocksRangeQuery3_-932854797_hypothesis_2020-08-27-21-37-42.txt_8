reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653541964-172.17.0.12-1598564548982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-7286535d-d10f-4abe-a4a1-2f73d5fd4289,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-78609f7a-05dc-49f9-8c80-aa047985ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-14363b56-5e0d-4c66-b008-5c05e2d0e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-150a054e-3f31-4b21-aec7-4a2eda524e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-da3078eb-5df9-4e52-b85f-7fe9047ae309,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-b91beb70-8e00-47fd-ada4-1f1eb91798ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-92a22b66-72d4-4190-ad15-ebcfaed9f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-08970c6e-bc97-43f8-951b-1ff92e76939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653541964-172.17.0.12-1598564548982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-7286535d-d10f-4abe-a4a1-2f73d5fd4289,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-78609f7a-05dc-49f9-8c80-aa047985ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-14363b56-5e0d-4c66-b008-5c05e2d0e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-150a054e-3f31-4b21-aec7-4a2eda524e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-da3078eb-5df9-4e52-b85f-7fe9047ae309,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-b91beb70-8e00-47fd-ada4-1f1eb91798ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-92a22b66-72d4-4190-ad15-ebcfaed9f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-08970c6e-bc97-43f8-951b-1ff92e76939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060353596-172.17.0.12-1598564606710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-84cce0dc-4cd4-462c-9d51-286a3be98963,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c2ba4376-17c7-4c44-b046-d5a9b3d9612b,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-84c07a50-9cec-4699-a51b-5dad083c6542,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-bd196316-3df0-4163-ada3-97911fb7738a,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-d939bf4f-0532-4894-9b49-ec58c12e2124,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-4e70fd4f-9ec7-4ca3-8a31-989662c85a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-0e42b5c3-a8f3-4a5b-8b94-60bcede5ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5c4794c1-5479-4b34-addf-af61e038f8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060353596-172.17.0.12-1598564606710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-84cce0dc-4cd4-462c-9d51-286a3be98963,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c2ba4376-17c7-4c44-b046-d5a9b3d9612b,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-84c07a50-9cec-4699-a51b-5dad083c6542,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-bd196316-3df0-4163-ada3-97911fb7738a,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-d939bf4f-0532-4894-9b49-ec58c12e2124,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-4e70fd4f-9ec7-4ca3-8a31-989662c85a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-0e42b5c3-a8f3-4a5b-8b94-60bcede5ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5c4794c1-5479-4b34-addf-af61e038f8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048683737-172.17.0.12-1598564668843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-fa18f109-c772-4b7d-9bd8-0d26eece2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-31a3d880-bc38-4786-bdd9-46c4d6899d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-e9ba014e-6569-4be5-a070-247afe00401f,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-4d570a5d-9eff-42e0-ad5f-19f76a49d0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-420c959e-d761-4022-b394-bc3d6599ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-bc8be084-bb59-44da-b26f-3812af0757a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-cde0556e-7c07-4df0-ac22-8401014bd08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-bd92cce8-5980-4d1c-af33-2da4d99b190a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048683737-172.17.0.12-1598564668843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-fa18f109-c772-4b7d-9bd8-0d26eece2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-31a3d880-bc38-4786-bdd9-46c4d6899d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-e9ba014e-6569-4be5-a070-247afe00401f,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-4d570a5d-9eff-42e0-ad5f-19f76a49d0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-420c959e-d761-4022-b394-bc3d6599ecae,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-bc8be084-bb59-44da-b26f-3812af0757a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-cde0556e-7c07-4df0-ac22-8401014bd08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-bd92cce8-5980-4d1c-af33-2da4d99b190a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889065257-172.17.0.12-1598564936792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-8607bd92-d9c2-4556-ad9c-b703b0b7494e,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4a2c17b9-8349-4c22-aef7-95f6357cdbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-c42d34a7-3287-4702-a260-d00676491230,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-aefccfad-6d98-4af9-9b5a-9c41bd3bccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-4f62314f-69d2-4765-af8b-d41e0765e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-61bdbc44-5887-44e9-9baf-d103940815ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-221617ee-77e1-4a82-b09d-07241c31aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-0abf5161-1c84-4b8d-a06a-a18d8d19212b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889065257-172.17.0.12-1598564936792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-8607bd92-d9c2-4556-ad9c-b703b0b7494e,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-4a2c17b9-8349-4c22-aef7-95f6357cdbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-c42d34a7-3287-4702-a260-d00676491230,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-aefccfad-6d98-4af9-9b5a-9c41bd3bccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-4f62314f-69d2-4765-af8b-d41e0765e6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-61bdbc44-5887-44e9-9baf-d103940815ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-221617ee-77e1-4a82-b09d-07241c31aa32,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-0abf5161-1c84-4b8d-a06a-a18d8d19212b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199259287-172.17.0.12-1598565535100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-b60f55a3-6e0e-40fb-9a4b-271060313354,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4b9173b0-552a-4cc9-aea5-7c97e3da583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-9c326e82-4233-42de-a3c5-9ea51c68a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b0dc529e-077e-4545-a10b-4cc2fd72e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-4a14b6bb-18ea-47d9-8640-0f7d5b2d5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5f082aaa-26a8-42b6-8158-72fbeffc92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-3dc41377-fa98-476d-b501-e6c70eae2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-6de97c1a-3bfa-4e59-b1ff-7c57a804724a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199259287-172.17.0.12-1598565535100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-b60f55a3-6e0e-40fb-9a4b-271060313354,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4b9173b0-552a-4cc9-aea5-7c97e3da583e,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-9c326e82-4233-42de-a3c5-9ea51c68a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b0dc529e-077e-4545-a10b-4cc2fd72e300,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-4a14b6bb-18ea-47d9-8640-0f7d5b2d5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5f082aaa-26a8-42b6-8158-72fbeffc92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-3dc41377-fa98-476d-b501-e6c70eae2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-6de97c1a-3bfa-4e59-b1ff-7c57a804724a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618476777-172.17.0.12-1598565611272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33518,DS-484ec89e-db15-4ffc-bef2-41c2edd2f180,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-cfab9b44-90ed-4d1d-b751-90e366fc58e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-7703f46f-b2b0-435b-b343-a6d95118443b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e2a6359e-bde2-4da3-bea9-0694683dba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-7febfd20-cb55-482d-9ed4-47af92b3149d,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-a6e881ce-2a52-4e46-993a-a1cb58901978,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-ba47c875-aab2-4ef3-a7b1-b4d2a32e7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-0eb8d7ae-4f2a-42c5-b46f-450b9b3ff608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618476777-172.17.0.12-1598565611272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33518,DS-484ec89e-db15-4ffc-bef2-41c2edd2f180,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-cfab9b44-90ed-4d1d-b751-90e366fc58e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-7703f46f-b2b0-435b-b343-a6d95118443b,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-e2a6359e-bde2-4da3-bea9-0694683dba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-7febfd20-cb55-482d-9ed4-47af92b3149d,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-a6e881ce-2a52-4e46-993a-a1cb58901978,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-ba47c875-aab2-4ef3-a7b1-b4d2a32e7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-0eb8d7ae-4f2a-42c5-b46f-450b9b3ff608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672348076-172.17.0.12-1598565761025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-04ae5aa1-02e0-40e8-8d1a-3dbf37815cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-c2776c1d-678f-4066-88b8-7699af7b0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-476c1df9-3dd9-404c-880f-297eb3daab86,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-8725d790-754f-49c9-9b74-7e723b9bb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-38321137-15e8-4fec-97b4-f25472331ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-967b9cc2-9549-4cce-a09d-8cc78c29f458,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-ae6ec3d4-e32a-4cbd-bc68-63f4386c0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-af81fa1a-50c1-4882-bab8-f1b167654d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672348076-172.17.0.12-1598565761025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-04ae5aa1-02e0-40e8-8d1a-3dbf37815cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-c2776c1d-678f-4066-88b8-7699af7b0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-476c1df9-3dd9-404c-880f-297eb3daab86,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-8725d790-754f-49c9-9b74-7e723b9bb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-38321137-15e8-4fec-97b4-f25472331ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-967b9cc2-9549-4cce-a09d-8cc78c29f458,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-ae6ec3d4-e32a-4cbd-bc68-63f4386c0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-af81fa1a-50c1-4882-bab8-f1b167654d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674815688-172.17.0.12-1598565914490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-42dcd402-77f4-415f-9d85-10231777a617,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-312bb449-3aa6-4af9-b0fc-15ec5c07de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-9f366a98-e21b-4e86-a13d-34f7d188728f,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c0266283-aea4-49cf-9edc-83d75fc60f21,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-79a27ff2-8a59-43c5-b7e8-ee2ba627ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-7ca13eed-cd32-4c2c-bba3-30ed6a0417aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-11e278e0-dfb0-4f99-9894-a0f63bf9bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-bf5a6592-933c-40a3-910e-5f068f3d1238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674815688-172.17.0.12-1598565914490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-42dcd402-77f4-415f-9d85-10231777a617,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-312bb449-3aa6-4af9-b0fc-15ec5c07de6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-9f366a98-e21b-4e86-a13d-34f7d188728f,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-c0266283-aea4-49cf-9edc-83d75fc60f21,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-79a27ff2-8a59-43c5-b7e8-ee2ba627ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-7ca13eed-cd32-4c2c-bba3-30ed6a0417aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-11e278e0-dfb0-4f99-9894-a0f63bf9bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-bf5a6592-933c-40a3-910e-5f068f3d1238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12909093-172.17.0.12-1598566441611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36634,DS-21bd296b-b5dc-47ad-956a-1b7cc9f6da84,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-8c425759-0fe7-40ab-a277-d48e59649de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-121450f9-111a-40d6-baef-072a4ac27f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-ea21b21c-66ee-4c9f-a01f-36ba6c27b2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b705f6b1-8679-443e-b51f-2324abad0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-8d3e43ab-d874-47ff-b38f-b9a33a66a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-673c3fad-54d0-4a71-b2fe-89fe7bfd07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-a17cce56-1561-4b4b-a67e-ac0f4e4ff11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12909093-172.17.0.12-1598566441611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36634,DS-21bd296b-b5dc-47ad-956a-1b7cc9f6da84,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-8c425759-0fe7-40ab-a277-d48e59649de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-121450f9-111a-40d6-baef-072a4ac27f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-ea21b21c-66ee-4c9f-a01f-36ba6c27b2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-b705f6b1-8679-443e-b51f-2324abad0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-8d3e43ab-d874-47ff-b38f-b9a33a66a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-673c3fad-54d0-4a71-b2fe-89fe7bfd07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-a17cce56-1561-4b4b-a67e-ac0f4e4ff11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133747216-172.17.0.12-1598566476551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41703,DS-aa9fc731-e77e-477e-ac40-17fc3cf629db,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-ad399173-0ac8-4aab-b8cd-e3eea3602a33,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-60060513-d520-4c65-96aa-8e5dd0bb35e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-df0eab19-7123-4453-85cd-7a183a099408,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-75a48fdf-99c2-4aa8-b943-b59d5b5bc279,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f8a04bbf-b7b3-4400-9c26-1313fefef3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-89688cc5-1744-49af-9cd4-30586ff3e647,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-66c98f18-f341-44b2-a490-c8dbd2f2d9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133747216-172.17.0.12-1598566476551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41703,DS-aa9fc731-e77e-477e-ac40-17fc3cf629db,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-ad399173-0ac8-4aab-b8cd-e3eea3602a33,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-60060513-d520-4c65-96aa-8e5dd0bb35e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-df0eab19-7123-4453-85cd-7a183a099408,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-75a48fdf-99c2-4aa8-b943-b59d5b5bc279,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-f8a04bbf-b7b3-4400-9c26-1313fefef3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-89688cc5-1744-49af-9cd4-30586ff3e647,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-66c98f18-f341-44b2-a490-c8dbd2f2d9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49749438-172.17.0.12-1598566512612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-17636deb-468a-45b0-b43f-59982e07bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-7f20d5f6-4f06-4b39-b455-83fb6e30aeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-3cc527d7-8c31-4a55-8771-f35601ce401b,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-f9e9e60d-7c49-4a73-96ad-4ce421d276b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-373347de-ca28-4d84-9027-728853c6e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-8e4804e3-1fb7-470a-9ea6-b61438caf8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-da5c66e9-71b6-4bbc-bb4e-2dafec3ee780,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-82c3dd6d-55c0-4777-8b94-6096fe78c5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49749438-172.17.0.12-1598566512612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42404,DS-17636deb-468a-45b0-b43f-59982e07bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-7f20d5f6-4f06-4b39-b455-83fb6e30aeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-3cc527d7-8c31-4a55-8771-f35601ce401b,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-f9e9e60d-7c49-4a73-96ad-4ce421d276b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-373347de-ca28-4d84-9027-728853c6e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-8e4804e3-1fb7-470a-9ea6-b61438caf8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-da5c66e9-71b6-4bbc-bb4e-2dafec3ee780,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-82c3dd6d-55c0-4777-8b94-6096fe78c5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375754898-172.17.0.12-1598566549517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-b3eae73b-7f17-462f-bedb-fd71ddb28fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-efa28d95-b151-463d-b941-aea260cdbba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-405e8138-f74d-45b6-a5c9-791a262df7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c796b5c6-44bd-473c-913d-9772c2a092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-071ab066-5dbe-4e6f-a344-a7c09127ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-d5fdd6c7-8e26-4eca-8f1b-ec6bab894d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-b0cbb6f6-a117-4b89-be96-6b0a0e4493ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-3601111d-d11e-453c-bb1b-49cf23e49c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375754898-172.17.0.12-1598566549517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45562,DS-b3eae73b-7f17-462f-bedb-fd71ddb28fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-efa28d95-b151-463d-b941-aea260cdbba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-405e8138-f74d-45b6-a5c9-791a262df7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-c796b5c6-44bd-473c-913d-9772c2a092f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-071ab066-5dbe-4e6f-a344-a7c09127ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-d5fdd6c7-8e26-4eca-8f1b-ec6bab894d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-b0cbb6f6-a117-4b89-be96-6b0a0e4493ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-3601111d-d11e-453c-bb1b-49cf23e49c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978241909-172.17.0.12-1598567578041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-ea1153da-df16-4f1f-9994-f3e0aa3e6155,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-a3dadd03-2b59-4f0a-b008-585d787ae45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a57e1416-06cc-4e3f-bb79-2d7cf0a406cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-7eb48282-12ce-4030-b2c2-7a79032c7948,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-50c99d97-25c2-4570-801f-2392dfa3a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-d93915c0-2ec9-4d92-9c79-69a20c752c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-5c701504-c195-4597-b436-58c73fe0ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-09367a7c-a75d-4f39-8657-f76a13cad8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978241909-172.17.0.12-1598567578041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-ea1153da-df16-4f1f-9994-f3e0aa3e6155,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-a3dadd03-2b59-4f0a-b008-585d787ae45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a57e1416-06cc-4e3f-bb79-2d7cf0a406cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-7eb48282-12ce-4030-b2c2-7a79032c7948,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-50c99d97-25c2-4570-801f-2392dfa3a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-d93915c0-2ec9-4d92-9c79-69a20c752c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-5c701504-c195-4597-b436-58c73fe0ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-09367a7c-a75d-4f39-8657-f76a13cad8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172675940-172.17.0.12-1598568081954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-6fc9c070-fdc7-42e0-a95d-f38cea10bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-fd9359da-2182-41f6-916a-a52975afc0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-ecfd1f5f-0783-4adc-92ff-f4d542938b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-8094853a-8816-42cc-9f74-8af8dc1a005e,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-25284d2f-fa60-4dc0-9189-11f6d09220ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4217083f-29e2-4f55-9607-a2ff52857e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-ca2f938c-3379-44cf-8a82-a57608d67f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8e0496b8-3b95-4dc4-b5b1-247d58b79279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172675940-172.17.0.12-1598568081954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-6fc9c070-fdc7-42e0-a95d-f38cea10bdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-fd9359da-2182-41f6-916a-a52975afc0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-ecfd1f5f-0783-4adc-92ff-f4d542938b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-8094853a-8816-42cc-9f74-8af8dc1a005e,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-25284d2f-fa60-4dc0-9189-11f6d09220ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4217083f-29e2-4f55-9607-a2ff52857e43,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-ca2f938c-3379-44cf-8a82-a57608d67f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8e0496b8-3b95-4dc4-b5b1-247d58b79279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782711944-172.17.0.12-1598568208693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-43fdc007-b4d9-436c-a0b7-c87d0a04ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-57f3a96d-ab8c-45c9-a29c-9b5b45a96615,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-844f53fc-6026-4740-8a67-3f15c4b19591,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-9e5666d1-6921-491d-9be4-7b1ba70d7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8c711f86-e04b-4632-809a-4e2b2f343adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-d3b4817c-f558-4e60-b75e-f88fea77738b,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-ea19b97c-1be1-4495-a82f-dd7a51a76461,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-868f4c3d-7dfa-4356-87f5-41ba0e1cc9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782711944-172.17.0.12-1598568208693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-43fdc007-b4d9-436c-a0b7-c87d0a04ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-57f3a96d-ab8c-45c9-a29c-9b5b45a96615,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-844f53fc-6026-4740-8a67-3f15c4b19591,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-9e5666d1-6921-491d-9be4-7b1ba70d7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8c711f86-e04b-4632-809a-4e2b2f343adb,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-d3b4817c-f558-4e60-b75e-f88fea77738b,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-ea19b97c-1be1-4495-a82f-dd7a51a76461,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-868f4c3d-7dfa-4356-87f5-41ba0e1cc9fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757767995-172.17.0.12-1598568555529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-0e767ba9-3e43-4fe4-a9e9-554b4075f85d,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-8349b044-34e1-4ff3-a4ba-4efa46b047b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-7be4413f-1a53-4504-9552-aac1dccf7d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-98d79f26-0ee9-4815-835a-b341cdd5c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c8bbd455-8ab0-4fc1-b9c8-b3d4524fd4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-974b4dff-93f9-408f-87e2-fb18be7c1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-a28bfc73-7355-444e-a40e-47e5aae93508,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-b8e448e7-bf4e-40c9-8621-5951ccce01f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757767995-172.17.0.12-1598568555529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-0e767ba9-3e43-4fe4-a9e9-554b4075f85d,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-8349b044-34e1-4ff3-a4ba-4efa46b047b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-7be4413f-1a53-4504-9552-aac1dccf7d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-98d79f26-0ee9-4815-835a-b341cdd5c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c8bbd455-8ab0-4fc1-b9c8-b3d4524fd4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-974b4dff-93f9-408f-87e2-fb18be7c1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-a28bfc73-7355-444e-a40e-47e5aae93508,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-b8e448e7-bf4e-40c9-8621-5951ccce01f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545719924-172.17.0.12-1598568593446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46287,DS-3640d836-d454-4a9c-9392-d5c42d9fa1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-920a3479-6dd5-4a67-aabf-3394f189e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-d8699169-2df1-42e3-9dec-d0489e28f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-376bace6-3a3c-4a92-bd22-2bfae865a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-c5bf1b8e-43d5-473c-85d5-93be15f1a780,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-97ee81cb-981c-4e4e-bf69-37cee025c336,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-43cff9bb-6761-4896-8380-0d283e755059,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-a6ad9af5-db2b-43eb-bb79-c263f6341680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545719924-172.17.0.12-1598568593446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46287,DS-3640d836-d454-4a9c-9392-d5c42d9fa1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-920a3479-6dd5-4a67-aabf-3394f189e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-d8699169-2df1-42e3-9dec-d0489e28f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-376bace6-3a3c-4a92-bd22-2bfae865a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-c5bf1b8e-43d5-473c-85d5-93be15f1a780,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-97ee81cb-981c-4e4e-bf69-37cee025c336,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-43cff9bb-6761-4896-8380-0d283e755059,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-a6ad9af5-db2b-43eb-bb79-c263f6341680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725478699-172.17.0.12-1598568981996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-0730db4b-9eea-401d-894a-1fef630b7643,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-ee13d0af-2ad7-417f-8eb7-1652be2d1254,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-1a687f56-7af6-4d16-a46d-a32513779d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-dc0f14e5-e9ae-492d-958d-e4688d9cb623,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-75f22f01-3ce5-40df-8110-470d31ff6743,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bd323c8b-6e56-45c5-93d6-6414dff10c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-acb58569-5e66-421d-a221-2328ec280973,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-91122e26-d33e-45d7-922b-02454a49b881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725478699-172.17.0.12-1598568981996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-0730db4b-9eea-401d-894a-1fef630b7643,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-ee13d0af-2ad7-417f-8eb7-1652be2d1254,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-1a687f56-7af6-4d16-a46d-a32513779d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-dc0f14e5-e9ae-492d-958d-e4688d9cb623,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-75f22f01-3ce5-40df-8110-470d31ff6743,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-bd323c8b-6e56-45c5-93d6-6414dff10c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-acb58569-5e66-421d-a221-2328ec280973,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-91122e26-d33e-45d7-922b-02454a49b881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138113408-172.17.0.12-1598569055317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-b527ce0a-1541-4f17-b549-5a5a3bf89ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-a00070ea-111f-479e-a72e-f33747fdfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-6df224f6-1255-4b8a-9bf3-27fe9a008af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-61ec3c1b-0fb6-44fd-9ccb-9e01d05c3841,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-02683dbd-28aa-4bd8-82e2-f56c6af166a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-6ba26edb-a8c2-4844-820b-8cbefb7a1116,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-da2db0a0-79b4-4bc2-a59f-bc7578084736,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f2725a57-3f74-4260-82b3-953645e4a2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138113408-172.17.0.12-1598569055317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-b527ce0a-1541-4f17-b549-5a5a3bf89ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-a00070ea-111f-479e-a72e-f33747fdfd38,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-6df224f6-1255-4b8a-9bf3-27fe9a008af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-61ec3c1b-0fb6-44fd-9ccb-9e01d05c3841,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-02683dbd-28aa-4bd8-82e2-f56c6af166a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-6ba26edb-a8c2-4844-820b-8cbefb7a1116,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-da2db0a0-79b4-4bc2-a59f-bc7578084736,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-f2725a57-3f74-4260-82b3-953645e4a2f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 50
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303784700-172.17.0.12-1598569255154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-7701f535-af99-401c-8187-38b64856ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-ff30ebea-634e-49bb-b6bd-fb2f44dd3953,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-d825074e-59c6-49f6-9b97-d05144443c74,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-4d2dbf0d-d849-42d3-a9e3-9c2cf68876de,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-884f767c-96bc-4faf-8e8b-6a2c158a93f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-ca09c481-e8eb-40e6-875e-875b4996447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-0e8a0acf-5556-48d6-adff-b4cbe3ec5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-6d5f3357-e606-4b4a-b1de-7e4f651c49a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303784700-172.17.0.12-1598569255154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-7701f535-af99-401c-8187-38b64856ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-ff30ebea-634e-49bb-b6bd-fb2f44dd3953,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-d825074e-59c6-49f6-9b97-d05144443c74,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-4d2dbf0d-d849-42d3-a9e3-9c2cf68876de,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-884f767c-96bc-4faf-8e8b-6a2c158a93f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-ca09c481-e8eb-40e6-875e-875b4996447b,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-0e8a0acf-5556-48d6-adff-b4cbe3ec5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-6d5f3357-e606-4b4a-b1de-7e4f651c49a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5054
