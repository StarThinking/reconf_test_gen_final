reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928589715-172.17.0.14-1598604440332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-a02746ff-40f8-49fe-9251-786f788b4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-215185e3-d806-4dfb-95ce-5dfc5f6ac4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-fbdbca2f-000f-427f-aa88-d98720b12df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-3cdabde9-2a2f-46a1-8db0-1a6d7334e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-288bf028-bd32-4903-927f-14ec69d0994c,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-02420b13-10f8-406f-9fdb-dfec1401ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-50239d0d-c0be-490d-80b0-e8f1d91481cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-eb661622-1d93-48bd-8a4b-d17a43be3e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928589715-172.17.0.14-1598604440332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-a02746ff-40f8-49fe-9251-786f788b4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-215185e3-d806-4dfb-95ce-5dfc5f6ac4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-fbdbca2f-000f-427f-aa88-d98720b12df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-3cdabde9-2a2f-46a1-8db0-1a6d7334e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-288bf028-bd32-4903-927f-14ec69d0994c,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-02420b13-10f8-406f-9fdb-dfec1401ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-50239d0d-c0be-490d-80b0-e8f1d91481cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-eb661622-1d93-48bd-8a4b-d17a43be3e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439426690-172.17.0.14-1598604592025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-4e13557a-76ce-4e0d-aad0-3c339f5f096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-86389742-3d12-48d3-847c-85ef9ffed564,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-24bcdbec-c2b7-40d7-b947-68a01e48fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3f86ec82-0f42-4c14-93d0-0b34dac9f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-d837c6eb-cb5c-4cb2-b7b4-59d576a1a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-547410b1-0d23-4daf-a81a-699907b26ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-8ac5d2bf-c5ed-43cb-ac4b-cdb618412ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-04f51411-234e-413b-9620-edda738bcef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439426690-172.17.0.14-1598604592025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-4e13557a-76ce-4e0d-aad0-3c339f5f096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-86389742-3d12-48d3-847c-85ef9ffed564,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-24bcdbec-c2b7-40d7-b947-68a01e48fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-3f86ec82-0f42-4c14-93d0-0b34dac9f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-d837c6eb-cb5c-4cb2-b7b4-59d576a1a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-547410b1-0d23-4daf-a81a-699907b26ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-8ac5d2bf-c5ed-43cb-ac4b-cdb618412ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-04f51411-234e-413b-9620-edda738bcef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512843694-172.17.0.14-1598605091594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-542c7735-db03-462b-a1ab-ca6c676323af,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-72b2d76a-4214-4fab-b8a4-a87397ae18ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-e040c80b-370e-4ce5-a91d-a29956003004,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-9fda406b-a8f6-421f-9346-4284d6f3847f,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-8cb01dae-4aee-4d46-9ba3-74f00fa041a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-2abd41e6-7bdc-44c8-9454-586ddb8c29e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-e83bd4d6-ef14-4dda-9aca-f7e9a2822bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-7eff8f0b-53c0-4196-8bfa-721fb0cf5e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512843694-172.17.0.14-1598605091594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-542c7735-db03-462b-a1ab-ca6c676323af,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-72b2d76a-4214-4fab-b8a4-a87397ae18ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-e040c80b-370e-4ce5-a91d-a29956003004,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-9fda406b-a8f6-421f-9346-4284d6f3847f,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-8cb01dae-4aee-4d46-9ba3-74f00fa041a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-2abd41e6-7bdc-44c8-9454-586ddb8c29e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-e83bd4d6-ef14-4dda-9aca-f7e9a2822bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-7eff8f0b-53c0-4196-8bfa-721fb0cf5e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478929147-172.17.0.14-1598605165411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-9d776e7e-54e7-4cdb-a2df-709a7cd282c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-f06d9d51-c08f-485b-a9ce-d30bed3ded56,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-084d5536-1a94-4a68-b52d-73a5d1637f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-8c2cde43-d624-4e13-b15b-982dc10ce646,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-980ec62c-565e-4493-a5ab-21367f4d3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-772362d9-0d72-4405-8885-1a949e3e4828,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-accc5b24-9c1e-476a-80d4-42663149105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-60e7c716-7fdd-496f-ba35-0e126248300a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478929147-172.17.0.14-1598605165411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-9d776e7e-54e7-4cdb-a2df-709a7cd282c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-f06d9d51-c08f-485b-a9ce-d30bed3ded56,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-084d5536-1a94-4a68-b52d-73a5d1637f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-8c2cde43-d624-4e13-b15b-982dc10ce646,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-980ec62c-565e-4493-a5ab-21367f4d3b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-772362d9-0d72-4405-8885-1a949e3e4828,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-accc5b24-9c1e-476a-80d4-42663149105e,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-60e7c716-7fdd-496f-ba35-0e126248300a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376317594-172.17.0.14-1598605325790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-7a9c96b5-1fe1-4258-8582-af39d9cb734f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-162e915d-5b74-4735-a507-abccaf851564,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-5de0000a-b6e8-4692-8159-74e74236d916,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-1c3a95d3-dd8e-43bd-ac21-f2eb6411b372,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-0135cd0a-d763-41e4-9519-0f4d17b6be78,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-a83d1862-1454-4541-b955-307f83b29c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-5c8cc8a7-e240-4cef-b971-3e0236a88cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-e0580dc4-148c-4909-8c24-400235b84c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376317594-172.17.0.14-1598605325790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-7a9c96b5-1fe1-4258-8582-af39d9cb734f,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-162e915d-5b74-4735-a507-abccaf851564,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-5de0000a-b6e8-4692-8159-74e74236d916,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-1c3a95d3-dd8e-43bd-ac21-f2eb6411b372,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-0135cd0a-d763-41e4-9519-0f4d17b6be78,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-a83d1862-1454-4541-b955-307f83b29c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-5c8cc8a7-e240-4cef-b971-3e0236a88cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-e0580dc4-148c-4909-8c24-400235b84c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675623320-172.17.0.14-1598605390021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-3d1f5140-1bf1-450e-adc4-1fbe73957460,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-48ecf302-66b7-40b3-9372-a8a38d8916db,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-18ae093f-36d9-47df-bf62-b38d9027f167,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-62c1dd04-23ae-4ed2-b147-b169530af36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-aa8732fb-4cd9-423a-915c-c0671cccd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c25628ad-c4cc-4440-84fc-e7ee7bb841db,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-d9ae2ecc-07aa-418a-8224-a791e273179e,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-a2796a20-c44f-44e0-ab1f-9ce7761111ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675623320-172.17.0.14-1598605390021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-3d1f5140-1bf1-450e-adc4-1fbe73957460,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-48ecf302-66b7-40b3-9372-a8a38d8916db,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-18ae093f-36d9-47df-bf62-b38d9027f167,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-62c1dd04-23ae-4ed2-b147-b169530af36e,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-aa8732fb-4cd9-423a-915c-c0671cccd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c25628ad-c4cc-4440-84fc-e7ee7bb841db,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-d9ae2ecc-07aa-418a-8224-a791e273179e,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-a2796a20-c44f-44e0-ab1f-9ce7761111ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947917041-172.17.0.14-1598605629746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-50645731-b241-484b-bb53-1fc276387b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ee984ca3-b26a-415d-a89d-240d3ad5ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-821fd749-fbe7-4b24-9b82-32019fb017aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-2aa3ce4b-291c-4aab-8169-eb4ddfd15756,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-add859e4-9c33-4440-a14c-5cd37acc1d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-98e81ace-3a51-4692-b6cb-ba539e71a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e682670b-c519-4373-8712-49418ff99704,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-482eabcd-2401-4e69-b3e0-817ec75a52c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1947917041-172.17.0.14-1598605629746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-50645731-b241-484b-bb53-1fc276387b31,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ee984ca3-b26a-415d-a89d-240d3ad5ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-821fd749-fbe7-4b24-9b82-32019fb017aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-2aa3ce4b-291c-4aab-8169-eb4ddfd15756,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-add859e4-9c33-4440-a14c-5cd37acc1d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-98e81ace-3a51-4692-b6cb-ba539e71a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e682670b-c519-4373-8712-49418ff99704,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-482eabcd-2401-4e69-b3e0-817ec75a52c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234209987-172.17.0.14-1598605887974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-84479cd1-274c-4098-8eac-c20627f1938d,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-398279ad-182e-43dd-81f3-716ffcf6c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-11974ffb-f54b-484f-9b54-0592e3d2d726,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-ffb71ee8-5512-4d25-a213-40d9393acf79,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-a2dcd5ac-01fe-4911-9243-4804c25da268,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-4c7e1979-c6bc-4612-b31a-3c45c196d183,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-461fa9f4-0b82-44c6-98cf-cae1d7c3954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-34d77a28-d07e-4edd-a235-6115c39ba8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234209987-172.17.0.14-1598605887974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-84479cd1-274c-4098-8eac-c20627f1938d,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-398279ad-182e-43dd-81f3-716ffcf6c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-11974ffb-f54b-484f-9b54-0592e3d2d726,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-ffb71ee8-5512-4d25-a213-40d9393acf79,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-a2dcd5ac-01fe-4911-9243-4804c25da268,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-4c7e1979-c6bc-4612-b31a-3c45c196d183,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-461fa9f4-0b82-44c6-98cf-cae1d7c3954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-34d77a28-d07e-4edd-a235-6115c39ba8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484046653-172.17.0.14-1598606381822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-6fb24677-0b5c-4c34-8b0d-de60bb02f117,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-88a16ddd-6d8c-43bb-b442-e18fbb6569f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-f191f995-8927-40a2-8c9f-98356d27d05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-681b78bf-63fa-469b-8939-019abfb3e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-6f38db17-5d0a-498b-b9da-9c4302e1c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-5c55e470-13d5-414d-ac36-a260ba740001,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-e79c30ef-48e9-468e-9710-1ddcfbc454a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-ca6458d6-09ac-4a3a-b013-9f4de4c3766b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484046653-172.17.0.14-1598606381822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-6fb24677-0b5c-4c34-8b0d-de60bb02f117,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-88a16ddd-6d8c-43bb-b442-e18fbb6569f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-f191f995-8927-40a2-8c9f-98356d27d05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-681b78bf-63fa-469b-8939-019abfb3e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-6f38db17-5d0a-498b-b9da-9c4302e1c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-5c55e470-13d5-414d-ac36-a260ba740001,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-e79c30ef-48e9-468e-9710-1ddcfbc454a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-ca6458d6-09ac-4a3a-b013-9f4de4c3766b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42306333-172.17.0.14-1598606450969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-a80b1402-5e9c-47fe-a288-a83a63379797,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-a4227fb5-2b6e-4f57-9601-46709febecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-25e7748c-73ae-4bb0-a1bb-f345828904b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-52b4a2f9-4569-4876-9e32-65dfdba97f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-8af573f0-8f2f-435b-b62a-13e26774d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-d066fef3-5854-463f-82cf-0a86fe566b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-3f01256d-fab3-4fad-abdf-d2741b345808,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5bf552d6-9f4d-4145-9321-b3395a0f35c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42306333-172.17.0.14-1598606450969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-a80b1402-5e9c-47fe-a288-a83a63379797,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-a4227fb5-2b6e-4f57-9601-46709febecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-25e7748c-73ae-4bb0-a1bb-f345828904b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-52b4a2f9-4569-4876-9e32-65dfdba97f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-8af573f0-8f2f-435b-b62a-13e26774d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-d066fef3-5854-463f-82cf-0a86fe566b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-3f01256d-fab3-4fad-abdf-d2741b345808,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5bf552d6-9f4d-4145-9321-b3395a0f35c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602587183-172.17.0.14-1598606643539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-bd7c9f4f-0f3e-43e6-a548-9253302177ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-a0751423-ac47-485e-9fa2-d677d2ae5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c4bbe767-7d87-43a9-96f9-96d01828534d,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-375c43ed-be63-4a39-a6c3-05de7363fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-47a18843-1b5a-4733-8daf-a7941610f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-2e3b7248-0160-419b-b2f9-8486385ef996,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-73c4bfd1-425a-4b49-8cea-eb73335654fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-d63f4013-44ea-4126-9d37-b8818cadb49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602587183-172.17.0.14-1598606643539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-bd7c9f4f-0f3e-43e6-a548-9253302177ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-a0751423-ac47-485e-9fa2-d677d2ae5e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c4bbe767-7d87-43a9-96f9-96d01828534d,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-375c43ed-be63-4a39-a6c3-05de7363fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-47a18843-1b5a-4733-8daf-a7941610f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-2e3b7248-0160-419b-b2f9-8486385ef996,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-73c4bfd1-425a-4b49-8cea-eb73335654fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-d63f4013-44ea-4126-9d37-b8818cadb49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306608937-172.17.0.14-1598606756800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34959,DS-93bd862a-9621-459e-b972-c718f7e52cae,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-0d8fa690-d3b4-4dbe-95d8-3aa03f2ac33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-c9524e01-0613-4449-9c14-16847de264db,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-e8958c7b-2afc-4216-a0b9-f3daedc40ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-82896705-b14a-4060-8533-379ed55c0778,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-af10c40c-92b9-4c89-b37e-addce531038e,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fd4b5605-4854-4a2a-a77f-06034cf21373,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-8adca2a8-e19d-44da-b550-c052408b9542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306608937-172.17.0.14-1598606756800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34959,DS-93bd862a-9621-459e-b972-c718f7e52cae,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-0d8fa690-d3b4-4dbe-95d8-3aa03f2ac33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-c9524e01-0613-4449-9c14-16847de264db,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-e8958c7b-2afc-4216-a0b9-f3daedc40ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-82896705-b14a-4060-8533-379ed55c0778,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-af10c40c-92b9-4c89-b37e-addce531038e,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fd4b5605-4854-4a2a-a77f-06034cf21373,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-8adca2a8-e19d-44da-b550-c052408b9542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424467915-172.17.0.14-1598607292967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-4a709960-603f-4d73-a234-2e7b393343d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-2b451595-6416-4cb7-91bb-8ae8aae11bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-c623747f-b3ed-4011-9aed-e4e0a6edd2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-4d5ed2db-ed4f-4b3e-9b69-fa1a37ca2c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-f083db20-bd7e-443c-8568-cc2f15c7c486,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-c4da2b4f-bc1b-4213-abac-6a4d8b249f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-ebd7951c-7a2e-440e-8238-882d04643bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-0364c834-026a-4886-864a-0dc4fe59cac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424467915-172.17.0.14-1598607292967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-4a709960-603f-4d73-a234-2e7b393343d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-2b451595-6416-4cb7-91bb-8ae8aae11bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-c623747f-b3ed-4011-9aed-e4e0a6edd2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-4d5ed2db-ed4f-4b3e-9b69-fa1a37ca2c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-f083db20-bd7e-443c-8568-cc2f15c7c486,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-c4da2b4f-bc1b-4213-abac-6a4d8b249f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-ebd7951c-7a2e-440e-8238-882d04643bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-0364c834-026a-4886-864a-0dc4fe59cac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142224625-172.17.0.14-1598607326617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-3659fb5b-63b6-4332-83d8-9cbbf6f3e8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-80375224-d655-4899-bda6-6597fb0f61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-a695c826-082a-449d-ab4f-5df5f8b365a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-529befc6-77fe-4c04-b371-432f2228b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-37b5faef-a37c-478c-9335-1d9f10048cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-03dfbb6d-4fc4-476b-b932-b5aa3aeacb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f1fa31a7-4c7f-4ea0-aea0-1a6fe8286dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-2a62568c-b153-4be8-806d-e232aea12c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142224625-172.17.0.14-1598607326617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-3659fb5b-63b6-4332-83d8-9cbbf6f3e8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-80375224-d655-4899-bda6-6597fb0f61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-a695c826-082a-449d-ab4f-5df5f8b365a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-529befc6-77fe-4c04-b371-432f2228b1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-37b5faef-a37c-478c-9335-1d9f10048cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-03dfbb6d-4fc4-476b-b932-b5aa3aeacb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f1fa31a7-4c7f-4ea0-aea0-1a6fe8286dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-2a62568c-b153-4be8-806d-e232aea12c45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139437361-172.17.0.14-1598607862389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-1497ac43-84c6-4daf-bde2-da02babad810,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-8c7e4334-5a0a-43bc-a528-d77b3ce006ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-5a803464-e70f-4eba-9ef2-62f46d8f337f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-9f7ff922-ee49-49eb-8c7f-9466a07d2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a3908ed6-9963-4e20-9ac7-b05100ad7ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-81c98979-3ae1-483a-9253-590ac813c491,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-ee3e2db3-46c1-4760-a7f9-90d1e2a53ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-a9f89982-3f99-455e-bbe3-2b8cfa68626d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139437361-172.17.0.14-1598607862389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-1497ac43-84c6-4daf-bde2-da02babad810,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-8c7e4334-5a0a-43bc-a528-d77b3ce006ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-5a803464-e70f-4eba-9ef2-62f46d8f337f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-9f7ff922-ee49-49eb-8c7f-9466a07d2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a3908ed6-9963-4e20-9ac7-b05100ad7ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-81c98979-3ae1-483a-9253-590ac813c491,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-ee3e2db3-46c1-4760-a7f9-90d1e2a53ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-a9f89982-3f99-455e-bbe3-2b8cfa68626d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114038994-172.17.0.14-1598608085100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-8f40e2ff-599d-4793-97a6-735d660359ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b4852b94-7fbf-4f45-bd37-a8ae1b70bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-246d06ba-499d-49fa-b367-d082f34b8db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-9a164513-7e36-4533-9d0a-f6d41168cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-a80a8f92-6d77-4deb-bdcb-566028ebbe80,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-4031fddd-85a1-41d3-adab-096f61b111a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-8923dfc4-4605-4833-9d32-e72c5080ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-12c8dc6b-8b3e-465b-b80a-f7e0f8d96111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114038994-172.17.0.14-1598608085100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35680,DS-8f40e2ff-599d-4793-97a6-735d660359ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b4852b94-7fbf-4f45-bd37-a8ae1b70bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-246d06ba-499d-49fa-b367-d082f34b8db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-9a164513-7e36-4533-9d0a-f6d41168cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-a80a8f92-6d77-4deb-bdcb-566028ebbe80,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-4031fddd-85a1-41d3-adab-096f61b111a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-8923dfc4-4605-4833-9d32-e72c5080ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-12c8dc6b-8b3e-465b-b80a-f7e0f8d96111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829647458-172.17.0.14-1598608317861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-2d46c52e-e778-47e7-96f2-045d176e0d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d1bcec8b-82e0-4029-945d-53e493b544d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-38133420-5cf8-4af3-9ebc-f702c7668b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-798b0381-e1eb-46b8-b945-76c141b4cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b6db0224-d114-41d1-aa4f-d51fdbb54feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-b25942e9-7f04-4969-ba7e-e2216c9413aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-59292ccc-dc0d-48b7-bc08-91dafb10d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-8fe6e6ce-c42e-4977-b168-29af3f32d3f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829647458-172.17.0.14-1598608317861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-2d46c52e-e778-47e7-96f2-045d176e0d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-d1bcec8b-82e0-4029-945d-53e493b544d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-38133420-5cf8-4af3-9ebc-f702c7668b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-798b0381-e1eb-46b8-b945-76c141b4cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-b6db0224-d114-41d1-aa4f-d51fdbb54feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-b25942e9-7f04-4969-ba7e-e2216c9413aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-59292ccc-dc0d-48b7-bc08-91dafb10d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-8fe6e6ce-c42e-4977-b168-29af3f32d3f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094300330-172.17.0.14-1598608458890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-bd19b40b-951b-4db9-9020-8afef4a98abd,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-5fcc0924-8202-4f92-9e4d-858bdeb08a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-ad8d269b-c187-419f-bdc8-e0da79605011,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-df281bf1-5df1-4b2d-9e45-97f6e9406eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d3d68b08-c251-4ca2-8705-0262a31c7953,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-534ae3a9-d858-4006-86a4-6fbee0f36ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-c46a3994-ed24-49af-8f57-18947c7d47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-b709823c-eda4-474e-9544-ad819710160c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094300330-172.17.0.14-1598608458890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-bd19b40b-951b-4db9-9020-8afef4a98abd,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-5fcc0924-8202-4f92-9e4d-858bdeb08a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-ad8d269b-c187-419f-bdc8-e0da79605011,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-df281bf1-5df1-4b2d-9e45-97f6e9406eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d3d68b08-c251-4ca2-8705-0262a31c7953,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-534ae3a9-d858-4006-86a4-6fbee0f36ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-c46a3994-ed24-49af-8f57-18947c7d47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-b709823c-eda4-474e-9544-ad819710160c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878561342-172.17.0.14-1598608530567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-2dd33763-b84c-4a3c-819a-5d4265e65e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b211fb50-53e1-40ed-9173-f6a2b4f1d574,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-f5880734-a5a4-43ea-9324-d697016bb9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-f49c9413-1ab5-4a98-bf51-3f932049ed79,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-8781f307-c2df-4cef-a421-f3d33d08df55,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-58ec8ecf-b661-47f7-948d-8709b14a470a,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-e46d77c1-f2d0-4581-8c7f-bc0fde07726b,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-6e1e4bc9-d687-44d4-afc0-2397d4540fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878561342-172.17.0.14-1598608530567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-2dd33763-b84c-4a3c-819a-5d4265e65e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-b211fb50-53e1-40ed-9173-f6a2b4f1d574,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-f5880734-a5a4-43ea-9324-d697016bb9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-f49c9413-1ab5-4a98-bf51-3f932049ed79,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-8781f307-c2df-4cef-a421-f3d33d08df55,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-58ec8ecf-b661-47f7-948d-8709b14a470a,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-e46d77c1-f2d0-4581-8c7f-bc0fde07726b,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-6e1e4bc9-d687-44d4-afc0-2397d4540fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395053168-172.17.0.14-1598608627362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43766,DS-11b4cc7d-682f-4e42-8f5e-b6a30e23b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-06f31c16-2e68-4ef3-96bf-92366c08ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-eea1ed2f-293f-4873-b91a-8c8c8a01611f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-6e74e95f-b444-462a-b836-dc7bc4a47e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-a2fdfd9d-0933-4041-b73c-ca0682773f58,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-c720ad75-ec9f-426e-b381-3af265aec94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-2e61cc13-7363-4ccd-bc06-e9832151a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-ea44fd00-b4a6-42dd-b601-1ee6dc239827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395053168-172.17.0.14-1598608627362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43766,DS-11b4cc7d-682f-4e42-8f5e-b6a30e23b8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-06f31c16-2e68-4ef3-96bf-92366c08ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-eea1ed2f-293f-4873-b91a-8c8c8a01611f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-6e74e95f-b444-462a-b836-dc7bc4a47e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-a2fdfd9d-0933-4041-b73c-ca0682773f58,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-c720ad75-ec9f-426e-b381-3af265aec94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-2e61cc13-7363-4ccd-bc06-e9832151a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-ea44fd00-b4a6-42dd-b601-1ee6dc239827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353189918-172.17.0.14-1598608988144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-217ec2a5-2abe-44bc-80dc-e9fb52fe3782,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-fe8b2a8a-b70d-49b5-b564-6485aa825caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1f1c835d-222e-410c-a5bf-792e067e4539,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9d16a9b0-1bdc-44c8-8606-a73ed0d53cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-8ea99a02-e65f-48b5-b3d4-82e086d3d3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-4d0d135c-37e0-4848-9f92-db4a29b8da17,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-6810d83f-f5b5-4c1b-a20c-3b9ead0885ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c017d200-ae55-4dad-abbf-2e1fc09796ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-353189918-172.17.0.14-1598608988144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-217ec2a5-2abe-44bc-80dc-e9fb52fe3782,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-fe8b2a8a-b70d-49b5-b564-6485aa825caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1f1c835d-222e-410c-a5bf-792e067e4539,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-9d16a9b0-1bdc-44c8-8606-a73ed0d53cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-8ea99a02-e65f-48b5-b3d4-82e086d3d3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-4d0d135c-37e0-4848-9f92-db4a29b8da17,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-6810d83f-f5b5-4c1b-a20c-3b9ead0885ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c017d200-ae55-4dad-abbf-2e1fc09796ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736716976-172.17.0.14-1598609132563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-3ae876f2-835c-44e5-a4b6-7db11ceee9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2128bb8f-ebc5-4879-a58c-4761873a544a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-fa587e1a-ec28-41cf-8702-e59491932464,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-6604c00d-6a44-43c9-ab13-412bf470950c,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-65a04852-3f59-436d-8652-d5b251f62231,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-07c4da19-1efc-4f1b-bd64-3f2fab83740c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-f90c4461-010a-4a28-9249-a0515cacb69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-72c42095-2122-4ec3-8d6a-b8f45b4733e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736716976-172.17.0.14-1598609132563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-3ae876f2-835c-44e5-a4b6-7db11ceee9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-2128bb8f-ebc5-4879-a58c-4761873a544a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-fa587e1a-ec28-41cf-8702-e59491932464,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-6604c00d-6a44-43c9-ab13-412bf470950c,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-65a04852-3f59-436d-8652-d5b251f62231,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-07c4da19-1efc-4f1b-bd64-3f2fab83740c,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-f90c4461-010a-4a28-9249-a0515cacb69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-72c42095-2122-4ec3-8d6a-b8f45b4733e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643789565-172.17.0.14-1598609380609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44635,DS-a0e74895-1893-450a-a7f9-c6e9de964984,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-6e59e3a6-1ba2-4b07-87d6-5828b9b2b364,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-291d5644-7e1e-4481-a7ba-ac997e4bdbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-69aac642-4ec4-4bd6-90b1-03725097b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-c8c9dd17-a4df-4cee-a399-bf791633de85,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3bffb901-867a-475f-8f43-30a885bcabbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-dee38fca-1bfe-4851-a2f9-dcb365473bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8b98a719-52a4-450e-98a7-afc0804788aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643789565-172.17.0.14-1598609380609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44635,DS-a0e74895-1893-450a-a7f9-c6e9de964984,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-6e59e3a6-1ba2-4b07-87d6-5828b9b2b364,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-291d5644-7e1e-4481-a7ba-ac997e4bdbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-69aac642-4ec4-4bd6-90b1-03725097b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-c8c9dd17-a4df-4cee-a399-bf791633de85,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3bffb901-867a-475f-8f43-30a885bcabbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-dee38fca-1bfe-4851-a2f9-dcb365473bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8b98a719-52a4-450e-98a7-afc0804788aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5305
