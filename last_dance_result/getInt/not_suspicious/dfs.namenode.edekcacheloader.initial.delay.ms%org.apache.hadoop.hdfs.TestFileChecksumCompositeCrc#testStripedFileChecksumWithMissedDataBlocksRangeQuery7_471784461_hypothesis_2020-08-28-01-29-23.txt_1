reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722300652-172.17.0.16-1598578205919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-57efd8c6-0a4a-483c-8f63-2ca50a1e3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8e3fc00a-78ff-4314-86d5-4b2c57d1ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-6a9e5f3b-4a7e-495d-aa8a-4cbddc7b22d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-0bf2becd-7e0c-42d9-8eee-8170343b631c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-7ac8bbba-c269-4df8-968c-13ade7267cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-ac7c1cdb-82b2-4f69-a251-ad1979127258,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-00aa5df2-d716-4f59-a7f4-f18f4e6fa9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-12920ec2-5107-431e-aee6-8341063d62b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722300652-172.17.0.16-1598578205919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-57efd8c6-0a4a-483c-8f63-2ca50a1e3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-8e3fc00a-78ff-4314-86d5-4b2c57d1ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-6a9e5f3b-4a7e-495d-aa8a-4cbddc7b22d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-0bf2becd-7e0c-42d9-8eee-8170343b631c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-7ac8bbba-c269-4df8-968c-13ade7267cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-ac7c1cdb-82b2-4f69-a251-ad1979127258,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-00aa5df2-d716-4f59-a7f4-f18f4e6fa9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-12920ec2-5107-431e-aee6-8341063d62b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76370578-172.17.0.16-1598578234953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-3e8949b3-6cf7-43ea-a36b-9cf888d33800,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-65b5337f-cc14-4e53-9b28-e13578947f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-2da124f5-06c0-4e33-9324-faaff184ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-6d1b95f2-4afb-4907-84da-4a003f5556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-05a88043-1ef5-4cae-81cc-e72ae0561c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-47ee27c7-0f6c-4066-96f0-a6df14ae20ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e0a0ccac-fac1-47ea-8774-54a811c727cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b6df77af-5f77-409a-977b-ef26cb9da46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76370578-172.17.0.16-1598578234953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-3e8949b3-6cf7-43ea-a36b-9cf888d33800,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-65b5337f-cc14-4e53-9b28-e13578947f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-2da124f5-06c0-4e33-9324-faaff184ca3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-6d1b95f2-4afb-4907-84da-4a003f5556b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-05a88043-1ef5-4cae-81cc-e72ae0561c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-47ee27c7-0f6c-4066-96f0-a6df14ae20ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e0a0ccac-fac1-47ea-8774-54a811c727cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-b6df77af-5f77-409a-977b-ef26cb9da46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650456871-172.17.0.16-1598578338479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-009216c9-3514-4738-a366-3e6c78b0dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c193447f-924a-4be3-93f0-f20e4f66f472,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-2e1beb88-5762-4ad0-839c-5ee3de818e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-02fda629-936a-412d-a623-6a384175153d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-27de6edb-50f3-4ce9-b9b6-20379136e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-ef9d954b-d084-4b5c-aad9-b9ba61a7a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-e9714d17-2a58-4e1e-85f8-5364db939704,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-ce667e51-347a-4aa0-a1f3-7f1c401b04d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650456871-172.17.0.16-1598578338479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-009216c9-3514-4738-a366-3e6c78b0dccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c193447f-924a-4be3-93f0-f20e4f66f472,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-2e1beb88-5762-4ad0-839c-5ee3de818e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-02fda629-936a-412d-a623-6a384175153d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-27de6edb-50f3-4ce9-b9b6-20379136e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-ef9d954b-d084-4b5c-aad9-b9ba61a7a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-e9714d17-2a58-4e1e-85f8-5364db939704,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-ce667e51-347a-4aa0-a1f3-7f1c401b04d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102300314-172.17.0.16-1598578411917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-68a67e30-fb4e-4b07-9d8e-7071278a8ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0007929a-6ae9-4e4c-adba-95daa0e557f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-df989b40-2fc9-4545-a175-714c01a9beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a1dd64c9-bc17-468d-af69-829add4b55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-add17524-cd4b-451c-8838-134dff29e964,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-17feb96a-d770-4e46-a8e2-f5efe3f38641,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-cd4e8e2d-1738-4f75-a0d2-c770ed7d4370,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e25947fd-9051-493c-91f9-fe20bc9a4cb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102300314-172.17.0.16-1598578411917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-68a67e30-fb4e-4b07-9d8e-7071278a8ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0007929a-6ae9-4e4c-adba-95daa0e557f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-df989b40-2fc9-4545-a175-714c01a9beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a1dd64c9-bc17-468d-af69-829add4b55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-add17524-cd4b-451c-8838-134dff29e964,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-17feb96a-d770-4e46-a8e2-f5efe3f38641,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-cd4e8e2d-1738-4f75-a0d2-c770ed7d4370,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e25947fd-9051-493c-91f9-fe20bc9a4cb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968045414-172.17.0.16-1598578564478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-a9164f9a-3115-45d0-b8b0-b5780b297cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d9590dee-6736-4af0-bfa9-b0848ae05fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-91e401f7-0143-449e-923c-49d6e202b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-b7171394-26ca-4114-a1b9-eefcbb7c3a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-77645e72-f7f4-487c-90c9-ad136ad2806b,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-0d737456-1b8b-4a2d-8bd1-768cf137c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-fa8ffb95-eb03-4efd-b0b0-2101c1f1fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-30049da3-370c-4be5-a947-7971b8ad2dce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968045414-172.17.0.16-1598578564478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-a9164f9a-3115-45d0-b8b0-b5780b297cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d9590dee-6736-4af0-bfa9-b0848ae05fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-91e401f7-0143-449e-923c-49d6e202b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-b7171394-26ca-4114-a1b9-eefcbb7c3a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-77645e72-f7f4-487c-90c9-ad136ad2806b,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-0d737456-1b8b-4a2d-8bd1-768cf137c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-fa8ffb95-eb03-4efd-b0b0-2101c1f1fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-30049da3-370c-4be5-a947-7971b8ad2dce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994632428-172.17.0.16-1598578770262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-83ba1977-3d92-48da-903a-c8567f090dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-baa0261a-aa8a-4996-9173-00bdce8e89be,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-27e99060-7434-4b00-8f14-377626502e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-641d4113-c097-4a55-a8df-d5bcbe08ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-bda1d04c-e112-430f-94f3-5971f234d283,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-604ba2a4-d498-4a6b-a239-9d7ef0f04370,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-c37e9fe6-2a0d-46f5-9865-06d24ee9133b,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-71618a4e-20ce-4cd3-9d87-44b0d8664513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994632428-172.17.0.16-1598578770262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-83ba1977-3d92-48da-903a-c8567f090dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-baa0261a-aa8a-4996-9173-00bdce8e89be,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-27e99060-7434-4b00-8f14-377626502e25,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-641d4113-c097-4a55-a8df-d5bcbe08ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-bda1d04c-e112-430f-94f3-5971f234d283,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-604ba2a4-d498-4a6b-a239-9d7ef0f04370,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-c37e9fe6-2a0d-46f5-9865-06d24ee9133b,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-71618a4e-20ce-4cd3-9d87-44b0d8664513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564779739-172.17.0.16-1598578803059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-e8fad0b6-5f46-4066-8818-c2730fa1197d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-17df4796-f5a1-40ff-946d-183e113b7574,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-1cf3447e-4f36-4a79-a6b0-ac3322c383cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-0ee366df-2550-401b-9cdc-9f29ba7709f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-6092a23c-df8e-48af-a9e6-a048c6d22690,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cf4ddf57-0748-4229-a29f-4ab829a8a426,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-ccb56107-58da-4a26-a1bc-b25744764ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-aafba5ba-1b7a-400f-bfbe-6f7421854a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564779739-172.17.0.16-1598578803059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43466,DS-e8fad0b6-5f46-4066-8818-c2730fa1197d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-17df4796-f5a1-40ff-946d-183e113b7574,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-1cf3447e-4f36-4a79-a6b0-ac3322c383cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-0ee366df-2550-401b-9cdc-9f29ba7709f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-6092a23c-df8e-48af-a9e6-a048c6d22690,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-cf4ddf57-0748-4229-a29f-4ab829a8a426,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-ccb56107-58da-4a26-a1bc-b25744764ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-aafba5ba-1b7a-400f-bfbe-6f7421854a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474484235-172.17.0.16-1598578990515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-40799a6a-57b4-4bd6-ba05-8819a88957a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-adba0bae-ce15-48b0-8e00-4bacbd0069f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-9200d55a-550c-4fa7-a4c0-8a3542259a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-99b38d98-c4a3-4d98-97cc-e6b9512a65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-9b76bfa1-68fd-4bbc-b497-ce60157d6631,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ae53bdda-56c0-45d2-9ee5-d7ad1abd520d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-ef8ca7b0-543a-49b4-b1d0-7fc6a26be714,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c9ea2a4c-27e9-4972-b3ee-f62190743375,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474484235-172.17.0.16-1598578990515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-40799a6a-57b4-4bd6-ba05-8819a88957a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-adba0bae-ce15-48b0-8e00-4bacbd0069f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-9200d55a-550c-4fa7-a4c0-8a3542259a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-99b38d98-c4a3-4d98-97cc-e6b9512a65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-9b76bfa1-68fd-4bbc-b497-ce60157d6631,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-ae53bdda-56c0-45d2-9ee5-d7ad1abd520d,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-ef8ca7b0-543a-49b4-b1d0-7fc6a26be714,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-c9ea2a4c-27e9-4972-b3ee-f62190743375,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969721710-172.17.0.16-1598579281564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-b21b6c50-3d9b-4c49-a19b-206d30bf6367,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-daf2412e-ad4f-4332-96b8-d464524428d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-30acb006-729d-4607-9e17-1ebb5a5f10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-60d6a935-1ee0-4837-a6a6-b9bc55972d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b2306e50-b49a-4546-8988-9913b2262c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-81c650c1-6401-4cba-9a49-f08f1e25919f,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0c67de39-31e7-4957-9960-52f3faf2e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-ff30142d-b059-4db4-baab-4b8506e7cea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969721710-172.17.0.16-1598579281564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-b21b6c50-3d9b-4c49-a19b-206d30bf6367,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-daf2412e-ad4f-4332-96b8-d464524428d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-30acb006-729d-4607-9e17-1ebb5a5f10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-60d6a935-1ee0-4837-a6a6-b9bc55972d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-b2306e50-b49a-4546-8988-9913b2262c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-81c650c1-6401-4cba-9a49-f08f1e25919f,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0c67de39-31e7-4957-9960-52f3faf2e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-ff30142d-b059-4db4-baab-4b8506e7cea3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350871177-172.17.0.16-1598579447121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-fe97b9b4-f279-4cb0-a7b5-f6514dc2f569,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-cc7346c0-1bcf-48c0-befb-efcbd20a1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-68b0b8aa-9329-49a9-8134-872a030b44ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-bcd83620-ca2d-4e66-9754-f8dd657129eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-73353326-e5e6-4411-84d9-3f7f1b87db19,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-fcf3ddd9-0167-41f7-88c5-b00cf14d5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-b44c86ad-3939-4eb2-adb3-37c69660a628,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-3bc05094-145b-4680-bbad-f94287f7fedb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350871177-172.17.0.16-1598579447121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-fe97b9b4-f279-4cb0-a7b5-f6514dc2f569,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-cc7346c0-1bcf-48c0-befb-efcbd20a1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-68b0b8aa-9329-49a9-8134-872a030b44ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-bcd83620-ca2d-4e66-9754-f8dd657129eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-73353326-e5e6-4411-84d9-3f7f1b87db19,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-fcf3ddd9-0167-41f7-88c5-b00cf14d5bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-b44c86ad-3939-4eb2-adb3-37c69660a628,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-3bc05094-145b-4680-bbad-f94287f7fedb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575940238-172.17.0.16-1598579607457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-1dd77280-d67a-43ae-880b-5aba0f545d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-5f635b30-f4e1-47e3-9b83-d089ac61e357,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-15c1a267-f17c-482e-911e-ccabd11d7053,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-ee589af6-0ac9-4b2b-bdb2-1d2e6441a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-2ea83ad3-c23e-4820-be5d-2ee127b1bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-d6323541-b85c-47fe-bda1-d2bef068cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-b5b3cd17-390e-499a-a136-f5aa03d64012,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-fcc221af-26ee-41ad-bc46-6fe722d07567,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1575940238-172.17.0.16-1598579607457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32826,DS-1dd77280-d67a-43ae-880b-5aba0f545d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-5f635b30-f4e1-47e3-9b83-d089ac61e357,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-15c1a267-f17c-482e-911e-ccabd11d7053,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-ee589af6-0ac9-4b2b-bdb2-1d2e6441a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-2ea83ad3-c23e-4820-be5d-2ee127b1bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-d6323541-b85c-47fe-bda1-d2bef068cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-b5b3cd17-390e-499a-a136-f5aa03d64012,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-fcc221af-26ee-41ad-bc46-6fe722d07567,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810396224-172.17.0.16-1598579780621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-7db36cbc-77b9-4793-9504-ed622be58674,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-96a928c5-9d8b-4f19-8280-ac129bac1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-d120949d-a7cd-48cb-a13f-fd2713df4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-5d872619-64ae-4557-934c-219234b90ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-6d84d84f-7ba1-4e30-a586-5c1ae83db9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-c5a90d0c-155d-40eb-87b8-769078bf88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4e40e163-49aa-4801-89b4-869ddb737308,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-43e6a128-293f-4504-94b2-6cd696673605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810396224-172.17.0.16-1598579780621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-7db36cbc-77b9-4793-9504-ed622be58674,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-96a928c5-9d8b-4f19-8280-ac129bac1f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-d120949d-a7cd-48cb-a13f-fd2713df4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-5d872619-64ae-4557-934c-219234b90ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-6d84d84f-7ba1-4e30-a586-5c1ae83db9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-c5a90d0c-155d-40eb-87b8-769078bf88a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4e40e163-49aa-4801-89b4-869ddb737308,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-43e6a128-293f-4504-94b2-6cd696673605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309751646-172.17.0.16-1598579809781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-ddc71200-9cf8-4136-8211-3cbbe8fcec29,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-10d662de-38cb-4c3c-a97a-cd2463447e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-2e884357-c7d0-496b-b14c-53f3ea69ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-5952b3af-8ecb-4b3c-a89c-4ff3a8c66933,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-9584fce4-c762-4a29-8e5f-22c5f6e5c975,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-acb28d39-5418-480f-86a3-29d690e0fee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-408f9cae-443d-443b-9957-d64428900266,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-1e8b2be3-0cf5-4778-8be5-f74b7ff5604c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309751646-172.17.0.16-1598579809781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-ddc71200-9cf8-4136-8211-3cbbe8fcec29,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-10d662de-38cb-4c3c-a97a-cd2463447e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-2e884357-c7d0-496b-b14c-53f3ea69ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-5952b3af-8ecb-4b3c-a89c-4ff3a8c66933,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-9584fce4-c762-4a29-8e5f-22c5f6e5c975,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-acb28d39-5418-480f-86a3-29d690e0fee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-408f9cae-443d-443b-9957-d64428900266,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-1e8b2be3-0cf5-4778-8be5-f74b7ff5604c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208377495-172.17.0.16-1598579863306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43673,DS-f30d39e0-c37f-49ca-bda7-5fd1b1ac2ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-1dab526b-8349-423d-ab51-e400354bfe54,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-dd93eedb-f748-48b8-80ab-12dfe3a0b211,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-fb5a9579-a3c5-48d5-9198-90946f5c39f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-a2513291-3304-4180-a12b-a9d55f49a84f,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-d7a41d69-9a8d-450e-9b5f-f1e109c20b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-3b957ad7-5c48-447d-a9a4-1c4ba4fda18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-8b4a662f-48df-424b-b707-a83befe4c1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208377495-172.17.0.16-1598579863306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43673,DS-f30d39e0-c37f-49ca-bda7-5fd1b1ac2ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-1dab526b-8349-423d-ab51-e400354bfe54,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-dd93eedb-f748-48b8-80ab-12dfe3a0b211,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-fb5a9579-a3c5-48d5-9198-90946f5c39f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-a2513291-3304-4180-a12b-a9d55f49a84f,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-d7a41d69-9a8d-450e-9b5f-f1e109c20b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-3b957ad7-5c48-447d-a9a4-1c4ba4fda18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-8b4a662f-48df-424b-b707-a83befe4c1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336067808-172.17.0.16-1598579898722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-b1abdb4a-ed73-4560-b3d4-b641b5da5734,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-a2358d5d-ed3f-4684-842b-ff012bda2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-923350d7-21bb-4a87-b92d-ecac0329c941,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-2ceddb69-19a5-468e-81bf-e6d6c9467f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-091cbe43-de84-4d42-8c4c-344a6485ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-503d495c-5c42-45f3-998b-5a57e4f0f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-514cb3bf-755f-4aff-bf17-934eb0c672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-f0ddedcb-3230-4808-9537-308c7a3311ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336067808-172.17.0.16-1598579898722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-b1abdb4a-ed73-4560-b3d4-b641b5da5734,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-a2358d5d-ed3f-4684-842b-ff012bda2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-923350d7-21bb-4a87-b92d-ecac0329c941,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-2ceddb69-19a5-468e-81bf-e6d6c9467f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-091cbe43-de84-4d42-8c4c-344a6485ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-503d495c-5c42-45f3-998b-5a57e4f0f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-514cb3bf-755f-4aff-bf17-934eb0c672e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-f0ddedcb-3230-4808-9537-308c7a3311ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378568835-172.17.0.16-1598579959152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-ccb22320-b898-4ae2-9db0-62fd63050821,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-ebd79452-ee6d-4c77-9e7c-2039ca9cb639,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-0e04c701-6c84-48e9-bb7c-0b48e6aee4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-0b642722-6c32-45a5-9a36-4c82643d7864,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-5273eaea-f7ad-4bc3-8b26-72db3ce197f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-c601b735-886e-46e0-aeaa-e4c2630a7593,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-ef85ea85-0785-493b-87dc-a203a1032df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-717a44de-769e-4913-aa96-ace03f385a88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378568835-172.17.0.16-1598579959152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-ccb22320-b898-4ae2-9db0-62fd63050821,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-ebd79452-ee6d-4c77-9e7c-2039ca9cb639,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-0e04c701-6c84-48e9-bb7c-0b48e6aee4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-0b642722-6c32-45a5-9a36-4c82643d7864,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-5273eaea-f7ad-4bc3-8b26-72db3ce197f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-c601b735-886e-46e0-aeaa-e4c2630a7593,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-ef85ea85-0785-493b-87dc-a203a1032df4,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-717a44de-769e-4913-aa96-ace03f385a88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059153615-172.17.0.16-1598580321908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-f9df841a-aeb4-41fb-99a6-b11ad99d9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-91e7a7fc-0178-49fb-91d6-be1d2de2513d,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-680950ff-7a4f-40e3-9002-5dfa0a186efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-03767018-eb32-48b3-ba44-051a5f62132d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-3177df3b-b8ee-4751-a4e3-c1ad853aa210,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-82a82c16-d590-4eb2-b45c-2ba768db918e,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-7d5aa9f3-9e26-49e2-82d8-095a8f1254c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-6ea6c553-9d74-4ab2-aa24-90d2e039b0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059153615-172.17.0.16-1598580321908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-f9df841a-aeb4-41fb-99a6-b11ad99d9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-91e7a7fc-0178-49fb-91d6-be1d2de2513d,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-680950ff-7a4f-40e3-9002-5dfa0a186efc,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-03767018-eb32-48b3-ba44-051a5f62132d,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-3177df3b-b8ee-4751-a4e3-c1ad853aa210,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-82a82c16-d590-4eb2-b45c-2ba768db918e,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-7d5aa9f3-9e26-49e2-82d8-095a8f1254c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-6ea6c553-9d74-4ab2-aa24-90d2e039b0bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517012540-172.17.0.16-1598580502118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-12ad570e-2e5a-4c2a-9bf9-a262aa47e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-24e02f92-ef91-4b7e-95cf-afa2bb62a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-696d519c-2034-42f2-a24d-e2c3e1270140,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-4b7b6cab-ec66-45bc-9b41-0cfd93a8ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-44174202-a35f-44aa-8961-28d8e8efee29,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-7618e011-7817-4c97-8fc6-aa5b219eb74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-b2a1f36a-675f-46b7-9ba8-a12b45977e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-4638161f-b1df-4634-8ecc-4c805b024d43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517012540-172.17.0.16-1598580502118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-12ad570e-2e5a-4c2a-9bf9-a262aa47e940,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-24e02f92-ef91-4b7e-95cf-afa2bb62a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-696d519c-2034-42f2-a24d-e2c3e1270140,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-4b7b6cab-ec66-45bc-9b41-0cfd93a8ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-44174202-a35f-44aa-8961-28d8e8efee29,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-7618e011-7817-4c97-8fc6-aa5b219eb74e,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-b2a1f36a-675f-46b7-9ba8-a12b45977e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-4638161f-b1df-4634-8ecc-4c805b024d43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630351177-172.17.0.16-1598580609494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-3a96695f-3fb3-4de7-ad9c-36aa361fd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-21e02922-cd55-4522-a167-2533ffad5453,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-53cc96f6-92e6-40e3-9985-ca7984ffc313,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-ca90a0ba-059e-43bc-95be-e0615bd5fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-f460469c-1431-4517-bf86-d127ea356418,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-b91e2a55-47c4-462d-b8ef-d56496b464af,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-a649cc49-19f7-4a33-9e27-773f54c340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-c32c08a4-21aa-499c-aa9c-2ec1cc25e222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630351177-172.17.0.16-1598580609494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-3a96695f-3fb3-4de7-ad9c-36aa361fd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-21e02922-cd55-4522-a167-2533ffad5453,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-53cc96f6-92e6-40e3-9985-ca7984ffc313,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-ca90a0ba-059e-43bc-95be-e0615bd5fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-f460469c-1431-4517-bf86-d127ea356418,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-b91e2a55-47c4-462d-b8ef-d56496b464af,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-a649cc49-19f7-4a33-9e27-773f54c340ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-c32c08a4-21aa-499c-aa9c-2ec1cc25e222,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003423932-172.17.0.16-1598580855307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-81be2e7b-1a8a-4171-8671-c8347d71230b,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9440a9b2-035d-4b0c-983d-a069e37f494e,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-a259a2cf-af6a-4445-9011-7954fc65c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f6fab5a5-164a-4eb6-a5a2-afb42787ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-b7bda144-4201-4e67-b40a-f8f609ccaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-78106bcb-9369-4d53-8bc4-41ffa1fc4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-afaa9f58-f132-4351-bd3c-e627dd0793af,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-e628d56b-a550-4add-ac2b-4f41f7f9ba59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003423932-172.17.0.16-1598580855307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-81be2e7b-1a8a-4171-8671-c8347d71230b,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-9440a9b2-035d-4b0c-983d-a069e37f494e,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-a259a2cf-af6a-4445-9011-7954fc65c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-f6fab5a5-164a-4eb6-a5a2-afb42787ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-b7bda144-4201-4e67-b40a-f8f609ccaf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-78106bcb-9369-4d53-8bc4-41ffa1fc4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-afaa9f58-f132-4351-bd3c-e627dd0793af,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-e628d56b-a550-4add-ac2b-4f41f7f9ba59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967397532-172.17.0.16-1598580956891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-e90d30ad-4352-4189-b870-4065e076946d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ecd704c2-e00c-459a-9b8a-ab447ab15cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-bf4303e3-f22e-431b-a91b-76687bfea51d,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-aca4d329-fccd-486e-a616-262621b32326,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-3bc92716-6af6-40b2-adde-0dfe4919c090,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-054fbcd2-0778-4065-b6d6-c4d086a669ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-56159465-befe-4ecf-8d95-71287cb73cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-e0616980-b281-4d02-8611-8fad57523593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967397532-172.17.0.16-1598580956891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40915,DS-e90d30ad-4352-4189-b870-4065e076946d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-ecd704c2-e00c-459a-9b8a-ab447ab15cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-bf4303e3-f22e-431b-a91b-76687bfea51d,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-aca4d329-fccd-486e-a616-262621b32326,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-3bc92716-6af6-40b2-adde-0dfe4919c090,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-054fbcd2-0778-4065-b6d6-c4d086a669ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-56159465-befe-4ecf-8d95-71287cb73cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-e0616980-b281-4d02-8611-8fad57523593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850031915-172.17.0.16-1598581168018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33294,DS-7fcc76a1-31d3-429e-8807-12243d213f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-9faa3375-d8ca-4011-9b37-1b99d37ba697,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-d2674200-577d-4a1d-878e-b2acefc14c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-33b4c9cd-cd35-4536-a727-8fadaee624d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-1e9f4d52-7e1c-49f6-83c1-3962c50b4558,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-7ebc4be5-e8d2-49ac-8177-b78f4f16299c,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3457ee61-f1ff-4260-aae2-55cf505bdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-db3aba6b-2e2f-4963-a667-3b18631fcf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850031915-172.17.0.16-1598581168018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33294,DS-7fcc76a1-31d3-429e-8807-12243d213f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-9faa3375-d8ca-4011-9b37-1b99d37ba697,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-d2674200-577d-4a1d-878e-b2acefc14c98,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-33b4c9cd-cd35-4536-a727-8fadaee624d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-1e9f4d52-7e1c-49f6-83c1-3962c50b4558,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-7ebc4be5-e8d2-49ac-8177-b78f4f16299c,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3457ee61-f1ff-4260-aae2-55cf505bdeec,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-db3aba6b-2e2f-4963-a667-3b18631fcf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729533788-172.17.0.16-1598581206158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-3a83a4ac-7308-4973-a9bd-ce166123af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-01846eb9-258b-4645-acc6-c1a2607b4358,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-12fb039c-5da5-4161-a71a-7b1cfdbc3c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-4a5966ac-93d2-4ec1-a3f1-542ad5a14b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bcf1bd11-436c-42f8-b939-0945328578a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-16b8c174-98a8-4ee6-9e1c-ac2433c3ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-834c5179-9096-403e-98f5-f2ce4a4abe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-3ce65336-ea7a-44a7-92c2-d782224cd613,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729533788-172.17.0.16-1598581206158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-3a83a4ac-7308-4973-a9bd-ce166123af8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-01846eb9-258b-4645-acc6-c1a2607b4358,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-12fb039c-5da5-4161-a71a-7b1cfdbc3c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-4a5966ac-93d2-4ec1-a3f1-542ad5a14b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-bcf1bd11-436c-42f8-b939-0945328578a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-16b8c174-98a8-4ee6-9e1c-ac2433c3ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-834c5179-9096-403e-98f5-f2ce4a4abe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-3ce65336-ea7a-44a7-92c2-d782224cd613,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80134735-172.17.0.16-1598581242413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-f37ce875-4fa6-44d1-85c9-1f309f844a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-0f3b6326-ce01-471a-be36-6a2e29ccdc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-125f8d4f-3d50-4ba3-af70-befdfb01f7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-cb70f59b-64f2-47c1-83cd-235d81f86686,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-330cb0f2-3e7a-4458-8a3b-3291f0ff0e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-6c3d714b-a80c-43b3-9f51-383076cc78c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-5940d860-731b-4a18-a5ae-20c392d72111,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-c16a7c79-5b16-489b-af04-d86d5309a36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80134735-172.17.0.16-1598581242413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-f37ce875-4fa6-44d1-85c9-1f309f844a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-0f3b6326-ce01-471a-be36-6a2e29ccdc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-125f8d4f-3d50-4ba3-af70-befdfb01f7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-cb70f59b-64f2-47c1-83cd-235d81f86686,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-330cb0f2-3e7a-4458-8a3b-3291f0ff0e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-6c3d714b-a80c-43b3-9f51-383076cc78c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-5940d860-731b-4a18-a5ae-20c392d72111,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-c16a7c79-5b16-489b-af04-d86d5309a36c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873811449-172.17.0.16-1598581271836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34851,DS-563b837a-7207-4a2f-93cc-f519bde0f210,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-18093313-af2b-43c5-922e-6980ec5be2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2a772d6a-65f9-47cb-8037-ce7727572171,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f5276cea-9944-4693-83bb-07f8b34f3614,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-03d7ee5f-c803-4909-beac-aed72d23b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-6437fe8c-9313-473b-b046-465dc7f6a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-50484e7f-cff9-4d0c-ba7b-3c7e2b2a80c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-4c364df3-9d70-45ba-af40-aaf2537fb56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873811449-172.17.0.16-1598581271836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34851,DS-563b837a-7207-4a2f-93cc-f519bde0f210,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-18093313-af2b-43c5-922e-6980ec5be2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-2a772d6a-65f9-47cb-8037-ce7727572171,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f5276cea-9944-4693-83bb-07f8b34f3614,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-03d7ee5f-c803-4909-beac-aed72d23b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-6437fe8c-9313-473b-b046-465dc7f6a4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-50484e7f-cff9-4d0c-ba7b-3c7e2b2a80c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-4c364df3-9d70-45ba-af40-aaf2537fb56b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963032370-172.17.0.16-1598581306855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-d4e379e5-e5c8-4448-90d9-290270e90d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-6ce6cddf-18fe-448e-aaa7-31af7de6a399,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-b879b8af-a643-4bca-b3aa-d4f06235be84,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-0c314aec-af2a-4bb9-83be-ca8c328d998b,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-686b87b8-0798-4368-9cb0-23dbd559ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-ab25d9c6-33b4-4008-bc41-9ff8021d4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-6953489e-0f0c-4751-8bc2-952baca638bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-9396f54f-230b-4d26-8b39-66cd33b49820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963032370-172.17.0.16-1598581306855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-d4e379e5-e5c8-4448-90d9-290270e90d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-6ce6cddf-18fe-448e-aaa7-31af7de6a399,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-b879b8af-a643-4bca-b3aa-d4f06235be84,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-0c314aec-af2a-4bb9-83be-ca8c328d998b,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-686b87b8-0798-4368-9cb0-23dbd559ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-ab25d9c6-33b4-4008-bc41-9ff8021d4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-6953489e-0f0c-4751-8bc2-952baca638bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-9396f54f-230b-4d26-8b39-66cd33b49820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267470605-172.17.0.16-1598581414819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-33bbd4ff-3684-4244-9613-13f5631c532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-da985ab1-895f-4a83-87d8-5fd87cf3eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-b5a64acf-dd55-4ce4-a6ce-6194d7737581,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-94f2cd12-9926-4759-854c-2167e8c44501,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-e085f9cc-6f8e-4610-956f-b919fed10f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-861142ee-6979-4563-8c5d-7f75eea4423c,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-f4b24847-ff66-43e5-a6e6-1dff14823133,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-d8fac0be-045f-4e04-9c8c-e4038ba0f615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267470605-172.17.0.16-1598581414819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-33bbd4ff-3684-4244-9613-13f5631c532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-da985ab1-895f-4a83-87d8-5fd87cf3eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-b5a64acf-dd55-4ce4-a6ce-6194d7737581,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-94f2cd12-9926-4759-854c-2167e8c44501,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-e085f9cc-6f8e-4610-956f-b919fed10f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-861142ee-6979-4563-8c5d-7f75eea4423c,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-f4b24847-ff66-43e5-a6e6-1dff14823133,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-d8fac0be-045f-4e04-9c8c-e4038ba0f615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95981935-172.17.0.16-1598581480694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34816,DS-27152955-e5f0-4136-954a-07164eb7a9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-c69b3855-218c-47b7-a634-c0d5e853ae73,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-3b6a15a5-5503-43a2-8e66-b849006bc5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0dbb0b61-67b3-4380-8938-cf063358416d,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-fee5551b-f9a5-4b6e-9cf9-683fa3b73542,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d548bf9c-3f1f-4f44-9314-865e8d860b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-b5deebe4-c0a2-40ca-91f4-280e30ae390f,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-a0f13500-921f-486e-a238-16c224831d9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95981935-172.17.0.16-1598581480694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34816,DS-27152955-e5f0-4136-954a-07164eb7a9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-c69b3855-218c-47b7-a634-c0d5e853ae73,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-3b6a15a5-5503-43a2-8e66-b849006bc5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0dbb0b61-67b3-4380-8938-cf063358416d,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-fee5551b-f9a5-4b6e-9cf9-683fa3b73542,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-d548bf9c-3f1f-4f44-9314-865e8d860b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-b5deebe4-c0a2-40ca-91f4-280e30ae390f,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-a0f13500-921f-486e-a238-16c224831d9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054716209-172.17.0.16-1598581583339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-d6e14cdd-61a3-4ab9-a516-2d6e47443df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-3ea0a783-f481-4899-836a-b23e56c4d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-ed99ee08-b793-45b2-821b-955edde9cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-9a1f5119-41b3-4853-bdd9-73501bd9753a,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-f8b96da8-d07a-4ea3-a79a-38833bbbda4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-941eb7b5-29dd-42d3-b6fc-6a457cf78b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9a9c2beb-a2e7-447e-952d-e5abb943c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-e3d00583-e610-42c3-afb0-f2a57536258c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054716209-172.17.0.16-1598581583339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-d6e14cdd-61a3-4ab9-a516-2d6e47443df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-3ea0a783-f481-4899-836a-b23e56c4d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-ed99ee08-b793-45b2-821b-955edde9cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-9a1f5119-41b3-4853-bdd9-73501bd9753a,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-f8b96da8-d07a-4ea3-a79a-38833bbbda4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-941eb7b5-29dd-42d3-b6fc-6a457cf78b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9a9c2beb-a2e7-447e-952d-e5abb943c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-e3d00583-e610-42c3-afb0-f2a57536258c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139560094-172.17.0.16-1598581790845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35271,DS-1344c716-763b-4c87-8a55-b5175b5ee632,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-6696d913-f69c-4eb3-8b68-30fbfb6aa39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-e5795869-9b8c-42fe-95f9-3e785e9b8592,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-365a5bb7-99ac-45f4-a0fe-1ab58710edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-b00e6f04-74cf-4e84-836c-efd7e3f02980,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-e845b4dd-ee62-46f3-890b-66f800f315a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-91273835-2970-431d-ae49-22c3e901a363,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-1b612d85-d28e-4278-889d-1c49856c3eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139560094-172.17.0.16-1598581790845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35271,DS-1344c716-763b-4c87-8a55-b5175b5ee632,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-6696d913-f69c-4eb3-8b68-30fbfb6aa39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-e5795869-9b8c-42fe-95f9-3e785e9b8592,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-365a5bb7-99ac-45f4-a0fe-1ab58710edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-b00e6f04-74cf-4e84-836c-efd7e3f02980,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-e845b4dd-ee62-46f3-890b-66f800f315a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-91273835-2970-431d-ae49-22c3e901a363,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-1b612d85-d28e-4278-889d-1c49856c3eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486019809-172.17.0.16-1598581823021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-a06223ce-d339-434f-a8d8-5b64e87a247b,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-103b2ae3-51d4-47bc-a550-1cb231c2d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-059f3c48-c7b6-4b62-8b4b-2a50d87016c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f1b87b21-d932-47d3-9463-5799a55470c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d97130e9-3acc-45c1-ba1b-921c94b7690b,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-a47ed5cd-1c97-4b8c-bc6e-a183e7ee67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-b1f1a16a-bb96-43b7-933a-5fdad40210c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b23797c6-ce1d-4494-9ae1-e6c5aa947c88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486019809-172.17.0.16-1598581823021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-a06223ce-d339-434f-a8d8-5b64e87a247b,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-103b2ae3-51d4-47bc-a550-1cb231c2d5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-059f3c48-c7b6-4b62-8b4b-2a50d87016c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-f1b87b21-d932-47d3-9463-5799a55470c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d97130e9-3acc-45c1-ba1b-921c94b7690b,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-a47ed5cd-1c97-4b8c-bc6e-a183e7ee67c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-b1f1a16a-bb96-43b7-933a-5fdad40210c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b23797c6-ce1d-4494-9ae1-e6c5aa947c88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900959776-172.17.0.16-1598581947097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-56bc9b9e-c665-474d-a002-7410975afee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-734b44cd-b3bb-4209-9206-6096be78f010,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-33e79cd4-ba5a-471b-98f6-23bd3be20f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-91b79f87-981e-40b6-8eb1-8b907c878918,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-84a85a4b-538c-434b-bcd2-6f1d69407332,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-ee9f262f-5ff3-4ce7-a2ca-2c49aaa6804e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ad70c9da-be87-4976-a5d4-8b015b466b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-de554287-d218-4c37-8f63-47190b3fac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900959776-172.17.0.16-1598581947097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45771,DS-56bc9b9e-c665-474d-a002-7410975afee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-734b44cd-b3bb-4209-9206-6096be78f010,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-33e79cd4-ba5a-471b-98f6-23bd3be20f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-91b79f87-981e-40b6-8eb1-8b907c878918,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-84a85a4b-538c-434b-bcd2-6f1d69407332,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-ee9f262f-5ff3-4ce7-a2ca-2c49aaa6804e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ad70c9da-be87-4976-a5d4-8b015b466b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-de554287-d218-4c37-8f63-47190b3fac87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218035976-172.17.0.16-1598582167870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-25b438e7-21f4-47bd-91fc-5f34fef3502a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-956999ae-6e1b-497e-9a17-d90053f18bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-7ae03622-f6f3-42b7-858f-96ea09333302,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c5078164-4cd5-4f49-b606-faeb7c182d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-8bb16ad2-3734-4b65-a382-d0853c57d228,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-acdeab5d-2170-4bbe-96bd-135d8f485b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-3752b7bc-698a-4313-9324-9d21fdd11b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-a5324ac7-5146-4f08-b2f0-78e1f9d3ce78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218035976-172.17.0.16-1598582167870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-25b438e7-21f4-47bd-91fc-5f34fef3502a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-956999ae-6e1b-497e-9a17-d90053f18bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-7ae03622-f6f3-42b7-858f-96ea09333302,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c5078164-4cd5-4f49-b606-faeb7c182d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-8bb16ad2-3734-4b65-a382-d0853c57d228,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-acdeab5d-2170-4bbe-96bd-135d8f485b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-3752b7bc-698a-4313-9324-9d21fdd11b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-a5324ac7-5146-4f08-b2f0-78e1f9d3ce78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89331113-172.17.0.16-1598582241868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-1f5b8bb8-e711-4d33-84ec-fb3b5145de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-ddb88170-c642-4de9-a352-d511e244e382,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-288d8f7d-14b1-47ed-b114-00b135f2baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-de53f056-4c5e-4fe0-9125-b83d9c29210e,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-6c825e9b-b35e-4441-ab9c-78298fc378d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-c783b1f1-e017-433a-a1b9-e3cb27ae8655,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-0b2631f4-0565-4e09-af8e-a13e70f7491d,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-06b5be60-cdc5-4103-b4f8-f4446727e242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89331113-172.17.0.16-1598582241868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-1f5b8bb8-e711-4d33-84ec-fb3b5145de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-ddb88170-c642-4de9-a352-d511e244e382,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-288d8f7d-14b1-47ed-b114-00b135f2baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-de53f056-4c5e-4fe0-9125-b83d9c29210e,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-6c825e9b-b35e-4441-ab9c-78298fc378d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-c783b1f1-e017-433a-a1b9-e3cb27ae8655,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-0b2631f4-0565-4e09-af8e-a13e70f7491d,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-06b5be60-cdc5-4103-b4f8-f4446727e242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627872654-172.17.0.16-1598582584848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-aaa4b5fc-5454-451e-8186-fbf23ed3abed,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-4a27849b-ec8d-4d4a-a12e-303ec1148714,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-a40bb799-8855-4f0f-999e-bafc1369ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b7a38c36-4bcb-411b-9b92-275051d4865d,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-775ae10b-1b38-4eea-a39a-d1d93b496b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7dba7d05-5c53-4851-a6cf-38964036119c,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-eca4a779-8c6d-4abb-87c2-74bc4dc6d384,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0d51f71f-ad1b-4f35-94e3-5614598212dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627872654-172.17.0.16-1598582584848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-aaa4b5fc-5454-451e-8186-fbf23ed3abed,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-4a27849b-ec8d-4d4a-a12e-303ec1148714,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-a40bb799-8855-4f0f-999e-bafc1369ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-b7a38c36-4bcb-411b-9b92-275051d4865d,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-775ae10b-1b38-4eea-a39a-d1d93b496b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-7dba7d05-5c53-4851-a6cf-38964036119c,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-eca4a779-8c6d-4abb-87c2-74bc4dc6d384,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0d51f71f-ad1b-4f35-94e3-5614598212dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036602711-172.17.0.16-1598582752082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-55e451bf-f3de-47bc-bc4d-764497c4bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-4774a23d-4b1d-439c-8866-be3471e612a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-89bfad19-75ec-4990-bad3-abf6845261bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-182dcfeb-1371-436f-830d-acbd8d8f9cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-b6e7d5bc-33a5-421f-b90b-1599605b22c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-ff99c29e-1013-44ff-b18a-3d2b9a0b0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-2c32031b-39d8-447c-bff0-c0de5b3101ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-f760ed81-9e93-4fae-9c12-80212bd42558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036602711-172.17.0.16-1598582752082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-55e451bf-f3de-47bc-bc4d-764497c4bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-4774a23d-4b1d-439c-8866-be3471e612a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-89bfad19-75ec-4990-bad3-abf6845261bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-182dcfeb-1371-436f-830d-acbd8d8f9cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-b6e7d5bc-33a5-421f-b90b-1599605b22c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-ff99c29e-1013-44ff-b18a-3d2b9a0b0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-2c32031b-39d8-447c-bff0-c0de5b3101ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-f760ed81-9e93-4fae-9c12-80212bd42558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062168739-172.17.0.16-1598582823162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-c1f3d39f-94d7-4a45-8386-68994a9e9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-c244d5b7-29de-4bd9-8cdf-79c670a2a76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-9393d1f6-7136-4ba1-bce1-614e65ede7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-2aa6a679-24dd-4391-9f03-63227d0ec214,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-21367b5f-69b7-4ca3-b1ce-b6db9262da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-8f10cc60-0773-4494-9770-dd96dd62aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-8f0d9374-4654-42ba-a926-df1ac285808e,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-86dd9474-2b18-4ea9-8d6d-2c5acb1cef78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062168739-172.17.0.16-1598582823162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-c1f3d39f-94d7-4a45-8386-68994a9e9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-c244d5b7-29de-4bd9-8cdf-79c670a2a76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-9393d1f6-7136-4ba1-bce1-614e65ede7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-2aa6a679-24dd-4391-9f03-63227d0ec214,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-21367b5f-69b7-4ca3-b1ce-b6db9262da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-8f10cc60-0773-4494-9770-dd96dd62aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-8f0d9374-4654-42ba-a926-df1ac285808e,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-86dd9474-2b18-4ea9-8d6d-2c5acb1cef78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124643656-172.17.0.16-1598583033579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-72b50812-a9f8-4863-897c-30466cf56ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-c4d4cda6-dcc0-4e3f-ba88-db647e4998e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-920f2f84-56dc-4c8c-ac34-0d9c358f451a,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-c271304c-fdd5-43ff-8b99-12ec96b8e949,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-2af0cfc1-66e1-4a0c-8d9c-00108efb74b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-6be3030d-75b3-4c24-93a0-c2888c34764e,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-f205f640-a455-4897-be30-de866a3feef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-2c7a2440-39b1-4bcd-8cd3-e3c3da604a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124643656-172.17.0.16-1598583033579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-72b50812-a9f8-4863-897c-30466cf56ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-c4d4cda6-dcc0-4e3f-ba88-db647e4998e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-920f2f84-56dc-4c8c-ac34-0d9c358f451a,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-c271304c-fdd5-43ff-8b99-12ec96b8e949,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-2af0cfc1-66e1-4a0c-8d9c-00108efb74b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-6be3030d-75b3-4c24-93a0-c2888c34764e,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-f205f640-a455-4897-be30-de866a3feef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-2c7a2440-39b1-4bcd-8cd3-e3c3da604a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333540891-172.17.0.16-1598583106777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-6d054fa7-61a4-4fd4-86b2-cf333218c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-9c08e745-3f17-46da-94f9-b5c5e5306180,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-14d1bb4b-72e9-4cdf-a483-624374f5af98,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-279cff0a-2e94-44b9-a1de-27622267af26,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bb206453-03f4-45af-8e67-5bc7bbe8074d,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-7b56d4ad-c0ad-4d0b-b7ee-ae2ad971f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9f2fe434-456e-43fa-b7c5-54e71cf6ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-8a234a48-e145-4732-a07e-c3c7ea0d4268,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333540891-172.17.0.16-1598583106777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-6d054fa7-61a4-4fd4-86b2-cf333218c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-9c08e745-3f17-46da-94f9-b5c5e5306180,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-14d1bb4b-72e9-4cdf-a483-624374f5af98,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-279cff0a-2e94-44b9-a1de-27622267af26,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bb206453-03f4-45af-8e67-5bc7bbe8074d,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-7b56d4ad-c0ad-4d0b-b7ee-ae2ad971f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-9f2fe434-456e-43fa-b7c5-54e71cf6ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-8a234a48-e145-4732-a07e-c3c7ea0d4268,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509156077-172.17.0.16-1598583238087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-843696d1-282b-43fb-bf05-4c64f6827e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-3876e6dc-e05e-46c0-9f01-532f53b6e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8a98db7d-5e9a-4b9e-8cb0-4aabc479235e,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-27f2557e-8c81-4d62-8bf7-0774b831b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-07b1de91-f2de-4253-add3-cefe4886cc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-543356a4-da97-4d50-96fc-c6643dcff5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5f2154bc-01e4-434b-8158-fe6d6eb42a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3a62a1c4-52a3-4a3b-8817-a028de1902fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509156077-172.17.0.16-1598583238087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-843696d1-282b-43fb-bf05-4c64f6827e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-3876e6dc-e05e-46c0-9f01-532f53b6e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8a98db7d-5e9a-4b9e-8cb0-4aabc479235e,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-27f2557e-8c81-4d62-8bf7-0774b831b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-07b1de91-f2de-4253-add3-cefe4886cc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-543356a4-da97-4d50-96fc-c6643dcff5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5f2154bc-01e4-434b-8158-fe6d6eb42a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3a62a1c4-52a3-4a3b-8817-a028de1902fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5092
