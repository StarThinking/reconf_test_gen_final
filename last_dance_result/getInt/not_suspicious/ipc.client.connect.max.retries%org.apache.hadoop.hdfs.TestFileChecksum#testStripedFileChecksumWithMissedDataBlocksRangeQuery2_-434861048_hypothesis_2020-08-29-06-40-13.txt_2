reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4590876-172.17.0.6-1598683651334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38104,DS-47105bc8-581f-4e9e-9cb2-4b0fe2db3b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-0586dbac-9118-4abf-989a-33173da6e943,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6564ba8f-4fdb-4a85-8ecf-df84c1b7dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-5f729e36-3490-4465-9e51-d1e1fd4fa0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-47be4c51-0e96-411c-b452-aa3725495960,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d4e9facf-04c8-4941-a978-a77a9961d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-e4ffa052-241d-41f5-bad1-79291934a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-2acfdc00-e6cc-4f96-bf31-17aad4c4e3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4590876-172.17.0.6-1598683651334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38104,DS-47105bc8-581f-4e9e-9cb2-4b0fe2db3b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-0586dbac-9118-4abf-989a-33173da6e943,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6564ba8f-4fdb-4a85-8ecf-df84c1b7dde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-5f729e36-3490-4465-9e51-d1e1fd4fa0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-47be4c51-0e96-411c-b452-aa3725495960,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d4e9facf-04c8-4941-a978-a77a9961d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-e4ffa052-241d-41f5-bad1-79291934a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-2acfdc00-e6cc-4f96-bf31-17aad4c4e3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980329511-172.17.0.6-1598683728551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-93d371a8-60ac-4c09-9874-6fd98052914b,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9abe9166-fcf3-430a-9b2f-a3c9ebadfc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-43349f9b-3fb0-4f17-9523-e05fa3d1a340,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-26d9a515-32cf-40b4-a7f0-36f5fe6ddb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-062386fa-ad95-4f8b-b242-7023f026f8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-40d78ea6-67d1-4eed-bb0d-dc620d05b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-a1e9dbed-89f1-421d-bd7d-9d7ff1ff1c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-223ea0bc-c560-4cca-ab0e-11b09d99d909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980329511-172.17.0.6-1598683728551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-93d371a8-60ac-4c09-9874-6fd98052914b,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9abe9166-fcf3-430a-9b2f-a3c9ebadfc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-43349f9b-3fb0-4f17-9523-e05fa3d1a340,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-26d9a515-32cf-40b4-a7f0-36f5fe6ddb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-062386fa-ad95-4f8b-b242-7023f026f8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-40d78ea6-67d1-4eed-bb0d-dc620d05b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-a1e9dbed-89f1-421d-bd7d-9d7ff1ff1c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-223ea0bc-c560-4cca-ab0e-11b09d99d909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919098882-172.17.0.6-1598684315938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-dfdff4c6-cfcc-4110-b1ab-456cc5a7b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-a5fdc85a-d5e8-4f93-b8c8-ad860af05d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-b055c424-0083-4d11-9702-6903a88d7472,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bed55597-6fea-4b77-8079-1a0f1086da69,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-9bd5a6d6-1e1b-478d-b234-ea3df185b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-45f53a42-efbf-42dd-95bf-44032cfea065,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e1e9c54a-0988-4a78-b359-a4b81062a643,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-0add9da2-8c5b-449b-b11c-4229dd40492b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919098882-172.17.0.6-1598684315938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-dfdff4c6-cfcc-4110-b1ab-456cc5a7b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-a5fdc85a-d5e8-4f93-b8c8-ad860af05d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-b055c424-0083-4d11-9702-6903a88d7472,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bed55597-6fea-4b77-8079-1a0f1086da69,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-9bd5a6d6-1e1b-478d-b234-ea3df185b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-45f53a42-efbf-42dd-95bf-44032cfea065,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e1e9c54a-0988-4a78-b359-a4b81062a643,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-0add9da2-8c5b-449b-b11c-4229dd40492b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702557015-172.17.0.6-1598685601490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-aef51492-222e-4d83-a186-c12980db1d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-537b3aa5-ee24-4ee5-b12d-84c95321846c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-7981cf73-9f65-464d-8053-4792260da815,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-92039191-07b9-4762-b958-f3510aa822ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-f00c16e9-7281-4e1f-81ab-44def22faed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-d0ba4459-6bfe-4cf0-a240-4d18fe8ed825,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-1affe32b-5f83-4290-9390-66e832fa91ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-9a43ea3f-77b6-406b-b217-4608d979d23d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702557015-172.17.0.6-1598685601490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-aef51492-222e-4d83-a186-c12980db1d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-537b3aa5-ee24-4ee5-b12d-84c95321846c,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-7981cf73-9f65-464d-8053-4792260da815,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-92039191-07b9-4762-b958-f3510aa822ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-f00c16e9-7281-4e1f-81ab-44def22faed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-d0ba4459-6bfe-4cf0-a240-4d18fe8ed825,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-1affe32b-5f83-4290-9390-66e832fa91ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-9a43ea3f-77b6-406b-b217-4608d979d23d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315308077-172.17.0.6-1598685676766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-29f17c2f-3173-4ef0-8006-e5e837c75fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-d1b8eb6e-5fa3-4a85-9747-b17315619840,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-a3549e3b-f4ee-4011-9a46-e527a61eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-f2b87ee6-01a7-4f32-a9be-a091edb4a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-5d265104-da3c-4ae9-8314-cc960bc460dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-3b20532b-7d82-4e87-8cc1-2af36fbb8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-d896b3bb-c1a1-466d-8285-48619d7202b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-da412ca4-68fd-469e-a33f-2a6965ae2f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315308077-172.17.0.6-1598685676766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-29f17c2f-3173-4ef0-8006-e5e837c75fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-d1b8eb6e-5fa3-4a85-9747-b17315619840,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-a3549e3b-f4ee-4011-9a46-e527a61eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-f2b87ee6-01a7-4f32-a9be-a091edb4a54d,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-5d265104-da3c-4ae9-8314-cc960bc460dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-3b20532b-7d82-4e87-8cc1-2af36fbb8c03,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-d896b3bb-c1a1-466d-8285-48619d7202b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-da412ca4-68fd-469e-a33f-2a6965ae2f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023286561-172.17.0.6-1598686267516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-149b19f5-1ab9-4564-b03e-7799db42b1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-2cd24eae-2c42-4f7d-8087-a90fe8abf704,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-e8cbd200-adc4-43dc-bb75-e02dfea69a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c0c6d5e2-763a-4910-ba24-017272db34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-46b17d70-4177-4b21-aa64-72f0d55697f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-19671e03-6fee-4535-be29-ae6d1a30853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-6838b29e-30a1-494c-80bf-5803a3483976,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6b1814a8-7421-407c-9648-ef27acb17e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023286561-172.17.0.6-1598686267516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-149b19f5-1ab9-4564-b03e-7799db42b1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-2cd24eae-2c42-4f7d-8087-a90fe8abf704,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-e8cbd200-adc4-43dc-bb75-e02dfea69a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-c0c6d5e2-763a-4910-ba24-017272db34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-46b17d70-4177-4b21-aa64-72f0d55697f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-19671e03-6fee-4535-be29-ae6d1a30853d,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-6838b29e-30a1-494c-80bf-5803a3483976,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6b1814a8-7421-407c-9648-ef27acb17e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625536951-172.17.0.6-1598686423667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35297,DS-8cff3dd4-c829-4b48-a732-bd1ef3393f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-abec1366-c304-4821-a598-31d2d5f5e382,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-961564dc-e5d1-4817-99a5-74aadde0fc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9caee7de-7e93-4624-ae55-769a319fe625,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-281b46bc-5bd0-4b0a-a25e-4bf718da1183,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-fd109c92-7bb4-44ab-80f5-8ca7fbc66543,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-c96dac5c-d259-407a-bcda-27a0cca17fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-13aba584-8d32-4b5b-8c4e-9057ca3c503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625536951-172.17.0.6-1598686423667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35297,DS-8cff3dd4-c829-4b48-a732-bd1ef3393f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-abec1366-c304-4821-a598-31d2d5f5e382,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-961564dc-e5d1-4817-99a5-74aadde0fc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9caee7de-7e93-4624-ae55-769a319fe625,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-281b46bc-5bd0-4b0a-a25e-4bf718da1183,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-fd109c92-7bb4-44ab-80f5-8ca7fbc66543,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-c96dac5c-d259-407a-bcda-27a0cca17fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-13aba584-8d32-4b5b-8c4e-9057ca3c503c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110224180-172.17.0.6-1598686457288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-41aeb22f-d259-41bd-9700-9dcdde1fbd80,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-4034aacd-1a9f-447f-a58c-7e4f47237475,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-497f6705-b8aa-4324-aac5-aa4c599e1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-d1b7fb80-2df2-425d-8015-741ef0e0f967,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-ca554ccb-ad8d-474a-b96a-81dd6db575ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-37a11989-2738-4aca-b744-9e07ee491470,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-13eaf976-78d5-460c-81ea-09d7472dd12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-559bf092-ea1e-4548-83fc-35af8fb3cb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110224180-172.17.0.6-1598686457288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-41aeb22f-d259-41bd-9700-9dcdde1fbd80,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-4034aacd-1a9f-447f-a58c-7e4f47237475,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-497f6705-b8aa-4324-aac5-aa4c599e1ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-d1b7fb80-2df2-425d-8015-741ef0e0f967,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-ca554ccb-ad8d-474a-b96a-81dd6db575ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-37a11989-2738-4aca-b744-9e07ee491470,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-13eaf976-78d5-460c-81ea-09d7472dd12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-559bf092-ea1e-4548-83fc-35af8fb3cb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744442079-172.17.0.6-1598686629190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-898fe187-922e-43d0-b41c-b8c4c8b0d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-504b46a8-8313-4796-966b-c4abe33d4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-0eefe303-cca2-468c-a01b-f632be3e9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-2d2023c1-7eab-4be6-b870-a0f4b22b7537,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-93a1067f-b6a2-40d5-9784-bcd6f6139cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-ce5fc7d8-5d72-4da6-babc-b24c80044e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-dbc017cb-06af-4ac3-8078-1a247341e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-8f9602f3-2e40-4a57-94e8-f44f89bb2ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744442079-172.17.0.6-1598686629190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-898fe187-922e-43d0-b41c-b8c4c8b0d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-504b46a8-8313-4796-966b-c4abe33d4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-0eefe303-cca2-468c-a01b-f632be3e9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-2d2023c1-7eab-4be6-b870-a0f4b22b7537,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-93a1067f-b6a2-40d5-9784-bcd6f6139cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-ce5fc7d8-5d72-4da6-babc-b24c80044e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-dbc017cb-06af-4ac3-8078-1a247341e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-8f9602f3-2e40-4a57-94e8-f44f89bb2ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624513974-172.17.0.6-1598686929773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-9e36b42f-1cc5-4dc1-b257-7ad84051c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-3ff3cd51-eff3-4bfa-9e2a-ba805bd33b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-9d419286-0af8-4402-95d0-e90917df6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-bb8cd412-523b-4bd8-b289-fd03eae20136,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-f1d03671-36d0-40c7-9e19-a75ab9fc75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-9acb8819-b94c-45d5-8374-3a8431dff5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-3992f05f-f795-4db1-a2e9-057f6dea2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-48b9dd2d-78f3-48ba-a270-85072e6e7115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624513974-172.17.0.6-1598686929773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45388,DS-9e36b42f-1cc5-4dc1-b257-7ad84051c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-3ff3cd51-eff3-4bfa-9e2a-ba805bd33b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-9d419286-0af8-4402-95d0-e90917df6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-bb8cd412-523b-4bd8-b289-fd03eae20136,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-f1d03671-36d0-40c7-9e19-a75ab9fc75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-9acb8819-b94c-45d5-8374-3a8431dff5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-3992f05f-f795-4db1-a2e9-057f6dea2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-48b9dd2d-78f3-48ba-a270-85072e6e7115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314832853-172.17.0.6-1598687406500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-4ceddcde-1ad6-4b2a-8582-f3551c14ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-3f8e8c4e-dd3d-4887-b556-22d8560ebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-3c38df24-c201-4858-a5e1-d2272345fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-fb42fa85-a079-4a30-ba4a-7c1ec275c764,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-92ebfd68-8980-4500-a13a-36fb0811161e,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0166e032-26e9-40d0-9dbf-f47576c6709b,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0a72f49d-1133-4802-a7aa-4046a485c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-fe15cda0-a859-4fc3-957a-72dd0b4564df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314832853-172.17.0.6-1598687406500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-4ceddcde-1ad6-4b2a-8582-f3551c14ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-3f8e8c4e-dd3d-4887-b556-22d8560ebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-3c38df24-c201-4858-a5e1-d2272345fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-fb42fa85-a079-4a30-ba4a-7c1ec275c764,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-92ebfd68-8980-4500-a13a-36fb0811161e,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-0166e032-26e9-40d0-9dbf-f47576c6709b,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0a72f49d-1133-4802-a7aa-4046a485c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-fe15cda0-a859-4fc3-957a-72dd0b4564df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583084956-172.17.0.6-1598687919887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-9567150a-df5f-4fe8-8d71-ce85cb2f96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-f1b36a94-5e26-4393-88f4-ae57bccd0090,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-d70b4763-2162-4404-8a0c-dcb8e9e992c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-20a9727e-3da4-4527-8cae-33da4cc6d299,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-94922d06-142d-4858-bee6-be8d99983bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-4aacb8f2-7c42-4314-9650-59de47ddb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-e51e9171-32fd-4a85-abe0-44c864163f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-5c2e6e5f-3e6e-4df7-b125-38b979b20a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583084956-172.17.0.6-1598687919887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-9567150a-df5f-4fe8-8d71-ce85cb2f96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-f1b36a94-5e26-4393-88f4-ae57bccd0090,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-d70b4763-2162-4404-8a0c-dcb8e9e992c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-20a9727e-3da4-4527-8cae-33da4cc6d299,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-94922d06-142d-4858-bee6-be8d99983bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-4aacb8f2-7c42-4314-9650-59de47ddb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-e51e9171-32fd-4a85-abe0-44c864163f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-5c2e6e5f-3e6e-4df7-b125-38b979b20a81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550583222-172.17.0.6-1598687987691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-dd867f42-4a5d-4479-9753-af532a154899,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-26b92aed-b786-4433-b132-e0508d6f9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-044cbea1-5527-439d-9efb-b37949692250,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-78e2d394-c2d4-48da-acf4-4ce6745bfb53,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b5c433b0-1e6a-4af5-8bb4-c36baa1b7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-f4675cc0-fd6d-4605-b52c-b97cf6da3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-284b25a5-499c-4755-bd37-e6da0c5e6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f601a94c-5578-414a-aace-bd7983aea931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550583222-172.17.0.6-1598687987691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-dd867f42-4a5d-4479-9753-af532a154899,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-26b92aed-b786-4433-b132-e0508d6f9d66,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-044cbea1-5527-439d-9efb-b37949692250,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-78e2d394-c2d4-48da-acf4-4ce6745bfb53,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-b5c433b0-1e6a-4af5-8bb4-c36baa1b7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-f4675cc0-fd6d-4605-b52c-b97cf6da3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-284b25a5-499c-4755-bd37-e6da0c5e6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f601a94c-5578-414a-aace-bd7983aea931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567420757-172.17.0.6-1598688235931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-1d85159f-3a59-4f18-aa30-e33a7367df97,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-554f55cb-c733-48d6-b44e-b2cde3bbba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-a694afc0-1247-443f-bca8-3219ca68b971,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-3f7c7660-926b-4066-a289-c5c2a7d88e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-edc62255-4b37-4624-bae8-ba2788eb67f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-6b0c8be1-c188-49eb-b4fe-26c9a6bd4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-30ba5dde-c1a4-4bde-8027-40c0f58ee311,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-2de626be-27d1-46d2-b5d3-29b204a04c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567420757-172.17.0.6-1598688235931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40566,DS-1d85159f-3a59-4f18-aa30-e33a7367df97,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-554f55cb-c733-48d6-b44e-b2cde3bbba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-a694afc0-1247-443f-bca8-3219ca68b971,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-3f7c7660-926b-4066-a289-c5c2a7d88e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-edc62255-4b37-4624-bae8-ba2788eb67f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-6b0c8be1-c188-49eb-b4fe-26c9a6bd4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-30ba5dde-c1a4-4bde-8027-40c0f58ee311,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-2de626be-27d1-46d2-b5d3-29b204a04c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5310
