reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114636878-172.17.0.18-1598644893236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-ff7c7b8c-bf7c-4158-aa3e-a671aa5464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-5c59fdd2-a3cd-4765-b6a3-05587babf9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-c377aa0a-7c45-45d4-bb5e-0bff0cede8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-0ea341c9-9dab-4d46-9ff4-db643cc58d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-41e47411-af8f-4e6a-81f3-f2e730651c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-31d0d90e-80f6-4c91-9dff-6bf9ea8a5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-bbedee90-3236-4ed8-a59c-cf37555957ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-5d1abb71-80a7-4c2e-9758-43c5c0388b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114636878-172.17.0.18-1598644893236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-ff7c7b8c-bf7c-4158-aa3e-a671aa5464c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-5c59fdd2-a3cd-4765-b6a3-05587babf9db,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-c377aa0a-7c45-45d4-bb5e-0bff0cede8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-0ea341c9-9dab-4d46-9ff4-db643cc58d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-41e47411-af8f-4e6a-81f3-f2e730651c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-31d0d90e-80f6-4c91-9dff-6bf9ea8a5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-bbedee90-3236-4ed8-a59c-cf37555957ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-5d1abb71-80a7-4c2e-9758-43c5c0388b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076774918-172.17.0.18-1598644929164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-774fd392-d94f-43a9-b42a-7bfb1960d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-125372ec-ca86-45af-bed2-80085dcf9faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7786c144-f334-454a-adbd-0aae67187ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-00553894-434b-4707-9465-dcdece292333,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-dda98771-0290-435e-a2d3-6e126ea6fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-a6b372f9-153c-4320-b7a7-62ec84d38451,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-c076d112-d309-46de-8d7a-5299e8202ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-1ffaa897-e6b8-4c5b-8336-ed44a24dedbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076774918-172.17.0.18-1598644929164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-774fd392-d94f-43a9-b42a-7bfb1960d05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-125372ec-ca86-45af-bed2-80085dcf9faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7786c144-f334-454a-adbd-0aae67187ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-00553894-434b-4707-9465-dcdece292333,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-dda98771-0290-435e-a2d3-6e126ea6fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-a6b372f9-153c-4320-b7a7-62ec84d38451,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-c076d112-d309-46de-8d7a-5299e8202ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-1ffaa897-e6b8-4c5b-8336-ed44a24dedbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495095230-172.17.0.18-1598645484952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-f977efc0-66f4-4379-a7a9-b2c5bd11cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-a395d49a-b286-4428-bea7-bd6d64a67e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-5fe7e38e-1624-4ab0-9039-3b8bc27f8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-cf26cf86-1956-467b-930a-a2826c867868,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-251c1620-1546-48e4-a406-0bd429af8f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-31435c13-48fa-4502-8ce9-b9c23644a833,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-b2ffb5cd-3e9b-43a0-8941-673711b7781b,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-17241e68-a955-47c6-996a-51e1f4cd4498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495095230-172.17.0.18-1598645484952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44724,DS-f977efc0-66f4-4379-a7a9-b2c5bd11cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-a395d49a-b286-4428-bea7-bd6d64a67e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-5fe7e38e-1624-4ab0-9039-3b8bc27f8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-cf26cf86-1956-467b-930a-a2826c867868,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-251c1620-1546-48e4-a406-0bd429af8f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-31435c13-48fa-4502-8ce9-b9c23644a833,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-b2ffb5cd-3e9b-43a0-8941-673711b7781b,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-17241e68-a955-47c6-996a-51e1f4cd4498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839078317-172.17.0.18-1598645768456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-00dcfa27-7792-4f9a-bb3d-9cf3244d4283,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-160e4130-1ef6-4c27-82e1-6059a0626b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-6287f245-6117-4a3d-97a5-1674e915dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-256ef7da-9c67-49b0-ba12-7c0acb0235c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-2ee7726b-79f4-4502-af47-bd54cc5151ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-50df364c-54c7-4d2e-b989-293a037f3130,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-d557f6bb-a860-48a5-ab3d-03c261febaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-cdc28ebe-1a8c-4cd2-838b-339a002fff73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839078317-172.17.0.18-1598645768456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-00dcfa27-7792-4f9a-bb3d-9cf3244d4283,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-160e4130-1ef6-4c27-82e1-6059a0626b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-6287f245-6117-4a3d-97a5-1674e915dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-256ef7da-9c67-49b0-ba12-7c0acb0235c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-2ee7726b-79f4-4502-af47-bd54cc5151ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-50df364c-54c7-4d2e-b989-293a037f3130,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-d557f6bb-a860-48a5-ab3d-03c261febaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-cdc28ebe-1a8c-4cd2-838b-339a002fff73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24526345-172.17.0.18-1598645809512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-0d6882e1-3f2a-4c39-b53c-6e7d4de9c33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-fd674708-5d5d-4274-b042-e519f3ff5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-06568fb1-af4e-4a1f-82f7-07ecc0d66461,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-a1229d85-30da-435c-a61c-c77c2f4a61a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-f749eb81-de44-4ee7-8643-380a06617093,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-102333c6-cb5a-470b-8776-1ac0720dad06,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-34d0d213-3543-4b94-9f04-49ad11ab564e,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ad9afc83-adf0-4c81-8285-375fdc583d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24526345-172.17.0.18-1598645809512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-0d6882e1-3f2a-4c39-b53c-6e7d4de9c33e,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-fd674708-5d5d-4274-b042-e519f3ff5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-06568fb1-af4e-4a1f-82f7-07ecc0d66461,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-a1229d85-30da-435c-a61c-c77c2f4a61a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-f749eb81-de44-4ee7-8643-380a06617093,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-102333c6-cb5a-470b-8776-1ac0720dad06,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-34d0d213-3543-4b94-9f04-49ad11ab564e,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ad9afc83-adf0-4c81-8285-375fdc583d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579666280-172.17.0.18-1598646914996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42855,DS-6f793124-f9d3-4b75-93ce-22673fd47462,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1d1ee8d4-0738-4533-bf3d-e609c8d0f281,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-e943e26a-b9d9-45c2-b3ef-aa82505a9611,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-0bf770d1-6b13-47a0-9d9e-6d4f8c2bf766,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-91d356fd-1dda-424e-b36b-3ca795551c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-bfd1773e-d948-425e-99ad-063dbd75abba,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-a93d99c0-de9b-4c0a-83ce-eeaa2f34cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-49646677-8d76-4cc5-b8c3-412a7feb5955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579666280-172.17.0.18-1598646914996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42855,DS-6f793124-f9d3-4b75-93ce-22673fd47462,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1d1ee8d4-0738-4533-bf3d-e609c8d0f281,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-e943e26a-b9d9-45c2-b3ef-aa82505a9611,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-0bf770d1-6b13-47a0-9d9e-6d4f8c2bf766,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-91d356fd-1dda-424e-b36b-3ca795551c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-bfd1773e-d948-425e-99ad-063dbd75abba,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-a93d99c0-de9b-4c0a-83ce-eeaa2f34cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-49646677-8d76-4cc5-b8c3-412a7feb5955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126303932-172.17.0.18-1598647205332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-d197686a-6a89-45c8-bbbf-fde6c7e9a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c3a1e6a8-55f7-48ad-b772-436efb984d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-80d49e88-4b77-48c9-b114-df1907eb5af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-28f601b7-d456-41aa-a047-0238dda8ba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-fa4ea8aa-4969-4f0a-907f-533ab702c865,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-b98a9c97-dcc9-4b38-bf71-a2f8498b8eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-3ac04a46-cd20-415d-895b-6b4395815157,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-295f736d-3a04-4c2b-a565-5885f1bea438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1126303932-172.17.0.18-1598647205332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-d197686a-6a89-45c8-bbbf-fde6c7e9a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-c3a1e6a8-55f7-48ad-b772-436efb984d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-80d49e88-4b77-48c9-b114-df1907eb5af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-28f601b7-d456-41aa-a047-0238dda8ba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-fa4ea8aa-4969-4f0a-907f-533ab702c865,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-b98a9c97-dcc9-4b38-bf71-a2f8498b8eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-3ac04a46-cd20-415d-895b-6b4395815157,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-295f736d-3a04-4c2b-a565-5885f1bea438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105426502-172.17.0.18-1598647315924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-013e5f91-e7a9-461f-900b-ab5c419056db,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-6a95dc1f-a9e3-46a9-b9d1-77831aa2895e,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d91b9bff-e588-436d-8a60-664997e97ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-3b4e75dc-8935-4f8b-85f0-d3689f34954c,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-ee69434b-afbb-4302-a0bd-3801b3521fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-ac8d824c-031d-499f-8c94-f856cf70bd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-bc22e53a-ff79-4e85-a733-76fecbefb282,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-ba35dd57-ad1d-4a7d-a1ac-da2a70334c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105426502-172.17.0.18-1598647315924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-013e5f91-e7a9-461f-900b-ab5c419056db,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-6a95dc1f-a9e3-46a9-b9d1-77831aa2895e,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d91b9bff-e588-436d-8a60-664997e97ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-3b4e75dc-8935-4f8b-85f0-d3689f34954c,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-ee69434b-afbb-4302-a0bd-3801b3521fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-ac8d824c-031d-499f-8c94-f856cf70bd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-bc22e53a-ff79-4e85-a733-76fecbefb282,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-ba35dd57-ad1d-4a7d-a1ac-da2a70334c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769275464-172.17.0.18-1598647683541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-d0fc5e2a-818b-4524-8c80-8183f8450aef,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-1a12ec92-f54e-4737-bd90-2f953b33bce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-70449303-e3b6-4344-a51c-88c1eb5d5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-15d46448-094b-414b-a1c2-f03bba0bbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9cc6c943-dfaa-4dde-851c-aaa5b88283c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-77d0941e-bcc8-4ed0-80d9-b3311fb8ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-e0464f7e-d329-464b-9b5b-337b54f5a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-254a0d74-cff7-4b44-baf9-c8d486b45e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769275464-172.17.0.18-1598647683541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-d0fc5e2a-818b-4524-8c80-8183f8450aef,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-1a12ec92-f54e-4737-bd90-2f953b33bce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-70449303-e3b6-4344-a51c-88c1eb5d5bad,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-15d46448-094b-414b-a1c2-f03bba0bbca7,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9cc6c943-dfaa-4dde-851c-aaa5b88283c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-77d0941e-bcc8-4ed0-80d9-b3311fb8ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-e0464f7e-d329-464b-9b5b-337b54f5a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-254a0d74-cff7-4b44-baf9-c8d486b45e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093646186-172.17.0.18-1598647898759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-4bb881bb-d44e-4cbc-98af-07c2df1a4cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e1354f85-b422-4d7f-8b6d-9f522559785b,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-31ec06dd-3669-40df-b2b1-b342c0227410,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-25f0cc17-7962-470f-889a-a9d33513732d,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-731d9b65-b851-4365-9a4f-cd4155fec498,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-8f58d52f-4759-429e-bf5f-ed9266dd4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-c4ce7481-af2c-4d4d-aaf9-df9bd6b0c680,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-5d2d1719-ac71-46c4-9398-666a1994744f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093646186-172.17.0.18-1598647898759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-4bb881bb-d44e-4cbc-98af-07c2df1a4cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-e1354f85-b422-4d7f-8b6d-9f522559785b,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-31ec06dd-3669-40df-b2b1-b342c0227410,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-25f0cc17-7962-470f-889a-a9d33513732d,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-731d9b65-b851-4365-9a4f-cd4155fec498,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-8f58d52f-4759-429e-bf5f-ed9266dd4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-c4ce7481-af2c-4d4d-aaf9-df9bd6b0c680,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-5d2d1719-ac71-46c4-9398-666a1994744f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565684403-172.17.0.18-1598648103428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-aa962127-2caf-4bcd-9236-7b8cfea96cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-7dd3be13-6473-4e33-92b1-0ba729d1e802,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-c6c081bf-0ce5-4697-a6eb-1f6bd4659327,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-11c1d246-a3ec-4389-aa9c-67b28fa117c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-be65126a-8bce-4723-8220-4708d4a2cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-65ad04ef-6e00-41f8-940b-ad5e2c93d869,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-6f68ae21-2370-4dd9-964f-876e747137d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-be21ad43-f58f-4bd9-8767-d8fef16aa994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565684403-172.17.0.18-1598648103428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42561,DS-aa962127-2caf-4bcd-9236-7b8cfea96cda,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-7dd3be13-6473-4e33-92b1-0ba729d1e802,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-c6c081bf-0ce5-4697-a6eb-1f6bd4659327,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-11c1d246-a3ec-4389-aa9c-67b28fa117c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-be65126a-8bce-4723-8220-4708d4a2cab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-65ad04ef-6e00-41f8-940b-ad5e2c93d869,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-6f68ae21-2370-4dd9-964f-876e747137d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-be21ad43-f58f-4bd9-8767-d8fef16aa994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695269552-172.17.0.18-1598648447683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35199,DS-4bce1e4f-9640-4367-97c0-8f29f4a2ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-1799be58-2b1f-4445-817e-1c758fc2878c,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-143fe473-fb8c-4f8c-b564-d30eac7ae893,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-bf35d602-e39a-47a6-acbf-c575cf9a1e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-5813d3d7-3213-4219-8b5f-5140c2b47b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-cb41b98e-f8c0-4b68-b9f9-ad1880d1fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-7f04e333-7d36-42d0-a7c0-1c3297631480,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d2ef239f-4ab6-4b4e-99f8-a7ac7a97c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695269552-172.17.0.18-1598648447683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35199,DS-4bce1e4f-9640-4367-97c0-8f29f4a2ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-1799be58-2b1f-4445-817e-1c758fc2878c,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-143fe473-fb8c-4f8c-b564-d30eac7ae893,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-bf35d602-e39a-47a6-acbf-c575cf9a1e94,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-5813d3d7-3213-4219-8b5f-5140c2b47b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-cb41b98e-f8c0-4b68-b9f9-ad1880d1fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-7f04e333-7d36-42d0-a7c0-1c3297631480,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d2ef239f-4ab6-4b4e-99f8-a7ac7a97c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977293568-172.17.0.18-1598648704139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-5662d678-c235-452b-b784-e910553360a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fac63fff-4b89-48ea-9ec7-d9aae883a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-ced2ba5d-23fb-493f-969d-6ddfa566ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-acb532ba-58ac-442a-88e1-dd6270a68627,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-831fc64d-286c-40cf-98a7-2258986e03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-3f501064-a758-4978-bb6c-744e13a55295,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-4838d009-e00b-4e49-bb24-305a594a1376,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-32e00d47-2dde-4aa5-b981-97d0ac419948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977293568-172.17.0.18-1598648704139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36640,DS-5662d678-c235-452b-b784-e910553360a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fac63fff-4b89-48ea-9ec7-d9aae883a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-ced2ba5d-23fb-493f-969d-6ddfa566ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-acb532ba-58ac-442a-88e1-dd6270a68627,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-831fc64d-286c-40cf-98a7-2258986e03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-3f501064-a758-4978-bb6c-744e13a55295,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-4838d009-e00b-4e49-bb24-305a594a1376,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-32e00d47-2dde-4aa5-b981-97d0ac419948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566832004-172.17.0.18-1598648740838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-062536aa-d9e3-4637-90ad-f66b3cb2a820,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-fab1117e-492f-41c3-a725-c8a54f5f1469,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f36aedc8-99b6-4772-a08a-907032f7b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-8ecb1836-0442-465b-b6c8-467de5311202,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d60ec28b-0d9f-4322-b19a-91c76294ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-90b20483-51f6-4576-b8dd-101b886f1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-11362acf-742f-4f52-bcc2-3666a60fb154,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-3660bace-9d93-4087-84ac-f4648eba093e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566832004-172.17.0.18-1598648740838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42136,DS-062536aa-d9e3-4637-90ad-f66b3cb2a820,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-fab1117e-492f-41c3-a725-c8a54f5f1469,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f36aedc8-99b6-4772-a08a-907032f7b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-8ecb1836-0442-465b-b6c8-467de5311202,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-d60ec28b-0d9f-4322-b19a-91c76294ddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-90b20483-51f6-4576-b8dd-101b886f1e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-11362acf-742f-4f52-bcc2-3666a60fb154,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-3660bace-9d93-4087-84ac-f4648eba093e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971920667-172.17.0.18-1598648817704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-bfc94d9e-e3c8-47da-84b8-4ff7a3e789e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-44ceae4d-295b-49ad-9d78-04cd4eb60bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-9d1d9a5d-7928-4c9a-8855-1a7c3927cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-939d4e80-857e-43a8-8d82-1ef27e7ece59,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-4a53a84b-f85a-4e60-8faf-02e2c2b1efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9fa6e720-0951-4821-a4d2-9076f355c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-eb2869e4-c096-4142-ac2c-228117724519,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c9b1b18b-6f2e-4fa0-9e3c-dfb958caf670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971920667-172.17.0.18-1598648817704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-bfc94d9e-e3c8-47da-84b8-4ff7a3e789e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-44ceae4d-295b-49ad-9d78-04cd4eb60bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-9d1d9a5d-7928-4c9a-8855-1a7c3927cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-939d4e80-857e-43a8-8d82-1ef27e7ece59,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-4a53a84b-f85a-4e60-8faf-02e2c2b1efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-9fa6e720-0951-4821-a4d2-9076f355c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-eb2869e4-c096-4142-ac2c-228117724519,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c9b1b18b-6f2e-4fa0-9e3c-dfb958caf670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298952844-172.17.0.18-1598649141014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-832e2bb4-5c82-4666-ac12-f9eb725acc13,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-682cb4d8-5fbb-4ec3-91b6-634f209c437a,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-241f81e4-bd99-46c5-a0ed-1928ed5a10bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-9d00daa5-625f-4bbd-bf6d-5b0d1b899fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-6d5e3de6-8434-47f7-811f-bae99403fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-92c9b66c-0f68-47f4-97f8-9263d38e69b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-85977139-63c3-4ff8-adc4-fba6b1c47791,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-b11f44b6-d02b-4eab-b571-7ce548940ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298952844-172.17.0.18-1598649141014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-832e2bb4-5c82-4666-ac12-f9eb725acc13,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-682cb4d8-5fbb-4ec3-91b6-634f209c437a,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-241f81e4-bd99-46c5-a0ed-1928ed5a10bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-9d00daa5-625f-4bbd-bf6d-5b0d1b899fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-6d5e3de6-8434-47f7-811f-bae99403fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-92c9b66c-0f68-47f4-97f8-9263d38e69b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-85977139-63c3-4ff8-adc4-fba6b1c47791,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-b11f44b6-d02b-4eab-b571-7ce548940ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676569004-172.17.0.18-1598649250454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-2800e368-1d55-48ea-93ff-3284955838ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-c59319e0-33ad-4b39-be80-67a0cc1335cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-3148bd71-a241-4883-96e4-a90a12a4e900,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-0c26e324-1795-4a09-9b23-47dd12985793,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-d5b34077-9b55-47ee-b6be-2fee95f5e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-1fbacd0b-b9ee-449c-8b7f-4c708443ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e03673a2-f3e1-4f54-b6e0-3357a97793df,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-15f24783-958d-404d-89d1-0f95967b2580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676569004-172.17.0.18-1598649250454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32891,DS-2800e368-1d55-48ea-93ff-3284955838ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-c59319e0-33ad-4b39-be80-67a0cc1335cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-3148bd71-a241-4883-96e4-a90a12a4e900,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-0c26e324-1795-4a09-9b23-47dd12985793,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-d5b34077-9b55-47ee-b6be-2fee95f5e5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-1fbacd0b-b9ee-449c-8b7f-4c708443ab09,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e03673a2-f3e1-4f54-b6e0-3357a97793df,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-15f24783-958d-404d-89d1-0f95967b2580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910871375-172.17.0.18-1598649396833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40479,DS-9a783652-028c-4dbd-b4a8-26bc244da6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6b1a0774-876f-4983-8609-fcca0591490a,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3b9924f6-d6bb-4017-8928-6eeb335d78ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-71348971-c813-46ba-8bfd-680aa72b1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ef0fcb23-f7c0-4ff2-b4d4-436c1b9459d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-94eafd52-c237-4835-bcfc-b8346174a554,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-433d17f0-3b64-4c84-b710-671ecd276b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-8d9af764-23c8-45b9-988b-09b6d2adcba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910871375-172.17.0.18-1598649396833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40479,DS-9a783652-028c-4dbd-b4a8-26bc244da6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6b1a0774-876f-4983-8609-fcca0591490a,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-3b9924f6-d6bb-4017-8928-6eeb335d78ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-71348971-c813-46ba-8bfd-680aa72b1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-ef0fcb23-f7c0-4ff2-b4d4-436c1b9459d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-94eafd52-c237-4835-bcfc-b8346174a554,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-433d17f0-3b64-4c84-b710-671ecd276b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-8d9af764-23c8-45b9-988b-09b6d2adcba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056944620-172.17.0.18-1598649987571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-509797a1-6b3e-458b-a4a6-c37200ad30ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-2bfcd912-080f-4e90-aa53-a547da459b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-25d0912d-fb05-423d-adca-d8920d61b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-75359d30-cac2-4714-b097-91b981bc97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-d88da19f-143d-4400-89bb-71a66a91c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-d9ebbb8d-0b1d-4485-951d-3617fbf69a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-3aaeba7c-cd66-4f68-984d-c9ff19509ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-d9acfa50-fbd7-48da-a7b1-198ecf67ef6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056944620-172.17.0.18-1598649987571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-509797a1-6b3e-458b-a4a6-c37200ad30ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-2bfcd912-080f-4e90-aa53-a547da459b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-25d0912d-fb05-423d-adca-d8920d61b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-75359d30-cac2-4714-b097-91b981bc97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-d88da19f-143d-4400-89bb-71a66a91c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-d9ebbb8d-0b1d-4485-951d-3617fbf69a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-3aaeba7c-cd66-4f68-984d-c9ff19509ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-d9acfa50-fbd7-48da-a7b1-198ecf67ef6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5535
