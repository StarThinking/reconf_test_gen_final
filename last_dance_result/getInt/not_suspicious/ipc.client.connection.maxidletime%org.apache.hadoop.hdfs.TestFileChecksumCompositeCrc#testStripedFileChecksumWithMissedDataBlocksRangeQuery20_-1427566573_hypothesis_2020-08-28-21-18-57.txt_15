reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963869013-172.17.0.12-1598649550199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-347caf13-d3f3-4958-a408-73092bbb164c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2beac6f8-02ae-45f5-bd78-43fb236ab9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-9c0ea021-cdd9-4cec-92e5-9ee6a54956a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9ad985bd-cec0-4926-9105-c0b7baf64d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-ea1ad13a-399b-47ab-afb3-5d0313dc4735,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-2eb31437-93b0-4b58-b698-f1b9c88ed5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-8615efa0-7cfd-4c54-87fb-ca1d7d4bba27,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-9a5c4b15-ec72-491e-8b8f-4b7958db70a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963869013-172.17.0.12-1598649550199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-347caf13-d3f3-4958-a408-73092bbb164c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-2beac6f8-02ae-45f5-bd78-43fb236ab9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-9c0ea021-cdd9-4cec-92e5-9ee6a54956a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9ad985bd-cec0-4926-9105-c0b7baf64d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-ea1ad13a-399b-47ab-afb3-5d0313dc4735,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-2eb31437-93b0-4b58-b698-f1b9c88ed5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-8615efa0-7cfd-4c54-87fb-ca1d7d4bba27,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-9a5c4b15-ec72-491e-8b8f-4b7958db70a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522064044-172.17.0.12-1598649591328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33730,DS-60de6f22-dc95-4913-b9e1-204af4b0ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-d3f8e6df-f8cd-4d66-ab75-14a5ad09013d,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-b3ddea4d-c2fc-4555-a4bd-e6e50d2a0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-c7fd87d8-78ff-4060-9c9b-3ee18c460576,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-18853837-f678-4c12-824a-df18e8b8603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-09490148-61db-47b4-8876-47289a635a04,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-5646e993-fb20-4035-9100-3bff4529e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-79a351d1-3217-4100-97d9-efd00c9257c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522064044-172.17.0.12-1598649591328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33730,DS-60de6f22-dc95-4913-b9e1-204af4b0ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-d3f8e6df-f8cd-4d66-ab75-14a5ad09013d,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-b3ddea4d-c2fc-4555-a4bd-e6e50d2a0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-c7fd87d8-78ff-4060-9c9b-3ee18c460576,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-18853837-f678-4c12-824a-df18e8b8603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-09490148-61db-47b4-8876-47289a635a04,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-5646e993-fb20-4035-9100-3bff4529e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-79a351d1-3217-4100-97d9-efd00c9257c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591121578-172.17.0.12-1598649805497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43390,DS-e5aa6acf-d8b3-4ef7-b969-99ada772911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-d17be9ce-432e-46f4-bd62-ff402902655a,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9933df1a-ab1a-45c5-b113-4ce373fe4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-6ed78d5c-8c2a-4782-b470-8d553d2df512,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-40e0ed44-3ee9-4841-84ad-1ef5a7a6b258,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-b6a7dc6b-d4c8-4f6b-b315-0cc860064931,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-abb9ad5a-9b55-4c0d-ad1c-eda0583b4884,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-dc477954-ca7d-49ed-88c1-addf35562c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591121578-172.17.0.12-1598649805497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43390,DS-e5aa6acf-d8b3-4ef7-b969-99ada772911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-d17be9ce-432e-46f4-bd62-ff402902655a,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-9933df1a-ab1a-45c5-b113-4ce373fe4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-6ed78d5c-8c2a-4782-b470-8d553d2df512,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-40e0ed44-3ee9-4841-84ad-1ef5a7a6b258,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-b6a7dc6b-d4c8-4f6b-b315-0cc860064931,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-abb9ad5a-9b55-4c0d-ad1c-eda0583b4884,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-dc477954-ca7d-49ed-88c1-addf35562c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756161190-172.17.0.12-1598649874786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-e5649d70-3cae-4ab8-86cb-a1655a42fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-bf814837-c5f0-47e5-bfe9-9476d576dc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8c0dc102-0d7a-464f-8efb-1d4c5d6056b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-5eae54cc-cca8-40fb-a969-0aebc1eda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b4fa8718-8489-4793-906b-0dca5f8a3ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-4c6f3706-f521-4a1f-9580-3d0739694cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-053e7282-36e2-4613-a3bf-2dceb62c43c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-c59aebe3-8795-46d7-a742-48fa707f8064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756161190-172.17.0.12-1598649874786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38007,DS-e5649d70-3cae-4ab8-86cb-a1655a42fe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-bf814837-c5f0-47e5-bfe9-9476d576dc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8c0dc102-0d7a-464f-8efb-1d4c5d6056b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-5eae54cc-cca8-40fb-a969-0aebc1eda2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-b4fa8718-8489-4793-906b-0dca5f8a3ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-4c6f3706-f521-4a1f-9580-3d0739694cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-053e7282-36e2-4613-a3bf-2dceb62c43c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-c59aebe3-8795-46d7-a742-48fa707f8064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650642690-172.17.0.12-1598649997845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-8eea48b5-4248-45b5-a0d9-bc65fce36d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-766fa141-71f3-4f7c-aeb7-e1955eacbf64,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-cb408c7e-4295-4416-8a60-0efdcbebeaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-848a0054-8383-4185-9fd8-7d78917ed7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-9ad1bad6-53b5-4772-8d8d-b01d8953527b,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-6c5b4f8a-0266-410b-8e8a-ea2d9e54cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-108dd788-b99f-4c20-b95d-27471f05b942,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-31e8a9e0-364f-461d-8b11-7d28918a6052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650642690-172.17.0.12-1598649997845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-8eea48b5-4248-45b5-a0d9-bc65fce36d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-766fa141-71f3-4f7c-aeb7-e1955eacbf64,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-cb408c7e-4295-4416-8a60-0efdcbebeaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-848a0054-8383-4185-9fd8-7d78917ed7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-9ad1bad6-53b5-4772-8d8d-b01d8953527b,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-6c5b4f8a-0266-410b-8e8a-ea2d9e54cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-108dd788-b99f-4c20-b95d-27471f05b942,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-31e8a9e0-364f-461d-8b11-7d28918a6052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904621261-172.17.0.12-1598650095978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-84157144-fbe1-4d78-adc3-be675b353b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-1b4c5f94-d27a-4c8d-b800-cf75d049cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-29467acd-818f-4de5-8db9-662e2818b377,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5d173795-b83c-4caa-93cd-8c340affdb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-45661753-8400-4917-898d-cd44d27c9886,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-77812f78-1615-48f1-8f5b-621887a57255,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-2f811fde-a583-4ea5-9d82-49d034358412,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-f86ddc0c-c80a-4f9a-8666-ee8d84e82334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-904621261-172.17.0.12-1598650095978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37203,DS-84157144-fbe1-4d78-adc3-be675b353b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-1b4c5f94-d27a-4c8d-b800-cf75d049cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-29467acd-818f-4de5-8db9-662e2818b377,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5d173795-b83c-4caa-93cd-8c340affdb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-45661753-8400-4917-898d-cd44d27c9886,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-77812f78-1615-48f1-8f5b-621887a57255,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-2f811fde-a583-4ea5-9d82-49d034358412,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-f86ddc0c-c80a-4f9a-8666-ee8d84e82334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378115969-172.17.0.12-1598650225077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-c16bbbb6-7507-4c77-98a4-d9be9f154fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-e1b385eb-cabc-450b-90b5-1555f19a7665,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-8b690a12-c36f-4e7f-b2aa-2958df0f501d,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-8917eaeb-fa0f-415f-8c83-d162bba405c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-fae8e06d-4bf8-4d96-b38b-70986216a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-dbab351e-1e6a-4122-9d70-3768b58edd22,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-d93d1bd0-8aa1-460a-a55c-16ec594a2112,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-20bb7b23-2bc6-438f-b499-75eaed670a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378115969-172.17.0.12-1598650225077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-c16bbbb6-7507-4c77-98a4-d9be9f154fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-e1b385eb-cabc-450b-90b5-1555f19a7665,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-8b690a12-c36f-4e7f-b2aa-2958df0f501d,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-8917eaeb-fa0f-415f-8c83-d162bba405c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-fae8e06d-4bf8-4d96-b38b-70986216a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-dbab351e-1e6a-4122-9d70-3768b58edd22,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-d93d1bd0-8aa1-460a-a55c-16ec594a2112,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-20bb7b23-2bc6-438f-b499-75eaed670a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231034492-172.17.0.12-1598650257087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-b59500d5-e92a-4818-ba56-cdb881b77f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d7979dec-8165-4586-ab20-c0c8320ae270,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-0ba4a9b5-545e-4cd5-8f46-bc2014873f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-563c7a2f-f9ee-46ed-bf54-dfc47fc7fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-28f898cf-fcbc-437e-83fd-bb1141c1003c,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-4f07f6db-e679-4d32-bfe1-e39deedf37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-4f648aa5-5f79-49df-863a-85c135ce2856,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-48eb24c2-f5c1-4587-ae3c-d80ce82bf37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231034492-172.17.0.12-1598650257087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-b59500d5-e92a-4818-ba56-cdb881b77f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d7979dec-8165-4586-ab20-c0c8320ae270,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-0ba4a9b5-545e-4cd5-8f46-bc2014873f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-563c7a2f-f9ee-46ed-bf54-dfc47fc7fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-28f898cf-fcbc-437e-83fd-bb1141c1003c,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-4f07f6db-e679-4d32-bfe1-e39deedf37f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-4f648aa5-5f79-49df-863a-85c135ce2856,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-48eb24c2-f5c1-4587-ae3c-d80ce82bf37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475916477-172.17.0.12-1598650590785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38862,DS-7ddbb7cb-87b9-4e11-9292-8bde8c3fe71d,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-8f8a152b-e2d9-493e-b349-85572d7208c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ba27a99a-1962-47d9-86c0-abcda71f355a,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-16fe81ef-1daf-4090-87a8-d81e9b0c8729,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0ef7ec5f-b1f2-40f9-8e5b-443b2e2b9708,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-299a869c-ac8f-4f95-94dd-5969196c9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-320cdc46-787f-467c-a992-b652d87d73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-f27078f4-adf9-49b0-bd48-d9b6720d5379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475916477-172.17.0.12-1598650590785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38862,DS-7ddbb7cb-87b9-4e11-9292-8bde8c3fe71d,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-8f8a152b-e2d9-493e-b349-85572d7208c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ba27a99a-1962-47d9-86c0-abcda71f355a,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-16fe81ef-1daf-4090-87a8-d81e9b0c8729,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0ef7ec5f-b1f2-40f9-8e5b-443b2e2b9708,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-299a869c-ac8f-4f95-94dd-5969196c9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-320cdc46-787f-467c-a992-b652d87d73b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-f27078f4-adf9-49b0-bd48-d9b6720d5379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421096302-172.17.0.12-1598650998892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39688,DS-6d3adf87-39a9-4285-8e5c-c5636ac76acc,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-ca664be5-b7c2-40de-af96-eb29eb7edd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-b6a6450b-f41b-47da-bed3-01c583bd085c,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-763d1ca3-88ef-4bf0-be59-6714612f24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-155517e5-27c3-4969-a7be-1875be20e985,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d0435bc6-95ae-42c6-822a-cf59045b6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-ad546c25-0202-4725-aec8-a3b3a451ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-73719bd7-7681-4971-9cf8-92753ba662c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421096302-172.17.0.12-1598650998892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39688,DS-6d3adf87-39a9-4285-8e5c-c5636ac76acc,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-ca664be5-b7c2-40de-af96-eb29eb7edd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-b6a6450b-f41b-47da-bed3-01c583bd085c,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-763d1ca3-88ef-4bf0-be59-6714612f24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-155517e5-27c3-4969-a7be-1875be20e985,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d0435bc6-95ae-42c6-822a-cf59045b6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-ad546c25-0202-4725-aec8-a3b3a451ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-73719bd7-7681-4971-9cf8-92753ba662c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734049569-172.17.0.12-1598652446512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-fb4b54f6-4eed-45c1-95ae-039ab7dc1bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-2c2490d7-9661-4468-8d58-59c6c01f8b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-b3eb6041-3d6b-4bd9-b1fe-d81c6021573a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-f686830c-51d6-45fd-8e0e-91b5cf2d5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ea5d45a6-5c48-493f-8d16-164fce561797,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-1f2bb48d-c894-451d-a910-a683924887a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-dd75d826-f526-4c3b-82c7-0f6afa3dbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-35b8c177-28a5-4e2d-86b5-a1350610f3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734049569-172.17.0.12-1598652446512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-fb4b54f6-4eed-45c1-95ae-039ab7dc1bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-2c2490d7-9661-4468-8d58-59c6c01f8b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-b3eb6041-3d6b-4bd9-b1fe-d81c6021573a,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-f686830c-51d6-45fd-8e0e-91b5cf2d5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-ea5d45a6-5c48-493f-8d16-164fce561797,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-1f2bb48d-c894-451d-a910-a683924887a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-dd75d826-f526-4c3b-82c7-0f6afa3dbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-35b8c177-28a5-4e2d-86b5-a1350610f3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473210856-172.17.0.12-1598652936001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-d748f47e-bb46-4f18-b200-254d954e622a,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-77476b29-3f65-4868-b65a-005a05116e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-6c64bf39-5630-47ff-ade1-4020969277e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-52d197b0-ab37-47c4-b398-3bc4837baf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-f5da10ec-8163-4e19-8f2e-14aa0cbef467,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-e6115218-598d-4c26-aa0e-d128770e8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-3a1d5aeb-ce75-4ca7-b63e-b664d50aee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-039be88f-d065-44b4-bd68-b7baaf4148c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473210856-172.17.0.12-1598652936001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-d748f47e-bb46-4f18-b200-254d954e622a,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-77476b29-3f65-4868-b65a-005a05116e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-6c64bf39-5630-47ff-ade1-4020969277e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-52d197b0-ab37-47c4-b398-3bc4837baf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-f5da10ec-8163-4e19-8f2e-14aa0cbef467,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-e6115218-598d-4c26-aa0e-d128770e8fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-3a1d5aeb-ce75-4ca7-b63e-b664d50aee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-039be88f-d065-44b4-bd68-b7baaf4148c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415100908-172.17.0.12-1598653382935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-b93ba4f1-7740-4aee-a589-96c9c748d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-8573912d-eb83-4d82-988a-28797e1bf611,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-17447f27-3a51-453f-a49d-5e0672ce0536,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-11228a3c-604b-4cb1-a709-f7f7f2fbeef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-7e3fda13-9cf5-495e-8485-a3ae85e7e2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-96efb413-9521-4052-a444-fcbf0acfd51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-140a0308-23c6-4ddd-beba-8e7ea7524e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-0827daba-bfc0-4244-8222-5aac8cc7f3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415100908-172.17.0.12-1598653382935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-b93ba4f1-7740-4aee-a589-96c9c748d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-8573912d-eb83-4d82-988a-28797e1bf611,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-17447f27-3a51-453f-a49d-5e0672ce0536,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-11228a3c-604b-4cb1-a709-f7f7f2fbeef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-7e3fda13-9cf5-495e-8485-a3ae85e7e2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-96efb413-9521-4052-a444-fcbf0acfd51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-140a0308-23c6-4ddd-beba-8e7ea7524e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-0827daba-bfc0-4244-8222-5aac8cc7f3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503399867-172.17.0.12-1598653917225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-6c2726b1-b502-489a-8389-80ffe9f4bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-0454932f-4142-4621-9e68-792862fef2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-c4d56e07-cd10-4389-8ca9-366b3075b715,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-26913e9a-3520-46ce-969f-361ad5b27fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2d3dfb47-1a80-462a-9025-c160f42e3e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-deeac449-1412-4224-aa96-033b5fc4fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-421eae7d-d1a5-41fd-bbc7-e56dcc64ced1,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7560f215-33d1-4bce-b26e-a9ba5a28a9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503399867-172.17.0.12-1598653917225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-6c2726b1-b502-489a-8389-80ffe9f4bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-0454932f-4142-4621-9e68-792862fef2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-c4d56e07-cd10-4389-8ca9-366b3075b715,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-26913e9a-3520-46ce-969f-361ad5b27fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2d3dfb47-1a80-462a-9025-c160f42e3e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-deeac449-1412-4224-aa96-033b5fc4fd66,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-421eae7d-d1a5-41fd-bbc7-e56dcc64ced1,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7560f215-33d1-4bce-b26e-a9ba5a28a9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106970680-172.17.0.12-1598653988271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-9243a62e-3a8b-40b1-83b9-4fd306921b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-7955efe8-b90b-4d63-a98d-ec0edd7c873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-307d2a88-a642-4095-b03e-0176907b643f,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-5d5791bd-d383-4842-9519-2b526ab257c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-4a19161e-08b1-4e32-bb0f-583469c96306,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-83067e17-847a-41e5-9a18-c8d43ff3acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9f5ba706-71f9-4a62-8c80-2436ba2be43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-ec8d7c1a-0ed6-4796-9be2-31e9ab764aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106970680-172.17.0.12-1598653988271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44850,DS-9243a62e-3a8b-40b1-83b9-4fd306921b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-7955efe8-b90b-4d63-a98d-ec0edd7c873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-307d2a88-a642-4095-b03e-0176907b643f,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-5d5791bd-d383-4842-9519-2b526ab257c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-4a19161e-08b1-4e32-bb0f-583469c96306,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-83067e17-847a-41e5-9a18-c8d43ff3acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-9f5ba706-71f9-4a62-8c80-2436ba2be43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-ec8d7c1a-0ed6-4796-9be2-31e9ab764aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083096399-172.17.0.12-1598654230213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-0b354f0f-c652-4530-ab2e-5d85feb23ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-efe374e6-c039-48af-8b04-7b4b7a7e0b89,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-571ac2c9-913c-41f1-b5f5-d1ae4b251e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-318934df-fc3d-4016-b31c-017092715bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-3d43aa9d-0723-48ca-8518-5774e7780682,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-59730384-0eac-48a0-b223-e76e0ced409c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-2aa617c9-74a9-4a27-b310-7b63989fec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-2b574acd-4dec-4cc8-af62-e538daa238df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083096399-172.17.0.12-1598654230213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-0b354f0f-c652-4530-ab2e-5d85feb23ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-efe374e6-c039-48af-8b04-7b4b7a7e0b89,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-571ac2c9-913c-41f1-b5f5-d1ae4b251e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-318934df-fc3d-4016-b31c-017092715bac,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-3d43aa9d-0723-48ca-8518-5774e7780682,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-59730384-0eac-48a0-b223-e76e0ced409c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-2aa617c9-74a9-4a27-b310-7b63989fec1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-2b574acd-4dec-4cc8-af62-e538daa238df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5055
