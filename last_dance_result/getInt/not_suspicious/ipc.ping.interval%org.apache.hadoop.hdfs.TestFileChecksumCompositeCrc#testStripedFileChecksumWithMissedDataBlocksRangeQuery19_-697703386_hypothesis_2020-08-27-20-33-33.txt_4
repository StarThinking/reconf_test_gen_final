reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027650612-172.17.0.7-1598560499401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-2f08fdd3-d0c0-452c-b21a-beceede5efab,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4a4fd912-b321-4ca8-a8e9-252fd4c4d634,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-1bf219bd-0e60-4522-8f51-8bcb8eb89cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-e122af58-3a23-4743-a6b3-033d553ca047,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-9de32093-3232-438d-9225-f96b071ba6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-79c070f7-0bbd-468f-ae1b-794edb1edf70,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0199570c-5998-441a-b5e4-0cca979c1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-755b45a7-e78a-4461-bc98-86b05565d2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027650612-172.17.0.7-1598560499401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-2f08fdd3-d0c0-452c-b21a-beceede5efab,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4a4fd912-b321-4ca8-a8e9-252fd4c4d634,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-1bf219bd-0e60-4522-8f51-8bcb8eb89cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-e122af58-3a23-4743-a6b3-033d553ca047,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-9de32093-3232-438d-9225-f96b071ba6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-79c070f7-0bbd-468f-ae1b-794edb1edf70,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-0199570c-5998-441a-b5e4-0cca979c1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-755b45a7-e78a-4461-bc98-86b05565d2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847295992-172.17.0.7-1598560686445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-5a512a45-e15b-4a05-ae1a-977463973b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-790da272-8292-428c-9b92-b4476ad88140,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-21d557d6-9da8-4f00-8771-784335f7db64,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ac215048-0861-4ce5-a726-c364298fff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-bb7b36b4-2607-4db8-956a-919d70b3576a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-a33dbfe9-7166-4fce-b0e6-58f28db811e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-d58b9af8-9e91-42d2-a6c1-8473c579e226,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-59a45673-0ef7-4101-a86b-1658061a285d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847295992-172.17.0.7-1598560686445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35369,DS-5a512a45-e15b-4a05-ae1a-977463973b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-790da272-8292-428c-9b92-b4476ad88140,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-21d557d6-9da8-4f00-8771-784335f7db64,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ac215048-0861-4ce5-a726-c364298fff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-bb7b36b4-2607-4db8-956a-919d70b3576a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-a33dbfe9-7166-4fce-b0e6-58f28db811e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-d58b9af8-9e91-42d2-a6c1-8473c579e226,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-59a45673-0ef7-4101-a86b-1658061a285d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360359347-172.17.0.7-1598560791815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-37ec2be2-3c06-4622-967e-460c1f99d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-9783e5cc-bf5e-4ee9-86e5-2c188cdb6f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-ebe7d37b-59bb-4d39-b8e5-89f19e3471ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1c372321-07da-46f8-87d4-ef2b7cebe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-80ff3619-b6ac-4945-a256-034da7306385,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-7f6cbc21-36ec-4df4-8b4e-bf2cf50c8880,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-43e8fb90-6085-4005-8aaa-2d7892ca1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-24056957-435a-428d-b623-0e4e1776e339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360359347-172.17.0.7-1598560791815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-37ec2be2-3c06-4622-967e-460c1f99d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-9783e5cc-bf5e-4ee9-86e5-2c188cdb6f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-ebe7d37b-59bb-4d39-b8e5-89f19e3471ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-1c372321-07da-46f8-87d4-ef2b7cebe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-80ff3619-b6ac-4945-a256-034da7306385,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-7f6cbc21-36ec-4df4-8b4e-bf2cf50c8880,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-43e8fb90-6085-4005-8aaa-2d7892ca1e85,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-24056957-435a-428d-b623-0e4e1776e339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645447156-172.17.0.7-1598561674584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-25156a48-3ed2-4b0d-b9d7-4b3876dd226d,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-ac9c3c3e-1d7f-45ee-bef2-1949db39b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-46dd4174-4881-4f01-828b-ffc40ca03bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-3abe0def-f843-475c-80f6-d3995b8cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-0f599ee2-1207-4074-803e-b0c5c2420102,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-ae87df9a-329e-4869-857b-2209e28bc3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-5045fa96-a224-4526-88dc-c196c0055b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-267ce216-c389-4ae7-a002-0c25d7ccabd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645447156-172.17.0.7-1598561674584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-25156a48-3ed2-4b0d-b9d7-4b3876dd226d,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-ac9c3c3e-1d7f-45ee-bef2-1949db39b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-46dd4174-4881-4f01-828b-ffc40ca03bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-3abe0def-f843-475c-80f6-d3995b8cb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-0f599ee2-1207-4074-803e-b0c5c2420102,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-ae87df9a-329e-4869-857b-2209e28bc3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-5045fa96-a224-4526-88dc-c196c0055b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-267ce216-c389-4ae7-a002-0c25d7ccabd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865053277-172.17.0.7-1598561852856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-c9104539-62ae-4e41-a876-b7bdc29f96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-5c13f801-ce34-4ad6-bb96-2a17d4144b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-78a3ef03-19c7-49d6-92cb-52545b75be9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-0e206372-dce7-432c-ab29-ac95d58a7f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-7c1659c7-ecd4-4638-a39d-7feeb48e7562,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5cbabd1e-bca4-47f1-8769-d7189d6326c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-25ffa22f-0aef-4fba-bc2a-4f0cb31699ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-af649405-6ab5-4c63-85da-8dee89ca8231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865053277-172.17.0.7-1598561852856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-c9104539-62ae-4e41-a876-b7bdc29f96ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-5c13f801-ce34-4ad6-bb96-2a17d4144b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-78a3ef03-19c7-49d6-92cb-52545b75be9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-0e206372-dce7-432c-ab29-ac95d58a7f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-7c1659c7-ecd4-4638-a39d-7feeb48e7562,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5cbabd1e-bca4-47f1-8769-d7189d6326c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-25ffa22f-0aef-4fba-bc2a-4f0cb31699ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-af649405-6ab5-4c63-85da-8dee89ca8231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775706883-172.17.0.7-1598562054560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-b69d2096-58b9-49b3-8d4f-648f8e388253,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-1d721d3f-f660-4c47-a001-9365346beba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-1eb7c8b7-81cb-40cf-a2f2-cedf49597041,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-1217f08f-e965-4365-8f3b-00718b9deab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-6691ed98-a15f-4aed-b06f-1318d69323b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2e91214a-615a-4f7d-8a8e-f2dc40e654a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-f8323ac3-aecb-414c-a656-2dec5e53fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-b6e2de7c-b81c-48d5-a336-72320b3572dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775706883-172.17.0.7-1598562054560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-b69d2096-58b9-49b3-8d4f-648f8e388253,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-1d721d3f-f660-4c47-a001-9365346beba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-1eb7c8b7-81cb-40cf-a2f2-cedf49597041,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-1217f08f-e965-4365-8f3b-00718b9deab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-6691ed98-a15f-4aed-b06f-1318d69323b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2e91214a-615a-4f7d-8a8e-f2dc40e654a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-f8323ac3-aecb-414c-a656-2dec5e53fff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-b6e2de7c-b81c-48d5-a336-72320b3572dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777910504-172.17.0.7-1598562551289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-e63d94e0-57e6-481f-ba65-f6ecb59fca96,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-f270b322-ad73-434b-b5fb-181a9a6f870b,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-68c96b02-47a4-4a30-b602-b815f2de8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-ed0e41a0-4333-46a5-ad43-f39dc00c53c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-9734cf3f-b686-4c80-b73f-a74401ad4d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-93f13842-a262-4e94-9814-3a6311ee08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-5e46c37f-bdf1-4f9a-999e-f2bb923acb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-020d1d48-4472-488a-8213-356619b09409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777910504-172.17.0.7-1598562551289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-e63d94e0-57e6-481f-ba65-f6ecb59fca96,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-f270b322-ad73-434b-b5fb-181a9a6f870b,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-68c96b02-47a4-4a30-b602-b815f2de8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-ed0e41a0-4333-46a5-ad43-f39dc00c53c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-9734cf3f-b686-4c80-b73f-a74401ad4d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-93f13842-a262-4e94-9814-3a6311ee08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-5e46c37f-bdf1-4f9a-999e-f2bb923acb22,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-020d1d48-4472-488a-8213-356619b09409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650414915-172.17.0.7-1598562660329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-680d48a8-deef-4fec-923e-11c735b6f896,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-70c218e3-bb5f-489f-86a5-706a512962b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-9492c181-d838-44f2-981b-29ba2afd593d,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-621300d4-148e-4fcf-aa13-71307447db17,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-021e35f3-b44a-4129-9366-acdacf8ad931,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-9e25ef2c-f0e3-48f2-94ca-b0918de62f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-ffd2af8c-40ce-441d-bb30-ea08d66594c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-9793149c-0a11-4ec8-91f5-dffd74d40132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650414915-172.17.0.7-1598562660329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-680d48a8-deef-4fec-923e-11c735b6f896,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-70c218e3-bb5f-489f-86a5-706a512962b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-9492c181-d838-44f2-981b-29ba2afd593d,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-621300d4-148e-4fcf-aa13-71307447db17,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-021e35f3-b44a-4129-9366-acdacf8ad931,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-9e25ef2c-f0e3-48f2-94ca-b0918de62f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-ffd2af8c-40ce-441d-bb30-ea08d66594c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-9793149c-0a11-4ec8-91f5-dffd74d40132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016451123-172.17.0.7-1598562959722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-6b1008c5-1a6c-4138-b2b6-fa8c4ee49e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-410d5bc1-9e9f-48bc-8c12-85ee96ed81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-1c275502-c403-473a-ab63-3b9136256d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-86df69e2-0759-47ab-a948-87c664b54e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-2d98c2c3-a913-4fa1-aec7-6847704abdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-44725bbc-d3b4-444e-8b3f-1796f5c7bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e7c96b9a-3245-422a-a9ed-481559d334fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-256480ee-6381-400e-ad6f-61d98e29475c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016451123-172.17.0.7-1598562959722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-6b1008c5-1a6c-4138-b2b6-fa8c4ee49e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-410d5bc1-9e9f-48bc-8c12-85ee96ed81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-1c275502-c403-473a-ab63-3b9136256d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-86df69e2-0759-47ab-a948-87c664b54e93,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-2d98c2c3-a913-4fa1-aec7-6847704abdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-44725bbc-d3b4-444e-8b3f-1796f5c7bbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e7c96b9a-3245-422a-a9ed-481559d334fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-256480ee-6381-400e-ad6f-61d98e29475c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342999337-172.17.0.7-1598563236643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36634,DS-dba71820-774c-40f1-889f-fe0e212a4f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-7bc5c4b4-b5ec-4eb4-ad1e-9ef7249e3cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-f4249f70-12f1-450c-a885-ddc2e1dc61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-7a104aa8-d328-429e-9685-fe1ff0fae408,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-732d61bf-0f85-466b-90a2-34b633d0c747,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-1b0a2361-b26e-41c1-b1d1-36445135b968,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-60992d38-541c-43ce-bc3a-376f3638a496,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-245389fb-710e-46c3-9567-6c67b58cf99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342999337-172.17.0.7-1598563236643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36634,DS-dba71820-774c-40f1-889f-fe0e212a4f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-7bc5c4b4-b5ec-4eb4-ad1e-9ef7249e3cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-f4249f70-12f1-450c-a885-ddc2e1dc61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-7a104aa8-d328-429e-9685-fe1ff0fae408,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-732d61bf-0f85-466b-90a2-34b633d0c747,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-1b0a2361-b26e-41c1-b1d1-36445135b968,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-60992d38-541c-43ce-bc3a-376f3638a496,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-245389fb-710e-46c3-9567-6c67b58cf99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861616134-172.17.0.7-1598563426672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-919fa4e0-38a2-4027-a6fb-3f52a4558e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-f3eda3a8-ae85-4449-9211-90fd09f7f045,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7fc8fd18-cac9-4b2c-9706-4d0268ab7368,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-5ccbb459-7b13-4fd8-a520-f2b4f8330cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6f25ef5d-9bed-4fe8-8c26-53965bfc25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-85a86ad9-6fbc-4621-8706-bbecfcfa0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cd643a4b-b1e1-4cc0-81ff-8b2b34c120f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-fd795990-2f94-42bb-bcd6-5757cf3361ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861616134-172.17.0.7-1598563426672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36415,DS-919fa4e0-38a2-4027-a6fb-3f52a4558e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-f3eda3a8-ae85-4449-9211-90fd09f7f045,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7fc8fd18-cac9-4b2c-9706-4d0268ab7368,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-5ccbb459-7b13-4fd8-a520-f2b4f8330cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6f25ef5d-9bed-4fe8-8c26-53965bfc25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-85a86ad9-6fbc-4621-8706-bbecfcfa0e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cd643a4b-b1e1-4cc0-81ff-8b2b34c120f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-fd795990-2f94-42bb-bcd6-5757cf3361ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024015622-172.17.0.7-1598564170472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-d25d0a8a-6db9-44b4-9dd3-0912a8128274,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-639a43f6-efe7-4ba6-bbbf-7d36e3d3ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-5aa0b68a-e1ae-4ed6-be80-0ea31fe9a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-addd7fba-2bcc-4218-a110-db16bd722369,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-cac8477d-635b-41ec-b1f5-565b3d85bf52,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-ce49a2f6-4cd0-4124-bb4b-1d139174d11d,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-472828ba-ef01-4b23-aa74-36b12a00fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-6c88f0be-5f2b-4184-9a44-e3da5d6c8438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024015622-172.17.0.7-1598564170472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-d25d0a8a-6db9-44b4-9dd3-0912a8128274,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-639a43f6-efe7-4ba6-bbbf-7d36e3d3ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-5aa0b68a-e1ae-4ed6-be80-0ea31fe9a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-addd7fba-2bcc-4218-a110-db16bd722369,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-cac8477d-635b-41ec-b1f5-565b3d85bf52,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-ce49a2f6-4cd0-4124-bb4b-1d139174d11d,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-472828ba-ef01-4b23-aa74-36b12a00fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-6c88f0be-5f2b-4184-9a44-e3da5d6c8438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090412497-172.17.0.7-1598564389441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34290,DS-1c737610-533c-4095-9e84-eed201cdc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f46ef4ac-20db-4f54-8719-663aab6246e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b4f5e686-156b-44bc-be16-7c7a0171b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-beb957e0-9aa7-4fe3-8e99-2b759f968e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-ec2ecbe6-a8e8-4aac-851b-4e6962010ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-91184e3a-b01b-4580-b34b-a74ba27b6774,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-e2485ff0-0b35-4549-bf53-8e76b02d345b,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0e3a0f0a-8d65-48da-8bc4-751616553f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090412497-172.17.0.7-1598564389441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34290,DS-1c737610-533c-4095-9e84-eed201cdc81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f46ef4ac-20db-4f54-8719-663aab6246e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b4f5e686-156b-44bc-be16-7c7a0171b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-beb957e0-9aa7-4fe3-8e99-2b759f968e61,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-ec2ecbe6-a8e8-4aac-851b-4e6962010ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-91184e3a-b01b-4580-b34b-a74ba27b6774,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-e2485ff0-0b35-4549-bf53-8e76b02d345b,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0e3a0f0a-8d65-48da-8bc4-751616553f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467831717-172.17.0.7-1598564719967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-48edec30-4a9f-44ee-9742-b654f123b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-3d460b2d-65c0-4e56-bed4-ab9b31e54197,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-2e8d496f-5adb-4839-98e0-0890dc5eff92,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a5325949-cf6b-4924-9d0c-ebf3360384ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-939341cb-ce46-4b94-a38c-9ff7889b70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a137972a-b7ad-43ed-ba3e-b8d01a430d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-8ed3e236-155d-48ed-9273-5d381479d794,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-c190d672-472a-45fb-9937-7c03b2d08b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467831717-172.17.0.7-1598564719967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-48edec30-4a9f-44ee-9742-b654f123b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-3d460b2d-65c0-4e56-bed4-ab9b31e54197,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-2e8d496f-5adb-4839-98e0-0890dc5eff92,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a5325949-cf6b-4924-9d0c-ebf3360384ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-939341cb-ce46-4b94-a38c-9ff7889b70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-a137972a-b7ad-43ed-ba3e-b8d01a430d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-8ed3e236-155d-48ed-9273-5d381479d794,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-c190d672-472a-45fb-9937-7c03b2d08b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138768119-172.17.0.7-1598564934996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-98898d5a-7416-4636-bc48-ad8256cbca64,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-6faf3aa3-1686-4c5f-949f-7fb65617aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-2bbff39e-fa99-4386-b826-c365989eaa46,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-2a6c46d1-bc9a-4bf3-89ea-66c6ba4abc18,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-40b85a9c-52de-4212-847b-893947adf08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-334fd2a1-01a4-4f56-bb4a-92ea12962110,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-664a9fa5-5100-4707-991d-a468f1450d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-646c59e0-43a2-4221-9dfa-bc125f2cd3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138768119-172.17.0.7-1598564934996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-98898d5a-7416-4636-bc48-ad8256cbca64,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-6faf3aa3-1686-4c5f-949f-7fb65617aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-2bbff39e-fa99-4386-b826-c365989eaa46,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-2a6c46d1-bc9a-4bf3-89ea-66c6ba4abc18,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-40b85a9c-52de-4212-847b-893947adf08c,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-334fd2a1-01a4-4f56-bb4a-92ea12962110,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-664a9fa5-5100-4707-991d-a468f1450d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-646c59e0-43a2-4221-9dfa-bc125f2cd3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608517351-172.17.0.7-1598564965412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-9276f511-6eb4-452e-bc57-18c94fc07518,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-0e6e4d25-e773-4b8a-b9eb-67ad7eb34582,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-330bcd15-5ae9-43ff-8072-fa3d4e91110b,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-7cf415be-a6e3-4a87-9b19-834adb3f8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-b3b5f67c-b3e1-4521-bf76-6bc60552b732,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-b5f94a30-f5fa-4137-8fad-cd1b3c2e5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-492a99bf-7927-4a1d-8309-bf42e0bf7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-8cb9ea50-b90a-4a6c-a132-41650b12e67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608517351-172.17.0.7-1598564965412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-9276f511-6eb4-452e-bc57-18c94fc07518,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-0e6e4d25-e773-4b8a-b9eb-67ad7eb34582,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-330bcd15-5ae9-43ff-8072-fa3d4e91110b,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-7cf415be-a6e3-4a87-9b19-834adb3f8b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-b3b5f67c-b3e1-4521-bf76-6bc60552b732,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-b5f94a30-f5fa-4137-8fad-cd1b3c2e5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-492a99bf-7927-4a1d-8309-bf42e0bf7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-8cb9ea50-b90a-4a6c-a132-41650b12e67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035098201-172.17.0.7-1598565462673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44823,DS-2cac50f6-9aaf-4ed7-8e14-8d1ef3fa36cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-4bd3dac1-454a-4b7e-9396-1d6e65f07e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0a9ec42c-641f-4c1b-9866-0fea80455ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-ad1a7eee-73b9-4713-a159-fc76ef96444c,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-0b32243f-2cd3-4f79-8de5-a5837d197d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-69f6e754-2cbf-409a-bc3b-39d66cfe87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-3545ec6a-1fa9-43c5-b3f6-8e730cbc1357,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-14a1bb85-e792-477e-ad30-7787ce75d5db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035098201-172.17.0.7-1598565462673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44823,DS-2cac50f6-9aaf-4ed7-8e14-8d1ef3fa36cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-4bd3dac1-454a-4b7e-9396-1d6e65f07e28,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-0a9ec42c-641f-4c1b-9866-0fea80455ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-ad1a7eee-73b9-4713-a159-fc76ef96444c,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-0b32243f-2cd3-4f79-8de5-a5837d197d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-69f6e754-2cbf-409a-bc3b-39d66cfe87c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-3545ec6a-1fa9-43c5-b3f6-8e730cbc1357,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-14a1bb85-e792-477e-ad30-7787ce75d5db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5065
