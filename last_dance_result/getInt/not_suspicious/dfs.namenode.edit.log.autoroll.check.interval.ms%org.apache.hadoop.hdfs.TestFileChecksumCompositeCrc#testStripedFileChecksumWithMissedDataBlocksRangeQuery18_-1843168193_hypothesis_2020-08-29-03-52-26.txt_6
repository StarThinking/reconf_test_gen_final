reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480967997-172.17.0.9-1598673313716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-c36a025f-6a19-4c0d-8422-576c9ea44c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-d38011ce-156e-41a8-817f-682442dd50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-d19ad036-7303-4819-a784-b4cfe51db80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-698113f0-1781-4da7-97dc-878e2ba8c3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-74f0ff16-ed32-46b4-9598-b49b2b28d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-fa5fe84a-053c-4d9e-bd95-02f74eeb38de,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-da7ba66d-cf3d-4654-9d64-30b0f1a918c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-284c1b8b-67ba-4bce-b78c-736f84ee81a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480967997-172.17.0.9-1598673313716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-c36a025f-6a19-4c0d-8422-576c9ea44c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-d38011ce-156e-41a8-817f-682442dd50d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-d19ad036-7303-4819-a784-b4cfe51db80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-698113f0-1781-4da7-97dc-878e2ba8c3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-74f0ff16-ed32-46b4-9598-b49b2b28d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-fa5fe84a-053c-4d9e-bd95-02f74eeb38de,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-da7ba66d-cf3d-4654-9d64-30b0f1a918c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-284c1b8b-67ba-4bce-b78c-736f84ee81a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017311154-172.17.0.9-1598673354092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-86fa4639-a296-49f2-aaa5-77d217dfe786,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0a526d34-ea06-44c8-b743-9918b8948c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-14db810f-dd0f-4f07-87d8-95d50cc35f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-d8223d8b-e5bd-401d-b9c9-a1944d3cda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-6819e0a2-ad3c-447f-b7e5-bc9d49fa05da,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-73631ee3-d184-466f-b18f-0d7dfed590f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-50da5f23-1243-4dc3-8560-21eb29003fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-671603c7-c979-436d-84d3-5debc3eed85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017311154-172.17.0.9-1598673354092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-86fa4639-a296-49f2-aaa5-77d217dfe786,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0a526d34-ea06-44c8-b743-9918b8948c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-14db810f-dd0f-4f07-87d8-95d50cc35f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-d8223d8b-e5bd-401d-b9c9-a1944d3cda1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-6819e0a2-ad3c-447f-b7e5-bc9d49fa05da,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-73631ee3-d184-466f-b18f-0d7dfed590f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-50da5f23-1243-4dc3-8560-21eb29003fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-671603c7-c979-436d-84d3-5debc3eed85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816161503-172.17.0.9-1598673392436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-c223bb99-7318-44b9-9433-848a2073d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-d2a4e48f-f6c6-4015-acba-6f8b5ebf43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-807595df-e767-43e2-af73-87fde7514e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ec3e253e-204e-4a99-9c13-86f0bf9ca831,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-a87351b2-7de4-449d-8f58-78a832b7ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-9429b489-4ed4-411b-9928-a41fab795df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-edcd8637-9186-40c3-9811-dd598a1ef9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-dbd3f1aa-da41-437a-807b-bf0db866276c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816161503-172.17.0.9-1598673392436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-c223bb99-7318-44b9-9433-848a2073d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-d2a4e48f-f6c6-4015-acba-6f8b5ebf43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-807595df-e767-43e2-af73-87fde7514e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ec3e253e-204e-4a99-9c13-86f0bf9ca831,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-a87351b2-7de4-449d-8f58-78a832b7ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-9429b489-4ed4-411b-9928-a41fab795df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-edcd8637-9186-40c3-9811-dd598a1ef9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-dbd3f1aa-da41-437a-807b-bf0db866276c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252346195-172.17.0.9-1598673502870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-7f184aaa-021a-4263-b459-3e2d579c8547,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5c505994-cc61-4675-aa53-69f7e83f628a,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-900ddb92-3e0c-4e4a-befe-89f4de8ab191,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-b0861f86-1236-4219-8874-6a04ab62c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-c4ff631e-47f0-43fd-907b-3b749f5df110,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-37915414-9891-41c8-9ec4-e6c3f301cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-9012afdf-abae-46be-a66b-09a43de59a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-0b442952-4f5f-4db0-bab7-44e0e9cdcd3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252346195-172.17.0.9-1598673502870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-7f184aaa-021a-4263-b459-3e2d579c8547,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-5c505994-cc61-4675-aa53-69f7e83f628a,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-900ddb92-3e0c-4e4a-befe-89f4de8ab191,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-b0861f86-1236-4219-8874-6a04ab62c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-c4ff631e-47f0-43fd-907b-3b749f5df110,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-37915414-9891-41c8-9ec4-e6c3f301cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-9012afdf-abae-46be-a66b-09a43de59a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-0b442952-4f5f-4db0-bab7-44e0e9cdcd3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784413056-172.17.0.9-1598673572116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-ca14adc2-1387-4b46-ac54-8d51ecf0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-788c557c-d8bc-4e8b-bbac-b674166fd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c24a79ce-7bdb-44c6-86cf-f055b0be5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-4e7a2ca1-8eb2-42ac-80fd-bfccafbcb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-b9dd8096-6c54-4667-944c-c34d15181fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-432615da-ebe0-4a68-860e-2f096cedb831,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-d2a3d607-1ab6-4193-9f7f-53bb01cc21eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-3ef71dc4-0eb1-4bbc-9448-40c532136243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784413056-172.17.0.9-1598673572116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-ca14adc2-1387-4b46-ac54-8d51ecf0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-788c557c-d8bc-4e8b-bbac-b674166fd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c24a79ce-7bdb-44c6-86cf-f055b0be5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-4e7a2ca1-8eb2-42ac-80fd-bfccafbcb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-b9dd8096-6c54-4667-944c-c34d15181fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-432615da-ebe0-4a68-860e-2f096cedb831,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-d2a3d607-1ab6-4193-9f7f-53bb01cc21eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-3ef71dc4-0eb1-4bbc-9448-40c532136243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159127524-172.17.0.9-1598673935392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-9336d12a-eea4-48c1-a677-7b9ae8eacb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-7468da2b-b132-4f76-b771-38ca3d238635,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-fee552f1-d4e2-42b6-b28e-cc0885b1bfce,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-6a084770-0792-417b-add9-cd87a88bba25,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2771bed0-7b8d-466e-8105-929579f73417,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-61951f33-e412-45d1-ab91-392b71073b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-8a1d47d7-6f3b-410b-9146-38a4189790ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-5440594f-a346-4371-9185-a98f863786b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159127524-172.17.0.9-1598673935392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-9336d12a-eea4-48c1-a677-7b9ae8eacb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-7468da2b-b132-4f76-b771-38ca3d238635,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-fee552f1-d4e2-42b6-b28e-cc0885b1bfce,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-6a084770-0792-417b-add9-cd87a88bba25,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-2771bed0-7b8d-466e-8105-929579f73417,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-61951f33-e412-45d1-ab91-392b71073b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-8a1d47d7-6f3b-410b-9146-38a4189790ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-5440594f-a346-4371-9185-a98f863786b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591423240-172.17.0.9-1598674274719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-012cffb5-a7e5-4c88-b284-ae47d9ed64a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-9d1c9166-d4ff-4202-8083-2f41d167b302,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-ae466fff-2120-47bf-8053-0f102080dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-aa1c31ec-ffbb-4f9d-92c3-b7f1da7f45df,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-a625a285-5656-4925-9eab-00d8626522ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c113f2a4-40a1-4920-9d15-e93a56478104,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-23bcbcc4-f0db-4f8d-9453-d950b1f7c010,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-d0b3cb52-d0f3-494e-9fee-1886fe05ab06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591423240-172.17.0.9-1598674274719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-012cffb5-a7e5-4c88-b284-ae47d9ed64a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-9d1c9166-d4ff-4202-8083-2f41d167b302,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-ae466fff-2120-47bf-8053-0f102080dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-aa1c31ec-ffbb-4f9d-92c3-b7f1da7f45df,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-a625a285-5656-4925-9eab-00d8626522ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c113f2a4-40a1-4920-9d15-e93a56478104,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-23bcbcc4-f0db-4f8d-9453-d950b1f7c010,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-d0b3cb52-d0f3-494e-9fee-1886fe05ab06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144223972-172.17.0.9-1598674620738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-c62fd571-4150-458e-890e-36a26862a770,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-00baf3bf-d79f-447d-885d-b91ed9e6effa,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-52565660-e906-4a78-a019-91f98728ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-c5d4f4e0-962c-4304-9045-0f07ccd577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-f9d16b58-cf52-4672-98f4-8a5280186409,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-db6a2323-6622-4b6c-8056-9295799cb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-30da1f68-ec5f-4ad5-9bec-111424569810,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-887b70e5-1a20-43a6-b279-0746b649cc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144223972-172.17.0.9-1598674620738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-c62fd571-4150-458e-890e-36a26862a770,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-00baf3bf-d79f-447d-885d-b91ed9e6effa,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-52565660-e906-4a78-a019-91f98728ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-c5d4f4e0-962c-4304-9045-0f07ccd577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-f9d16b58-cf52-4672-98f4-8a5280186409,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-db6a2323-6622-4b6c-8056-9295799cb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-30da1f68-ec5f-4ad5-9bec-111424569810,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-887b70e5-1a20-43a6-b279-0746b649cc77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079090698-172.17.0.9-1598674728123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43960,DS-f0da3a1d-c981-4f82-ac49-6c037d8fcf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-0102adca-1526-43a2-88e7-89e512c5c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-c97c7aae-e45e-44c6-8cc4-da5101ae88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-068fcb33-25e7-420b-bbec-fe49950bb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-eeaf0605-b322-4bc2-bcd8-a40069615faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-d5b05891-dc30-4d09-8a70-ada1fec70a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8430b50f-020a-4b5a-9381-4691884fb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-1d5e59b2-7144-4aaa-a533-a6b59ced28bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079090698-172.17.0.9-1598674728123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43960,DS-f0da3a1d-c981-4f82-ac49-6c037d8fcf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-0102adca-1526-43a2-88e7-89e512c5c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-c97c7aae-e45e-44c6-8cc4-da5101ae88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-068fcb33-25e7-420b-bbec-fe49950bb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-eeaf0605-b322-4bc2-bcd8-a40069615faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-d5b05891-dc30-4d09-8a70-ada1fec70a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-8430b50f-020a-4b5a-9381-4691884fb7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-1d5e59b2-7144-4aaa-a533-a6b59ced28bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494166001-172.17.0.9-1598674907137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-d0d10bbb-5a72-4977-904f-9a4f4489bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-34db1cfe-1cfa-4f5b-ac4d-11aec2810ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-47fa66ae-7ea7-4b59-8c9a-a4f700719f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-885ace03-fac2-4f38-ac3d-945e226bb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-76d5a116-7b99-451e-b370-462259c7e728,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-78d82a82-a076-4247-b6de-60b773d48b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-6b975bd2-d1b5-4380-b372-123e6d2681d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-fd06f010-b9f2-45cc-891e-028e12c9490a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494166001-172.17.0.9-1598674907137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-d0d10bbb-5a72-4977-904f-9a4f4489bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-34db1cfe-1cfa-4f5b-ac4d-11aec2810ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-47fa66ae-7ea7-4b59-8c9a-a4f700719f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-885ace03-fac2-4f38-ac3d-945e226bb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-76d5a116-7b99-451e-b370-462259c7e728,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-78d82a82-a076-4247-b6de-60b773d48b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-6b975bd2-d1b5-4380-b372-123e6d2681d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-fd06f010-b9f2-45cc-891e-028e12c9490a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368569630-172.17.0.9-1598675335688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-e3aab138-cb73-4621-80fc-3ff9efd45003,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-838d9b08-d561-4f4d-b693-e1dc843eba71,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-3258c04a-4289-4683-bdfa-a5d3571a508b,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-6dc3c5f5-3ffe-4f8b-9332-d427c83177af,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-112e8c86-f6c6-4561-90e6-16235d74b988,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-7dd63609-23b3-403a-ae19-71e0c86fc609,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-c065db99-64ed-403b-bb17-61599c3b3797,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-c546c100-fc17-4ba2-ad9d-f5a1d03b175e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368569630-172.17.0.9-1598675335688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-e3aab138-cb73-4621-80fc-3ff9efd45003,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-838d9b08-d561-4f4d-b693-e1dc843eba71,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-3258c04a-4289-4683-bdfa-a5d3571a508b,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-6dc3c5f5-3ffe-4f8b-9332-d427c83177af,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-112e8c86-f6c6-4561-90e6-16235d74b988,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-7dd63609-23b3-403a-ae19-71e0c86fc609,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-c065db99-64ed-403b-bb17-61599c3b3797,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-c546c100-fc17-4ba2-ad9d-f5a1d03b175e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069023551-172.17.0.9-1598675479832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-ef0b4519-b6d3-4b7d-9fc9-c738eb8c9930,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-3b36e4b4-12bd-44f0-b0bb-5b359a886da0,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-a62bdedc-3bc1-4b47-87d3-4e6bc0272562,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8f363e9b-7502-4aed-8220-589113a9505d,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-6104b80a-258b-4bbc-965a-962dc646d941,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-4f2ccb8e-6d3b-460e-b695-b9032f119183,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-42cd9014-ba05-4ecf-bf8d-c6f28135181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-fd312538-522e-42f7-b080-21ab6cf30a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069023551-172.17.0.9-1598675479832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-ef0b4519-b6d3-4b7d-9fc9-c738eb8c9930,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-3b36e4b4-12bd-44f0-b0bb-5b359a886da0,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-a62bdedc-3bc1-4b47-87d3-4e6bc0272562,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8f363e9b-7502-4aed-8220-589113a9505d,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-6104b80a-258b-4bbc-965a-962dc646d941,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-4f2ccb8e-6d3b-460e-b695-b9032f119183,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-42cd9014-ba05-4ecf-bf8d-c6f28135181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-fd312538-522e-42f7-b080-21ab6cf30a6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129134399-172.17.0.9-1598675781519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45162,DS-5e754427-1078-49ad-ad6b-3db9039d7667,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-e2d21185-1aec-4cbd-ae9c-f7df4075e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-6c6fd55c-fb1f-463e-9e3d-80187cd39ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-ddaca411-6583-4eed-9a20-4c862356116e,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-12eb61cc-6e6f-45d5-9399-d057b0b90384,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-1ac1d255-d2a9-4410-b065-5ba6edf43027,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-8587b995-8062-456b-accd-c520f42115c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-e34cd441-7766-4d01-800f-7fa2773584ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129134399-172.17.0.9-1598675781519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45162,DS-5e754427-1078-49ad-ad6b-3db9039d7667,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-e2d21185-1aec-4cbd-ae9c-f7df4075e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-6c6fd55c-fb1f-463e-9e3d-80187cd39ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-ddaca411-6583-4eed-9a20-4c862356116e,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-12eb61cc-6e6f-45d5-9399-d057b0b90384,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-1ac1d255-d2a9-4410-b065-5ba6edf43027,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-8587b995-8062-456b-accd-c520f42115c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-e34cd441-7766-4d01-800f-7fa2773584ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002343455-172.17.0.9-1598675842824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-3179564e-fa96-4a5f-b1a9-da01a7bb0079,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-c6c68bcd-6efa-4e8c-9d2f-8e686b83e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-7f29f472-3aa2-4e2f-acf7-e25d658e2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e3a2cba2-6a6c-4585-a142-48c4e0e6078e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-815320f7-5c91-45ad-b2e0-65630c1379e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-ed3c807a-2924-4467-b410-226a22801148,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-fdc535f1-9879-4b3a-b350-d38fe70285c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-d233eac7-6303-465c-8c92-399014e32862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1002343455-172.17.0.9-1598675842824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-3179564e-fa96-4a5f-b1a9-da01a7bb0079,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-c6c68bcd-6efa-4e8c-9d2f-8e686b83e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-7f29f472-3aa2-4e2f-acf7-e25d658e2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-e3a2cba2-6a6c-4585-a142-48c4e0e6078e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-815320f7-5c91-45ad-b2e0-65630c1379e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-ed3c807a-2924-4467-b410-226a22801148,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-fdc535f1-9879-4b3a-b350-d38fe70285c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-d233eac7-6303-465c-8c92-399014e32862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112600942-172.17.0.9-1598676142515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-830d1820-23e3-4cf6-85de-5ecd94802328,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-6841fe56-fa5e-4f5d-82cd-ef36cf85332b,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b558199e-4205-4351-bb1e-014bf1acfe81,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-50e90e1c-92a5-48b8-af30-8aa2e67acfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-41b265f2-ed3f-47dd-97a9-52dc1f7d3f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-9f87cca1-8924-4950-a5c4-61481a159fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-ad31897a-2cc6-4116-af43-fc91798f8163,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c314b00a-000c-43b5-84b5-a1201cd3e1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112600942-172.17.0.9-1598676142515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-830d1820-23e3-4cf6-85de-5ecd94802328,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-6841fe56-fa5e-4f5d-82cd-ef36cf85332b,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b558199e-4205-4351-bb1e-014bf1acfe81,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-50e90e1c-92a5-48b8-af30-8aa2e67acfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-41b265f2-ed3f-47dd-97a9-52dc1f7d3f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-9f87cca1-8924-4950-a5c4-61481a159fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-ad31897a-2cc6-4116-af43-fc91798f8163,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-c314b00a-000c-43b5-84b5-a1201cd3e1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227090811-172.17.0.9-1598676252031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-b12287f6-fb75-4ef1-8df3-6f25a2a52612,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-0c376989-1714-4f35-a9aa-0b264d1a400d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-ff5e17c0-f0a1-409e-978a-300c756769ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-bbdb3062-c73a-4fa2-9363-f05ee1e31b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-fb34029c-1b96-478d-9d98-74a1d1c21931,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-2d36fa29-d3b7-4f47-b960-be979ef0788b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-8322005f-7afa-4c0c-a3c0-1991af2a98d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-62ca7134-0772-4f5f-a4ee-27287c67d5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227090811-172.17.0.9-1598676252031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-b12287f6-fb75-4ef1-8df3-6f25a2a52612,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-0c376989-1714-4f35-a9aa-0b264d1a400d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-ff5e17c0-f0a1-409e-978a-300c756769ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-bbdb3062-c73a-4fa2-9363-f05ee1e31b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-fb34029c-1b96-478d-9d98-74a1d1c21931,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-2d36fa29-d3b7-4f47-b960-be979ef0788b,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-8322005f-7afa-4c0c-a3c0-1991af2a98d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-62ca7134-0772-4f5f-a4ee-27287c67d5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788927451-172.17.0.9-1598676533456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-76bcd20f-4f6b-4b31-adcc-c3f179fefacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-829382db-26cd-424a-b48d-29bc4f93480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-471b2c9d-8985-4a0e-9bf9-8b221b33e640,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-6e818d78-8497-402c-ad4c-e9f99617160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-5bf87ee1-8497-446e-ace2-11245c0d8416,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9ce90643-f159-48fd-80e2-f30bb1391159,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-278e6a6f-c58c-401c-82de-c9bc4a77447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-59185fd9-7de6-47d3-bb3d-42a95cf47a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788927451-172.17.0.9-1598676533456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-76bcd20f-4f6b-4b31-adcc-c3f179fefacb,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-829382db-26cd-424a-b48d-29bc4f93480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-471b2c9d-8985-4a0e-9bf9-8b221b33e640,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-6e818d78-8497-402c-ad4c-e9f99617160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-5bf87ee1-8497-446e-ace2-11245c0d8416,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-9ce90643-f159-48fd-80e2-f30bb1391159,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-278e6a6f-c58c-401c-82de-c9bc4a77447a,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-59185fd9-7de6-47d3-bb3d-42a95cf47a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539692580-172.17.0.9-1598676593952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-54567c4f-54d0-4ad4-b9ec-c303247789e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-991bfbcb-4732-4345-9f30-814a4a4b1774,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-feb2de58-9520-4940-8450-3b306306b897,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-c4630423-8c50-418f-91b7-8e7f14072aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-edd2eb80-7983-48da-b8e4-158d8152735c,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-76c286d3-0dd5-42d0-9b53-2cc3d26577f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-56202049-a0d6-4858-85f6-72dc4144084c,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f7cb9cea-a045-475e-8eda-2d84932043a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539692580-172.17.0.9-1598676593952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-54567c4f-54d0-4ad4-b9ec-c303247789e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-991bfbcb-4732-4345-9f30-814a4a4b1774,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-feb2de58-9520-4940-8450-3b306306b897,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-c4630423-8c50-418f-91b7-8e7f14072aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-edd2eb80-7983-48da-b8e4-158d8152735c,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-76c286d3-0dd5-42d0-9b53-2cc3d26577f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-56202049-a0d6-4858-85f6-72dc4144084c,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-f7cb9cea-a045-475e-8eda-2d84932043a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322598868-172.17.0.9-1598676967996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39565,DS-d42e47ae-087c-4a61-9bce-2f59b067544e,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-b5a5b2ac-b3bd-4360-8486-af533c6bfeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2c497664-349c-400f-805c-dbc83fc1d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-3ca2a419-dbbf-4840-83ab-376162f86383,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-978fa3a2-f37f-42a1-8a58-1c2e5c27fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-9b7dc139-67ca-4118-b9b6-d9fff73dd222,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1045a202-f6b6-4b75-9914-4aa4802b1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-af6aa49b-fe72-4697-90c4-91ca4a4201cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322598868-172.17.0.9-1598676967996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39565,DS-d42e47ae-087c-4a61-9bce-2f59b067544e,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-b5a5b2ac-b3bd-4360-8486-af533c6bfeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2c497664-349c-400f-805c-dbc83fc1d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-3ca2a419-dbbf-4840-83ab-376162f86383,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-978fa3a2-f37f-42a1-8a58-1c2e5c27fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-9b7dc139-67ca-4118-b9b6-d9fff73dd222,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-1045a202-f6b6-4b75-9914-4aa4802b1cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-af6aa49b-fe72-4697-90c4-91ca4a4201cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693536455-172.17.0.9-1598677387107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-b6e88ff7-849d-4479-aa21-efb995feb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-30ae304e-978d-47f7-b391-3ea981d6fc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-888b35ed-8515-428f-9b5a-2678a2a7dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-1e0ea435-bcbb-4939-a229-a5b71419eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-6a5cef4d-a51b-495d-bc1c-2a4da0e96b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-1687ab1d-a186-41ef-89cb-95bd993c0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c71beccb-74cc-4865-b6d8-2d2e6bfcf59b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-889b4853-2467-45ed-8eee-9d6bada85c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693536455-172.17.0.9-1598677387107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-b6e88ff7-849d-4479-aa21-efb995feb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-30ae304e-978d-47f7-b391-3ea981d6fc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-888b35ed-8515-428f-9b5a-2678a2a7dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-1e0ea435-bcbb-4939-a229-a5b71419eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-6a5cef4d-a51b-495d-bc1c-2a4da0e96b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-1687ab1d-a186-41ef-89cb-95bd993c0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c71beccb-74cc-4865-b6d8-2d2e6bfcf59b,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-889b4853-2467-45ed-8eee-9d6bada85c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685916632-172.17.0.9-1598677756319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-7e62e81e-d4c5-40c3-8090-27636b775616,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-e4fd68d8-00cc-40c8-99bc-3efc236de74e,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-6779f17c-4f54-4c58-aa2d-e1e16b16a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-85516332-2b06-4b05-b5eb-0cf16d661583,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-522d3718-431d-41b1-9293-bb7e3f8fb94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-0dcfcce5-3380-44f0-a935-1c3cb8ee39f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-a94bf900-ae5c-4c42-976a-cfbea185d586,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-ce97ad5f-f5c9-485f-a2d4-83f76f2039af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685916632-172.17.0.9-1598677756319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-7e62e81e-d4c5-40c3-8090-27636b775616,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-e4fd68d8-00cc-40c8-99bc-3efc236de74e,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-6779f17c-4f54-4c58-aa2d-e1e16b16a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-85516332-2b06-4b05-b5eb-0cf16d661583,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-522d3718-431d-41b1-9293-bb7e3f8fb94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-0dcfcce5-3380-44f0-a935-1c3cb8ee39f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-a94bf900-ae5c-4c42-976a-cfbea185d586,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-ce97ad5f-f5c9-485f-a2d4-83f76f2039af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511339595-172.17.0.9-1598677838637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-340354c0-b78c-49ee-bb3b-ba937895ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-460210a5-5212-4de7-8971-e466e122c45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-5760efae-95d3-4da0-83df-39d28a6c3597,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-bbbb09c4-ada8-4a14-8f31-366deceb3e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-490eb741-7984-4592-9431-7f7fba674a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-ffe6e542-aa89-42a6-9d7c-9cec38fab397,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-28a9d6f1-7f43-471b-8b91-e0750f01985c,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-f3e7c09e-0643-4b16-9472-4fd952b2751e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511339595-172.17.0.9-1598677838637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-340354c0-b78c-49ee-bb3b-ba937895ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-460210a5-5212-4de7-8971-e466e122c45b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-5760efae-95d3-4da0-83df-39d28a6c3597,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-bbbb09c4-ada8-4a14-8f31-366deceb3e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-490eb741-7984-4592-9431-7f7fba674a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-ffe6e542-aa89-42a6-9d7c-9cec38fab397,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-28a9d6f1-7f43-471b-8b91-e0750f01985c,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-f3e7c09e-0643-4b16-9472-4fd952b2751e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945430200-172.17.0.9-1598678197850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39389,DS-c38e1cb0-4486-4203-9382-b23da7fbb1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-31d4c1ba-01b9-40d4-9a0c-1ab4fe0a1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-97385682-0857-4ac9-8228-b22afd61f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-77166be3-bafd-4d7e-9c3d-524e0e17085d,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed94e159-bca2-47ae-96bc-70a9b9f0a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-59bdd142-b3b9-4cb0-bc61-2c3c27d19b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-b8515a2c-312c-43d3-b319-5562c8a3b901,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-7945ea62-aeac-4b9c-b3fc-5d2c1f3beedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945430200-172.17.0.9-1598678197850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39389,DS-c38e1cb0-4486-4203-9382-b23da7fbb1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-31d4c1ba-01b9-40d4-9a0c-1ab4fe0a1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-97385682-0857-4ac9-8228-b22afd61f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-77166be3-bafd-4d7e-9c3d-524e0e17085d,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed94e159-bca2-47ae-96bc-70a9b9f0a64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-59bdd142-b3b9-4cb0-bc61-2c3c27d19b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-b8515a2c-312c-43d3-b319-5562c8a3b901,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-7945ea62-aeac-4b9c-b3fc-5d2c1f3beedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5366
