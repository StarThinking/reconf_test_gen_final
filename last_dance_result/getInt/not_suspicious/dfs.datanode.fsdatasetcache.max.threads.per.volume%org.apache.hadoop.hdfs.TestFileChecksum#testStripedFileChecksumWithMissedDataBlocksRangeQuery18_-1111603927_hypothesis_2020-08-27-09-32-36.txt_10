reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393585028-172.17.0.13-1598520932898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42882,DS-10e6f061-6aad-4515-9e43-72935d1182e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-b6ed6c90-e72b-479e-9e46-fb084202bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-79bf2c27-b0af-4cd0-9121-7c0a972fe18e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-2fddd500-dfb1-4cd6-943c-c10ab99ee768,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-9eb6877e-dda3-4023-a6c8-7a7db783ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-912dcb3c-9071-49de-8f89-d9cd88d93d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c83dda75-0c2f-4ec0-80e9-b80da31087af,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-73cbb57a-3ce9-4197-8dbd-6d485a19425b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393585028-172.17.0.13-1598520932898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42882,DS-10e6f061-6aad-4515-9e43-72935d1182e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-b6ed6c90-e72b-479e-9e46-fb084202bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-79bf2c27-b0af-4cd0-9121-7c0a972fe18e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-2fddd500-dfb1-4cd6-943c-c10ab99ee768,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-9eb6877e-dda3-4023-a6c8-7a7db783ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-912dcb3c-9071-49de-8f89-d9cd88d93d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-c83dda75-0c2f-4ec0-80e9-b80da31087af,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-73cbb57a-3ce9-4197-8dbd-6d485a19425b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139923118-172.17.0.13-1598521209482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-747060d7-a869-4139-a3c1-7945551700bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-25407e83-f914-4716-ad77-e85927e3c535,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-47f6de02-a35b-425b-8aed-6d124b13080b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-325827f8-c324-4455-8215-6c05585516c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6f2bd0e7-3a02-4e5f-87be-e61cc4737706,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-b15b68f7-dab1-4ba5-9e5c-4a6340781c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b2bc5a91-60e4-46d3-9f99-732f867dfd87,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-2da23faa-b247-4791-98f8-91f35d72c70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139923118-172.17.0.13-1598521209482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-747060d7-a869-4139-a3c1-7945551700bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-25407e83-f914-4716-ad77-e85927e3c535,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-47f6de02-a35b-425b-8aed-6d124b13080b,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-325827f8-c324-4455-8215-6c05585516c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6f2bd0e7-3a02-4e5f-87be-e61cc4737706,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-b15b68f7-dab1-4ba5-9e5c-4a6340781c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b2bc5a91-60e4-46d3-9f99-732f867dfd87,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-2da23faa-b247-4791-98f8-91f35d72c70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613699165-172.17.0.13-1598521730970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-a20a062e-2e57-4b7f-bc1a-b8aca665ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-40f76343-8613-4ab6-bdd9-c2a09b750039,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-14fc1047-258b-4e02-9172-01e3e21a695a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-38f5e6b0-7d08-4e58-ac20-275164ffb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-5670393b-2079-4499-bed5-7fc4eae8ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-b6937399-fc28-4b4e-a29d-1094f1259a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-e3cd6c5d-8819-4deb-a8ce-c6f3c4d0fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-8ad57f32-6c76-406d-a87f-d13b6de56e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613699165-172.17.0.13-1598521730970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-a20a062e-2e57-4b7f-bc1a-b8aca665ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-40f76343-8613-4ab6-bdd9-c2a09b750039,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-14fc1047-258b-4e02-9172-01e3e21a695a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-38f5e6b0-7d08-4e58-ac20-275164ffb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-5670393b-2079-4499-bed5-7fc4eae8ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-b6937399-fc28-4b4e-a29d-1094f1259a93,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-e3cd6c5d-8819-4deb-a8ce-c6f3c4d0fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-8ad57f32-6c76-406d-a87f-d13b6de56e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960664924-172.17.0.13-1598521953351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-0e57614f-7f24-4394-a161-0db0c1c6429e,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c8948596-1064-401b-a470-dd9bf50987ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-51aa2764-2a94-43a4-bd8d-8f203a33be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-2353568e-cf9b-461f-b8cc-ddcc4c4698a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-58d2187b-09c4-43ff-a4bd-933c4cbbccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-765ad260-5191-49de-9ed3-27fa7b5a0929,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ceddeaae-1e7a-48fd-b8e3-295c587e51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-e15b5c5c-df4d-4106-9b94-c2a85ca68a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960664924-172.17.0.13-1598521953351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-0e57614f-7f24-4394-a161-0db0c1c6429e,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c8948596-1064-401b-a470-dd9bf50987ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-51aa2764-2a94-43a4-bd8d-8f203a33be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-2353568e-cf9b-461f-b8cc-ddcc4c4698a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-58d2187b-09c4-43ff-a4bd-933c4cbbccc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-765ad260-5191-49de-9ed3-27fa7b5a0929,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ceddeaae-1e7a-48fd-b8e3-295c587e51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-e15b5c5c-df4d-4106-9b94-c2a85ca68a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378546920-172.17.0.13-1598522458285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-634d5d90-a339-4e5f-b7c9-6fa4a1a8fb33,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-4fc4fd6b-b808-4702-b3ef-448ebf5ba2db,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-73c44275-114b-45fd-a75e-896c716c8626,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-4c0819d2-502a-476d-81a7-4260c7c119d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-de4fb250-8691-4f85-9639-78a2e6eec75c,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5e1baf6c-549e-46bc-ad72-ef6bd0d2974f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-f4698797-f41f-4e49-8c68-16b1022a9928,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-3c5f3ba5-2189-4521-b467-253c03822eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378546920-172.17.0.13-1598522458285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-634d5d90-a339-4e5f-b7c9-6fa4a1a8fb33,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-4fc4fd6b-b808-4702-b3ef-448ebf5ba2db,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-73c44275-114b-45fd-a75e-896c716c8626,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-4c0819d2-502a-476d-81a7-4260c7c119d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-de4fb250-8691-4f85-9639-78a2e6eec75c,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-5e1baf6c-549e-46bc-ad72-ef6bd0d2974f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-f4698797-f41f-4e49-8c68-16b1022a9928,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-3c5f3ba5-2189-4521-b467-253c03822eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138185556-172.17.0.13-1598522902860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-76abe812-c880-42c3-95cf-f6890cda32af,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-901a1630-49ee-44c9-8890-4fdffce9082d,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-5f5a94dd-8ae6-451f-8516-d8902a0ebebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-92deb330-3a41-4777-afaf-3c5f03306e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-bea75b85-07e6-4195-a8af-282cdb2495f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-9ff90a53-d911-45a1-b4b3-0e57b696485c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-da27dbd4-9b11-418d-9721-88cb289ddc28,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-416a4d3c-894d-4c21-a753-7b6dedbb9e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138185556-172.17.0.13-1598522902860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-76abe812-c880-42c3-95cf-f6890cda32af,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-901a1630-49ee-44c9-8890-4fdffce9082d,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-5f5a94dd-8ae6-451f-8516-d8902a0ebebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-92deb330-3a41-4777-afaf-3c5f03306e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-bea75b85-07e6-4195-a8af-282cdb2495f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-9ff90a53-d911-45a1-b4b3-0e57b696485c,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-da27dbd4-9b11-418d-9721-88cb289ddc28,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-416a4d3c-894d-4c21-a753-7b6dedbb9e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232938486-172.17.0.13-1598522981942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-2832239d-f73c-4046-900a-35b9851ce2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-288782d8-76dc-4fb8-8762-f3bbb851f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-bb68673a-fdcd-49b7-9e62-2478b5453675,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-e5f0df6e-177d-459b-9729-6a48d07b2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-1024172e-04c7-4c0b-8315-3be70a9e9045,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-505ea214-cf84-43d3-b221-e725def56d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3ba23bdd-2956-4925-b786-0bbaf3731978,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-383373b4-d804-433a-aa0d-6f844ac49763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232938486-172.17.0.13-1598522981942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-2832239d-f73c-4046-900a-35b9851ce2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-288782d8-76dc-4fb8-8762-f3bbb851f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-bb68673a-fdcd-49b7-9e62-2478b5453675,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-e5f0df6e-177d-459b-9729-6a48d07b2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-1024172e-04c7-4c0b-8315-3be70a9e9045,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-505ea214-cf84-43d3-b221-e725def56d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3ba23bdd-2956-4925-b786-0bbaf3731978,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-383373b4-d804-433a-aa0d-6f844ac49763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865593111-172.17.0.13-1598523293916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-d3a4550f-eb45-429c-816b-069c604eeae1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-3de1e19c-1fd5-4337-a319-106c67c43c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-8eda36e3-1b92-4bc2-8dc8-decd5d6ad7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-3f0e78cb-4698-4994-956c-82a144b1797e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-48878ebc-9d47-4c53-a454-af0e2e1add5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-5f265516-66b5-4277-b89f-b0876b11a070,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-97bd7cc1-7ba0-467a-8ed1-3fa3235c4d36,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-2532e38d-a828-4cf0-9fcf-10a9121753c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865593111-172.17.0.13-1598523293916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-d3a4550f-eb45-429c-816b-069c604eeae1,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-3de1e19c-1fd5-4337-a319-106c67c43c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-8eda36e3-1b92-4bc2-8dc8-decd5d6ad7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-3f0e78cb-4698-4994-956c-82a144b1797e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-48878ebc-9d47-4c53-a454-af0e2e1add5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-5f265516-66b5-4277-b89f-b0876b11a070,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-97bd7cc1-7ba0-467a-8ed1-3fa3235c4d36,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-2532e38d-a828-4cf0-9fcf-10a9121753c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277102072-172.17.0.13-1598523868442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-219a5d98-0f52-4ddd-a6e1-0990d6985477,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-87647af8-a2bd-4ecd-a266-63e7511659af,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-88dacc22-6e38-4c3c-b316-32dc008a7f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-c21f85a2-acae-43ba-8a55-bff55343d52d,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-78d81f87-4dc2-4184-aa26-e8f014abe14d,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-c66e74ef-fff7-44fc-bee8-edc161720181,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-08432325-afa9-4f7b-a5e7-e7249b2ae658,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2f3581c6-eeef-4f3b-8d2b-7fcb21863133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277102072-172.17.0.13-1598523868442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-219a5d98-0f52-4ddd-a6e1-0990d6985477,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-87647af8-a2bd-4ecd-a266-63e7511659af,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-88dacc22-6e38-4c3c-b316-32dc008a7f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-c21f85a2-acae-43ba-8a55-bff55343d52d,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-78d81f87-4dc2-4184-aa26-e8f014abe14d,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-c66e74ef-fff7-44fc-bee8-edc161720181,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-08432325-afa9-4f7b-a5e7-e7249b2ae658,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2f3581c6-eeef-4f3b-8d2b-7fcb21863133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301894030-172.17.0.13-1598523982561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-557ef9cb-3800-4195-a1c6-6287e79315ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-97760240-e1e3-4793-8802-57d4aedd25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-6c85674b-3608-4d33-8738-48f7f2975d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-07877a6b-32dc-4e91-990a-29128de71e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-9e67dba9-2895-4725-bea2-ee283b2b21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-cb8709e7-8bfa-4ba9-a138-8e04b9393272,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-d56d9adc-a937-4377-ba27-d2537f34e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-b1a0b6f4-1747-4586-8475-8cb5975248e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301894030-172.17.0.13-1598523982561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33900,DS-557ef9cb-3800-4195-a1c6-6287e79315ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-97760240-e1e3-4793-8802-57d4aedd25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-6c85674b-3608-4d33-8738-48f7f2975d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-07877a6b-32dc-4e91-990a-29128de71e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-9e67dba9-2895-4725-bea2-ee283b2b21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-cb8709e7-8bfa-4ba9-a138-8e04b9393272,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-d56d9adc-a937-4377-ba27-d2537f34e42f,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-b1a0b6f4-1747-4586-8475-8cb5975248e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905449238-172.17.0.13-1598524018563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34681,DS-acf2656d-cf93-4169-97de-b22ced96b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-4032dc82-d479-42b4-99ed-628d751eec83,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-3d4b523f-2a59-499b-8ed3-00d761a95df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-0cf9b6fe-fa57-40a9-842e-db7f163206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b11a3055-925e-45e5-a86e-a9ac1ab00de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-b0fd8262-cb90-4356-9327-c3e6285ca258,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-1e32ae51-a5d9-410f-b6a1-050d17d58a55,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-c1229aca-69a2-4876-ac15-68f66a85f35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905449238-172.17.0.13-1598524018563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34681,DS-acf2656d-cf93-4169-97de-b22ced96b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-4032dc82-d479-42b4-99ed-628d751eec83,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-3d4b523f-2a59-499b-8ed3-00d761a95df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-0cf9b6fe-fa57-40a9-842e-db7f163206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b11a3055-925e-45e5-a86e-a9ac1ab00de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-b0fd8262-cb90-4356-9327-c3e6285ca258,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-1e32ae51-a5d9-410f-b6a1-050d17d58a55,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-c1229aca-69a2-4876-ac15-68f66a85f35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253014602-172.17.0.13-1598525003617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-55e7f990-7513-41c4-bd7b-fece5ca02d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-10a78c10-10fa-4b31-a2b9-db676823c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-fc0d5220-a451-412e-b93c-ccacde37188d,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-db4c7e5f-684e-4b99-bbf4-3740c681722d,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-047a2e31-ef40-43a4-a84a-fb025e73d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-7030eb31-dfee-40a4-895f-27cf9bde58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-327c7f47-503d-48e7-8193-6bb93aa23785,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-cbdffa1e-8a31-458c-a09d-75fd8411078e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-253014602-172.17.0.13-1598525003617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-55e7f990-7513-41c4-bd7b-fece5ca02d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-10a78c10-10fa-4b31-a2b9-db676823c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-fc0d5220-a451-412e-b93c-ccacde37188d,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-db4c7e5f-684e-4b99-bbf4-3740c681722d,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-047a2e31-ef40-43a4-a84a-fb025e73d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-7030eb31-dfee-40a4-895f-27cf9bde58d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-327c7f47-503d-48e7-8193-6bb93aa23785,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-cbdffa1e-8a31-458c-a09d-75fd8411078e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532990602-172.17.0.13-1598525273831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-a174adc8-f032-4c42-a904-0bca225b66d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-67a2c8f1-695d-44e1-b862-02e190119e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-129f7631-d880-4b65-ad57-1c8a7189643a,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-0934e83e-9577-403c-8d47-ec158d8f8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-64f3c2d1-8b79-4deb-9b13-bae80b0e8453,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-750a1fe5-29a6-4de7-805a-a10af65f4186,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-8203e63c-d623-46f5-aecd-78a22e9ffe17,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-4afdb100-31e8-4ab0-a714-dad76ee59f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1532990602-172.17.0.13-1598525273831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-a174adc8-f032-4c42-a904-0bca225b66d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-67a2c8f1-695d-44e1-b862-02e190119e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-129f7631-d880-4b65-ad57-1c8a7189643a,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-0934e83e-9577-403c-8d47-ec158d8f8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-64f3c2d1-8b79-4deb-9b13-bae80b0e8453,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-750a1fe5-29a6-4de7-805a-a10af65f4186,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-8203e63c-d623-46f5-aecd-78a22e9ffe17,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-4afdb100-31e8-4ab0-a714-dad76ee59f73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027092325-172.17.0.13-1598525341297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-e74885c4-1825-483e-a840-c030804e3550,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-aaeed3d4-f9d3-410f-af55-2b41ca9a587b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-76c69836-4cf7-46fa-9c55-4cd5751c44ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-e665c421-29d1-45b7-999d-9bc9dc130b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-209cf688-6db9-411b-835d-ada452db7f65,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-c5efafac-f557-44b6-bc2b-c8871118251b,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6a8ac5ce-5abd-443f-a3d4-7b3beb2a1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-44ae1d62-6d38-411c-b398-287a74a57102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027092325-172.17.0.13-1598525341297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34037,DS-e74885c4-1825-483e-a840-c030804e3550,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-aaeed3d4-f9d3-410f-af55-2b41ca9a587b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-76c69836-4cf7-46fa-9c55-4cd5751c44ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-e665c421-29d1-45b7-999d-9bc9dc130b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-209cf688-6db9-411b-835d-ada452db7f65,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-c5efafac-f557-44b6-bc2b-c8871118251b,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-6a8ac5ce-5abd-443f-a3d4-7b3beb2a1a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-44ae1d62-6d38-411c-b398-287a74a57102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287637369-172.17.0.13-1598525444237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-39b05246-4d08-45df-98d5-087033c0bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-4e94a14d-df10-44a9-b556-593a3c404357,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-b4a0698b-a219-45d0-a9af-b015a4f9fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d6e96481-eca5-4c47-9081-8f4fd4fcb613,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-6791ffb8-e552-485e-a1c3-499234818414,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-2a10afa4-0b9b-4dc5-956b-372ebd5ade7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8643d537-5bfb-44de-9ae2-027acda81ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-8b121326-cb86-4a3b-992b-f06c2c6d68cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1287637369-172.17.0.13-1598525444237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-39b05246-4d08-45df-98d5-087033c0bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-4e94a14d-df10-44a9-b556-593a3c404357,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-b4a0698b-a219-45d0-a9af-b015a4f9fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d6e96481-eca5-4c47-9081-8f4fd4fcb613,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-6791ffb8-e552-485e-a1c3-499234818414,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-2a10afa4-0b9b-4dc5-956b-372ebd5ade7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8643d537-5bfb-44de-9ae2-027acda81ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-8b121326-cb86-4a3b-992b-f06c2c6d68cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635641427-172.17.0.13-1598525506814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-605c1619-a6ee-4687-9e40-a178faf0cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cb8ec440-1203-490d-a5c9-56ad69662df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-6a0fe77b-8462-4418-b9be-f3c235ae6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-50d57cde-24fb-419e-9bd0-3a202275113b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5b2dcab6-3865-4631-8017-18a9041adba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d8e51359-ea9f-4ede-81d8-5ccc5b76a176,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-c5d2c1be-5da5-4c3a-917a-08ab6bdef684,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-046f56d8-4372-400a-abf6-486aa1530e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635641427-172.17.0.13-1598525506814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-605c1619-a6ee-4687-9e40-a178faf0cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-cb8ec440-1203-490d-a5c9-56ad69662df1,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-6a0fe77b-8462-4418-b9be-f3c235ae6d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-50d57cde-24fb-419e-9bd0-3a202275113b,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-5b2dcab6-3865-4631-8017-18a9041adba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d8e51359-ea9f-4ede-81d8-5ccc5b76a176,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-c5d2c1be-5da5-4c3a-917a-08ab6bdef684,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-046f56d8-4372-400a-abf6-486aa1530e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814230065-172.17.0.13-1598525575226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-e3450584-8d53-4b98-828f-d5bba65061c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-077d8513-4f91-4bfa-8a21-73c87b03137d,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-3b17d999-eeb9-44d3-b812-96cd62c9d579,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-a0464ee7-9790-4f7b-af71-fbdea820fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-52bac285-6334-4098-ac2f-8f91f1871239,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-a53e997c-e1cc-4759-9b5d-c192072e5205,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-af828a69-2abd-4b1d-9a92-159983f80337,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3aec102e-00ea-4768-8842-5971fdc024b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814230065-172.17.0.13-1598525575226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-e3450584-8d53-4b98-828f-d5bba65061c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-077d8513-4f91-4bfa-8a21-73c87b03137d,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-3b17d999-eeb9-44d3-b812-96cd62c9d579,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-a0464ee7-9790-4f7b-af71-fbdea820fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-52bac285-6334-4098-ac2f-8f91f1871239,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-a53e997c-e1cc-4759-9b5d-c192072e5205,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-af828a69-2abd-4b1d-9a92-159983f80337,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-3aec102e-00ea-4768-8842-5971fdc024b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896146676-172.17.0.13-1598525681318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45309,DS-b4c4cb60-4ee2-4ca6-b52a-9fca39ffe0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-824c9540-9114-4a01-ad6c-9b49f067b265,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-a8a01fc2-b49c-47ee-9c67-759a2cdda141,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-9c659c37-0b84-40c8-941c-3a9b95a8b978,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-152d5f7d-c6f9-493a-8b3f-68a88607f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-cd41a788-97f4-4234-b895-2262e20e23b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-5df42bed-e23e-4819-a4b3-1d503cb4e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-5c73c211-7981-4c37-9273-3977b153f89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896146676-172.17.0.13-1598525681318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45309,DS-b4c4cb60-4ee2-4ca6-b52a-9fca39ffe0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-824c9540-9114-4a01-ad6c-9b49f067b265,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-a8a01fc2-b49c-47ee-9c67-759a2cdda141,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-9c659c37-0b84-40c8-941c-3a9b95a8b978,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-152d5f7d-c6f9-493a-8b3f-68a88607f723,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-cd41a788-97f4-4234-b895-2262e20e23b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-5df42bed-e23e-4819-a4b3-1d503cb4e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-5c73c211-7981-4c37-9273-3977b153f89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146829703-172.17.0.13-1598525992331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44291,DS-ac15bb6f-8f80-4139-bc0c-8b1a2b14486a,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-3c3b80c8-5fa8-436f-9b0c-d5a821786b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-4477d332-143a-46ed-96e3-a5ae564152fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-40147667-34e4-4b64-ba3b-6533fb59dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-8e221454-78b7-40b1-a2e0-5eacb9cd2052,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-3228e7c6-fc11-40a1-9169-4772dced2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-fbae25f6-f878-4da1-b93d-5250205527cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-5a3f114c-ec00-4d34-aa04-83ce02dbe47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146829703-172.17.0.13-1598525992331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44291,DS-ac15bb6f-8f80-4139-bc0c-8b1a2b14486a,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-3c3b80c8-5fa8-436f-9b0c-d5a821786b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-4477d332-143a-46ed-96e3-a5ae564152fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-40147667-34e4-4b64-ba3b-6533fb59dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-8e221454-78b7-40b1-a2e0-5eacb9cd2052,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-3228e7c6-fc11-40a1-9169-4772dced2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-fbae25f6-f878-4da1-b93d-5250205527cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-5a3f114c-ec00-4d34-aa04-83ce02dbe47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 1
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825260467-172.17.0.13-1598526095053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-a7132f96-ee67-4bea-98f5-5fababa03c78,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-b1bec285-267f-4d78-96c0-6a3fbbcc25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-43ca0753-3fca-4ae8-ba3d-d7e0a1ccf08f,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-be1b26b4-50e8-4697-833c-5f48e2e01c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-e0d74ad9-5397-493e-90e5-36998e1991b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-9bf21d88-61f9-4933-a671-b827821e463b,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-29c37c88-da61-41b3-83b5-e2f940f86974,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-cfb8bd6b-7d8f-4e49-b1f9-8943c0490d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825260467-172.17.0.13-1598526095053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-a7132f96-ee67-4bea-98f5-5fababa03c78,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-b1bec285-267f-4d78-96c0-6a3fbbcc25a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-43ca0753-3fca-4ae8-ba3d-d7e0a1ccf08f,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-be1b26b4-50e8-4697-833c-5f48e2e01c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-e0d74ad9-5397-493e-90e5-36998e1991b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-9bf21d88-61f9-4933-a671-b827821e463b,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-29c37c88-da61-41b3-83b5-e2f940f86974,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-cfb8bd6b-7d8f-4e49-b1f9-8943c0490d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5397
