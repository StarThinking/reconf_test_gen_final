reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808758783-172.17.0.21-1598672955652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-92b38d7e-6a13-4d10-9c77-fd096084fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-5401520a-f7af-4cfb-8d3b-ed20b91ce9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-d9f6152f-97be-46d9-90f7-8103a26f9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-631f5bce-fa4c-4813-b1e4-606330f00e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-fec8eae8-7688-46d0-8c38-fa90ce22e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-4c3f5c3d-388c-48cb-9660-4ed19821bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-9d790cb7-9b65-4734-b048-a5fd5b00d960,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-0b26a15b-dd94-449b-9d54-8f4c2a8211ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808758783-172.17.0.21-1598672955652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-92b38d7e-6a13-4d10-9c77-fd096084fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-5401520a-f7af-4cfb-8d3b-ed20b91ce9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-d9f6152f-97be-46d9-90f7-8103a26f9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-631f5bce-fa4c-4813-b1e4-606330f00e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-fec8eae8-7688-46d0-8c38-fa90ce22e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-4c3f5c3d-388c-48cb-9660-4ed19821bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-9d790cb7-9b65-4734-b048-a5fd5b00d960,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-0b26a15b-dd94-449b-9d54-8f4c2a8211ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971729570-172.17.0.21-1598673360487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-43c364b7-b0d3-44b1-b577-902110aba917,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-f17f049c-a241-47c3-a9ed-ff0b9a6e205a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-af69d716-9381-425e-a4f0-cfcac727af84,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-23e8d00b-378b-4c7a-a264-02e2183858fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-ce3a9c38-b58d-49da-9860-3ff94d96c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-6c2b710a-4107-478a-ad94-1221a4bfbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-35607e56-9ecc-46c9-bafe-2fafa11703a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-d0b134c4-7547-4b38-abc7-7751792bc151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971729570-172.17.0.21-1598673360487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-43c364b7-b0d3-44b1-b577-902110aba917,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-f17f049c-a241-47c3-a9ed-ff0b9a6e205a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-af69d716-9381-425e-a4f0-cfcac727af84,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-23e8d00b-378b-4c7a-a264-02e2183858fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-ce3a9c38-b58d-49da-9860-3ff94d96c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-6c2b710a-4107-478a-ad94-1221a4bfbdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-35607e56-9ecc-46c9-bafe-2fafa11703a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-d0b134c4-7547-4b38-abc7-7751792bc151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580985050-172.17.0.21-1598673399893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-ff702982-bf47-44b7-a088-a815c14c242e,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-be10d03c-eb8a-48b7-be87-2c4e4691d625,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-8561fe68-ea34-4eba-829d-471c82c925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-d83592f5-aadf-4585-a67c-9c5bc4c35048,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-8b3b527f-f8b8-4a91-8526-d5458b1a0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-de9b41c8-dcb7-409e-ba92-24e783587a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-2b57bd65-61ba-4a39-9b92-952bf84535bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-8e34a4a2-9687-4c74-8774-d1dd218accb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580985050-172.17.0.21-1598673399893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-ff702982-bf47-44b7-a088-a815c14c242e,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-be10d03c-eb8a-48b7-be87-2c4e4691d625,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-8561fe68-ea34-4eba-829d-471c82c925ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-d83592f5-aadf-4585-a67c-9c5bc4c35048,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-8b3b527f-f8b8-4a91-8526-d5458b1a0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-de9b41c8-dcb7-409e-ba92-24e783587a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-2b57bd65-61ba-4a39-9b92-952bf84535bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-8e34a4a2-9687-4c74-8774-d1dd218accb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634772900-172.17.0.21-1598673580505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-d16fa04e-bed4-4602-b8ff-cbc0acf6e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-87369150-3cc0-44ce-b562-d7b883ecf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-ba8b1d4d-162e-460c-8caf-648af1b22879,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d81da484-db91-485d-a5e5-66abe919ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-3912c308-489f-40bc-8908-946593478fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-97462e71-f1f0-4954-9103-163df6b03c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-e25bb08a-9e19-4805-bbb4-52e77cd19b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-709ea036-ed2a-4bc7-8132-b99bb459549e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634772900-172.17.0.21-1598673580505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44310,DS-d16fa04e-bed4-4602-b8ff-cbc0acf6e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-87369150-3cc0-44ce-b562-d7b883ecf6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-ba8b1d4d-162e-460c-8caf-648af1b22879,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d81da484-db91-485d-a5e5-66abe919ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-3912c308-489f-40bc-8908-946593478fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-97462e71-f1f0-4954-9103-163df6b03c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-e25bb08a-9e19-4805-bbb4-52e77cd19b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-709ea036-ed2a-4bc7-8132-b99bb459549e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214004005-172.17.0.21-1598673777965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-0629d9c7-7d74-474e-9fbb-ba57b95dd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-e61a8ad8-5dfc-46a3-ab17-413d20477a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-529fd4df-222a-47c3-9569-24926e72dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-0eb60e8d-1c75-4180-a6f9-a6a135eaaa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-959667c9-a162-4e1d-a4b0-eb8f0d700049,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-05d580aa-7998-4e42-9b48-17d52226d356,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-fc0927c4-10a3-414b-a8e7-0e2d6917ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-04532459-ac91-407e-832c-85e3fad44ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214004005-172.17.0.21-1598673777965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41618,DS-0629d9c7-7d74-474e-9fbb-ba57b95dd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-e61a8ad8-5dfc-46a3-ab17-413d20477a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-529fd4df-222a-47c3-9569-24926e72dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-0eb60e8d-1c75-4180-a6f9-a6a135eaaa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-959667c9-a162-4e1d-a4b0-eb8f0d700049,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-05d580aa-7998-4e42-9b48-17d52226d356,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-fc0927c4-10a3-414b-a8e7-0e2d6917ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-04532459-ac91-407e-832c-85e3fad44ee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109676664-172.17.0.21-1598673818477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46792,DS-347e60aa-ae03-4d2f-82e8-298e9dc19bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-4abe6ef1-9fc7-49c8-b71b-13e9741ad7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-c45ebdd0-13c8-46f9-8b19-6f4e2c6f1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-1a42e702-8f71-4017-b9e3-fa7c3c173c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-d0ddcfad-a94f-4654-b57c-99b67270e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-2f9cfdfb-d66b-4e83-a0be-8480f144f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-b3978b13-edb7-45bb-802b-c9feac92800c,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-12c8b8bb-d803-42b3-bc3b-bd325543841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109676664-172.17.0.21-1598673818477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46792,DS-347e60aa-ae03-4d2f-82e8-298e9dc19bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-4abe6ef1-9fc7-49c8-b71b-13e9741ad7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-c45ebdd0-13c8-46f9-8b19-6f4e2c6f1fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-1a42e702-8f71-4017-b9e3-fa7c3c173c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-d0ddcfad-a94f-4654-b57c-99b67270e09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-2f9cfdfb-d66b-4e83-a0be-8480f144f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-b3978b13-edb7-45bb-802b-c9feac92800c,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-12c8b8bb-d803-42b3-bc3b-bd325543841c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539204326-172.17.0.21-1598673853752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36154,DS-79da7291-d84c-4f28-b957-f2cbc6242185,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b4b78c31-7f8f-41c6-80dd-9675f05ef247,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-1c0a0f98-f6d4-4c31-a454-2c74bfae287f,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e51f6007-0b69-4e25-9269-4b1c31a7877c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-54c8dd91-14a8-49ec-89bb-f2eb9782245b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0a1e1dfe-808f-4291-946f-abd896950167,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-d95d2179-49cf-4e93-b3f3-d12f4def64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-3cef970a-1f8f-4635-8c85-f4c4dae939cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539204326-172.17.0.21-1598673853752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36154,DS-79da7291-d84c-4f28-b957-f2cbc6242185,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b4b78c31-7f8f-41c6-80dd-9675f05ef247,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-1c0a0f98-f6d4-4c31-a454-2c74bfae287f,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e51f6007-0b69-4e25-9269-4b1c31a7877c,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-54c8dd91-14a8-49ec-89bb-f2eb9782245b,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0a1e1dfe-808f-4291-946f-abd896950167,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-d95d2179-49cf-4e93-b3f3-d12f4def64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-3cef970a-1f8f-4635-8c85-f4c4dae939cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95171563-172.17.0.21-1598673997969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-d5910d3a-38b7-4cb6-902e-bf880a432d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-ef3237c3-79a3-40ff-a994-3709fb495d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-e6553cf8-c3ae-4aaf-b477-e233d13498b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6c488a6a-d542-4d13-b8b3-7821eb7d8565,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-8e4e1c1c-e4d6-4098-a7a7-e55dcd5c5312,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9f927f6b-de30-4fae-8ee1-b33a4bebcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-09565c51-f4a1-4269-93cd-c5f1bbca159f,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-cfa3dcf7-db9b-4677-99fc-4b3123fd8e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95171563-172.17.0.21-1598673997969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-d5910d3a-38b7-4cb6-902e-bf880a432d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-ef3237c3-79a3-40ff-a994-3709fb495d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-e6553cf8-c3ae-4aaf-b477-e233d13498b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-6c488a6a-d542-4d13-b8b3-7821eb7d8565,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-8e4e1c1c-e4d6-4098-a7a7-e55dcd5c5312,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9f927f6b-de30-4fae-8ee1-b33a4bebcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-09565c51-f4a1-4269-93cd-c5f1bbca159f,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-cfa3dcf7-db9b-4677-99fc-4b3123fd8e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248861323-172.17.0.21-1598674106393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-907d7789-2b08-428c-b38a-b08a8def4881,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-01e6e8ff-84d9-4eb7-b9ee-7f9b6e270a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-02fd1e88-d396-4434-9397-ce5e5b96dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-dfd40d29-dfcf-4a81-b0e8-cb9adc0dc30a,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b15a6011-c489-4589-9374-46b85693e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-8a1f6d8c-d4c1-46f6-b3e1-f0f66e51301d,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-42095062-21b5-4296-ba43-e46be39570ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4198f685-8d79-4ecd-a07b-1fac326763f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248861323-172.17.0.21-1598674106393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-907d7789-2b08-428c-b38a-b08a8def4881,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-01e6e8ff-84d9-4eb7-b9ee-7f9b6e270a10,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-02fd1e88-d396-4434-9397-ce5e5b96dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-dfd40d29-dfcf-4a81-b0e8-cb9adc0dc30a,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-b15a6011-c489-4589-9374-46b85693e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-8a1f6d8c-d4c1-46f6-b3e1-f0f66e51301d,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-42095062-21b5-4296-ba43-e46be39570ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-4198f685-8d79-4ecd-a07b-1fac326763f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794482812-172.17.0.21-1598674403432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-0a00fac2-aaca-4ada-a6ce-f2e6913f0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-072cdb0e-215c-4bad-a155-606c894ca51c,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-6cc89acd-14fc-4d97-9360-c34f30745c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8bb26d5f-39a3-4ecb-9426-5d6c772b0d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-db29540f-c46f-40c2-8f5b-0accabee79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-17cc07e7-5d7f-48e5-9dde-8298fb29e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-7a5f5d5f-dd75-4e21-8810-1521ab9ae39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-00e3766a-6bd3-454e-813e-5f794fecf984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794482812-172.17.0.21-1598674403432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39495,DS-0a00fac2-aaca-4ada-a6ce-f2e6913f0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-072cdb0e-215c-4bad-a155-606c894ca51c,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-6cc89acd-14fc-4d97-9360-c34f30745c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8bb26d5f-39a3-4ecb-9426-5d6c772b0d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-db29540f-c46f-40c2-8f5b-0accabee79cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-17cc07e7-5d7f-48e5-9dde-8298fb29e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-7a5f5d5f-dd75-4e21-8810-1521ab9ae39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-00e3766a-6bd3-454e-813e-5f794fecf984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824673911-172.17.0.21-1598674815293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-05a23701-4563-4057-918c-89e623decd61,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-893afe44-00f6-43dd-9104-9b2a58532d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-a981a5fc-79ca-48d9-abe1-721f0891c233,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-ae035b36-1162-4fe8-8f12-05790f83545a,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-8973fc61-08bf-4f00-b88d-0fb6f3b8f927,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-37ed7c71-ac1d-4f93-9b93-4e2c21ecb2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-47c50be5-c6ed-4e7b-b4f7-fb57026038ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3f3ad5a5-3c55-490f-8213-1cc56509db1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824673911-172.17.0.21-1598674815293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-05a23701-4563-4057-918c-89e623decd61,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-893afe44-00f6-43dd-9104-9b2a58532d36,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-a981a5fc-79ca-48d9-abe1-721f0891c233,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-ae035b36-1162-4fe8-8f12-05790f83545a,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-8973fc61-08bf-4f00-b88d-0fb6f3b8f927,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-37ed7c71-ac1d-4f93-9b93-4e2c21ecb2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-47c50be5-c6ed-4e7b-b4f7-fb57026038ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3f3ad5a5-3c55-490f-8213-1cc56509db1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176603546-172.17.0.21-1598674988142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-381981cf-972b-4922-8c4f-efdf318773e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-2f6346b6-c052-4c07-b54f-3563e7fca14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-3c821f92-e111-4662-99ba-dcc536b7bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-e4edb643-3690-40a4-849e-ff076e60eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-92115ffe-a5b0-42c3-821a-f10e4645f176,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-835ffd8f-0edb-4558-8d3d-442d4d93a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-2a452f74-e747-49ef-8b5c-d4f54f7f20dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-59343dd9-67f8-4c5e-997d-0a27faa9205d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176603546-172.17.0.21-1598674988142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-381981cf-972b-4922-8c4f-efdf318773e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-2f6346b6-c052-4c07-b54f-3563e7fca14b,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-3c821f92-e111-4662-99ba-dcc536b7bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-e4edb643-3690-40a4-849e-ff076e60eb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-92115ffe-a5b0-42c3-821a-f10e4645f176,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-835ffd8f-0edb-4558-8d3d-442d4d93a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-2a452f74-e747-49ef-8b5c-d4f54f7f20dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-59343dd9-67f8-4c5e-997d-0a27faa9205d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227584080-172.17.0.21-1598675188700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45468,DS-8799889d-cf4e-4fef-aae0-ac41580c0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-4e54b350-1d4d-442b-b505-0bb4e47cb397,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-64f05916-d84d-48b6-90f1-4f94c6387d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-6f55a6f0-65ef-4270-91e5-ae95c45b488b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-75bf742f-8171-4bbd-b790-e24f635c02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-2a378bf4-762a-426f-93a5-404871de89fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-66d048ee-60cf-472b-82c0-4d4df1f053d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-1b9d8924-d565-4931-8646-3d4a69f35ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227584080-172.17.0.21-1598675188700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45468,DS-8799889d-cf4e-4fef-aae0-ac41580c0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-4e54b350-1d4d-442b-b505-0bb4e47cb397,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-64f05916-d84d-48b6-90f1-4f94c6387d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-6f55a6f0-65ef-4270-91e5-ae95c45b488b,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-75bf742f-8171-4bbd-b790-e24f635c02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-2a378bf4-762a-426f-93a5-404871de89fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-66d048ee-60cf-472b-82c0-4d4df1f053d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-1b9d8924-d565-4931-8646-3d4a69f35ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398094007-172.17.0.21-1598675379119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-0a72aa79-346e-4ddf-b593-5879b56ae789,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8ebbe0e8-ab79-4e14-a9fd-0dbe603ed8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-1ae4f7da-d4b0-4b4c-be2a-16693d67f480,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-6f81d716-36d1-4dda-85dc-9fca38dd5277,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-4b375b88-6959-4afb-9ac6-929eee737a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-52645408-b279-47bb-a81d-192c26d7f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-829d6b23-bc2a-4ef9-86a9-26cd58824e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6a0db14d-cdf3-4515-8af6-ffa3ac0f6461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398094007-172.17.0.21-1598675379119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-0a72aa79-346e-4ddf-b593-5879b56ae789,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8ebbe0e8-ab79-4e14-a9fd-0dbe603ed8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-1ae4f7da-d4b0-4b4c-be2a-16693d67f480,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-6f81d716-36d1-4dda-85dc-9fca38dd5277,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-4b375b88-6959-4afb-9ac6-929eee737a94,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-52645408-b279-47bb-a81d-192c26d7f452,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-829d6b23-bc2a-4ef9-86a9-26cd58824e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-6a0db14d-cdf3-4515-8af6-ffa3ac0f6461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517601504-172.17.0.21-1598675455338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-b85dddd7-e694-47be-82d4-2e3920d328c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-576df77b-0f90-4293-bf97-dc87505df5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e5b41c27-d0df-40ce-a544-789f9d6d48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-da1b77aa-8204-4d21-a172-94990453fc92,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-4c223a28-c79e-47e8-84bb-1bff1d9221b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-de7a6116-ae81-404f-9f35-fa655e8278d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-51c254cf-7770-4f3b-8625-0c75210b346d,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-b6626499-3d9e-44d9-a9d5-8cef0bafdbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517601504-172.17.0.21-1598675455338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-b85dddd7-e694-47be-82d4-2e3920d328c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-576df77b-0f90-4293-bf97-dc87505df5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e5b41c27-d0df-40ce-a544-789f9d6d48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-da1b77aa-8204-4d21-a172-94990453fc92,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-4c223a28-c79e-47e8-84bb-1bff1d9221b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-de7a6116-ae81-404f-9f35-fa655e8278d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-51c254cf-7770-4f3b-8625-0c75210b346d,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-b6626499-3d9e-44d9-a9d5-8cef0bafdbb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697285916-172.17.0.21-1598675979180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45121,DS-92dec59a-ec17-4978-a518-7294aee92d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b99ade6e-2dc1-4ee7-84d0-28fd0175be26,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-1864dc1b-a0b8-4dd8-8052-c2257154274e,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-ee94cdd6-0fc9-499e-a742-5aed4164be95,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-6839eb41-74d1-49e4-9e00-3c0e34e71c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-577ecf4f-859d-4cfb-ab3f-f0624f9e2262,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-e0d717e8-a258-458f-9835-db84e449e16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-a66c207e-447c-4438-910d-1b987caea81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697285916-172.17.0.21-1598675979180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45121,DS-92dec59a-ec17-4978-a518-7294aee92d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b99ade6e-2dc1-4ee7-84d0-28fd0175be26,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-1864dc1b-a0b8-4dd8-8052-c2257154274e,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-ee94cdd6-0fc9-499e-a742-5aed4164be95,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-6839eb41-74d1-49e4-9e00-3c0e34e71c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-577ecf4f-859d-4cfb-ab3f-f0624f9e2262,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-e0d717e8-a258-458f-9835-db84e449e16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-a66c207e-447c-4438-910d-1b987caea81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508697119-172.17.0.21-1598676024988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46672,DS-047ff21e-11bf-471e-bc84-fc46cd0502eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-36b09fee-66e7-480d-ba99-b885046c932e,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-f9f86fa3-b7dd-4faa-b90e-c016fd88fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0891e96c-7087-4458-8d13-2a374d754207,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-f1253648-76f2-4550-8c9a-a5083e609ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cf6d55c9-04b7-43e2-b468-f5cbfc0c60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-18120d62-508c-4c17-a464-4025ce196ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-cf4b5dde-25b2-4cbf-aba6-73abbcd02890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508697119-172.17.0.21-1598676024988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46672,DS-047ff21e-11bf-471e-bc84-fc46cd0502eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-36b09fee-66e7-480d-ba99-b885046c932e,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-f9f86fa3-b7dd-4faa-b90e-c016fd88fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0891e96c-7087-4458-8d13-2a374d754207,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-f1253648-76f2-4550-8c9a-a5083e609ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cf6d55c9-04b7-43e2-b468-f5cbfc0c60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-18120d62-508c-4c17-a464-4025ce196ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-cf4b5dde-25b2-4cbf-aba6-73abbcd02890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526346382-172.17.0.21-1598676259766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-261d6918-2083-4bcd-9d55-f675ee48dbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-529ec561-5cbc-40cf-955b-225db1e015d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77f10803-0711-46ef-9c1f-4215e5af683b,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-1a81776c-c35f-49c1-861d-3bd1d2c6c214,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-2804a06e-a0c4-40a4-a0dc-0dd47292eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-0011c0c6-b971-4a6e-a813-856b486dac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-d028e710-2ba9-42be-9c3c-dcc382039edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-1cf4d545-8af2-4b64-9e2c-99c3950e1ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526346382-172.17.0.21-1598676259766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41377,DS-261d6918-2083-4bcd-9d55-f675ee48dbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-529ec561-5cbc-40cf-955b-225db1e015d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77f10803-0711-46ef-9c1f-4215e5af683b,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-1a81776c-c35f-49c1-861d-3bd1d2c6c214,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-2804a06e-a0c4-40a4-a0dc-0dd47292eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-0011c0c6-b971-4a6e-a813-856b486dac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-d028e710-2ba9-42be-9c3c-dcc382039edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-1cf4d545-8af2-4b64-9e2c-99c3950e1ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841501926-172.17.0.21-1598676417241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-3b58a933-cb70-455d-ba81-ede2e7315966,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9f3ce1ec-2d41-468a-a874-e22dfcbb73d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-70aabf10-de25-4cc4-84ab-7d2d6e37da75,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-274b372f-cd1e-4c30-a797-b7cac49e0be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-c09da214-4255-4068-8f92-3213de154a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-7963776e-1e54-43fe-a209-bc087ce2f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-2791cfd0-c9af-4867-b99e-9251575cd949,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-f5703d13-7af6-41e4-9f07-88433572baf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841501926-172.17.0.21-1598676417241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-3b58a933-cb70-455d-ba81-ede2e7315966,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9f3ce1ec-2d41-468a-a874-e22dfcbb73d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-70aabf10-de25-4cc4-84ab-7d2d6e37da75,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-274b372f-cd1e-4c30-a797-b7cac49e0be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-c09da214-4255-4068-8f92-3213de154a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-7963776e-1e54-43fe-a209-bc087ce2f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-2791cfd0-c9af-4867-b99e-9251575cd949,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-f5703d13-7af6-41e4-9f07-88433572baf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843888934-172.17.0.21-1598677611358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-a099a1e4-b298-4634-a1ec-de44b7fc4ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cc780fb1-15cc-4be8-af7f-c70eddc03873,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-b4f11df9-6dff-415d-950a-882c98bb1e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-415db6c5-3d1f-4e3c-841d-229cf8c34522,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-e45bdd35-b5df-4eb7-8296-992fd7777b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-d026c49c-c453-490f-9b1b-18cdabdb49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-f66d8378-1c26-4dcf-ad42-5a7210a3cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-e39a6ca3-f2b7-489c-9773-47ae67ad45b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1843888934-172.17.0.21-1598677611358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-a099a1e4-b298-4634-a1ec-de44b7fc4ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cc780fb1-15cc-4be8-af7f-c70eddc03873,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-b4f11df9-6dff-415d-950a-882c98bb1e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-415db6c5-3d1f-4e3c-841d-229cf8c34522,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-e45bdd35-b5df-4eb7-8296-992fd7777b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-d026c49c-c453-490f-9b1b-18cdabdb49aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-f66d8378-1c26-4dcf-ad42-5a7210a3cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-e39a6ca3-f2b7-489c-9773-47ae67ad45b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461547736-172.17.0.21-1598677729008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-a7dfc149-a2dc-4b04-abf0-a625e2fee75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-56845129-40c6-4168-86e9-df020ab9c44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-2d598d76-dfa7-444c-bc61-e22296a5f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-13cdc47a-6803-4047-a5f2-9161946bdf24,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-286bd0eb-e1c9-4d8e-a1dd-04dad9822d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-072937c1-bea0-4bc2-ba19-76aacdb1bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7722ceff-6c20-49da-ac7d-688d15c69970,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7e92879a-0f86-46cb-9c0a-96269779252d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461547736-172.17.0.21-1598677729008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44354,DS-a7dfc149-a2dc-4b04-abf0-a625e2fee75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-56845129-40c6-4168-86e9-df020ab9c44f,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-2d598d76-dfa7-444c-bc61-e22296a5f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-13cdc47a-6803-4047-a5f2-9161946bdf24,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-286bd0eb-e1c9-4d8e-a1dd-04dad9822d37,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-072937c1-bea0-4bc2-ba19-76aacdb1bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7722ceff-6c20-49da-ac7d-688d15c69970,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-7e92879a-0f86-46cb-9c0a-96269779252d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.min.datanodes
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830123188-172.17.0.21-1598677804813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43080,DS-31a03f80-a538-4431-9beb-e8f70b6f0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-6265c393-f019-4847-b4dd-622deede47a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ca8d456b-7237-4323-a7e7-27b98162d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-3e14def5-f456-49d8-9a0d-dbb5edf2e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-d7385fb3-327f-4ddd-9120-da319640f446,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-505e7b87-1745-44f9-9d8c-671e0270eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-45c7c734-5eca-42f3-a27a-bee89b9e2120,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8eafd6dc-ce44-45b5-86f8-f07585ffee0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830123188-172.17.0.21-1598677804813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43080,DS-31a03f80-a538-4431-9beb-e8f70b6f0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-6265c393-f019-4847-b4dd-622deede47a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ca8d456b-7237-4323-a7e7-27b98162d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-3e14def5-f456-49d8-9a0d-dbb5edf2e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-d7385fb3-327f-4ddd-9120-da319640f446,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-505e7b87-1745-44f9-9d8c-671e0270eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-45c7c734-5eca-42f3-a27a-bee89b9e2120,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-8eafd6dc-ce44-45b5-86f8-f07585ffee0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5615
