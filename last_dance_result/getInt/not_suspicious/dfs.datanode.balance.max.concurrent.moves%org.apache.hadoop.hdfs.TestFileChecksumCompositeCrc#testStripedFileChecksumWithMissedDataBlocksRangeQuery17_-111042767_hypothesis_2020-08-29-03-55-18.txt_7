reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915305761-172.17.0.19-1598673432491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-04288a86-db5d-4e83-8c27-0757690f1818,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-f84218e0-8581-4883-be00-99d56f8065ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-4f256fef-d7fa-4835-959e-173a69a37ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-0368903a-6dc5-4b18-aa8b-9c47c066f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-12745770-c5e9-4312-9c81-9b6241317e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f45ba04c-41ac-4b00-bccc-95c5a311aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-0bfd3ad3-a5fa-417c-a479-42003221f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-3440a496-b41b-47c4-bda4-416af82ef25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915305761-172.17.0.19-1598673432491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43129,DS-04288a86-db5d-4e83-8c27-0757690f1818,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-f84218e0-8581-4883-be00-99d56f8065ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-4f256fef-d7fa-4835-959e-173a69a37ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-0368903a-6dc5-4b18-aa8b-9c47c066f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-12745770-c5e9-4312-9c81-9b6241317e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f45ba04c-41ac-4b00-bccc-95c5a311aa57,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-0bfd3ad3-a5fa-417c-a479-42003221f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-3440a496-b41b-47c4-bda4-416af82ef25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142320642-172.17.0.19-1598673595643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-9c18b97b-f747-4d5c-b3b3-020fa42d3ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-b14f487e-3783-497f-bf15-ee7a55ec4ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-5fe3f698-59b2-41a6-87de-49d81fa6bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-9d1dd044-716a-4f2c-b1ca-c6b243b7f879,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-cf82af7b-3b50-46eb-a688-a5b956f127e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-174038dc-afce-4546-8f41-733da55f6f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-777e3d5d-f7e2-48b7-882e-26fe6dfe97af,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-62a48272-8152-457b-8b52-e2cdcc476108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142320642-172.17.0.19-1598673595643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-9c18b97b-f747-4d5c-b3b3-020fa42d3ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-b14f487e-3783-497f-bf15-ee7a55ec4ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-5fe3f698-59b2-41a6-87de-49d81fa6bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-9d1dd044-716a-4f2c-b1ca-c6b243b7f879,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-cf82af7b-3b50-46eb-a688-a5b956f127e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-174038dc-afce-4546-8f41-733da55f6f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-777e3d5d-f7e2-48b7-882e-26fe6dfe97af,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-62a48272-8152-457b-8b52-e2cdcc476108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991910821-172.17.0.19-1598674003582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46603,DS-28c18e01-1cb9-4bdf-ae36-2b12f87b93a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-f44054b8-d4cc-4f87-b661-b56852581700,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-9530e233-6466-4726-a676-f2298831b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-bcc90154-87b8-4606-b0d3-094ea3d36c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-dcd9ffeb-a837-4f5d-a238-4fbdda60ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-9e62eb71-af65-4dbc-a730-d5b756674b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-e2429121-dbd9-4b48-b51d-f37cb1696b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-12f885ca-aacf-4226-a72e-d65499ee3537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991910821-172.17.0.19-1598674003582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46603,DS-28c18e01-1cb9-4bdf-ae36-2b12f87b93a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-f44054b8-d4cc-4f87-b661-b56852581700,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-9530e233-6466-4726-a676-f2298831b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-bcc90154-87b8-4606-b0d3-094ea3d36c67,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-dcd9ffeb-a837-4f5d-a238-4fbdda60ea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-9e62eb71-af65-4dbc-a730-d5b756674b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-e2429121-dbd9-4b48-b51d-f37cb1696b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-12f885ca-aacf-4226-a72e-d65499ee3537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156411862-172.17.0.19-1598675141802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-e9c5b2bd-5977-4528-8291-74140fab7a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-3c8e133b-19aa-452e-935d-43fafa2b1717,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-7180bd4f-8fe7-48c9-ba59-9c181cc8cee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-ceba63e6-d508-4e18-be16-9d8bcb932484,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-ee7260f9-ddd9-4fe5-9ae4-acf7e303a023,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-4e4f9874-3c86-4714-bedf-91dc1d93337b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-843fd6d8-4d26-40b8-b917-fe083b9bf101,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-3872059d-92f3-41a5-ab3d-c3b2de6f11a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156411862-172.17.0.19-1598675141802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-e9c5b2bd-5977-4528-8291-74140fab7a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-3c8e133b-19aa-452e-935d-43fafa2b1717,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-7180bd4f-8fe7-48c9-ba59-9c181cc8cee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-ceba63e6-d508-4e18-be16-9d8bcb932484,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-ee7260f9-ddd9-4fe5-9ae4-acf7e303a023,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-4e4f9874-3c86-4714-bedf-91dc1d93337b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-843fd6d8-4d26-40b8-b917-fe083b9bf101,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-3872059d-92f3-41a5-ab3d-c3b2de6f11a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640527542-172.17.0.19-1598675552046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36488,DS-9ff0d447-552f-402d-8828-0211e3bf3498,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-f959eb00-9c2a-4040-b34a-7851caf0aa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-86293069-3ffb-4ca6-a9e8-4ae6dc942e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ddeb2535-7443-4d05-ac0a-8821f203134a,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-97f0a2bf-54da-46eb-8db8-08422360cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-7ae25350-5d53-4607-851b-a7d92fb39ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-deffb575-def7-4e90-95e3-c6175de6e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-825971cf-608b-4ce9-84f3-9a80a77cc2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640527542-172.17.0.19-1598675552046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36488,DS-9ff0d447-552f-402d-8828-0211e3bf3498,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-f959eb00-9c2a-4040-b34a-7851caf0aa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-86293069-3ffb-4ca6-a9e8-4ae6dc942e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-ddeb2535-7443-4d05-ac0a-8821f203134a,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-97f0a2bf-54da-46eb-8db8-08422360cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-7ae25350-5d53-4607-851b-a7d92fb39ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-deffb575-def7-4e90-95e3-c6175de6e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-825971cf-608b-4ce9-84f3-9a80a77cc2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094782467-172.17.0.19-1598675980099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-a82da83c-0e75-436e-bae2-575ce4ab0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-94880265-db7e-4f51-89bd-609e85ba1032,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-77416388-76e3-4300-afaa-f36d9c4688db,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-5c91312d-a4d0-4d5e-b9ca-787addbc6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-737684af-62a9-4ce4-bc1c-aa4237fea3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e2bc99c1-647c-4204-ae5c-076c10227bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d56d5ef0-d649-4b81-af6f-a6145b0ef402,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-45fcb33e-37c1-44fb-aa55-20163e33774a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094782467-172.17.0.19-1598675980099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-a82da83c-0e75-436e-bae2-575ce4ab0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-94880265-db7e-4f51-89bd-609e85ba1032,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-77416388-76e3-4300-afaa-f36d9c4688db,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-5c91312d-a4d0-4d5e-b9ca-787addbc6e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-737684af-62a9-4ce4-bc1c-aa4237fea3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e2bc99c1-647c-4204-ae5c-076c10227bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-d56d5ef0-d649-4b81-af6f-a6145b0ef402,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-45fcb33e-37c1-44fb-aa55-20163e33774a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676981789-172.17.0.19-1598676014009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33129,DS-f6e5f8ce-bbe4-4c6b-953a-eafac68d2001,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-1d5fc490-eaec-438b-b078-d107c9068017,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6a4f68c6-5441-43fa-983b-1f9615887d42,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-f962efbf-3c2a-4e80-9b0c-037974ba0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-fcf7cd69-2b30-4286-a9e5-7367ff8e6097,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-57a9f59b-718d-48d4-b372-a570ae0b596b,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f2f14870-d331-443f-9d03-0f8466bed3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-9301fa48-9205-4f2a-9382-b29ad215a287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676981789-172.17.0.19-1598676014009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33129,DS-f6e5f8ce-bbe4-4c6b-953a-eafac68d2001,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-1d5fc490-eaec-438b-b078-d107c9068017,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6a4f68c6-5441-43fa-983b-1f9615887d42,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-f962efbf-3c2a-4e80-9b0c-037974ba0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-fcf7cd69-2b30-4286-a9e5-7367ff8e6097,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-57a9f59b-718d-48d4-b372-a570ae0b596b,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f2f14870-d331-443f-9d03-0f8466bed3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-9301fa48-9205-4f2a-9382-b29ad215a287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896083407-172.17.0.19-1598676540716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-07c02648-3352-41ce-9d4c-c0777bf9456f,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-7b060484-b97f-42f6-a7ac-b80094d770fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-80440c46-8375-4754-b2c9-471de0f5aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-57df684f-3740-4013-bd5e-6344be0297b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e50fd862-c1fd-4ce0-9b79-793f75ca5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-7b6bd256-0dd6-4a3b-9f5e-9e58a2c33078,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e96c680f-d88c-4542-a0bd-c425fc4ee73a,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-84099b17-8999-48f5-9f7d-c6f031d78015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896083407-172.17.0.19-1598676540716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-07c02648-3352-41ce-9d4c-c0777bf9456f,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-7b060484-b97f-42f6-a7ac-b80094d770fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-80440c46-8375-4754-b2c9-471de0f5aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-57df684f-3740-4013-bd5e-6344be0297b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-e50fd862-c1fd-4ce0-9b79-793f75ca5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-7b6bd256-0dd6-4a3b-9f5e-9e58a2c33078,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e96c680f-d88c-4542-a0bd-c425fc4ee73a,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-84099b17-8999-48f5-9f7d-c6f031d78015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181545060-172.17.0.19-1598677664700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-02920c34-75c2-422d-989f-f94162efdc59,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-6cee29e9-6bc0-4605-8ebc-250d2a6449d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-9a80e88a-cb13-4517-b68b-8948d524140c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-eb9d692a-1099-4a04-9a64-23747b5d83e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-893c7054-029e-44b6-be22-f6a84a220963,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-c4a1f7fc-0b7c-48c8-a17c-aafe671bc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-fa422aa3-a199-47c8-9099-98fa82e6e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4a1d0859-4957-4144-8218-0da8fbfc7cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181545060-172.17.0.19-1598677664700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-02920c34-75c2-422d-989f-f94162efdc59,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-6cee29e9-6bc0-4605-8ebc-250d2a6449d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-9a80e88a-cb13-4517-b68b-8948d524140c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-eb9d692a-1099-4a04-9a64-23747b5d83e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-893c7054-029e-44b6-be22-f6a84a220963,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-c4a1f7fc-0b7c-48c8-a17c-aafe671bc4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-fa422aa3-a199-47c8-9099-98fa82e6e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-4a1d0859-4957-4144-8218-0da8fbfc7cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642980056-172.17.0.19-1598677887709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-fda9a2e4-4aca-4aba-9605-d9946f68378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-6cc06644-929f-42fb-bfdc-c6deafd2275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-b829c9b5-b84d-4e7d-9a50-ad0745549b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-d29b8ad8-db89-4fda-a6eb-dcb445be13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-68bb6014-a397-4d7f-80bc-1b6593bc7adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-f918e8f9-e82a-4ffd-b462-5f51927032ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-374e75c1-ab7a-4204-b723-09764398d586,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-42005e4d-9822-40ef-bc6c-963d1036bad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642980056-172.17.0.19-1598677887709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-fda9a2e4-4aca-4aba-9605-d9946f68378e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-6cc06644-929f-42fb-bfdc-c6deafd2275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-b829c9b5-b84d-4e7d-9a50-ad0745549b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-d29b8ad8-db89-4fda-a6eb-dcb445be13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-68bb6014-a397-4d7f-80bc-1b6593bc7adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-f918e8f9-e82a-4ffd-b462-5f51927032ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-374e75c1-ab7a-4204-b723-09764398d586,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-42005e4d-9822-40ef-bc6c-963d1036bad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4854
