reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303832606-172.17.0.19-1598485740895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-29a2407d-c383-4fa6-adce-4bafba3d8241,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-0f0a3049-5c49-4f84-a78b-ec0d451b7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-c3fe913d-4332-4343-9e54-0017b47eb113,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-c69a5c0c-f5f0-4197-a2fd-0b9fe91bc3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-8dd61da1-554d-495c-9c73-ecf2474ab545,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-91312a57-1971-4cd3-8615-4678593bd812,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-d283fc17-efbe-4c4a-82c8-54e982ed6646,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-eaf714dd-74b4-43e1-af76-9a210d9a0417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303832606-172.17.0.19-1598485740895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41668,DS-29a2407d-c383-4fa6-adce-4bafba3d8241,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-0f0a3049-5c49-4f84-a78b-ec0d451b7c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-c3fe913d-4332-4343-9e54-0017b47eb113,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-c69a5c0c-f5f0-4197-a2fd-0b9fe91bc3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-8dd61da1-554d-495c-9c73-ecf2474ab545,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-91312a57-1971-4cd3-8615-4678593bd812,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-d283fc17-efbe-4c4a-82c8-54e982ed6646,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-eaf714dd-74b4-43e1-af76-9a210d9a0417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807073003-172.17.0.19-1598485775561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42601,DS-02317dba-c56c-461a-a26f-7f63403ee099,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0e2a907e-b86c-4057-a87d-63f52488ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-9b46cd43-e571-4c17-a415-b0cceb2892db,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-9a759c8e-3808-4f06-9aef-e04a92c48fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-aa54102c-d80a-406a-b475-7237acbd74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-33321638-528b-463a-9a21-e458dd65c213,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-54966230-a46b-405d-b31b-5d6d943db5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-53eaff2c-9bef-4ac9-abf5-9867154b1b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807073003-172.17.0.19-1598485775561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42601,DS-02317dba-c56c-461a-a26f-7f63403ee099,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0e2a907e-b86c-4057-a87d-63f52488ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-9b46cd43-e571-4c17-a415-b0cceb2892db,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-9a759c8e-3808-4f06-9aef-e04a92c48fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-aa54102c-d80a-406a-b475-7237acbd74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-33321638-528b-463a-9a21-e458dd65c213,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-54966230-a46b-405d-b31b-5d6d943db5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-53eaff2c-9bef-4ac9-abf5-9867154b1b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484793446-172.17.0.19-1598485972003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-b2eaa4d6-48a1-498c-940b-200a46c79782,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-95b38916-66da-4d68-8fa9-a13ff9528709,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-809cbfbc-c965-4a8d-8ebd-618141f9c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-a647edf3-c025-4a8c-ae21-6b09f7f34b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-96ef6588-5762-4a43-a060-284b59025dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-01aff4e2-b10a-4e62-a02b-886f407aa7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-af670fa2-2f11-4dfd-b441-6b4857bd1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-ea6e3f08-0bc0-4073-8277-96b2e95740bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484793446-172.17.0.19-1598485972003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-b2eaa4d6-48a1-498c-940b-200a46c79782,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-95b38916-66da-4d68-8fa9-a13ff9528709,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-809cbfbc-c965-4a8d-8ebd-618141f9c84e,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-a647edf3-c025-4a8c-ae21-6b09f7f34b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-96ef6588-5762-4a43-a060-284b59025dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-01aff4e2-b10a-4e62-a02b-886f407aa7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-af670fa2-2f11-4dfd-b441-6b4857bd1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-ea6e3f08-0bc0-4073-8277-96b2e95740bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316414627-172.17.0.19-1598486269310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-f7b39b50-8272-47c8-a33a-34a8f521b9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-3f9e6b9d-e9f9-4cc4-aa89-962e2d6b469d,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-62c14dc1-ff79-441c-a4cf-92203586258e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-f4b4db55-eccc-4daa-a87f-8d498d7b4037,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-dd5b428e-ae9f-456b-a22a-5b064a88d192,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-7959f73e-aad4-4b49-ab2d-758e61e7bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8c4de6c2-50bb-4490-b35d-bd9056b1bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-025a02f8-6ff7-43f8-b2f2-c077e8ad903b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316414627-172.17.0.19-1598486269310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-f7b39b50-8272-47c8-a33a-34a8f521b9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-3f9e6b9d-e9f9-4cc4-aa89-962e2d6b469d,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-62c14dc1-ff79-441c-a4cf-92203586258e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-f4b4db55-eccc-4daa-a87f-8d498d7b4037,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-dd5b428e-ae9f-456b-a22a-5b064a88d192,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-7959f73e-aad4-4b49-ab2d-758e61e7bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-8c4de6c2-50bb-4490-b35d-bd9056b1bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-025a02f8-6ff7-43f8-b2f2-c077e8ad903b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478221398-172.17.0.19-1598486843299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-293a3d73-9912-486f-8cf8-d63fd7059150,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-2d2ea39c-7d49-4ac0-a4ca-d6b25c17d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-05dfd461-0430-48a9-b125-6b37119bf372,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-25fe4c69-5d54-4970-a99f-64a2b0d01064,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-9af9b704-35ba-469d-81f6-9a18538b4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-117a4835-2526-48b9-8c87-cd05f125cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7f8dab06-7d13-426b-838c-5696dba4a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-e51a299d-3e58-4205-8bf9-598a388739b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478221398-172.17.0.19-1598486843299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-293a3d73-9912-486f-8cf8-d63fd7059150,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-2d2ea39c-7d49-4ac0-a4ca-d6b25c17d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-05dfd461-0430-48a9-b125-6b37119bf372,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-25fe4c69-5d54-4970-a99f-64a2b0d01064,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-9af9b704-35ba-469d-81f6-9a18538b4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-117a4835-2526-48b9-8c87-cd05f125cd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7f8dab06-7d13-426b-838c-5696dba4a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-e51a299d-3e58-4205-8bf9-598a388739b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849223156-172.17.0.19-1598487122730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-a45a0250-33ff-44e9-9b5a-52965d2821f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-b9297439-585f-4f0c-bec4-38836b92b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-37b4eba4-2c62-4003-a0b8-3d57c8029584,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-cf25ac8a-fc78-4bbc-8229-94430a21b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-ecfe8312-566d-4809-8ce8-e6088920ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-9d68554b-ffbb-4896-a326-54523bce7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-1243a1ad-f1e6-40fd-8acb-7e0d6a94c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-ecbd4877-ece8-4129-a9bf-9fbc7bf6b4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849223156-172.17.0.19-1598487122730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33022,DS-a45a0250-33ff-44e9-9b5a-52965d2821f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-b9297439-585f-4f0c-bec4-38836b92b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-37b4eba4-2c62-4003-a0b8-3d57c8029584,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-cf25ac8a-fc78-4bbc-8229-94430a21b6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-ecfe8312-566d-4809-8ce8-e6088920ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-9d68554b-ffbb-4896-a326-54523bce7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-1243a1ad-f1e6-40fd-8acb-7e0d6a94c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-ecbd4877-ece8-4129-a9bf-9fbc7bf6b4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965309412-172.17.0.19-1598487219440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-e1ea7109-c676-4140-95d2-6788c0fa7264,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-d16f8c33-1f0c-496a-86bb-8a3943a47aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-65c75848-a165-4855-a502-596a831a83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f99a785a-64be-4ddb-ad11-2fee5a698d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-6c082343-2c72-47eb-a765-18079ed101d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-e49ed2a2-917e-41ab-9664-c6e473302595,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-21c524b3-92b9-4a5c-a10a-54484d3f71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-397ee47f-ce59-4b97-bde0-db0005e3ef0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965309412-172.17.0.19-1598487219440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-e1ea7109-c676-4140-95d2-6788c0fa7264,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-d16f8c33-1f0c-496a-86bb-8a3943a47aab,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-65c75848-a165-4855-a502-596a831a83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f99a785a-64be-4ddb-ad11-2fee5a698d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-6c082343-2c72-47eb-a765-18079ed101d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-e49ed2a2-917e-41ab-9664-c6e473302595,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-21c524b3-92b9-4a5c-a10a-54484d3f71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-397ee47f-ce59-4b97-bde0-db0005e3ef0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28556287-172.17.0.19-1598487639715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-78610f50-9550-4cff-8799-acc7e127a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-cd4338e0-b0dd-4792-8c6b-83018ad97d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-cb032147-a9d0-4052-a6a8-2e80ea06a0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-a28128de-d544-430a-858d-3077a382fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-db0c392b-5cd1-4082-af8f-1584c9026526,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-d9efe728-05f2-4b8d-842e-7e02e6a9aa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e262c4d-d9af-454f-8cb0-022b92dea47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-d8b73733-92ba-469e-9b71-5f1e93a6d622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28556287-172.17.0.19-1598487639715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-78610f50-9550-4cff-8799-acc7e127a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-cd4338e0-b0dd-4792-8c6b-83018ad97d68,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-cb032147-a9d0-4052-a6a8-2e80ea06a0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-a28128de-d544-430a-858d-3077a382fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-db0c392b-5cd1-4082-af8f-1584c9026526,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-d9efe728-05f2-4b8d-842e-7e02e6a9aa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-1e262c4d-d9af-454f-8cb0-022b92dea47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-d8b73733-92ba-469e-9b71-5f1e93a6d622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978935936-172.17.0.19-1598487820503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33858,DS-17d48e03-aa58-44ea-9815-2e98c0eb14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-4ee0f82b-21b0-4f83-b724-2122965955da,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-7cc4c82b-cf19-4a89-be19-1c8816c92f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-c6e4a341-fa8f-480a-9a59-1ab19150fba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-92918362-8bd4-498d-8bf1-0c874345c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-491e5c8e-121a-4692-a6a5-25f2544b9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-987e045e-fd28-490c-b644-7bf4ba103bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-a1419c53-53f5-4866-897a-713f8fb8c41c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978935936-172.17.0.19-1598487820503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33858,DS-17d48e03-aa58-44ea-9815-2e98c0eb14b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-4ee0f82b-21b0-4f83-b724-2122965955da,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-7cc4c82b-cf19-4a89-be19-1c8816c92f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-c6e4a341-fa8f-480a-9a59-1ab19150fba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-92918362-8bd4-498d-8bf1-0c874345c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-491e5c8e-121a-4692-a6a5-25f2544b9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-987e045e-fd28-490c-b644-7bf4ba103bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-a1419c53-53f5-4866-897a-713f8fb8c41c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555390357-172.17.0.19-1598487857691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-d2e268c8-fa70-4c62-b6f3-bcd1976dce67,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-a94947c9-2cd5-4eb8-b056-93a8b85d196d,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f31acf5f-24b1-4083-a58f-5d130cb98d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-33f362f3-c3bf-42eb-9c8f-7313de4f3a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7a50f8c0-e6b3-407b-b460-0719589ff89e,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-0e4bc167-5512-4739-9f2b-9b8aeafae602,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5cf166d5-6353-4e6e-bf05-00a2cec9efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-24d5ef6c-a16b-42e3-a5bd-207025c4e901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555390357-172.17.0.19-1598487857691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-d2e268c8-fa70-4c62-b6f3-bcd1976dce67,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-a94947c9-2cd5-4eb8-b056-93a8b85d196d,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f31acf5f-24b1-4083-a58f-5d130cb98d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-33f362f3-c3bf-42eb-9c8f-7313de4f3a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7a50f8c0-e6b3-407b-b460-0719589ff89e,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-0e4bc167-5512-4739-9f2b-9b8aeafae602,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5cf166d5-6353-4e6e-bf05-00a2cec9efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-24d5ef6c-a16b-42e3-a5bd-207025c4e901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839750515-172.17.0.19-1598488429724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0c68d127-7b43-46ec-bc57-752be052fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-325f9bd7-a273-4fe5-94dd-b8602d89201b,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3dc1d3b3-a63f-446d-ada4-242d61d0aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-3bf22515-d747-49ea-b5ee-401ce7d49dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-dff6bebb-f38b-4598-8711-ac4578505c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7e7c470d-6dc2-44a6-b020-7ad02ddefaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ec5eb1cb-02cd-4be3-8d2f-1ceb1780acc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-6c5e7626-7a86-43bb-97c5-3256b955f4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839750515-172.17.0.19-1598488429724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0c68d127-7b43-46ec-bc57-752be052fa48,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-325f9bd7-a273-4fe5-94dd-b8602d89201b,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-3dc1d3b3-a63f-446d-ada4-242d61d0aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-3bf22515-d747-49ea-b5ee-401ce7d49dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-dff6bebb-f38b-4598-8711-ac4578505c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-7e7c470d-6dc2-44a6-b020-7ad02ddefaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-ec5eb1cb-02cd-4be3-8d2f-1ceb1780acc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-6c5e7626-7a86-43bb-97c5-3256b955f4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610906688-172.17.0.19-1598488840918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-1f4bdf12-02d6-4bbe-bf90-64faa6ed143e,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-bb2101f6-b65a-4fc2-8e20-a85a2b24886a,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f96a5880-9abe-437f-8138-b819607a47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-be7d1a35-7da1-4227-814d-411c1d94eead,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-5146a0c2-5f7a-4311-8180-bfaae48fa2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-aadd043f-89fe-4f21-ba62-3b86b9911e66,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-214a8782-2da2-494a-940e-80ccaf1663bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9c86871c-1976-4363-80ce-cc9f3ba79d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610906688-172.17.0.19-1598488840918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-1f4bdf12-02d6-4bbe-bf90-64faa6ed143e,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-bb2101f6-b65a-4fc2-8e20-a85a2b24886a,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f96a5880-9abe-437f-8138-b819607a47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-be7d1a35-7da1-4227-814d-411c1d94eead,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-5146a0c2-5f7a-4311-8180-bfaae48fa2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-aadd043f-89fe-4f21-ba62-3b86b9911e66,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-214a8782-2da2-494a-940e-80ccaf1663bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9c86871c-1976-4363-80ce-cc9f3ba79d3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217282175-172.17.0.19-1598489504842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-51c617b4-98fd-44c7-86f0-051f45a4f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-64e5b9b1-5bb4-4c73-83be-882a9e0f63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-280f328e-00ee-42a2-93c6-ff00b42d7389,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-08891fc7-58ba-42e0-aa37-f2fc5fb67850,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-8e31c881-228e-4ea4-88fc-0c7c237f4fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-6b618d5c-b66d-4701-a83f-86c998ca604e,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-4dc42d1d-a8da-4f36-b358-76bda6c1c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-1d01f1fb-bbe7-4dfe-8ce1-466b8b2f39c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217282175-172.17.0.19-1598489504842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-51c617b4-98fd-44c7-86f0-051f45a4f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-64e5b9b1-5bb4-4c73-83be-882a9e0f63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-280f328e-00ee-42a2-93c6-ff00b42d7389,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-08891fc7-58ba-42e0-aa37-f2fc5fb67850,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-8e31c881-228e-4ea4-88fc-0c7c237f4fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-6b618d5c-b66d-4701-a83f-86c998ca604e,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-4dc42d1d-a8da-4f36-b358-76bda6c1c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-1d01f1fb-bbe7-4dfe-8ce1-466b8b2f39c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671415751-172.17.0.19-1598489769518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-1b2b06b4-e4bd-4e96-b2e3-d2662c9beac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-7831ee29-d257-4fad-b293-0cb51d6f6994,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-a20e9d06-1f66-4c2b-a599-c49552b3a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-91630c67-fa7f-4723-b133-775bb32ca034,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-aa382c77-73f2-4470-b318-0851c632f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b886bb2e-75c8-4991-b0f2-b27493ebbb11,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-32fa09b5-d2dd-43ce-aa9f-d25977235895,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-aaf1c0af-ba97-477c-bd7b-5b85ed5336ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671415751-172.17.0.19-1598489769518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-1b2b06b4-e4bd-4e96-b2e3-d2662c9beac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-7831ee29-d257-4fad-b293-0cb51d6f6994,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-a20e9d06-1f66-4c2b-a599-c49552b3a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-91630c67-fa7f-4723-b133-775bb32ca034,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-aa382c77-73f2-4470-b318-0851c632f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b886bb2e-75c8-4991-b0f2-b27493ebbb11,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-32fa09b5-d2dd-43ce-aa9f-d25977235895,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-aaf1c0af-ba97-477c-bd7b-5b85ed5336ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201236225-172.17.0.19-1598490236565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35551,DS-e4e712e3-cd53-4c80-b959-813762fb182f,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2f175fd7-6959-4bed-8934-5904310c72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c4135494-c151-422c-8e1e-cf32df7c8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-18ae6fd6-cae8-4212-8bf9-54b9d645e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-fca878cf-70f7-41c3-81d2-44ab2d0ef18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-508f6a6b-bf71-461d-a71d-486756072b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-88cf171d-c18d-4f4c-8b90-f3d3181b5f24,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-20d9d204-78b5-48fa-b588-955d755d9923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201236225-172.17.0.19-1598490236565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35551,DS-e4e712e3-cd53-4c80-b959-813762fb182f,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2f175fd7-6959-4bed-8934-5904310c72bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-c4135494-c151-422c-8e1e-cf32df7c8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-18ae6fd6-cae8-4212-8bf9-54b9d645e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-fca878cf-70f7-41c3-81d2-44ab2d0ef18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-508f6a6b-bf71-461d-a71d-486756072b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-88cf171d-c18d-4f4c-8b90-f3d3181b5f24,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-20d9d204-78b5-48fa-b588-955d755d9923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208698008-172.17.0.19-1598490329949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-a6342783-b2a7-4524-9c47-9d5a2668e955,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-6e8d8b20-9fe2-4e3a-9112-7b5746ec1764,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-714e4667-e1c5-428c-9cc3-a31f288da65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-b21e40cc-4d76-4c8f-85fc-c8ef5489e38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-c2dfb810-51cc-4395-9470-96892c800d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-577f119d-5631-46b1-8e75-154bb55aff15,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-53c5ed9f-5c7d-44d4-9050-11ff56db68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-f16e4527-0b69-445f-b904-f54902d6f08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208698008-172.17.0.19-1598490329949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39263,DS-a6342783-b2a7-4524-9c47-9d5a2668e955,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-6e8d8b20-9fe2-4e3a-9112-7b5746ec1764,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-714e4667-e1c5-428c-9cc3-a31f288da65c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-b21e40cc-4d76-4c8f-85fc-c8ef5489e38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-c2dfb810-51cc-4395-9470-96892c800d87,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-577f119d-5631-46b1-8e75-154bb55aff15,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-53c5ed9f-5c7d-44d4-9050-11ff56db68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-f16e4527-0b69-445f-b904-f54902d6f08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734872181-172.17.0.19-1598490366703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-13c44e6e-70d4-478b-abf5-452d3ddcc556,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a43a69e3-342f-411f-8f05-bf7462fffc53,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-c477a3ec-8d7e-43a5-9452-475d32f345e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-ba822624-7465-4dd1-baa0-07bc99578b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-36d94bd1-f3c8-46f0-ae19-9439c55caae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-3f19384d-7719-4b12-9827-a8d8382386f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-b7fd4c2f-5319-4237-b82c-4407e5db8047,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-24088065-1042-4e1e-8f60-e17756782632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734872181-172.17.0.19-1598490366703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44584,DS-13c44e6e-70d4-478b-abf5-452d3ddcc556,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-a43a69e3-342f-411f-8f05-bf7462fffc53,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-c477a3ec-8d7e-43a5-9452-475d32f345e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-ba822624-7465-4dd1-baa0-07bc99578b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-36d94bd1-f3c8-46f0-ae19-9439c55caae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-3f19384d-7719-4b12-9827-a8d8382386f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-b7fd4c2f-5319-4237-b82c-4407e5db8047,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-24088065-1042-4e1e-8f60-e17756782632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5266
