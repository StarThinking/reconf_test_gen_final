reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768351358-172.17.0.16-1598580678988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-dba3b9cd-8c06-40e2-b9c3-71e4a6183b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-ecb2b96e-2443-487d-9600-f8529beb8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-a47fde51-895d-4d34-9d55-a23255532d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-0b4e344e-717e-4696-878b-b49a088c2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-9ea0c65d-481d-48b1-ad4e-ae9e2ed96f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-042bebba-f35d-454c-980d-118840b6ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-17e8a6ee-618c-44f8-a675-c7a8a10a028d,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-56ed046c-3403-4128-9cef-1a03b3dbd990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768351358-172.17.0.16-1598580678988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-dba3b9cd-8c06-40e2-b9c3-71e4a6183b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-ecb2b96e-2443-487d-9600-f8529beb8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-a47fde51-895d-4d34-9d55-a23255532d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-0b4e344e-717e-4696-878b-b49a088c2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-9ea0c65d-481d-48b1-ad4e-ae9e2ed96f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-042bebba-f35d-454c-980d-118840b6ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-17e8a6ee-618c-44f8-a675-c7a8a10a028d,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-56ed046c-3403-4128-9cef-1a03b3dbd990,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177714507-172.17.0.16-1598580779873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-ff998d88-e6f2-4e59-9ce4-7fce3fa191a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-7f56da27-da4d-47d0-beb9-76737384a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-062ecdaa-52fc-4118-af0f-6f7e1afff72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-fab93b6a-d170-456f-b381-0d36e4abdeea,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-0dc34b7c-4add-492b-97ee-197dd2968f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-1cbfecbb-3119-4254-b960-373cfbfef142,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-1e063229-1e65-469e-883c-6a8b59e8c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-a9bf5c97-af1a-40fc-beff-d67e6ab02e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177714507-172.17.0.16-1598580779873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-ff998d88-e6f2-4e59-9ce4-7fce3fa191a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-7f56da27-da4d-47d0-beb9-76737384a0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-062ecdaa-52fc-4118-af0f-6f7e1afff72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-fab93b6a-d170-456f-b381-0d36e4abdeea,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-0dc34b7c-4add-492b-97ee-197dd2968f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-1cbfecbb-3119-4254-b960-373cfbfef142,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-1e063229-1e65-469e-883c-6a8b59e8c03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-a9bf5c97-af1a-40fc-beff-d67e6ab02e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979121202-172.17.0.16-1598580874697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-ab42776c-5a4d-4f50-883e-b47f66a6b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-314ab978-1559-4385-b19c-80cd84194de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-8dbc3ccd-7c9b-4ad4-8224-afe9cee1bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c9f99c0c-c4e8-4498-9fc6-d407f1da1663,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-3e8fb33e-b7b4-4e68-89d4-429972eab066,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-461b8a7f-fa3e-42e0-9784-a123d8efc291,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-ad23d6ad-7266-4ae2-be10-eed3911fbb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-42d6504e-f326-4e86-bbfd-88e4515c6e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979121202-172.17.0.16-1598580874697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-ab42776c-5a4d-4f50-883e-b47f66a6b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-314ab978-1559-4385-b19c-80cd84194de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-8dbc3ccd-7c9b-4ad4-8224-afe9cee1bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c9f99c0c-c4e8-4498-9fc6-d407f1da1663,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-3e8fb33e-b7b4-4e68-89d4-429972eab066,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-461b8a7f-fa3e-42e0-9784-a123d8efc291,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-ad23d6ad-7266-4ae2-be10-eed3911fbb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-42d6504e-f326-4e86-bbfd-88e4515c6e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134720633-172.17.0.16-1598580935485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-47d88acc-8ba3-4900-a062-e557993337ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-8f62fb99-d473-4f8e-babb-078b3b5344ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-c07c2ba5-1534-4b81-ab9d-b4ac82bc12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-dc53faf7-557c-421b-9769-e1c81d34a286,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-d46081eb-dcde-4e46-9b73-baf96908487f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a45b2a38-76e6-4a8e-bf4d-d245d3268b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-907ba11c-1aa2-4b1d-8806-2633fdc608e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-47b4e989-d81c-48e3-9d8b-dae5a3a445f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134720633-172.17.0.16-1598580935485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44339,DS-47d88acc-8ba3-4900-a062-e557993337ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-8f62fb99-d473-4f8e-babb-078b3b5344ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-c07c2ba5-1534-4b81-ab9d-b4ac82bc12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-dc53faf7-557c-421b-9769-e1c81d34a286,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-d46081eb-dcde-4e46-9b73-baf96908487f,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-a45b2a38-76e6-4a8e-bf4d-d245d3268b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-907ba11c-1aa2-4b1d-8806-2633fdc608e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-47b4e989-d81c-48e3-9d8b-dae5a3a445f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424913730-172.17.0.16-1598581915882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-22b8dc27-91dc-44ea-96e4-59639a74dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4350269a-adc5-4b18-baa8-d4a56d7407ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-dd0ae958-e42b-4584-9762-de8c27a0e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5ac1b53f-065c-42b3-b6ff-c84d7fcbbecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-15a293c9-b677-424c-be00-53df0b87628b,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-a3e9eadc-8db6-492d-84c8-c106ec0f0860,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-ac9c1fbe-13ff-4f29-bb46-fb8581323214,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-5801ca39-06c4-41bc-bc04-c6749182f90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424913730-172.17.0.16-1598581915882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-22b8dc27-91dc-44ea-96e4-59639a74dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4350269a-adc5-4b18-baa8-d4a56d7407ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-dd0ae958-e42b-4584-9762-de8c27a0e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-5ac1b53f-065c-42b3-b6ff-c84d7fcbbecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-15a293c9-b677-424c-be00-53df0b87628b,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-a3e9eadc-8db6-492d-84c8-c106ec0f0860,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-ac9c1fbe-13ff-4f29-bb46-fb8581323214,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-5801ca39-06c4-41bc-bc04-c6749182f90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33703908-172.17.0.16-1598582058397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-baa04ff5-e422-45de-94a2-9e404ac6122a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-5d9bafdc-59f3-45fa-a455-892a9364660d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-4bba5067-766c-4234-9544-9b94689ad588,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-435a4dfa-39c3-40a9-a043-80ad467d7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-795edc8e-0c85-464a-b5b1-f8544c3cbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-74a556ac-9f4e-4708-b3b6-974452ae4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-fc82373a-bf3e-4ad8-806d-8809793302a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5aeaddbe-15a4-4b8a-968e-cf0a1988c3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33703908-172.17.0.16-1598582058397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40776,DS-baa04ff5-e422-45de-94a2-9e404ac6122a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-5d9bafdc-59f3-45fa-a455-892a9364660d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-4bba5067-766c-4234-9544-9b94689ad588,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-435a4dfa-39c3-40a9-a043-80ad467d7c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-795edc8e-0c85-464a-b5b1-f8544c3cbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-74a556ac-9f4e-4708-b3b6-974452ae4ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-fc82373a-bf3e-4ad8-806d-8809793302a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-5aeaddbe-15a4-4b8a-968e-cf0a1988c3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14467202-172.17.0.16-1598582171808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-2a1b7462-768b-4e85-a344-0e8dc3fe6158,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f64b664c-da02-4bac-84e4-d319b9379b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-14fac3c4-1b62-46a8-a5a7-78eb9f326544,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-6b4b0e7d-3b2e-4908-b97e-a3c43d443e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-88656d65-0ed7-477c-96a2-f9b34ca6d866,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-db6dcafb-804e-4f59-8f8a-4748c633432e,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-a9040ccd-4c4b-4b87-be6e-6c91fdaf1edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-fc50f8d6-5025-4e77-ac42-eb4457c3db99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14467202-172.17.0.16-1598582171808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-2a1b7462-768b-4e85-a344-0e8dc3fe6158,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f64b664c-da02-4bac-84e4-d319b9379b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-14fac3c4-1b62-46a8-a5a7-78eb9f326544,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-6b4b0e7d-3b2e-4908-b97e-a3c43d443e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-88656d65-0ed7-477c-96a2-f9b34ca6d866,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-db6dcafb-804e-4f59-8f8a-4748c633432e,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-a9040ccd-4c4b-4b87-be6e-6c91fdaf1edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-fc50f8d6-5025-4e77-ac42-eb4457c3db99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791885690-172.17.0.16-1598583509521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-9802b3d0-c06a-4ca2-b456-a11c0c81631c,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-8ab02003-b453-4e3c-a0fa-2605f8b8e627,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-ecbd400f-cf0b-44f1-9b3e-15845fa868f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-5655bcd8-47a9-44f0-92e3-6396c9ea44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-5d7adc4f-c61c-4b33-83ec-fd69463224ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-782a446f-f43e-4973-8798-4c5801c2ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-88a3bbba-7c92-4f78-b3b8-4ba78b18158f,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-90696895-d788-4b22-9742-743a49425536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791885690-172.17.0.16-1598583509521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-9802b3d0-c06a-4ca2-b456-a11c0c81631c,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-8ab02003-b453-4e3c-a0fa-2605f8b8e627,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-ecbd400f-cf0b-44f1-9b3e-15845fa868f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-5655bcd8-47a9-44f0-92e3-6396c9ea44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-5d7adc4f-c61c-4b33-83ec-fd69463224ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-782a446f-f43e-4973-8798-4c5801c2ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-88a3bbba-7c92-4f78-b3b8-4ba78b18158f,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-90696895-d788-4b22-9742-743a49425536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471614996-172.17.0.16-1598584105183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-19e3c88a-8d95-4d1e-8789-9528f33aa422,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-81d7d1d6-fd9d-41e5-8428-05bcacd3f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-b8b67747-804f-457c-afd1-2b59fdecca15,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-c17d7f50-eba5-4d46-9790-16dee90cb093,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b0bf3122-697e-4b3f-8876-ad3c0a787ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-0bd0da81-33e7-4e24-90cb-7f8840c5a515,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-a06dd019-62a4-47de-a454-66d7447bcfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-79a56100-a43e-42fa-a548-eb46127d5dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1471614996-172.17.0.16-1598584105183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-19e3c88a-8d95-4d1e-8789-9528f33aa422,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-81d7d1d6-fd9d-41e5-8428-05bcacd3f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-b8b67747-804f-457c-afd1-2b59fdecca15,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-c17d7f50-eba5-4d46-9790-16dee90cb093,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b0bf3122-697e-4b3f-8876-ad3c0a787ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-0bd0da81-33e7-4e24-90cb-7f8840c5a515,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-a06dd019-62a4-47de-a454-66d7447bcfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-79a56100-a43e-42fa-a548-eb46127d5dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998918234-172.17.0.16-1598584140594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-03dc3c6d-1591-42eb-a1d4-7edb99c8b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-a57a25bf-fe7d-4d8c-b2ad-aca3febdece9,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-aa5a5e28-84b5-4a85-9330-4888ec90f00c,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-7fdaae40-42c7-42d3-ab27-51b150adcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-fcd0bfe8-44ef-4cc0-867f-db7dab33faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-71661123-3b67-453f-9445-ac7ab053c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-47430cd7-947e-47fb-bea0-e78271e312c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-38c68caf-8c5d-42a8-ad16-c5d9e4541fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998918234-172.17.0.16-1598584140594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-03dc3c6d-1591-42eb-a1d4-7edb99c8b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-a57a25bf-fe7d-4d8c-b2ad-aca3febdece9,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-aa5a5e28-84b5-4a85-9330-4888ec90f00c,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-7fdaae40-42c7-42d3-ab27-51b150adcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-fcd0bfe8-44ef-4cc0-867f-db7dab33faa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-71661123-3b67-453f-9445-ac7ab053c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-47430cd7-947e-47fb-bea0-e78271e312c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-38c68caf-8c5d-42a8-ad16-c5d9e4541fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952836196-172.17.0.16-1598584305810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-ffdfa34d-389c-4339-b637-2a18f77c5228,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-5c387791-c05d-439e-9145-fcb7a984b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-bb9611d7-1e08-401b-9e99-d06d96d94fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-69d4ef77-bd3c-4387-8338-be5fbe257090,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-22561153-859c-417f-84c5-413c35b06a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-1e5a5cd3-00e5-4970-b476-e22750743268,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8ad047d4-dd36-48e5-8c6a-bc82bf201025,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-8b972bfe-6345-4110-83c1-1845573680bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952836196-172.17.0.16-1598584305810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-ffdfa34d-389c-4339-b637-2a18f77c5228,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-5c387791-c05d-439e-9145-fcb7a984b08f,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-bb9611d7-1e08-401b-9e99-d06d96d94fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-69d4ef77-bd3c-4387-8338-be5fbe257090,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-22561153-859c-417f-84c5-413c35b06a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-1e5a5cd3-00e5-4970-b476-e22750743268,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8ad047d4-dd36-48e5-8c6a-bc82bf201025,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-8b972bfe-6345-4110-83c1-1845573680bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: hdfs:NameNode
v1: 300000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579870071-172.17.0.16-1598585624715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-fa85d027-5b77-44dc-83af-f2f4466734d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-5b978b36-6a07-4f58-8abf-e0977c8e9792,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-d0b0f131-c04f-4bd4-b25d-00fd43aaf426,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-e7a0d87f-e15b-4a0d-ad76-b8c5ea1c7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-ec391496-3f90-4835-808a-4f9b2cf3642a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-d3bcdc45-7f14-4199-9de6-88cded7bdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-327fe978-2e87-46cf-9b0c-c425f3b25738,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-0797ddfd-8224-43d7-95a4-ff6bf2ee4a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579870071-172.17.0.16-1598585624715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-fa85d027-5b77-44dc-83af-f2f4466734d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-5b978b36-6a07-4f58-8abf-e0977c8e9792,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-d0b0f131-c04f-4bd4-b25d-00fd43aaf426,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-e7a0d87f-e15b-4a0d-ad76-b8c5ea1c7bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-ec391496-3f90-4835-808a-4f9b2cf3642a,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-d3bcdc45-7f14-4199-9de6-88cded7bdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-327fe978-2e87-46cf-9b0c-c425f3b25738,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-0797ddfd-8224-43d7-95a4-ff6bf2ee4a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5011
