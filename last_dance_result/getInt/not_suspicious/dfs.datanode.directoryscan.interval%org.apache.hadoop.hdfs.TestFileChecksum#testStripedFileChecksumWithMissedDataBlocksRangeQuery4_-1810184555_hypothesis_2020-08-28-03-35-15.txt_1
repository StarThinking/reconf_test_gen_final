reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832409506-172.17.0.14-1598585934163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-cc30bb41-3c1c-40be-910d-fcacfa599e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-58693136-048e-42ea-9ee9-e827424dc697,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-79c0575f-036a-4929-a9bb-fe50946c5506,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-364c7070-719d-4d44-92be-30afb3dbc11e,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-fae40b16-9319-40f8-bf75-d25ca198614f,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6762517c-26c1-4dc8-a47e-5a86f5225dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-f4fe3b2e-c4b2-4332-b346-f1da0a0ba827,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d595bc66-93d1-4922-ad08-c1dfdfee2e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832409506-172.17.0.14-1598585934163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-cc30bb41-3c1c-40be-910d-fcacfa599e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-58693136-048e-42ea-9ee9-e827424dc697,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-79c0575f-036a-4929-a9bb-fe50946c5506,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-364c7070-719d-4d44-92be-30afb3dbc11e,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-fae40b16-9319-40f8-bf75-d25ca198614f,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6762517c-26c1-4dc8-a47e-5a86f5225dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-f4fe3b2e-c4b2-4332-b346-f1da0a0ba827,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d595bc66-93d1-4922-ad08-c1dfdfee2e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629103719-172.17.0.14-1598586180580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45222,DS-16c03354-9861-4c82-904b-56ca79c63c74,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-14c420e6-1d6f-41da-a85e-e9ee1f2740b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-60389f2d-f26a-4a30-88cb-d71ec40b0674,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-f21ad20b-4442-4d72-93fa-5e8bf0afb09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-67f7f7f7-35a9-4349-9eda-ad050abcf7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fd2233d0-b1b0-42fa-a866-a7b56551475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-6d52c0e1-def0-4a9c-b4a2-bbcb50442469,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-9b3fc8df-f874-4420-a2e2-e39d792ce1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629103719-172.17.0.14-1598586180580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45222,DS-16c03354-9861-4c82-904b-56ca79c63c74,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-14c420e6-1d6f-41da-a85e-e9ee1f2740b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-60389f2d-f26a-4a30-88cb-d71ec40b0674,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-f21ad20b-4442-4d72-93fa-5e8bf0afb09c,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-67f7f7f7-35a9-4349-9eda-ad050abcf7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-fd2233d0-b1b0-42fa-a866-a7b56551475b,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-6d52c0e1-def0-4a9c-b4a2-bbcb50442469,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-9b3fc8df-f874-4420-a2e2-e39d792ce1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924673721-172.17.0.14-1598586295989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-89d38344-63ea-42b9-84d8-fadf50e885d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-9b3d105b-aa1e-4cb7-8166-5b2edba31088,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-105dc55d-867c-455d-a1ce-70dd7d2b9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-9614efa1-1c2a-43c1-b691-a62fae68c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-d915773a-fa53-4b97-8bc5-914061e856b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-31466da4-ab8e-412a-ba5f-ce5b7cf86e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-9a0fc6ca-da28-4204-9684-ba0405516521,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-2129b38a-9818-4f98-8323-62fbc00bdcf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924673721-172.17.0.14-1598586295989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-89d38344-63ea-42b9-84d8-fadf50e885d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-9b3d105b-aa1e-4cb7-8166-5b2edba31088,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-105dc55d-867c-455d-a1ce-70dd7d2b9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-9614efa1-1c2a-43c1-b691-a62fae68c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-d915773a-fa53-4b97-8bc5-914061e856b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-31466da4-ab8e-412a-ba5f-ce5b7cf86e88,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-9a0fc6ca-da28-4204-9684-ba0405516521,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-2129b38a-9818-4f98-8323-62fbc00bdcf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607212336-172.17.0.14-1598586403160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-d994968a-4922-487b-bdde-2d63a29981f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-26fa982e-0e5b-4900-acff-bb38fe2ec881,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-baf5fe31-738a-4c68-88be-1541e3d8d2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-ef2c92c9-fd04-4012-ae9d-62b10cd5e154,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a9140ef7-1e1f-4219-a031-236bee74a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-f0ccb716-5b55-4fb7-9001-5dd093ddc198,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-500911ed-49f1-401f-aba3-cf4edd9577c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-72060e90-c21b-412a-99d7-4ca079a9793a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607212336-172.17.0.14-1598586403160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-d994968a-4922-487b-bdde-2d63a29981f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-26fa982e-0e5b-4900-acff-bb38fe2ec881,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-baf5fe31-738a-4c68-88be-1541e3d8d2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-ef2c92c9-fd04-4012-ae9d-62b10cd5e154,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a9140ef7-1e1f-4219-a031-236bee74a48f,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-f0ccb716-5b55-4fb7-9001-5dd093ddc198,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-500911ed-49f1-401f-aba3-cf4edd9577c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-72060e90-c21b-412a-99d7-4ca079a9793a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807569651-172.17.0.14-1598586692725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-41cdae2c-d5ef-48ca-a046-555fbf5b6719,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-68b0b7ee-57bb-45f0-8425-7bd35b7f572f,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-7987da09-8661-47ca-ab29-770211be7194,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-596f3754-8b69-45d8-bb68-dcedf52faaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-b12f9e61-d92f-40d4-a52c-9fc637a30882,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-ba50f699-fd87-46a7-a753-0c2ecfcba269,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-4b7125db-2903-400a-813c-b412fbf73d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-ff283f62-5b1f-4a92-b297-3cf7ae03f7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807569651-172.17.0.14-1598586692725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-41cdae2c-d5ef-48ca-a046-555fbf5b6719,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-68b0b7ee-57bb-45f0-8425-7bd35b7f572f,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-7987da09-8661-47ca-ab29-770211be7194,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-596f3754-8b69-45d8-bb68-dcedf52faaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-b12f9e61-d92f-40d4-a52c-9fc637a30882,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-ba50f699-fd87-46a7-a753-0c2ecfcba269,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-4b7125db-2903-400a-813c-b412fbf73d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-ff283f62-5b1f-4a92-b297-3cf7ae03f7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841459343-172.17.0.14-1598587080353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-3d495fa6-9881-460d-be5c-86b8e3ddf751,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-76ba7519-483c-46a0-9c5f-2f3f28b4401e,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-5977d765-2eab-4797-92cd-eb319fc47543,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-36dc9d2b-9520-4eab-8760-5c4c662a8208,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-93c0adfa-c88f-473b-bde8-00a3760a9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-d49396bd-e9b2-4987-98a1-bd710bdfc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-c2f211c6-2f04-48eb-959b-11dff0fe97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-0f42fd7f-8702-4b72-9d1f-ee31e6ce74b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841459343-172.17.0.14-1598587080353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-3d495fa6-9881-460d-be5c-86b8e3ddf751,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-76ba7519-483c-46a0-9c5f-2f3f28b4401e,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-5977d765-2eab-4797-92cd-eb319fc47543,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-36dc9d2b-9520-4eab-8760-5c4c662a8208,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-93c0adfa-c88f-473b-bde8-00a3760a9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-d49396bd-e9b2-4987-98a1-bd710bdfc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-c2f211c6-2f04-48eb-959b-11dff0fe97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-0f42fd7f-8702-4b72-9d1f-ee31e6ce74b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123168992-172.17.0.14-1598587725625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-563e305e-6c78-42d9-94d9-a4f946f12deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-408a3de3-f7f0-4b06-811b-ef882ee3cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-51a67bc6-58c7-45ea-af5c-f4fc64864dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-490cf525-0d6e-4860-8dfe-abf2e2ab5e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-be85d172-0a7a-45b2-8a74-b75b09392fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-9b7ea4ac-8815-444c-9c3a-56e8a0d54a82,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-f1fb349a-f511-4cc1-ad46-b9585bced913,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-0f6cee44-28a7-48c0-982e-b7523297feef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123168992-172.17.0.14-1598587725625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-563e305e-6c78-42d9-94d9-a4f946f12deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-408a3de3-f7f0-4b06-811b-ef882ee3cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-51a67bc6-58c7-45ea-af5c-f4fc64864dde,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-490cf525-0d6e-4860-8dfe-abf2e2ab5e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-be85d172-0a7a-45b2-8a74-b75b09392fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-9b7ea4ac-8815-444c-9c3a-56e8a0d54a82,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-f1fb349a-f511-4cc1-ad46-b9585bced913,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-0f6cee44-28a7-48c0-982e-b7523297feef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484902193-172.17.0.14-1598588065483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-f152a5e9-e231-415c-9aee-12c1755ba53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fcfe9ba5-8b9c-4662-925d-edb2ad1b3248,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-2d23b5fe-23a6-4923-80c6-d58e53982705,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-6fe70939-7fbe-4b48-85cb-c52e4c920bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-4f7a9578-5310-4961-8503-26337d4e61a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-09f9ed0b-ae00-4b64-ba21-edaee4c412a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-cf321cc5-de5c-42a3-946b-e35b97dafc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c4c24a7d-a9eb-4ab7-a5a9-7ea17d1a3e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484902193-172.17.0.14-1598588065483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-f152a5e9-e231-415c-9aee-12c1755ba53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-fcfe9ba5-8b9c-4662-925d-edb2ad1b3248,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-2d23b5fe-23a6-4923-80c6-d58e53982705,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-6fe70939-7fbe-4b48-85cb-c52e4c920bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-4f7a9578-5310-4961-8503-26337d4e61a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-09f9ed0b-ae00-4b64-ba21-edaee4c412a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-cf321cc5-de5c-42a3-946b-e35b97dafc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c4c24a7d-a9eb-4ab7-a5a9-7ea17d1a3e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527208394-172.17.0.14-1598588107593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-c0f1bb26-f3a0-4ff8-bb7b-d0be4c827cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-76d0beaa-e63a-4e3f-8774-eae5e7432d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-58016dee-365d-4302-8d6d-8f2f4fcb7a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-5c6b2829-8d66-453b-8b92-8c354e5942dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-24721ecc-e770-4642-abfa-42be15a54e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-9f94e243-030a-4ab9-811d-3290152d7464,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-4e9b66af-7dd5-4930-a2b8-f9dd9af4ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-4dbbe2f8-cff2-4297-88e6-96f0b96c63e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527208394-172.17.0.14-1598588107593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-c0f1bb26-f3a0-4ff8-bb7b-d0be4c827cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-76d0beaa-e63a-4e3f-8774-eae5e7432d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-58016dee-365d-4302-8d6d-8f2f4fcb7a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-5c6b2829-8d66-453b-8b92-8c354e5942dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-24721ecc-e770-4642-abfa-42be15a54e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-9f94e243-030a-4ab9-811d-3290152d7464,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-4e9b66af-7dd5-4930-a2b8-f9dd9af4ff3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-4dbbe2f8-cff2-4297-88e6-96f0b96c63e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041877021-172.17.0.14-1598588247775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37778,DS-4cd0702a-5e8c-4cad-bdaf-6d8fe64d8fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-c2b795f8-b33f-4100-b1ab-5953aaeda4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-6da93623-3dae-4fea-85ef-b73926c6d0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-95337d72-2528-417c-9a00-4ef180134e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-b17f8a8e-dc40-4c59-8ce5-92614f6e1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-2c002160-4516-4755-be9e-63dea6364d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-33d62efc-e8e7-45de-b67a-290872432f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-7128647c-ddbe-4418-afef-c20e6d62b81a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041877021-172.17.0.14-1598588247775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37778,DS-4cd0702a-5e8c-4cad-bdaf-6d8fe64d8fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-c2b795f8-b33f-4100-b1ab-5953aaeda4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-6da93623-3dae-4fea-85ef-b73926c6d0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-95337d72-2528-417c-9a00-4ef180134e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-b17f8a8e-dc40-4c59-8ce5-92614f6e1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-2c002160-4516-4755-be9e-63dea6364d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-33d62efc-e8e7-45de-b67a-290872432f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-7128647c-ddbe-4418-afef-c20e6d62b81a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945692597-172.17.0.14-1598588508923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-6327284f-68f3-4362-af30-8298e9912f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-ae2da157-0c8e-45fe-b6dc-a500338f4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-799bc2ec-a96d-4225-bb2e-bff19fee6a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-33c16577-35f4-44f7-9bcd-d248a0dc441e,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-0c6f5c64-3788-4770-bbd2-8bbda56b00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-8949412b-5913-4cbd-b2ad-09ff6719f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-e6a9a93d-e759-4621-b2d4-70012b0cd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-fa8f268e-cf0c-435e-8c62-a249a1f34ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945692597-172.17.0.14-1598588508923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45128,DS-6327284f-68f3-4362-af30-8298e9912f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-ae2da157-0c8e-45fe-b6dc-a500338f4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-799bc2ec-a96d-4225-bb2e-bff19fee6a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-33c16577-35f4-44f7-9bcd-d248a0dc441e,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-0c6f5c64-3788-4770-bbd2-8bbda56b00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-8949412b-5913-4cbd-b2ad-09ff6719f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-e6a9a93d-e759-4621-b2d4-70012b0cd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-fa8f268e-cf0c-435e-8c62-a249a1f34ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565593452-172.17.0.14-1598588932316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-bb7058cc-3226-4833-8344-b8a661e1755c,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-f8019508-5bc6-4722-a6c6-d605cca3a8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-55d73155-05ae-43f5-8201-9e259c226947,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-74fd7e31-db40-4b86-887b-cd84d81e19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-29dc8a97-8512-400a-be21-99099da3614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-c6ac5f81-55fb-4385-bd72-e3d8e5d9a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-637c4763-4bd0-4a2e-893c-a3a1d977b194,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-ad593f26-debb-418b-9eff-5b5377f0eed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565593452-172.17.0.14-1598588932316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-bb7058cc-3226-4833-8344-b8a661e1755c,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-f8019508-5bc6-4722-a6c6-d605cca3a8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-55d73155-05ae-43f5-8201-9e259c226947,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-74fd7e31-db40-4b86-887b-cd84d81e19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-29dc8a97-8512-400a-be21-99099da3614e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-c6ac5f81-55fb-4385-bd72-e3d8e5d9a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-637c4763-4bd0-4a2e-893c-a3a1d977b194,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-ad593f26-debb-418b-9eff-5b5377f0eed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077604264-172.17.0.14-1598589003205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-6531c7ed-8730-4c7b-99f3-e1afef996ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-ab67d5a8-4072-471b-aac2-2b9eb2b45a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-ed9be211-32c2-4c48-9e58-761bb32cabd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-63547722-60da-485f-ac0b-ac0c0c84f9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-77b00f65-87cd-4a28-aadc-d63c7d62e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f1e44698-c95a-479f-9ab8-824a847f0534,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-437e57b0-d766-4364-8358-ab5cfb059aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-30473d82-2f2b-4b05-ab0f-3deab2c4af1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077604264-172.17.0.14-1598589003205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-6531c7ed-8730-4c7b-99f3-e1afef996ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-ab67d5a8-4072-471b-aac2-2b9eb2b45a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-ed9be211-32c2-4c48-9e58-761bb32cabd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-63547722-60da-485f-ac0b-ac0c0c84f9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-77b00f65-87cd-4a28-aadc-d63c7d62e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-f1e44698-c95a-479f-9ab8-824a847f0534,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-437e57b0-d766-4364-8358-ab5cfb059aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-30473d82-2f2b-4b05-ab0f-3deab2c4af1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696977951-172.17.0.14-1598589182965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-b39b6f09-ce83-4d07-b141-9cb3cd8ad3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-08ffeee4-293d-407a-9e39-286d239ceaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-d5b17848-c1c1-4f07-b700-736e4c6f9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-3f1ac08e-67f8-475b-ab1f-1b82b3842f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-e819de89-5f1c-4cfa-8ab9-132970d2a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-aaee66bb-48ce-4e6f-9a72-ec23fec90398,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-0dd54a00-441a-4dba-8970-ef0879bf7336,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cc9c823c-cadf-4ebc-9657-01a9cc61d885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696977951-172.17.0.14-1598589182965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-b39b6f09-ce83-4d07-b141-9cb3cd8ad3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-08ffeee4-293d-407a-9e39-286d239ceaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-d5b17848-c1c1-4f07-b700-736e4c6f9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-3f1ac08e-67f8-475b-ab1f-1b82b3842f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-e819de89-5f1c-4cfa-8ab9-132970d2a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-aaee66bb-48ce-4e6f-9a72-ec23fec90398,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-0dd54a00-441a-4dba-8970-ef0879bf7336,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cc9c823c-cadf-4ebc-9657-01a9cc61d885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901100457-172.17.0.14-1598589515208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-48e61a21-4279-4504-96bd-b77f30a3f22a,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-54f679e6-b587-4262-badf-de2a2e4557ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2afad3e7-9a3e-4de7-af36-107d9b4fa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-2f505d0e-431b-4f45-9340-dd900f2de7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-e0c44ac3-bcd1-480a-990f-41da39a41c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-eba8dd4e-d80d-4a1a-9ed9-99b23b8b5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-5f537dbc-2587-4c9e-8f02-bcc86690685c,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-8efbd5a3-a00d-4bb4-8cb3-6574739217a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901100457-172.17.0.14-1598589515208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-48e61a21-4279-4504-96bd-b77f30a3f22a,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-54f679e6-b587-4262-badf-de2a2e4557ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-2afad3e7-9a3e-4de7-af36-107d9b4fa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-2f505d0e-431b-4f45-9340-dd900f2de7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-e0c44ac3-bcd1-480a-990f-41da39a41c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-eba8dd4e-d80d-4a1a-9ed9-99b23b8b5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-5f537dbc-2587-4c9e-8f02-bcc86690685c,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-8efbd5a3-a00d-4bb4-8cb3-6574739217a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172958183-172.17.0.14-1598589942731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-31580f2f-ff47-4720-9f14-bb1a2aab6857,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b25d0796-cb43-46d3-9080-59258adc3629,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-af38b3ae-8fd9-48f1-b2b0-120487dad1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-12c9dec5-fd3c-48dd-a640-3cbfaa736471,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-993e51d2-8979-4898-a38f-8c06a895fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-a8a8d8f6-d26d-4ec7-a1b9-e58e667d992d,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-b032b947-f0c6-44fe-96a3-e3c93f4dc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-34deb998-77ac-44b0-9ef0-dfe6c1d4c898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172958183-172.17.0.14-1598589942731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-31580f2f-ff47-4720-9f14-bb1a2aab6857,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-b25d0796-cb43-46d3-9080-59258adc3629,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-af38b3ae-8fd9-48f1-b2b0-120487dad1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-12c9dec5-fd3c-48dd-a640-3cbfaa736471,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-993e51d2-8979-4898-a38f-8c06a895fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-a8a8d8f6-d26d-4ec7-a1b9-e58e667d992d,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-b032b947-f0c6-44fe-96a3-e3c93f4dc85b,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-34deb998-77ac-44b0-9ef0-dfe6c1d4c898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434374836-172.17.0.14-1598590632021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-7592c1dd-6ac1-4fea-89bd-0f976cd917ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-a1b7cdc2-7f67-4005-b6a3-a127e6a824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-7e5f605c-521e-49a4-9837-9b0ce4fe762f,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-576868c7-74ac-4837-98e0-bd4b4b871203,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-1d248a4e-8a97-486e-8f77-b455bd729124,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-50cb21fd-3170-4d50-a65b-ea2dcf020629,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-70d895c3-d8e9-4aba-852d-5e390efa18b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-240746ee-5af6-4daf-954e-4f3971320962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434374836-172.17.0.14-1598590632021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-7592c1dd-6ac1-4fea-89bd-0f976cd917ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-a1b7cdc2-7f67-4005-b6a3-a127e6a824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-7e5f605c-521e-49a4-9837-9b0ce4fe762f,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-576868c7-74ac-4837-98e0-bd4b4b871203,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-1d248a4e-8a97-486e-8f77-b455bd729124,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-50cb21fd-3170-4d50-a65b-ea2dcf020629,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-70d895c3-d8e9-4aba-852d-5e390efa18b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-240746ee-5af6-4daf-954e-4f3971320962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394673252-172.17.0.14-1598590874291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-bf5c69e0-4ffa-40f2-a76e-2303c8143ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-0f0f2f2c-b090-4e8e-aeac-b9b689c5aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-d3033707-902a-45e3-85fc-8ff88e466184,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-2121afe8-16ed-494b-951e-713b799082c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-daeb92b2-b437-46f8-add2-be64885c7217,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-b64414ff-9e32-4b10-a90e-b5e41e3baa50,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1041eea1-d14b-46a0-bcf0-0eb472d49247,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-c74b280a-a89a-4334-acbb-4b2ed4b5a268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394673252-172.17.0.14-1598590874291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-bf5c69e0-4ffa-40f2-a76e-2303c8143ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-0f0f2f2c-b090-4e8e-aeac-b9b689c5aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-d3033707-902a-45e3-85fc-8ff88e466184,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-2121afe8-16ed-494b-951e-713b799082c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-daeb92b2-b437-46f8-add2-be64885c7217,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-b64414ff-9e32-4b10-a90e-b5e41e3baa50,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1041eea1-d14b-46a0-bcf0-0eb472d49247,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-c74b280a-a89a-4334-acbb-4b2ed4b5a268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5315
