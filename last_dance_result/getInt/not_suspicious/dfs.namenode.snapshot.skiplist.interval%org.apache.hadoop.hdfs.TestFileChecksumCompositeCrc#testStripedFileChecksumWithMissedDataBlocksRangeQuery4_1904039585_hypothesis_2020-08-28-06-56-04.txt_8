reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957338895-172.17.0.13-1598598519636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39248,DS-ad5d8600-8e51-4cce-9bc6-47c2d2509eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2cb61f53-aede-451e-9b0f-e3705bfea5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-52ae8311-976a-4351-87df-bf2135616173,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e3059aea-9210-4d9c-b840-777c26a42c52,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-b8a1ab7c-109c-4f81-af05-7f91788244dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-268bba71-b068-43f3-82c7-ce075aeb54be,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3b3c5048-0871-40bc-b18a-9d4b49bf982d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-5c56401a-7ad8-4efc-afd5-80853bb26e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957338895-172.17.0.13-1598598519636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39248,DS-ad5d8600-8e51-4cce-9bc6-47c2d2509eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-2cb61f53-aede-451e-9b0f-e3705bfea5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-52ae8311-976a-4351-87df-bf2135616173,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e3059aea-9210-4d9c-b840-777c26a42c52,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-b8a1ab7c-109c-4f81-af05-7f91788244dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-268bba71-b068-43f3-82c7-ce075aeb54be,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-3b3c5048-0871-40bc-b18a-9d4b49bf982d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-5c56401a-7ad8-4efc-afd5-80853bb26e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108297985-172.17.0.13-1598598930818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-efabeaa5-9a8b-4b1c-92c1-71f2e880c69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-f4a72fe7-c684-4570-aaac-34d191da8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-35a69a0b-17e0-483b-9292-764c50505466,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-fe0de9c6-1bdb-475c-9a86-e20b258676c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-c152db55-ff42-4154-9f4c-f66e4ff85b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-b0eb3564-9d04-4378-86cb-588d5a8367df,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-3a748ad8-8a93-4762-941b-fed7ec7d021c,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-9d9fbc80-a4b1-4273-b13b-0130cbe132a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108297985-172.17.0.13-1598598930818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-efabeaa5-9a8b-4b1c-92c1-71f2e880c69d,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-f4a72fe7-c684-4570-aaac-34d191da8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-35a69a0b-17e0-483b-9292-764c50505466,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-fe0de9c6-1bdb-475c-9a86-e20b258676c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-c152db55-ff42-4154-9f4c-f66e4ff85b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-b0eb3564-9d04-4378-86cb-588d5a8367df,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-3a748ad8-8a93-4762-941b-fed7ec7d021c,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-9d9fbc80-a4b1-4273-b13b-0130cbe132a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037095699-172.17.0.13-1598599037465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36489,DS-43e3019e-7fd3-4c37-8a69-f00c868a39c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-8d5e2e0e-d963-45a0-8494-273bb5a80009,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-9a800147-dddf-49ea-ab4e-5aff01b95ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-34ffe95c-bfcb-411f-ba89-9baf77e0cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-42158e8d-dc5d-4eac-8320-51b60593ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-96e2b1ad-77e0-48e1-8311-5753667496b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-447663ff-d6f7-4b62-bd9b-b8f43eccee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-14155d8d-45cb-4bb6-a3d5-4553caef9281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037095699-172.17.0.13-1598599037465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36489,DS-43e3019e-7fd3-4c37-8a69-f00c868a39c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-8d5e2e0e-d963-45a0-8494-273bb5a80009,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-9a800147-dddf-49ea-ab4e-5aff01b95ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-34ffe95c-bfcb-411f-ba89-9baf77e0cb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-42158e8d-dc5d-4eac-8320-51b60593ed94,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-96e2b1ad-77e0-48e1-8311-5753667496b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-447663ff-d6f7-4b62-bd9b-b8f43eccee7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-14155d8d-45cb-4bb6-a3d5-4553caef9281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042786712-172.17.0.13-1598599933742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40311,DS-8d246b9a-ca96-4b3c-9d6a-7111fda89e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-6fa00a1f-0c44-4cc9-bfee-b20b0c175dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-4375748b-6aa9-45f8-8734-3f8807684921,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0e7cb84e-1071-46b0-92d1-8c8e0063f743,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-396d0628-0f73-496f-a91a-4335792c2beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-db937b0b-c752-41f7-a813-808e57354672,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-09948be4-bb79-490b-b06d-0d0623df5f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0d596170-6d60-4574-88ed-0678f3ae4c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042786712-172.17.0.13-1598599933742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40311,DS-8d246b9a-ca96-4b3c-9d6a-7111fda89e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-6fa00a1f-0c44-4cc9-bfee-b20b0c175dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-4375748b-6aa9-45f8-8734-3f8807684921,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0e7cb84e-1071-46b0-92d1-8c8e0063f743,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-396d0628-0f73-496f-a91a-4335792c2beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-db937b0b-c752-41f7-a813-808e57354672,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-09948be4-bb79-490b-b06d-0d0623df5f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0d596170-6d60-4574-88ed-0678f3ae4c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103742951-172.17.0.13-1598600066406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-3ebe0cb8-a0cc-4a71-a7dc-459dacd0b956,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-076f882c-331a-41d5-bc74-76766b5f06b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f9d7f47b-62fa-44ba-ac0e-150b12d18628,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-eeabcbae-48e7-4728-a897-4fa51ef58d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-01e48a6d-6087-43d2-955c-db4cd3dd0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-b8f5e4b1-f754-46bc-a64d-ddc65753c078,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-65e7847f-0c40-4ae0-916c-69d8e7c5b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-5299a7e4-737f-4f9c-9447-50240ad53d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103742951-172.17.0.13-1598600066406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34546,DS-3ebe0cb8-a0cc-4a71-a7dc-459dacd0b956,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-076f882c-331a-41d5-bc74-76766b5f06b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-f9d7f47b-62fa-44ba-ac0e-150b12d18628,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-eeabcbae-48e7-4728-a897-4fa51ef58d67,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-01e48a6d-6087-43d2-955c-db4cd3dd0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-b8f5e4b1-f754-46bc-a64d-ddc65753c078,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-65e7847f-0c40-4ae0-916c-69d8e7c5b87f,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-5299a7e4-737f-4f9c-9447-50240ad53d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966716556-172.17.0.13-1598600547025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-2325d95d-63dd-4e69-be21-d3376dd77298,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-138614e9-d7c4-47ef-b7a0-b145aaf40d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-08285ee6-df7d-48ec-b8c8-90bb71cd9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a8f98be2-9632-47e7-9fda-f45a90258a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-66b200dd-b4ea-4ee1-acbf-b4e8bf47de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-eda56d01-c4ca-4a2d-90d7-dc6d4e9c79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2ab1fa0d-7c16-4ce9-a1de-e52e4f177c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8ed7740c-39cf-4344-949b-3bba7165d52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966716556-172.17.0.13-1598600547025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-2325d95d-63dd-4e69-be21-d3376dd77298,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-138614e9-d7c4-47ef-b7a0-b145aaf40d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-08285ee6-df7d-48ec-b8c8-90bb71cd9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-a8f98be2-9632-47e7-9fda-f45a90258a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-66b200dd-b4ea-4ee1-acbf-b4e8bf47de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-eda56d01-c4ca-4a2d-90d7-dc6d4e9c79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-2ab1fa0d-7c16-4ce9-a1de-e52e4f177c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-8ed7740c-39cf-4344-949b-3bba7165d52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603331386-172.17.0.13-1598600897240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-60378656-3a4b-41f7-a802-7ebcf0d6adb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-d9ff6987-8ef8-4c60-bda6-ca4f647b8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-961f6495-37bf-4ca6-aa36-fcd4c0d088f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-eeeba91b-f41e-4e6d-b2a1-279eed8214ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-71b4e3b7-732a-4978-90ad-e19fad4fc324,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-abbaf206-e3c9-41d4-9556-d2b6a9c7d787,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-fa72503a-9eb1-4f88-9308-c37352ccbe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f7630791-c18a-4e86-95ca-e5ab17f35915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603331386-172.17.0.13-1598600897240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-60378656-3a4b-41f7-a802-7ebcf0d6adb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-d9ff6987-8ef8-4c60-bda6-ca4f647b8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-961f6495-37bf-4ca6-aa36-fcd4c0d088f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-eeeba91b-f41e-4e6d-b2a1-279eed8214ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-71b4e3b7-732a-4978-90ad-e19fad4fc324,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-abbaf206-e3c9-41d4-9556-d2b6a9c7d787,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-fa72503a-9eb1-4f88-9308-c37352ccbe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f7630791-c18a-4e86-95ca-e5ab17f35915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491408245-172.17.0.13-1598601178339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-96e5423f-fc40-4489-8885-93c5d1ff2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c8889dc4-d650-443e-b3dd-70355f5720c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-d1e4fc70-0a84-49d6-88e9-ad40d4549014,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-359c29c4-5d5f-496e-96b5-36eb27ad4608,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-3a171a39-e2e4-4214-b613-8e57a47ed72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-b1a47d61-6735-4691-91d9-9323fbcb6cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-787ebee4-0a12-4631-8a93-19a2ccb9f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-5ae80c75-057c-47cd-9ad7-4a8e783237d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491408245-172.17.0.13-1598601178339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-96e5423f-fc40-4489-8885-93c5d1ff2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c8889dc4-d650-443e-b3dd-70355f5720c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-d1e4fc70-0a84-49d6-88e9-ad40d4549014,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-359c29c4-5d5f-496e-96b5-36eb27ad4608,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-3a171a39-e2e4-4214-b613-8e57a47ed72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-b1a47d61-6735-4691-91d9-9323fbcb6cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-787ebee4-0a12-4631-8a93-19a2ccb9f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-5ae80c75-057c-47cd-9ad7-4a8e783237d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454756573-172.17.0.13-1598601291461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-ce7a7338-fe77-4294-bea7-820d008b288f,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e63e8017-46d2-4c42-899a-7d328b071617,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-6ba7efe3-6a2c-413c-8164-8def1f61b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-afb725fa-86ed-4288-95f7-95cfd6d06d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-2d8cc0cf-95c7-4bca-8eb6-5930209a416b,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-27909ee3-cb59-44d8-984b-5394709ffc64,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-6066c2e3-22b4-457a-b4d5-29ce03d92dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-fec724df-90bd-47e2-b1ac-0594d557ac42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454756573-172.17.0.13-1598601291461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44817,DS-ce7a7338-fe77-4294-bea7-820d008b288f,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e63e8017-46d2-4c42-899a-7d328b071617,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-6ba7efe3-6a2c-413c-8164-8def1f61b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-afb725fa-86ed-4288-95f7-95cfd6d06d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-2d8cc0cf-95c7-4bca-8eb6-5930209a416b,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-27909ee3-cb59-44d8-984b-5394709ffc64,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-6066c2e3-22b4-457a-b4d5-29ce03d92dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-fec724df-90bd-47e2-b1ac-0594d557ac42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178920331-172.17.0.13-1598601333186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-36ecfdbc-a5a6-473c-acba-7a7b683daad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-e14e3697-c3e2-4e86-a1cc-9040a33fa5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-17854c25-4c43-4e18-b723-edeaf16ba4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-4185db1e-97da-4e7f-b41f-ab89b91e2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-09a6b2f6-48f4-433a-a0a3-7276543d0906,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-6d8e0cfd-352b-4650-9069-a18e3b03cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-9c817af8-403e-407d-9384-391cd84cf28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-64bbbe58-e711-4b71-8f1e-3d719188c625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178920331-172.17.0.13-1598601333186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-36ecfdbc-a5a6-473c-acba-7a7b683daad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-e14e3697-c3e2-4e86-a1cc-9040a33fa5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-17854c25-4c43-4e18-b723-edeaf16ba4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-4185db1e-97da-4e7f-b41f-ab89b91e2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-09a6b2f6-48f4-433a-a0a3-7276543d0906,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-6d8e0cfd-352b-4650-9069-a18e3b03cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-9c817af8-403e-407d-9384-391cd84cf28c,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-64bbbe58-e711-4b71-8f1e-3d719188c625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214621402-172.17.0.13-1598601740425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-c9c771ca-2699-4f56-956f-ef6f8324ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-07beb1fd-ec13-49e6-9660-ffe8a771da16,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-4c6ea04b-8e4a-478d-b6a0-63bbb2a4f3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-d4510ceb-7955-4265-bd09-e5e1930c74fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-e78572dd-7285-4bd7-85bb-de3d02930247,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-92d6c547-ec6a-45eb-bbaf-80c8552aab77,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-454f16df-fb4c-477f-a6b7-77394ce1746f,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-1d3cc77e-c4f5-48ae-bd82-39be098acde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214621402-172.17.0.13-1598601740425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37153,DS-c9c771ca-2699-4f56-956f-ef6f8324ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-07beb1fd-ec13-49e6-9660-ffe8a771da16,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-4c6ea04b-8e4a-478d-b6a0-63bbb2a4f3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-d4510ceb-7955-4265-bd09-e5e1930c74fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-e78572dd-7285-4bd7-85bb-de3d02930247,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-92d6c547-ec6a-45eb-bbaf-80c8552aab77,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-454f16df-fb4c-477f-a6b7-77394ce1746f,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-1d3cc77e-c4f5-48ae-bd82-39be098acde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250611522-172.17.0.13-1598602425448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-5214753c-1305-44c9-9689-d7fd9bf21a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-d7ceb682-01db-4e5e-a447-a06e53edcfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-5bcb0bd0-9cd8-44e8-9f16-72300c3e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-0079fe10-81d8-475e-b7ac-72bd39e6f788,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-63a90c8f-03a7-4c1d-a0d4-ac9105f9c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-330c9f20-b758-4354-b21d-6011e030134d,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-acab3fba-0b71-4bd4-80eb-030fec01e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-d5be239f-c5ee-4ffa-8afb-4b22dfb05dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250611522-172.17.0.13-1598602425448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43279,DS-5214753c-1305-44c9-9689-d7fd9bf21a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-d7ceb682-01db-4e5e-a447-a06e53edcfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-5bcb0bd0-9cd8-44e8-9f16-72300c3e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-0079fe10-81d8-475e-b7ac-72bd39e6f788,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-63a90c8f-03a7-4c1d-a0d4-ac9105f9c23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-330c9f20-b758-4354-b21d-6011e030134d,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-acab3fba-0b71-4bd4-80eb-030fec01e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-d5be239f-c5ee-4ffa-8afb-4b22dfb05dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068515047-172.17.0.13-1598602465833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-5dd1249d-d24f-4808-9b0b-3735c6a5b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a8d1b43e-498f-4e17-b65f-1ba9c6139f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-de1a3489-34e4-4ae9-a741-5bb8ed001b93,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-48d4217b-cdc1-4b21-92bb-c8ec6aa5d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-361670e4-9684-4899-aed5-ef4c232fc1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-64a30135-690d-4663-a091-e6881eb5512e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-be26869e-dac9-4868-afc5-037fafd3385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-d74eb873-dd1e-4435-b5ad-e7d2ee183ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068515047-172.17.0.13-1598602465833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-5dd1249d-d24f-4808-9b0b-3735c6a5b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a8d1b43e-498f-4e17-b65f-1ba9c6139f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-de1a3489-34e4-4ae9-a741-5bb8ed001b93,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-48d4217b-cdc1-4b21-92bb-c8ec6aa5d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-361670e4-9684-4899-aed5-ef4c232fc1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-64a30135-690d-4663-a091-e6881eb5512e,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-be26869e-dac9-4868-afc5-037fafd3385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-d74eb873-dd1e-4435-b5ad-e7d2ee183ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skiplist.interval
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78296914-172.17.0.13-1598602820537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-6ba2fe56-7bca-4ce2-a071-93ad94f413e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-862d4433-a546-4fe1-b29b-bd5ed389f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-28f59429-8332-41b0-8eb1-73be95e578c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-9d9cd940-e8b4-4044-ba2e-e4ba4f4327f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-2a57b3c8-3d18-43d2-a4a1-eaa658bf0692,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-57085e12-18ab-4de1-9a15-a1384c5b8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-a1d2ec31-c8ee-437a-8d26-e504af234e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-75db1d50-0fa2-460e-b98a-a0627476535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78296914-172.17.0.13-1598602820537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44541,DS-6ba2fe56-7bca-4ce2-a071-93ad94f413e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-862d4433-a546-4fe1-b29b-bd5ed389f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-28f59429-8332-41b0-8eb1-73be95e578c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-9d9cd940-e8b4-4044-ba2e-e4ba4f4327f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-2a57b3c8-3d18-43d2-a4a1-eaa658bf0692,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-57085e12-18ab-4de1-9a15-a1384c5b8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-a1d2ec31-c8ee-437a-8d26-e504af234e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-75db1d50-0fa2-460e-b98a-a0627476535a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5411
