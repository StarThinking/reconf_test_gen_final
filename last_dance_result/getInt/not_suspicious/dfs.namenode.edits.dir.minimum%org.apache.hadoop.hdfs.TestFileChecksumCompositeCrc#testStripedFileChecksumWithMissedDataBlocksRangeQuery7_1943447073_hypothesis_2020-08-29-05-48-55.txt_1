reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426687399-172.17.0.6-1598680554634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-0be89f28-220b-44df-9d2d-fbf74318aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-b719d9a1-8c21-4c58-939f-d0feaaa4f3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-83008367-75e1-491c-854e-84cefa134c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-2d9db76f-6015-4b38-b396-a98a6fafc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-9435e882-59a1-4832-8328-5732c7b62b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-29afd3cc-1a70-4835-b05e-094de2ef907c,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-765530c1-1af5-403b-9bb2-c0cfdcb0f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c9204209-600d-411f-bd78-f35954ddc3d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426687399-172.17.0.6-1598680554634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-0be89f28-220b-44df-9d2d-fbf74318aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-b719d9a1-8c21-4c58-939f-d0feaaa4f3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-83008367-75e1-491c-854e-84cefa134c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-2d9db76f-6015-4b38-b396-a98a6fafc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-9435e882-59a1-4832-8328-5732c7b62b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-29afd3cc-1a70-4835-b05e-094de2ef907c,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-765530c1-1af5-403b-9bb2-c0cfdcb0f1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c9204209-600d-411f-bd78-f35954ddc3d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767076375-172.17.0.6-1598680771293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-61039b1e-36a2-4639-82aa-5a77ac76f802,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-683812f8-711c-47a7-bed4-b54121de7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-0328787c-4c88-4e4c-aa01-5928b63ad6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-a44ce08a-4ca1-4913-aaac-dd5af8e19058,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-41169b2e-ae14-4ff2-ac63-54f0a9bbf1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-90622132-4627-4ddf-9815-22e81d1cfb33,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-1258504b-162d-4e7a-a1e6-6c271a11fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-2eb7013d-6f3b-41e0-b557-fc2d45acec87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767076375-172.17.0.6-1598680771293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-61039b1e-36a2-4639-82aa-5a77ac76f802,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-683812f8-711c-47a7-bed4-b54121de7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-0328787c-4c88-4e4c-aa01-5928b63ad6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-a44ce08a-4ca1-4913-aaac-dd5af8e19058,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-41169b2e-ae14-4ff2-ac63-54f0a9bbf1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-90622132-4627-4ddf-9815-22e81d1cfb33,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-1258504b-162d-4e7a-a1e6-6c271a11fc51,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-2eb7013d-6f3b-41e0-b557-fc2d45acec87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081379261-172.17.0.6-1598680896784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-0dd8014a-61f4-4366-89fb-256a71236711,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-3575d495-415b-4846-883e-35ba6841dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-bbcb8609-40ca-4465-a7d3-35e376bda2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-32ef61d9-0d48-465e-96fb-6e531747c4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-9690ea0c-f7a4-4d87-9c6a-e3c49415c771,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-473d6692-085d-451f-881d-a603a613caed,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6512d980-c574-4a82-879b-d2cabe4bd7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d753cd2b-bc80-4a26-93cd-bdbece25594c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081379261-172.17.0.6-1598680896784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-0dd8014a-61f4-4366-89fb-256a71236711,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-3575d495-415b-4846-883e-35ba6841dea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-bbcb8609-40ca-4465-a7d3-35e376bda2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-32ef61d9-0d48-465e-96fb-6e531747c4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-9690ea0c-f7a4-4d87-9c6a-e3c49415c771,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-473d6692-085d-451f-881d-a603a613caed,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-6512d980-c574-4a82-879b-d2cabe4bd7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d753cd2b-bc80-4a26-93cd-bdbece25594c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392391991-172.17.0.6-1598681188787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-1f03e8e0-8211-40f2-8f65-95307e30e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-163ee088-ce67-4917-bdad-0ae529b828de,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b9efbf58-1d75-4130-a482-d298be6c4ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-82de148d-f704-4730-9129-cb5efa5e3843,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-5a0c9cea-1080-4f06-8e67-42d370df39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6121638b-1745-45a1-a0eb-7b5e92dd6180,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-3bcd8c6a-12a6-4023-a77d-a651b6dbbbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-391f34ab-ed78-4100-9836-46dcf2e23599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392391991-172.17.0.6-1598681188787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-1f03e8e0-8211-40f2-8f65-95307e30e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-163ee088-ce67-4917-bdad-0ae529b828de,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b9efbf58-1d75-4130-a482-d298be6c4ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-82de148d-f704-4730-9129-cb5efa5e3843,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-5a0c9cea-1080-4f06-8e67-42d370df39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6121638b-1745-45a1-a0eb-7b5e92dd6180,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-3bcd8c6a-12a6-4023-a77d-a651b6dbbbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-391f34ab-ed78-4100-9836-46dcf2e23599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295711101-172.17.0.6-1598681302109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44275,DS-e389f0f6-cf64-473b-9363-fd31ef3fdc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-8dcfcf1b-ffb8-475e-8caa-beaaf9f10045,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-dbc3d963-29dc-4996-b696-f7b7a57ded3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-26fff6d1-c219-4b6d-9789-f2b9ab157adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-8e57086d-25a8-49de-8849-1259670994ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-5b88ec2e-a4c4-4089-92fa-bfa1c3793256,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-57971214-33df-4379-b5ea-3658e77f9470,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-2bffb249-cba0-4040-a237-9cd6ccdb5597,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295711101-172.17.0.6-1598681302109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44275,DS-e389f0f6-cf64-473b-9363-fd31ef3fdc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-8dcfcf1b-ffb8-475e-8caa-beaaf9f10045,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-dbc3d963-29dc-4996-b696-f7b7a57ded3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-26fff6d1-c219-4b6d-9789-f2b9ab157adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-8e57086d-25a8-49de-8849-1259670994ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-5b88ec2e-a4c4-4089-92fa-bfa1c3793256,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-57971214-33df-4379-b5ea-3658e77f9470,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-2bffb249-cba0-4040-a237-9cd6ccdb5597,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530610581-172.17.0.6-1598681337815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-8454813b-8891-4853-ad96-8f418f9880d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5a4fb072-7d38-4257-b815-445b321dca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-7939db7b-817a-4dad-8155-77e51e13be1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-c1550f59-b0ce-40b8-857b-385a253618d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-aba79fdf-9cb6-474f-a796-dbf331663417,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-b5421b55-399e-4be0-a51e-4cff2db5876f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-593d590c-bbe9-4f74-a602-c00acf656c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-bfd7e296-15ef-4913-acd0-b08c1bb706b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530610581-172.17.0.6-1598681337815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-8454813b-8891-4853-ad96-8f418f9880d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-5a4fb072-7d38-4257-b815-445b321dca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-7939db7b-817a-4dad-8155-77e51e13be1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-c1550f59-b0ce-40b8-857b-385a253618d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-aba79fdf-9cb6-474f-a796-dbf331663417,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-b5421b55-399e-4be0-a51e-4cff2db5876f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-593d590c-bbe9-4f74-a602-c00acf656c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-bfd7e296-15ef-4913-acd0-b08c1bb706b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424824292-172.17.0.6-1598681449137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-81d2517f-e3e7-4b3b-99c8-9f6ad4b624fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-0362e35b-8b85-415a-861a-c8c30d0cae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-b3abe43f-ffb8-4346-ab7f-4cc38295dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-99033568-4a41-47d6-9e68-295b1dd49704,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e52f489d-facc-4d17-9396-0111b7982214,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-ad26b6ea-3546-4e95-92b3-67148a4be088,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-3fa0b6f1-9bfe-4e29-8629-99f5ce3ab656,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-132d72e4-6b25-43ac-8887-5dfab3794c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424824292-172.17.0.6-1598681449137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-81d2517f-e3e7-4b3b-99c8-9f6ad4b624fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-0362e35b-8b85-415a-861a-c8c30d0cae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-b3abe43f-ffb8-4346-ab7f-4cc38295dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-99033568-4a41-47d6-9e68-295b1dd49704,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e52f489d-facc-4d17-9396-0111b7982214,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-ad26b6ea-3546-4e95-92b3-67148a4be088,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-3fa0b6f1-9bfe-4e29-8629-99f5ce3ab656,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-132d72e4-6b25-43ac-8887-5dfab3794c8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18134729-172.17.0.6-1598681598166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-09313383-96a7-4636-a0a6-e9f83c9d2e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-f9ffb6f1-93b7-4bac-98e7-727eb0989651,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-94749019-1926-496a-8f57-5a2101d0773d,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-aaa8e67b-3e9f-4500-a87c-fb1c82bb5745,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-f220a4df-2377-4bdc-a0f6-3b6066fd2e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-133eeae9-8e6a-4c50-8e2b-c9bf219be142,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-7b3dab9e-a245-4c28-af6e-a864431e7088,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-92415317-4efe-4efd-b2dc-b985c42f4477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18134729-172.17.0.6-1598681598166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-09313383-96a7-4636-a0a6-e9f83c9d2e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-f9ffb6f1-93b7-4bac-98e7-727eb0989651,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-94749019-1926-496a-8f57-5a2101d0773d,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-aaa8e67b-3e9f-4500-a87c-fb1c82bb5745,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-f220a4df-2377-4bdc-a0f6-3b6066fd2e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-133eeae9-8e6a-4c50-8e2b-c9bf219be142,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-7b3dab9e-a245-4c28-af6e-a864431e7088,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-92415317-4efe-4efd-b2dc-b985c42f4477,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316644573-172.17.0.6-1598681714942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-b5f66146-01b2-494b-aaab-47a58becc558,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-ddd9dcef-6d10-4352-b74e-8ff621454772,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-dfcb7796-80d9-437b-b2cb-351bcbc01e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-7568d90d-6049-4938-b0ae-f1a72359b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-c3930d2c-482e-42bd-aaa1-a74e8245005c,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-17686e64-eb2f-493b-9930-4dcee626c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-3bc29370-7499-4cda-bc9b-d28d983190ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-dbe37395-2fb0-47d8-9460-40d4432308ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316644573-172.17.0.6-1598681714942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-b5f66146-01b2-494b-aaab-47a58becc558,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-ddd9dcef-6d10-4352-b74e-8ff621454772,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-dfcb7796-80d9-437b-b2cb-351bcbc01e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-7568d90d-6049-4938-b0ae-f1a72359b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-c3930d2c-482e-42bd-aaa1-a74e8245005c,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-17686e64-eb2f-493b-9930-4dcee626c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-3bc29370-7499-4cda-bc9b-d28d983190ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-dbe37395-2fb0-47d8-9460-40d4432308ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82555898-172.17.0.6-1598681916695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-80aca2de-5a8b-4204-9f97-6d45353043d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-3bcf4336-7078-4741-b422-4332ca01bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-869c29cb-0b80-432a-951f-8042367556b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-6505a17a-65c7-4e44-95f5-4eb5a1d4b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-fcdc3b5c-d2a1-4b47-a1a7-74dc56b08fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-871d333a-e856-467e-b035-97cc8ad0ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-c19c4b6a-1a58-475b-8b44-35b7be98bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-af4409c2-82c6-4916-8c3c-a30f0bd2b69a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82555898-172.17.0.6-1598681916695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-80aca2de-5a8b-4204-9f97-6d45353043d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-3bcf4336-7078-4741-b422-4332ca01bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-869c29cb-0b80-432a-951f-8042367556b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-6505a17a-65c7-4e44-95f5-4eb5a1d4b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-fcdc3b5c-d2a1-4b47-a1a7-74dc56b08fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-871d333a-e856-467e-b035-97cc8ad0ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-c19c4b6a-1a58-475b-8b44-35b7be98bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-af4409c2-82c6-4916-8c3c-a30f0bd2b69a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796303256-172.17.0.6-1598682028431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-02ac7806-059e-494a-97b5-5a8917c5c151,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-3dcf78fe-dfcd-4bd1-a4cc-aa42f734820d,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-2bdcacb4-7c22-4244-8976-f1cbb25b733b,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-77a50a34-60ac-4180-aa21-b565779a7312,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-d9d07162-75d3-4519-98fc-986e07150cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-0b1c6e0e-c653-471b-b1ce-7689f781de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-089e85ad-7f18-4e32-b1f6-2571744e72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-46bef994-f1dc-4be7-996f-0261e629f23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796303256-172.17.0.6-1598682028431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-02ac7806-059e-494a-97b5-5a8917c5c151,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-3dcf78fe-dfcd-4bd1-a4cc-aa42f734820d,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-2bdcacb4-7c22-4244-8976-f1cbb25b733b,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-77a50a34-60ac-4180-aa21-b565779a7312,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-d9d07162-75d3-4519-98fc-986e07150cab,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-0b1c6e0e-c653-471b-b1ce-7689f781de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-089e85ad-7f18-4e32-b1f6-2571744e72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-46bef994-f1dc-4be7-996f-0261e629f23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969636127-172.17.0.6-1598682338874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-e915e9b8-a1ed-4d1c-8763-34b2f466164e,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8780dd7c-5574-4d7c-a49d-d1cf8d76fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a332e057-602b-4787-a047-14dc2c168713,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-8a60fe8a-353e-4c4e-b870-895accc803e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-d5e08c60-e952-4fb5-8af0-03ba6ad95730,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-98a62711-1b7d-4631-a5c5-c2933acaf440,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-c1cd2e62-1eaf-4faf-9490-9724ac8d36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-35a85e25-c271-419c-9081-c6807cb457f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969636127-172.17.0.6-1598682338874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-e915e9b8-a1ed-4d1c-8763-34b2f466164e,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8780dd7c-5574-4d7c-a49d-d1cf8d76fc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-a332e057-602b-4787-a047-14dc2c168713,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-8a60fe8a-353e-4c4e-b870-895accc803e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-d5e08c60-e952-4fb5-8af0-03ba6ad95730,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-98a62711-1b7d-4631-a5c5-c2933acaf440,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-c1cd2e62-1eaf-4faf-9490-9724ac8d36ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-35a85e25-c271-419c-9081-c6807cb457f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604825196-172.17.0.6-1598682416216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-8694320f-7a0e-437e-b397-92f10183a516,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-696e7f08-76cc-4352-bc9f-18813c5a671f,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d4e6f46b-77b3-4b10-ab76-a27109d33e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-5c85964a-dab5-4563-b2d3-0e7f92cdce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-4d1b5121-21be-48af-9c7d-0cc057b95db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-89bb2e09-b247-47d6-a0e5-32c5cf281f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-942c200c-8dd2-4f18-a3b0-7f2b9e778728,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-21f089f1-eb49-4738-a65e-021a55014943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604825196-172.17.0.6-1598682416216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-8694320f-7a0e-437e-b397-92f10183a516,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-696e7f08-76cc-4352-bc9f-18813c5a671f,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d4e6f46b-77b3-4b10-ab76-a27109d33e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-5c85964a-dab5-4563-b2d3-0e7f92cdce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-4d1b5121-21be-48af-9c7d-0cc057b95db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-89bb2e09-b247-47d6-a0e5-32c5cf281f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-942c200c-8dd2-4f18-a3b0-7f2b9e778728,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-21f089f1-eb49-4738-a65e-021a55014943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169198207-172.17.0.6-1598682524869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33972,DS-164f377e-5552-4755-9fec-83eeeca5458b,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-fa0af447-00b5-4d3c-b056-b0010796adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-cdc3094e-28ad-4a77-bdb6-9e25133089aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-a1d58c94-be21-43cc-8347-101b1a332070,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-14351155-77a0-4965-ad46-85a047fc8843,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-cdad4d3a-516f-4c2c-bf9b-93effd2c9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-45b4c17b-dacc-4050-9f18-a48f409d90cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-fc32577f-d46d-4cff-9e1f-e4d21f433a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169198207-172.17.0.6-1598682524869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33972,DS-164f377e-5552-4755-9fec-83eeeca5458b,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-fa0af447-00b5-4d3c-b056-b0010796adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-cdc3094e-28ad-4a77-bdb6-9e25133089aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-a1d58c94-be21-43cc-8347-101b1a332070,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-14351155-77a0-4965-ad46-85a047fc8843,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-cdad4d3a-516f-4c2c-bf9b-93effd2c9f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-45b4c17b-dacc-4050-9f18-a48f409d90cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-fc32577f-d46d-4cff-9e1f-e4d21f433a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392988648-172.17.0.6-1598682560902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-02f0e0cb-0e7a-48a6-bf3e-a11c4afe5865,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-335ac0de-6821-4f71-8aa0-ac75e53969e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-3e7c8a3c-96b1-4934-88a4-01e4cfc13f59,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b0f4081e-716c-4981-830c-f1fa67fc60df,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-fa9a25f1-6c33-4db4-b27a-d5da7f0d31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-3b12c6f3-44cb-45e7-b2b6-ff424ee4df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b5e6ce57-d916-4fc5-b713-3b22d30dbf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-66669df0-a264-42ce-ad9e-1efa627cd830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392988648-172.17.0.6-1598682560902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-02f0e0cb-0e7a-48a6-bf3e-a11c4afe5865,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-335ac0de-6821-4f71-8aa0-ac75e53969e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-3e7c8a3c-96b1-4934-88a4-01e4cfc13f59,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b0f4081e-716c-4981-830c-f1fa67fc60df,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-fa9a25f1-6c33-4db4-b27a-d5da7f0d31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-3b12c6f3-44cb-45e7-b2b6-ff424ee4df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b5e6ce57-d916-4fc5-b713-3b22d30dbf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-66669df0-a264-42ce-ad9e-1efa627cd830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552294976-172.17.0.6-1598682603371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-0d9ff772-3821-4fb6-bb2a-9c5b909dd593,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-703c4c39-4026-4e4c-8fec-c4a5085c034a,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-0b153759-d326-474d-b35d-5622f2a172e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-03d7c7a6-6d6d-4c9f-a59e-6b646552928c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-b1bc6b71-2c53-435a-9643-2543ffe08c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-7c69b846-e27d-4244-90fa-db7d4c58b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-92fcd200-9adc-4f38-95b7-b56a745c8476,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-d10c6937-b526-47eb-87e8-6e5095f6e63a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552294976-172.17.0.6-1598682603371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42341,DS-0d9ff772-3821-4fb6-bb2a-9c5b909dd593,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-703c4c39-4026-4e4c-8fec-c4a5085c034a,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-0b153759-d326-474d-b35d-5622f2a172e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-03d7c7a6-6d6d-4c9f-a59e-6b646552928c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-b1bc6b71-2c53-435a-9643-2543ffe08c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-7c69b846-e27d-4244-90fa-db7d4c58b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-92fcd200-9adc-4f38-95b7-b56a745c8476,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-d10c6937-b526-47eb-87e8-6e5095f6e63a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917697309-172.17.0.6-1598682720156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-8bbfae37-57b5-41be-ae68-9d55254e17cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-7f14c944-4064-4757-b1ee-26a3dc8c3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-17fa0453-40f9-45da-92bb-a0bbb5ad8347,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-49a89dc9-43f7-4a96-bce2-099cb131dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-a7c61825-785b-4eba-982a-36b4518ea80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-357330fc-7324-4f29-a20c-348f38708979,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-2572bb6c-0538-4ff9-991c-550f2edeb458,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-01dc9d41-f6bb-4cc2-aed5-f6cb450e9800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917697309-172.17.0.6-1598682720156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-8bbfae37-57b5-41be-ae68-9d55254e17cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-7f14c944-4064-4757-b1ee-26a3dc8c3a08,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-17fa0453-40f9-45da-92bb-a0bbb5ad8347,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-49a89dc9-43f7-4a96-bce2-099cb131dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-a7c61825-785b-4eba-982a-36b4518ea80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-357330fc-7324-4f29-a20c-348f38708979,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-2572bb6c-0538-4ff9-991c-550f2edeb458,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-01dc9d41-f6bb-4cc2-aed5-f6cb450e9800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853252682-172.17.0.6-1598682796294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-585be464-fc68-4bc1-a9c9-68d662e268f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c0f47278-fddb-440c-b0eb-32a544f0cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-729b0df2-bf2d-4e97-97d5-77a3efa7a512,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f8bfe9bb-5521-460d-a861-0844d4457df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-b2fffdff-771c-48d6-bd6d-4921726a9125,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-cfbed08e-34a8-4895-9043-8cad06fb2293,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-9c13dd0a-b76a-4805-b591-61248d8ad69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-cad7eee9-ae3d-46fc-97cf-cf20fb48dabe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853252682-172.17.0.6-1598682796294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-585be464-fc68-4bc1-a9c9-68d662e268f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-c0f47278-fddb-440c-b0eb-32a544f0cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-729b0df2-bf2d-4e97-97d5-77a3efa7a512,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f8bfe9bb-5521-460d-a861-0844d4457df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-b2fffdff-771c-48d6-bd6d-4921726a9125,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-cfbed08e-34a8-4895-9043-8cad06fb2293,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-9c13dd0a-b76a-4805-b591-61248d8ad69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-cad7eee9-ae3d-46fc-97cf-cf20fb48dabe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294153322-172.17.0.6-1598682833443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-998594ac-3753-4975-a3f2-6a7ef6b48f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-56a03fdd-e1c3-47ca-a0ec-de9d4ba9bb50,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-66116049-dc3a-498c-9f62-e4447d7794fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f9f06609-c96a-4e4e-a013-e39f000600e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-4605ecb8-7f54-401c-850e-1f606bb5bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-3453cb70-8422-47b3-8fa8-d1f10bf0c290,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-60602efc-9fb6-4760-81aa-30d814db47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-7b889381-d5d2-43c2-9432-190db76f8d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294153322-172.17.0.6-1598682833443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-998594ac-3753-4975-a3f2-6a7ef6b48f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-56a03fdd-e1c3-47ca-a0ec-de9d4ba9bb50,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-66116049-dc3a-498c-9f62-e4447d7794fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-f9f06609-c96a-4e4e-a013-e39f000600e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-4605ecb8-7f54-401c-850e-1f606bb5bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-3453cb70-8422-47b3-8fa8-d1f10bf0c290,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-60602efc-9fb6-4760-81aa-30d814db47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-7b889381-d5d2-43c2-9432-190db76f8d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294341056-172.17.0.6-1598682905220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42614,DS-3b077495-f5fc-4ac7-a5d2-3a3612c7fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-b44aa64c-a4d3-4016-a21f-3f0a5edff638,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-9df9b881-ab19-4193-8414-9eccbbc1048b,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-778e088b-6ff1-41eb-a727-d735997d374f,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-45dd874b-33b8-467f-b8e4-b663712b09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-8d83f862-623e-4a00-a365-aa80e53bb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-3f06ef29-43ea-4830-866b-ce658c146b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-0d4f1bcc-6f19-4ff4-8876-c4337c1b2ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294341056-172.17.0.6-1598682905220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42614,DS-3b077495-f5fc-4ac7-a5d2-3a3612c7fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-b44aa64c-a4d3-4016-a21f-3f0a5edff638,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-9df9b881-ab19-4193-8414-9eccbbc1048b,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-778e088b-6ff1-41eb-a727-d735997d374f,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-45dd874b-33b8-467f-b8e4-b663712b09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-8d83f862-623e-4a00-a365-aa80e53bb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-3f06ef29-43ea-4830-866b-ce658c146b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-0d4f1bcc-6f19-4ff4-8876-c4337c1b2ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570578243-172.17.0.6-1598682942047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-bddf2ab4-bb7e-496a-8be6-60c04e0f4038,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-fbcd2923-cd96-492f-8ca0-0e1b60042904,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-a3b077c2-6145-4e84-8083-446ef2292839,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-6d2c4c7e-24f8-4af6-a33a-6a7e00843a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-42b40e46-c7d2-4df4-8fc2-2314519441d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-cb69ed99-094c-4e95-9191-fcb629b6d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-067d6bf9-13c4-4ed4-82cf-e5eb94625696,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-2eb52d7b-10b5-4271-af80-23d3c03b01a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570578243-172.17.0.6-1598682942047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-bddf2ab4-bb7e-496a-8be6-60c04e0f4038,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-fbcd2923-cd96-492f-8ca0-0e1b60042904,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-a3b077c2-6145-4e84-8083-446ef2292839,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-6d2c4c7e-24f8-4af6-a33a-6a7e00843a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-42b40e46-c7d2-4df4-8fc2-2314519441d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-cb69ed99-094c-4e95-9191-fcb629b6d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-067d6bf9-13c4-4ed4-82cf-e5eb94625696,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-2eb52d7b-10b5-4271-af80-23d3c03b01a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536776392-172.17.0.6-1598683052605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46733,DS-d389621c-109c-464a-9013-86ddbb7c1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c771a823-989e-4ed6-b93b-1803284b3a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ca051762-e812-47f6-ab1f-c00ea0a9966e,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-089ab020-cdf8-4a77-a76c-01911afa7133,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-1ede0a0c-0f23-4e67-870c-764953e090b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-a7512386-d630-4903-b74f-9f96f33021f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c3800145-ab1f-4f1e-8d34-d41ef427fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-6d309a9d-4daf-42b8-9791-f8021711682e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536776392-172.17.0.6-1598683052605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46733,DS-d389621c-109c-464a-9013-86ddbb7c1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c771a823-989e-4ed6-b93b-1803284b3a42,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ca051762-e812-47f6-ab1f-c00ea0a9966e,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-089ab020-cdf8-4a77-a76c-01911afa7133,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-1ede0a0c-0f23-4e67-870c-764953e090b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-a7512386-d630-4903-b74f-9f96f33021f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-c3800145-ab1f-4f1e-8d34-d41ef427fed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-6d309a9d-4daf-42b8-9791-f8021711682e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668727134-172.17.0.6-1598683153215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-1f61dfda-7a6e-42b9-bf6b-3ef599322f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-df2935d2-a9cd-4f08-b1a4-42ab2db76bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-668c9da5-8e82-4eea-a5dd-749aa009abc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-f959474e-f7cd-400e-9c1b-d03ff854d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-b48a175e-3d44-4e9e-926a-7e5eff9a637d,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-7ec375bf-5b00-4a7e-ad5e-e921a1195118,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f1da7086-aa20-41c3-83bd-2ac9cdeb687c,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-65034f01-3310-48c4-a341-4590cc5e0e3f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668727134-172.17.0.6-1598683153215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-1f61dfda-7a6e-42b9-bf6b-3ef599322f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-df2935d2-a9cd-4f08-b1a4-42ab2db76bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-668c9da5-8e82-4eea-a5dd-749aa009abc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-f959474e-f7cd-400e-9c1b-d03ff854d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-b48a175e-3d44-4e9e-926a-7e5eff9a637d,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-7ec375bf-5b00-4a7e-ad5e-e921a1195118,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f1da7086-aa20-41c3-83bd-2ac9cdeb687c,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-65034f01-3310-48c4-a341-4590cc5e0e3f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897556714-172.17.0.6-1598683192459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-a2b0116a-763e-4b8c-be62-7ce4032b62f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-575eea32-9afa-40c9-ae6c-02eb62c320ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-f84774a1-4afc-4c92-af47-e858f9af9051,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-c422cd01-1e05-4d9a-bc1a-ff9a66eb3d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-1885b90b-64b6-469b-8170-07291b13759f,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-a104a6c7-8ec9-452b-8430-b92a16f1ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-ced23489-8867-4403-a4f0-08dab17413c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-8724dbfb-033a-42c4-8541-9d9f430a2a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897556714-172.17.0.6-1598683192459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-a2b0116a-763e-4b8c-be62-7ce4032b62f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-575eea32-9afa-40c9-ae6c-02eb62c320ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-f84774a1-4afc-4c92-af47-e858f9af9051,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-c422cd01-1e05-4d9a-bc1a-ff9a66eb3d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-1885b90b-64b6-469b-8170-07291b13759f,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-a104a6c7-8ec9-452b-8430-b92a16f1ece5,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-ced23489-8867-4403-a4f0-08dab17413c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-8724dbfb-033a-42c4-8541-9d9f430a2a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161435511-172.17.0.6-1598683412794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-1b6b1203-de27-4dba-aa72-6e76d0623f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-d8019ef3-30ad-468a-9ed5-c12c49e709f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-d91fbab6-d23d-4b74-be38-32e24fa67cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-12d75502-bfd3-497e-b2c9-50696a86c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-16242f82-c0f6-4584-b409-c07a3b5fa1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-f846f323-3fe2-437c-a331-7a2b5bf0dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-9a48578e-e088-4ad8-89ed-bb9916d58096,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-7cc5f6ff-156c-453d-a2d5-19594cc959ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161435511-172.17.0.6-1598683412794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44753,DS-1b6b1203-de27-4dba-aa72-6e76d0623f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-d8019ef3-30ad-468a-9ed5-c12c49e709f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-d91fbab6-d23d-4b74-be38-32e24fa67cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-12d75502-bfd3-497e-b2c9-50696a86c86a,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-16242f82-c0f6-4584-b409-c07a3b5fa1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-f846f323-3fe2-437c-a331-7a2b5bf0dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-9a48578e-e088-4ad8-89ed-bb9916d58096,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-7cc5f6ff-156c-453d-a2d5-19594cc959ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396237631-172.17.0.6-1598683448971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-e5d098b8-15ab-47d6-9068-32ed9cef0113,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-a1385711-7f33-45e6-9854-07ce8c187345,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-0bd5b864-1e01-4c71-9ae4-95558ac65432,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e1e43940-3ba7-4de8-b515-48e8847e1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-c41dc51a-91bb-449b-b09a-ca5187dd9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-98c92470-23cb-45d2-8554-8104708704ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-ba6be09a-77aa-4485-9216-ac5313b9bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-91d68a67-2acd-4b57-bbd1-30b9d8ce8f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396237631-172.17.0.6-1598683448971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-e5d098b8-15ab-47d6-9068-32ed9cef0113,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-a1385711-7f33-45e6-9854-07ce8c187345,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-0bd5b864-1e01-4c71-9ae4-95558ac65432,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e1e43940-3ba7-4de8-b515-48e8847e1de0,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-c41dc51a-91bb-449b-b09a-ca5187dd9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-98c92470-23cb-45d2-8554-8104708704ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-ba6be09a-77aa-4485-9216-ac5313b9bf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-91d68a67-2acd-4b57-bbd1-30b9d8ce8f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664207607-172.17.0.6-1598683631256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-ecb6c171-2cc8-4487-9069-15e495a675c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-e8235f99-ac6c-4bf5-a12a-1d9c87bbaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-082812c3-c56d-4565-a940-9ecd0d83d2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-d07d9f94-2dda-47c5-a3f3-3b5db244044d,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-06ac31ca-7acd-4041-b40f-61148da70744,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-58e4e835-746d-4127-8850-f5ffe60803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-2e493b77-9367-40d3-b1b1-7e31a60be073,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-03012318-9aa4-4b1b-982f-392b3aeb289f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664207607-172.17.0.6-1598683631256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-ecb6c171-2cc8-4487-9069-15e495a675c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-e8235f99-ac6c-4bf5-a12a-1d9c87bbaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-082812c3-c56d-4565-a940-9ecd0d83d2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-d07d9f94-2dda-47c5-a3f3-3b5db244044d,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-06ac31ca-7acd-4041-b40f-61148da70744,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-58e4e835-746d-4127-8850-f5ffe60803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-2e493b77-9367-40d3-b1b1-7e31a60be073,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-03012318-9aa4-4b1b-982f-392b3aeb289f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313735977-172.17.0.6-1598683711181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43460,DS-98613bb7-5966-4032-a0e8-2a817b81ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-83bc2f3d-2f78-4792-984e-b83f682aec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-2047ec04-8008-41ae-8f4a-2e531339f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-becea46d-fdd2-47a1-adbc-fceffc54d486,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-b9bedf8f-3de0-440b-b4cb-9908899d3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-fb8aa3f2-a204-42ab-978e-ba9cb59f8d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-ed3d7174-db03-4545-84b8-47a3a1c65ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-58e1c544-3d0f-4ce6-8692-292457747e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313735977-172.17.0.6-1598683711181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43460,DS-98613bb7-5966-4032-a0e8-2a817b81ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-83bc2f3d-2f78-4792-984e-b83f682aec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-2047ec04-8008-41ae-8f4a-2e531339f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-becea46d-fdd2-47a1-adbc-fceffc54d486,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-b9bedf8f-3de0-440b-b4cb-9908899d3eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-fb8aa3f2-a204-42ab-978e-ba9cb59f8d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-ed3d7174-db03-4545-84b8-47a3a1c65ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-58e1c544-3d0f-4ce6-8692-292457747e2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440762528-172.17.0.6-1598683745953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-07ea4f02-9a09-49e8-9045-bd98934bc0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-48e971f3-0ed0-435c-8508-ae479e09e4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-378017c6-9d22-490a-869c-5416c5c242b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9ee1d01e-9582-4d5f-b87d-3d8a7ba69384,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-055aeded-0d7a-4423-9a94-f85630bd6093,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-fe7d38dd-da3a-4ce1-a250-cc95941c58bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-1f484abf-cd12-4010-820a-c93480b68ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-e534765d-51d1-4c5e-9933-4b5d56403247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440762528-172.17.0.6-1598683745953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-07ea4f02-9a09-49e8-9045-bd98934bc0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-48e971f3-0ed0-435c-8508-ae479e09e4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-378017c6-9d22-490a-869c-5416c5c242b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9ee1d01e-9582-4d5f-b87d-3d8a7ba69384,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-055aeded-0d7a-4423-9a94-f85630bd6093,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-fe7d38dd-da3a-4ce1-a250-cc95941c58bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-1f484abf-cd12-4010-820a-c93480b68ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-e534765d-51d1-4c5e-9933-4b5d56403247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345899335-172.17.0.6-1598683892113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-5c9f1267-97c6-4573-a34e-afcf79c469bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-00b7d887-5158-4013-ad7c-ffbb34426146,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-4a67bfad-a0bc-4937-98a1-c1bd31e68f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-e07e76e3-e3bc-427c-8969-a46b89d31fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-a4875fc3-ed6c-428f-b8a8-52f86a0c5b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-9a66194a-78e2-4579-bfc9-8412c7be9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5075bb0e-532d-4525-85ba-933a1fad7c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-47f02465-7e0b-4671-901f-f6d9e7eb294c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345899335-172.17.0.6-1598683892113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-5c9f1267-97c6-4573-a34e-afcf79c469bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-00b7d887-5158-4013-ad7c-ffbb34426146,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-4a67bfad-a0bc-4937-98a1-c1bd31e68f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-e07e76e3-e3bc-427c-8969-a46b89d31fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-a4875fc3-ed6c-428f-b8a8-52f86a0c5b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-9a66194a-78e2-4579-bfc9-8412c7be9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5075bb0e-532d-4525-85ba-933a1fad7c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-47f02465-7e0b-4671-901f-f6d9e7eb294c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238231745-172.17.0.6-1598684361642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-7a460fc1-a080-4184-b256-d6f93bfaa862,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-9373679b-7dcf-43f6-911c-6eaa29497d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-5bc6292e-adb6-41be-ab86-132c92db09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-d5153b62-2fd6-4f7f-8838-f0625559b026,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-c51deac2-e3b9-41f3-9ce9-dbf7188fe45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-445b1525-1da3-4407-9605-92f3d425b581,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-2b3f67de-6367-42de-a60b-933f8b826582,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-7220dfa1-0aa6-4086-9087-4803feb61c02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238231745-172.17.0.6-1598684361642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-7a460fc1-a080-4184-b256-d6f93bfaa862,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-9373679b-7dcf-43f6-911c-6eaa29497d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-5bc6292e-adb6-41be-ab86-132c92db09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-d5153b62-2fd6-4f7f-8838-f0625559b026,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-c51deac2-e3b9-41f3-9ce9-dbf7188fe45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-445b1525-1da3-4407-9605-92f3d425b581,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-2b3f67de-6367-42de-a60b-933f8b826582,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-7220dfa1-0aa6-4086-9087-4803feb61c02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884991750-172.17.0.6-1598684397910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-412a7eed-4a60-41b9-9288-8bde88ad141f,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8c37fe8b-5287-47d9-919e-fc9df080178f,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-0939d71a-cd69-41ff-9523-835958cd4866,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-07b35508-2eb2-48a4-bfb0-777bce37ebee,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-80d38695-d1d7-4e01-826f-64b9550f737b,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-15a7f626-078a-4caa-ab97-77b2da024921,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-4d5308eb-e23c-4f42-a4e7-9eaaf708db76,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-a963748e-5166-4412-907f-ce0fdf9a02d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884991750-172.17.0.6-1598684397910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-412a7eed-4a60-41b9-9288-8bde88ad141f,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8c37fe8b-5287-47d9-919e-fc9df080178f,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-0939d71a-cd69-41ff-9523-835958cd4866,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-07b35508-2eb2-48a4-bfb0-777bce37ebee,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-80d38695-d1d7-4e01-826f-64b9550f737b,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-15a7f626-078a-4caa-ab97-77b2da024921,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-4d5308eb-e23c-4f42-a4e7-9eaaf708db76,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-a963748e-5166-4412-907f-ce0fdf9a02d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156865101-172.17.0.6-1598684505778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36015,DS-6a21eafc-1e9b-40c1-9ea5-d3da7e0e8a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-18e26c9f-d367-465d-8639-e28cf624c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-e51ebe8b-7308-4e03-abe9-1de1d92aae38,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-623b2cac-c36d-4500-84dd-97d1bc05ef07,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-191a058f-357a-4fc3-8971-b8334c7a2af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-f6356da2-876f-479a-8ca3-610e57954ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-8e71215d-80d3-4e9e-a728-fbbfb77f6613,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-30f06b32-1cc5-44c9-bd2d-e420d1145146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156865101-172.17.0.6-1598684505778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36015,DS-6a21eafc-1e9b-40c1-9ea5-d3da7e0e8a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-18e26c9f-d367-465d-8639-e28cf624c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-e51ebe8b-7308-4e03-abe9-1de1d92aae38,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-623b2cac-c36d-4500-84dd-97d1bc05ef07,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-191a058f-357a-4fc3-8971-b8334c7a2af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-f6356da2-876f-479a-8ca3-610e57954ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-8e71215d-80d3-4e9e-a728-fbbfb77f6613,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-30f06b32-1cc5-44c9-bd2d-e420d1145146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990692484-172.17.0.6-1598684571977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-6c39e759-ae67-4cc0-a594-568b20644a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-92577fa1-0f6c-47c9-b557-a3e416609546,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-9db927b1-6c6e-4bfd-aa16-19350ca7ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2828c8d4-fcd6-4292-8df4-dcbae3e34191,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-967f1714-4d1d-4896-bba8-c25272d296f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-77e9e003-ca42-4b92-b7e1-d53f1019f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-b7c4acbd-f420-4cfc-ac33-4fdc4870b753,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-9d34fa97-8061-4761-a43b-e601e33814df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990692484-172.17.0.6-1598684571977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-6c39e759-ae67-4cc0-a594-568b20644a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-92577fa1-0f6c-47c9-b557-a3e416609546,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-9db927b1-6c6e-4bfd-aa16-19350ca7ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2828c8d4-fcd6-4292-8df4-dcbae3e34191,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-967f1714-4d1d-4896-bba8-c25272d296f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-77e9e003-ca42-4b92-b7e1-d53f1019f7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-b7c4acbd-f420-4cfc-ac33-4fdc4870b753,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-9d34fa97-8061-4761-a43b-e601e33814df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391899915-172.17.0.6-1598684604593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-269df3ed-ca47-40a6-b565-071ef1cde16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7962ef26-cadc-45ef-8c64-32722c34a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-9a2fe062-eda1-4a28-8562-9c20517c126c,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-3811fd05-92e1-410d-877d-74728d4e8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-51239b4f-7f05-405f-a210-98b1bfeaedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-0b779ee7-544f-4f85-a629-ebee5de73437,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-edb1e82b-b840-46e4-925a-d31df5217d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-e480f45c-6f00-4b35-b6b3-ffc9fdd137c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391899915-172.17.0.6-1598684604593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-269df3ed-ca47-40a6-b565-071ef1cde16e,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-7962ef26-cadc-45ef-8c64-32722c34a4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-9a2fe062-eda1-4a28-8562-9c20517c126c,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-3811fd05-92e1-410d-877d-74728d4e8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-51239b4f-7f05-405f-a210-98b1bfeaedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-0b779ee7-544f-4f85-a629-ebee5de73437,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-edb1e82b-b840-46e4-925a-d31df5217d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-e480f45c-6f00-4b35-b6b3-ffc9fdd137c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676053799-172.17.0.6-1598684677048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34742,DS-d182beb5-6dea-4c7b-8935-966b84c6bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-866dfe0d-8c3d-4b9b-a446-f991bc50f517,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-646157f1-d7a8-4deb-b737-6b5a928b288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-b564af26-3aba-49ea-bab7-fd80419a8339,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-9e5ad1ad-790f-436d-aa1f-c62acf8a6b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-9a370423-197f-4ff9-8a77-344317320daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-c6096298-6d49-478d-be87-dfea98a9fbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1591729f-d950-4647-b9c7-a20c17afaf12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676053799-172.17.0.6-1598684677048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34742,DS-d182beb5-6dea-4c7b-8935-966b84c6bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-866dfe0d-8c3d-4b9b-a446-f991bc50f517,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-646157f1-d7a8-4deb-b737-6b5a928b288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-b564af26-3aba-49ea-bab7-fd80419a8339,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-9e5ad1ad-790f-436d-aa1f-c62acf8a6b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-9a370423-197f-4ff9-8a77-344317320daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-c6096298-6d49-478d-be87-dfea98a9fbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1591729f-d950-4647-b9c7-a20c17afaf12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145869849-172.17.0.6-1598684714157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-dd240ec7-c3c3-486c-bb56-a5fc2e4229b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-cf56e4d9-c33c-40eb-8ee9-8f83aa58e827,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-b9295ca7-18f3-48a6-9f36-636949b7298b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-971660b8-3da2-41e5-aa6a-2b6d2a7fd461,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-f7c63404-9f16-4ec1-bf9d-522748bb32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-2d732b5d-f523-47b0-93cc-8b0363808fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-daae8461-9e42-42aa-8f6a-b9f7b471abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f62b733d-b614-482a-856f-d8fee9593777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145869849-172.17.0.6-1598684714157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-dd240ec7-c3c3-486c-bb56-a5fc2e4229b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-cf56e4d9-c33c-40eb-8ee9-8f83aa58e827,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-b9295ca7-18f3-48a6-9f36-636949b7298b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-971660b8-3da2-41e5-aa6a-2b6d2a7fd461,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-f7c63404-9f16-4ec1-bf9d-522748bb32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-2d732b5d-f523-47b0-93cc-8b0363808fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-daae8461-9e42-42aa-8f6a-b9f7b471abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-f62b733d-b614-482a-856f-d8fee9593777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109158623-172.17.0.6-1598684781953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-be6c082c-8fe4-47c2-855d-d3ad7d034672,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aa0e70ff-8fc4-486c-9b52-5a8f12a14335,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-b670dc26-ccbb-4de1-978e-19c9a4e9d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-2dc56734-49df-4845-adb8-64302e98f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-816d491c-718d-4cdc-8950-d84e65eb960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-1b6747c8-7a82-420c-a0a2-091df7acedff,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-dccaf2dd-3939-4177-ae13-bfe1595342ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f066b153-c38a-4bf1-94c4-ebc5642d5537,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109158623-172.17.0.6-1598684781953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-be6c082c-8fe4-47c2-855d-d3ad7d034672,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aa0e70ff-8fc4-486c-9b52-5a8f12a14335,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-b670dc26-ccbb-4de1-978e-19c9a4e9d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-2dc56734-49df-4845-adb8-64302e98f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-816d491c-718d-4cdc-8950-d84e65eb960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-1b6747c8-7a82-420c-a0a2-091df7acedff,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-dccaf2dd-3939-4177-ae13-bfe1595342ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f066b153-c38a-4bf1-94c4-ebc5642d5537,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99317772-172.17.0.6-1598685004971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35148,DS-fa402e60-6568-43ac-96ec-19b20915540b,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-515dc504-3f92-44a4-9ad0-90864283aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-712b7c77-5709-4c86-8178-40ef96d12152,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-434fbe4d-e092-45c4-928b-91974dbffcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d4d8095b-fa5d-4f08-a280-d17619688cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-aec730ff-d061-4a2b-b122-ab89c31bd236,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-d45ce970-b9be-4b9d-b583-3599cc3708ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-ac90832f-2dbf-4607-b104-bcc9ee30c072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99317772-172.17.0.6-1598685004971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35148,DS-fa402e60-6568-43ac-96ec-19b20915540b,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-515dc504-3f92-44a4-9ad0-90864283aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-712b7c77-5709-4c86-8178-40ef96d12152,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-434fbe4d-e092-45c4-928b-91974dbffcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d4d8095b-fa5d-4f08-a280-d17619688cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-aec730ff-d061-4a2b-b122-ab89c31bd236,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-d45ce970-b9be-4b9d-b583-3599cc3708ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-ac90832f-2dbf-4607-b104-bcc9ee30c072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934568687-172.17.0.6-1598685285719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-c9a4e15b-abeb-4266-81fb-d1fba987804d,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-1f052e00-185a-405d-b7f4-94b7f6bbb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-1e88e495-35e2-4bfb-81a4-01cea6b16da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-0f7667b8-d892-4940-8f87-80f776f72acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-9efb78ad-8149-49df-8c35-c74b2a5f6440,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8ed538dc-6a98-45c3-9188-6680474bad91,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-bbf5c5b1-3c31-43f3-b5e4-ec516dbe95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-5be092e7-0c2d-4ae0-b141-c128e5d49e14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934568687-172.17.0.6-1598685285719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-c9a4e15b-abeb-4266-81fb-d1fba987804d,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-1f052e00-185a-405d-b7f4-94b7f6bbb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-1e88e495-35e2-4bfb-81a4-01cea6b16da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-0f7667b8-d892-4940-8f87-80f776f72acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-9efb78ad-8149-49df-8c35-c74b2a5f6440,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-8ed538dc-6a98-45c3-9188-6680474bad91,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-bbf5c5b1-3c31-43f3-b5e4-ec516dbe95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-5be092e7-0c2d-4ae0-b141-c128e5d49e14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072642614-172.17.0.6-1598685362288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37196,DS-d87d130e-aa8f-4745-8a51-1aa38e770fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-25ab8fa0-903a-435e-b7ec-3ef4ef4a00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-66586ca0-57b0-4751-813e-3e238c04ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7e895f20-3583-46e0-869a-7f7ddbb1a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5a9acdc9-dc2c-41aa-83a5-855444acf33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-c6815ce7-e8d1-4af0-a5e5-280b8310c715,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-b03443bb-aaf8-4550-ace6-2d2d2608ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-8a9aab7a-464a-48dd-84b8-1a41430e0c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072642614-172.17.0.6-1598685362288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37196,DS-d87d130e-aa8f-4745-8a51-1aa38e770fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-25ab8fa0-903a-435e-b7ec-3ef4ef4a00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-66586ca0-57b0-4751-813e-3e238c04ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7e895f20-3583-46e0-869a-7f7ddbb1a934,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5a9acdc9-dc2c-41aa-83a5-855444acf33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-c6815ce7-e8d1-4af0-a5e5-280b8310c715,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-b03443bb-aaf8-4550-ace6-2d2d2608ef02,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-8a9aab7a-464a-48dd-84b8-1a41430e0c1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246619315-172.17.0.6-1598685550970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-34a64ffc-f0bf-47c8-988f-a8a91649a854,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-42a8f622-b39a-4852-a855-877c1ea51bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-fdc21cef-2ca0-4dba-8a2f-4a118966d562,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-6968b9cd-186b-46b1-9c6f-8d39292c3ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-80a2a66b-9485-4dfd-996f-b70244947474,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-6b772a88-78ef-46f1-9c30-3e2d59f60107,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-b649d07a-4bba-493b-ad45-96973241cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-12223872-57bc-4e57-ab35-929318f0634f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246619315-172.17.0.6-1598685550970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-34a64ffc-f0bf-47c8-988f-a8a91649a854,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-42a8f622-b39a-4852-a855-877c1ea51bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-fdc21cef-2ca0-4dba-8a2f-4a118966d562,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-6968b9cd-186b-46b1-9c6f-8d39292c3ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-80a2a66b-9485-4dfd-996f-b70244947474,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-6b772a88-78ef-46f1-9c30-3e2d59f60107,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-b649d07a-4bba-493b-ad45-96973241cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-12223872-57bc-4e57-ab35-929318f0634f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 28 out of 50
result: false positive !!!
Total execution time in seconds : 5627
