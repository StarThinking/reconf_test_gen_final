reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696053924-172.17.0.4-1598650173067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-9c472e8c-bd6f-46cb-92cc-1f18e487daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5790dca3-7fd6-4856-9e25-9cc8246e77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-42013df0-af3e-4eb6-aaa9-a198257fd93f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-34a535f8-84c1-4088-94d3-c0d58cc43edd,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-854d0c5a-f930-4c88-bcf4-e40993e2457f,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-f3156775-9048-4f0f-8622-898a93037e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-9f67dec9-fb8b-4bd4-8a15-b741de310261,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-684a7a8c-9418-489c-8b0a-2b184258f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696053924-172.17.0.4-1598650173067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-9c472e8c-bd6f-46cb-92cc-1f18e487daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5790dca3-7fd6-4856-9e25-9cc8246e77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-42013df0-af3e-4eb6-aaa9-a198257fd93f,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-34a535f8-84c1-4088-94d3-c0d58cc43edd,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-854d0c5a-f930-4c88-bcf4-e40993e2457f,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-f3156775-9048-4f0f-8622-898a93037e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-9f67dec9-fb8b-4bd4-8a15-b741de310261,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-684a7a8c-9418-489c-8b0a-2b184258f520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377616579-172.17.0.4-1598650824636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-91af20fc-c1c8-4a16-9f1e-97ce7e5a0fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-c45f4d65-932c-4ec5-8737-78275b20f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-f81e7757-2496-4697-8786-52dcdfd9a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-ce133df9-6cd3-476d-80b6-cbc01abe9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-fc8da0f5-d229-4193-92a3-60f617e787cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-d65824fb-6459-48e6-991f-3bb78072a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a2ee4350-16ca-4483-8122-a858cfca8236,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c8568911-0065-4634-ae54-51c1397692bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377616579-172.17.0.4-1598650824636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-91af20fc-c1c8-4a16-9f1e-97ce7e5a0fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-c45f4d65-932c-4ec5-8737-78275b20f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-f81e7757-2496-4697-8786-52dcdfd9a3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-ce133df9-6cd3-476d-80b6-cbc01abe9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-fc8da0f5-d229-4193-92a3-60f617e787cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-d65824fb-6459-48e6-991f-3bb78072a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-a2ee4350-16ca-4483-8122-a858cfca8236,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c8568911-0065-4634-ae54-51c1397692bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305618841-172.17.0.4-1598650863550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-32cf4343-c6c5-4c4b-b366-e1a966208f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-2ca03663-8335-4370-8d8a-2c189c1cee46,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-229f6032-2940-4461-9e1b-3386b2ee9473,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-128d5244-9d7b-46c0-936a-79644ce8ea79,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e8496c2b-2cae-4cfa-b369-7896c3a074cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-685573e2-941e-4f00-abff-7552ee33f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-9c427ab5-c35d-4eee-85c6-2cc992b70f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-73131459-232a-4396-9fc6-1f8fa94b2c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305618841-172.17.0.4-1598650863550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43629,DS-32cf4343-c6c5-4c4b-b366-e1a966208f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-2ca03663-8335-4370-8d8a-2c189c1cee46,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-229f6032-2940-4461-9e1b-3386b2ee9473,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-128d5244-9d7b-46c0-936a-79644ce8ea79,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e8496c2b-2cae-4cfa-b369-7896c3a074cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-685573e2-941e-4f00-abff-7552ee33f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-9c427ab5-c35d-4eee-85c6-2cc992b70f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-73131459-232a-4396-9fc6-1f8fa94b2c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303650567-172.17.0.4-1598650896559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39134,DS-8de663e1-548d-4659-a4aa-422de948a709,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-8903c553-c7cf-4d32-88e5-ba220515e297,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-caeb829d-76a8-48c4-b35f-c484c0a5b691,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-be1e31c7-2db1-4f7d-b757-396569ceaf33,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-b8aa014c-1c4b-4f3a-9383-82c04ff12439,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-b555ef91-f184-422d-ab44-da1798066606,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-a6728a99-d669-4ea0-8555-f7f5e3ce377a,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-039333b4-8ddd-46b0-965a-9c51f6c3b2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303650567-172.17.0.4-1598650896559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39134,DS-8de663e1-548d-4659-a4aa-422de948a709,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-8903c553-c7cf-4d32-88e5-ba220515e297,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-caeb829d-76a8-48c4-b35f-c484c0a5b691,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-be1e31c7-2db1-4f7d-b757-396569ceaf33,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-b8aa014c-1c4b-4f3a-9383-82c04ff12439,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-b555ef91-f184-422d-ab44-da1798066606,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-a6728a99-d669-4ea0-8555-f7f5e3ce377a,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-039333b4-8ddd-46b0-965a-9c51f6c3b2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327243454-172.17.0.4-1598651080905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-81d69ad5-b18b-426d-a895-e662ee5e858b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-c1fa855a-247c-4252-9e39-ef189fbf9dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-d8805c75-0b87-4f6b-ae13-4b0a416a2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-b6b7fd00-e0ae-4fc1-bcf3-1f626f94b105,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-4b30d6bb-eaf0-497e-b138-5d9d7043b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-81eafbd2-39d4-4916-9167-84703d3e8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-37164dd0-925d-4e9a-bd73-c34fc8e818c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-0dc9284e-0cd2-4e21-ba4d-43956ca433eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327243454-172.17.0.4-1598651080905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-81d69ad5-b18b-426d-a895-e662ee5e858b,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-c1fa855a-247c-4252-9e39-ef189fbf9dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-d8805c75-0b87-4f6b-ae13-4b0a416a2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-b6b7fd00-e0ae-4fc1-bcf3-1f626f94b105,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-4b30d6bb-eaf0-497e-b138-5d9d7043b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-81eafbd2-39d4-4916-9167-84703d3e8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-37164dd0-925d-4e9a-bd73-c34fc8e818c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-0dc9284e-0cd2-4e21-ba4d-43956ca433eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840157092-172.17.0.4-1598651453210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-75e97482-d26e-4277-aeca-42537b0afb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-d47d45f0-2bf9-4947-8c7c-41d4ceb638f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7b89b9c3-187c-49b2-92fc-1af4d4bb1173,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-ea718657-4977-4137-8ac8-815ed1ee697d,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-fad06054-041b-48b0-898c-4a9c85675296,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-debf0b71-02c1-4b0a-815d-75b327a61fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-90d022b7-347f-4725-af1f-76ad9fb404a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e988ad21-398c-40e7-af60-e717490df634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840157092-172.17.0.4-1598651453210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-75e97482-d26e-4277-aeca-42537b0afb12,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-d47d45f0-2bf9-4947-8c7c-41d4ceb638f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7b89b9c3-187c-49b2-92fc-1af4d4bb1173,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-ea718657-4977-4137-8ac8-815ed1ee697d,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-fad06054-041b-48b0-898c-4a9c85675296,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-debf0b71-02c1-4b0a-815d-75b327a61fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-90d022b7-347f-4725-af1f-76ad9fb404a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e988ad21-398c-40e7-af60-e717490df634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232071957-172.17.0.4-1598651749941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-dc10c8cb-513e-46d4-b8b0-f3de06ef2e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-bfce813f-9dd2-4f3f-ad7a-1cde21765804,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-714a39a8-5df6-46e3-8933-3aaab2f665d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-d83ff74d-09a4-4a91-9565-c0e643ed9f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-9a0fee71-c528-4b27-8285-afde3e998d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-56accb53-eb56-4a25-97ac-81a23d059a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ecae338d-7d00-496b-84b2-d6e4177c76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-5c7f3eeb-1500-492d-953a-050fc1e8286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232071957-172.17.0.4-1598651749941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-dc10c8cb-513e-46d4-b8b0-f3de06ef2e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-bfce813f-9dd2-4f3f-ad7a-1cde21765804,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-714a39a8-5df6-46e3-8933-3aaab2f665d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-d83ff74d-09a4-4a91-9565-c0e643ed9f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-9a0fee71-c528-4b27-8285-afde3e998d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-56accb53-eb56-4a25-97ac-81a23d059a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ecae338d-7d00-496b-84b2-d6e4177c76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-5c7f3eeb-1500-492d-953a-050fc1e8286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144809955-172.17.0.4-1598651850851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-208646aa-6c8f-4a45-a755-3e6a4e8c6fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-0e7e55fd-689c-4a94-80cb-8c65917d5492,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-2c0c5cb4-22e3-48c4-ba95-19b0294c06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-9a572a26-05f7-43d7-93e2-a64847b11afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-8ace151f-073c-461c-9e45-c0542e0449a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-2764d5ca-ceca-4f0e-bbed-4e09f67b4a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-3ed7d6b9-f044-4650-a8ec-1f3ed594869e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-7da07c99-2928-4897-b938-8a89dccc562e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144809955-172.17.0.4-1598651850851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-208646aa-6c8f-4a45-a755-3e6a4e8c6fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-0e7e55fd-689c-4a94-80cb-8c65917d5492,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-2c0c5cb4-22e3-48c4-ba95-19b0294c06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-9a572a26-05f7-43d7-93e2-a64847b11afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-8ace151f-073c-461c-9e45-c0542e0449a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-2764d5ca-ceca-4f0e-bbed-4e09f67b4a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-3ed7d6b9-f044-4650-a8ec-1f3ed594869e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-7da07c99-2928-4897-b938-8a89dccc562e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925339465-172.17.0.4-1598651886489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-5ffdc973-78a2-426b-81df-4b15936f97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-8084be5f-4300-4d87-b6b7-8c8367a9e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ae37f5bf-e043-4cda-8300-a794b211d822,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ba2ec04f-5004-4136-9bbe-ba6831849631,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-ccde1b17-35cf-4dcb-80b5-ef58b30339af,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-2012a8b5-ba70-47c6-998f-b569a38c6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-23ac8d58-66eb-4880-b009-fe17fa929e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-fceb7389-1c2a-48f5-968f-a89676c0300f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-925339465-172.17.0.4-1598651886489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-5ffdc973-78a2-426b-81df-4b15936f97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-8084be5f-4300-4d87-b6b7-8c8367a9e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ae37f5bf-e043-4cda-8300-a794b211d822,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ba2ec04f-5004-4136-9bbe-ba6831849631,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-ccde1b17-35cf-4dcb-80b5-ef58b30339af,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-2012a8b5-ba70-47c6-998f-b569a38c6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-23ac8d58-66eb-4880-b009-fe17fa929e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-fceb7389-1c2a-48f5-968f-a89676c0300f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825007338-172.17.0.4-1598652045851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-4e23756f-e188-4010-a7d2-0e9e406d8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-c03892ad-87e9-453f-8b31-6baa3868c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-461c740d-c0b6-447a-801a-7d29809680b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-3244328d-7bc6-4f5b-a05b-66f10df7b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-a8624af0-fc69-4ac7-b401-65d0b7e966a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-cf0994fe-2c22-4cf5-81f4-eb7a58de1868,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3c276a42-5fe8-492f-8d4b-c4dec2a4a0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-0f1d4b89-b642-4400-9cc1-585e02503093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825007338-172.17.0.4-1598652045851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-4e23756f-e188-4010-a7d2-0e9e406d8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-c03892ad-87e9-453f-8b31-6baa3868c7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-461c740d-c0b6-447a-801a-7d29809680b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-3244328d-7bc6-4f5b-a05b-66f10df7b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-a8624af0-fc69-4ac7-b401-65d0b7e966a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-cf0994fe-2c22-4cf5-81f4-eb7a58de1868,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3c276a42-5fe8-492f-8d4b-c4dec2a4a0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-0f1d4b89-b642-4400-9cc1-585e02503093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761675009-172.17.0.4-1598652104950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-ec714e2e-f782-46fb-b87c-b94c93f1b4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-272bc671-e8aa-4c12-b760-cc70e0487499,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-fd0f0eaf-5635-4ca8-9c55-fca5e04bc31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-2481c1d4-486d-48f4-bda8-1a60232a761d,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-00b518fa-fd97-43b2-9de6-aa0712586066,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-f8ff2745-1f31-4d27-b251-f815da58de86,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-bb7a4a6f-01ca-4b75-b857-7fcabd447494,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-86173c0b-c9a2-4f03-bf4f-89ee0e2423fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761675009-172.17.0.4-1598652104950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-ec714e2e-f782-46fb-b87c-b94c93f1b4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-272bc671-e8aa-4c12-b760-cc70e0487499,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-fd0f0eaf-5635-4ca8-9c55-fca5e04bc31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-2481c1d4-486d-48f4-bda8-1a60232a761d,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-00b518fa-fd97-43b2-9de6-aa0712586066,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-f8ff2745-1f31-4d27-b251-f815da58de86,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-bb7a4a6f-01ca-4b75-b857-7fcabd447494,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-86173c0b-c9a2-4f03-bf4f-89ee0e2423fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718774747-172.17.0.4-1598652305823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-cecfe3e6-fc87-4329-a474-c04200cf6982,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-89f1cd12-7adf-49a1-85dd-880d02ad9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-edcb6307-7183-46bf-9417-eaa92114ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-d87ea030-e75d-44f1-a165-ef640056a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-a563c2a9-b9ab-4678-8b6c-d442e7a53cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c76a69cb-e323-4654-a03a-136342c2d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-d45a84a3-b3e2-49b9-a83b-729f02c6813e,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-6a249131-738d-48f4-b228-d2f3943a7516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718774747-172.17.0.4-1598652305823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-cecfe3e6-fc87-4329-a474-c04200cf6982,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-89f1cd12-7adf-49a1-85dd-880d02ad9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-edcb6307-7183-46bf-9417-eaa92114ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-d87ea030-e75d-44f1-a165-ef640056a2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-a563c2a9-b9ab-4678-8b6c-d442e7a53cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-c76a69cb-e323-4654-a03a-136342c2d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-d45a84a3-b3e2-49b9-a83b-729f02c6813e,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-6a249131-738d-48f4-b228-d2f3943a7516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175498431-172.17.0.4-1598652871550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-8cf06f9f-9ec6-4dfc-b391-5858ef4b4081,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-e689035c-3a19-4fb2-9918-39144b9002ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-90f8964e-687b-40f4-b69a-69ff749df7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-76215f3d-7fec-40a3-84e1-9359ca7e6529,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-9b8388bf-7a17-4594-aab6-2d4b0f66d711,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-58dc1d46-1969-486b-b409-8c36dfcb1a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-52cb2692-dcaa-4286-8370-8735a0eb2b76,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-484b524e-147d-4339-b0bb-8f0cd409ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175498431-172.17.0.4-1598652871550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38463,DS-8cf06f9f-9ec6-4dfc-b391-5858ef4b4081,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-e689035c-3a19-4fb2-9918-39144b9002ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-90f8964e-687b-40f4-b69a-69ff749df7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-76215f3d-7fec-40a3-84e1-9359ca7e6529,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-9b8388bf-7a17-4594-aab6-2d4b0f66d711,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-58dc1d46-1969-486b-b409-8c36dfcb1a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-52cb2692-dcaa-4286-8370-8735a0eb2b76,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-484b524e-147d-4339-b0bb-8f0cd409ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127613751-172.17.0.4-1598652903967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-29a65746-9806-4b98-90c2-e6e4f2fa8627,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-756b0d53-716f-46be-b899-69d9a906c20f,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-93020889-ca52-485e-a33a-f7bd64fdd038,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-1dd8d56a-6a38-42ce-aef7-02a769f3613a,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-9e69f075-4614-4b35-9ad2-415a9817ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-60541649-8d71-46ff-9dc7-a887a99c3390,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-5ff818d3-4095-4e93-8088-4e5eb99ba86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-803af3fe-7ca5-4b9e-939b-39e0c95ee1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127613751-172.17.0.4-1598652903967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39014,DS-29a65746-9806-4b98-90c2-e6e4f2fa8627,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-756b0d53-716f-46be-b899-69d9a906c20f,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-93020889-ca52-485e-a33a-f7bd64fdd038,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-1dd8d56a-6a38-42ce-aef7-02a769f3613a,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-9e69f075-4614-4b35-9ad2-415a9817ddf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-60541649-8d71-46ff-9dc7-a887a99c3390,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-5ff818d3-4095-4e93-8088-4e5eb99ba86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-803af3fe-7ca5-4b9e-939b-39e0c95ee1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399537331-172.17.0.4-1598654037334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-f059639b-4360-42ae-9011-38b513fd1c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-679c557f-d847-4df4-a483-cc1c24175f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-b468dfed-e5dc-4da8-9081-6b92ceb95ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3c53654c-b7b9-4c40-9b05-f2cc6907d470,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-651cbfa0-4782-42a0-a7fe-2f2a794121f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-205bfdcb-c81a-42a9-ab4c-87cb4655afc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-4234bec3-3616-4e2f-8524-bae895f8ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-98a13ae2-b9d6-4ae5-94b5-9b2ea1c2b84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399537331-172.17.0.4-1598654037334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35951,DS-f059639b-4360-42ae-9011-38b513fd1c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-679c557f-d847-4df4-a483-cc1c24175f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-b468dfed-e5dc-4da8-9081-6b92ceb95ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-3c53654c-b7b9-4c40-9b05-f2cc6907d470,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-651cbfa0-4782-42a0-a7fe-2f2a794121f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-205bfdcb-c81a-42a9-ab4c-87cb4655afc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-4234bec3-3616-4e2f-8524-bae895f8ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-98a13ae2-b9d6-4ae5-94b5-9b2ea1c2b84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535285137-172.17.0.4-1598654211428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-d8f4493d-0d1c-4ca1-8b58-00624ada0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-c421e1eb-c15d-4221-9682-1d8ef190fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7012cdcc-d4eb-4471-9e94-3888a8e48990,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-19998470-47aa-44ec-8363-5ebaa103bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-b6f0a64e-f6f3-4b64-bc2d-ca29ebdc3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-8fff87ee-4c93-4d0c-b490-4763e7a11fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-96b47b9e-90ec-4159-89c9-d0b6f78fa0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-371a1444-79e2-4a58-bbe4-cdb40e0d8828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1535285137-172.17.0.4-1598654211428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44491,DS-d8f4493d-0d1c-4ca1-8b58-00624ada0e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-c421e1eb-c15d-4221-9682-1d8ef190fb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7012cdcc-d4eb-4471-9e94-3888a8e48990,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-19998470-47aa-44ec-8363-5ebaa103bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-b6f0a64e-f6f3-4b64-bc2d-ca29ebdc3e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-8fff87ee-4c93-4d0c-b490-4763e7a11fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-96b47b9e-90ec-4159-89c9-d0b6f78fa0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-371a1444-79e2-4a58-bbe4-cdb40e0d8828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146084359-172.17.0.4-1598654371538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-74c73fd4-6c8e-43f8-8959-79add437257c,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-f54b78ea-5e41-430b-8a4d-fbc2efc7d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4b558b6a-10bb-4ed0-acc8-5baf0d2fbc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-d730b025-bbe4-4f3c-9b48-76e87b369430,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-4240a891-0952-4585-822a-2459c525f423,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-3aeb1c5a-7c13-47af-ae16-82e767d5c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-df9323ad-25c1-4590-aec4-21446faac915,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-2f00b881-1c48-43d0-b505-8a85d3558079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146084359-172.17.0.4-1598654371538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-74c73fd4-6c8e-43f8-8959-79add437257c,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-f54b78ea-5e41-430b-8a4d-fbc2efc7d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-4b558b6a-10bb-4ed0-acc8-5baf0d2fbc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-d730b025-bbe4-4f3c-9b48-76e87b369430,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-4240a891-0952-4585-822a-2459c525f423,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-3aeb1c5a-7c13-47af-ae16-82e767d5c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-df9323ad-25c1-4590-aec4-21446faac915,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-2f00b881-1c48-43d0-b505-8a85d3558079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218193314-172.17.0.4-1598654401999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42911,DS-ce75ce57-ca37-46dc-b0f1-f9ef3f355702,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-ae13d3f4-5384-4854-8d62-d17b734d2d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-4f1c792f-a65b-41ec-89dd-28ef5888a765,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-424c15e0-6f49-4b49-8e0c-bd82f3bd3070,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9ee77a04-dad1-42b7-9503-869501c262d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-a9eb4158-f954-4707-9a86-4949c0392ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-349bab41-f1f7-475e-b345-46604315b208,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-1756c601-b0c8-4638-968e-715a986af54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218193314-172.17.0.4-1598654401999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42911,DS-ce75ce57-ca37-46dc-b0f1-f9ef3f355702,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-ae13d3f4-5384-4854-8d62-d17b734d2d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-4f1c792f-a65b-41ec-89dd-28ef5888a765,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-424c15e0-6f49-4b49-8e0c-bd82f3bd3070,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9ee77a04-dad1-42b7-9503-869501c262d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-a9eb4158-f954-4707-9a86-4949c0392ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-349bab41-f1f7-475e-b345-46604315b208,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-1756c601-b0c8-4638-968e-715a986af54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732809249-172.17.0.4-1598654430248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-ff6edde3-80bd-467d-8fe2-27cd7aec7ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-54b402a5-74d0-49c6-8f97-cb1d0cc42c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-39855869-b492-498a-b08b-5a5c7add70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-a02259d6-ba90-404f-9a3d-3a59e9abb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e8a09bea-c1a0-402d-9807-4b560b38c000,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-7fc6de95-1fb1-415a-962b-7c40627338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e1bf3d28-ae98-46a5-8e21-b89b0f95ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-fee2dd9e-d31f-4659-b5df-570642fb782f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732809249-172.17.0.4-1598654430248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45552,DS-ff6edde3-80bd-467d-8fe2-27cd7aec7ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-54b402a5-74d0-49c6-8f97-cb1d0cc42c65,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-39855869-b492-498a-b08b-5a5c7add70fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-a02259d6-ba90-404f-9a3d-3a59e9abb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e8a09bea-c1a0-402d-9807-4b560b38c000,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-7fc6de95-1fb1-415a-962b-7c40627338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e1bf3d28-ae98-46a5-8e21-b89b0f95ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-fee2dd9e-d31f-4659-b5df-570642fb782f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761866439-172.17.0.4-1598654540060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-9b72ddbe-b583-409d-ad78-8ab25a929777,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-941a245f-4573-4a0a-aeea-80867e41e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-2c374159-6404-43c5-b961-fcbfcace74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-14c0af34-89c2-47e4-b688-bb1139603ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-5ffdc14f-16c8-4280-a45f-e96238f19165,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6505f798-b286-4f09-9078-f89a4f9222e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-cb304444-3d29-4297-8bc3-7e884474c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-30496a63-9af9-4202-97a1-07ebf192fb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761866439-172.17.0.4-1598654540060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-9b72ddbe-b583-409d-ad78-8ab25a929777,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-941a245f-4573-4a0a-aeea-80867e41e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-2c374159-6404-43c5-b961-fcbfcace74fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-14c0af34-89c2-47e4-b688-bb1139603ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-5ffdc14f-16c8-4280-a45f-e96238f19165,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6505f798-b286-4f09-9078-f89a4f9222e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-cb304444-3d29-4297-8bc3-7e884474c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-30496a63-9af9-4202-97a1-07ebf192fb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118413131-172.17.0.4-1598654618504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-19a591d6-1435-4c56-8364-4fc0aa539674,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1828d94b-f4d0-4aec-8f10-66f53bac891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-b2e61763-a2b4-4a16-a43d-38d5fcc1e477,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-f95ed350-960d-4004-9d4c-8ec522b0304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-20a8c6be-fbbe-493d-86ee-adeb6bacff89,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-5d097638-1440-424c-b3eb-34ac97a4c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-86b89bc4-c87a-46c6-94b8-fb573cd62828,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-af0a8b2f-6d43-4e04-888b-05343fa7bc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118413131-172.17.0.4-1598654618504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-19a591d6-1435-4c56-8364-4fc0aa539674,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1828d94b-f4d0-4aec-8f10-66f53bac891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-b2e61763-a2b4-4a16-a43d-38d5fcc1e477,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-f95ed350-960d-4004-9d4c-8ec522b0304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-20a8c6be-fbbe-493d-86ee-adeb6bacff89,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-5d097638-1440-424c-b3eb-34ac97a4c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-86b89bc4-c87a-46c6-94b8-fb573cd62828,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-af0a8b2f-6d43-4e04-888b-05343fa7bc4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4835
