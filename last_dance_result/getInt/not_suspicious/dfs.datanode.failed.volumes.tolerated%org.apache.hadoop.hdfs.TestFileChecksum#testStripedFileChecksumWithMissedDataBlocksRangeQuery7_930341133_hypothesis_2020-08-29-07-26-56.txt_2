reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900432247-172.17.0.4-1598686382167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-5a6a9303-c477-4114-bdaf-f629abf4fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-c4e831fb-e2e2-46ca-8dea-8ed1f43a3db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-70e36d4d-5c92-4b89-bb9c-af27017ca360,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-a8ee16a8-d39f-4977-8cc8-901c23c7c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-74ebe5e4-0bae-4e24-8eaa-458543fdaece,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-1d265e82-94cf-4167-aabd-6a9b4297b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-6f08b261-92c0-4cc4-bf08-0a1509b989a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-658eb96b-0663-4fa8-8405-5899ed6036e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900432247-172.17.0.4-1598686382167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-5a6a9303-c477-4114-bdaf-f629abf4fa29,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-c4e831fb-e2e2-46ca-8dea-8ed1f43a3db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-70e36d4d-5c92-4b89-bb9c-af27017ca360,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-a8ee16a8-d39f-4977-8cc8-901c23c7c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-74ebe5e4-0bae-4e24-8eaa-458543fdaece,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-1d265e82-94cf-4167-aabd-6a9b4297b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-6f08b261-92c0-4cc4-bf08-0a1509b989a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-658eb96b-0663-4fa8-8405-5899ed6036e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426221649-172.17.0.4-1598686537593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-9c53cd24-2650-4e03-98ec-6ca77d3e844e,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3495ae27-3e53-4637-8cc5-fd45435ccfef,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-48a7b481-1e9a-4a43-bb21-a1ba9c942a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-40d235bc-3c6f-4855-9fbb-ab4f0014c103,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-08688fef-0b7b-429c-82fc-2b3f479d8918,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-aaacc171-cfbf-42c2-892d-e6e11e912a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-0c1c8b85-357e-40a8-aa40-30c19af6408c,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-9eee0c0e-a0b0-46f7-8ff0-d0d5f19f1464,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426221649-172.17.0.4-1598686537593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-9c53cd24-2650-4e03-98ec-6ca77d3e844e,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-3495ae27-3e53-4637-8cc5-fd45435ccfef,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-48a7b481-1e9a-4a43-bb21-a1ba9c942a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-40d235bc-3c6f-4855-9fbb-ab4f0014c103,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-08688fef-0b7b-429c-82fc-2b3f479d8918,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-aaacc171-cfbf-42c2-892d-e6e11e912a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-0c1c8b85-357e-40a8-aa40-30c19af6408c,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-9eee0c0e-a0b0-46f7-8ff0-d0d5f19f1464,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646233910-172.17.0.4-1598686618882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-50744b88-1e79-42d0-b765-f3d771903ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-459987bf-6b3b-441a-8569-13e5099170ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5971bcae-436b-4dc6-853c-5fe370b87f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-a1d1552b-f2f7-4703-906e-5da228490f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-6e18f954-b902-4b1f-9605-0b6773bcc25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-bbf85c9d-16cd-43d8-bd6c-60dc761b2751,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-44bffb14-f589-4773-922e-d63fd3078c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-894a0596-eded-4e0d-b651-0f1907e7c56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646233910-172.17.0.4-1598686618882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38705,DS-50744b88-1e79-42d0-b765-f3d771903ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-459987bf-6b3b-441a-8569-13e5099170ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5971bcae-436b-4dc6-853c-5fe370b87f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-a1d1552b-f2f7-4703-906e-5da228490f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-6e18f954-b902-4b1f-9605-0b6773bcc25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-bbf85c9d-16cd-43d8-bd6c-60dc761b2751,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-44bffb14-f589-4773-922e-d63fd3078c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-894a0596-eded-4e0d-b651-0f1907e7c56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348352507-172.17.0.4-1598686976580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-3e907d2d-76c6-4131-81f6-748fa6f5d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-39abc1d2-db2b-4858-ba95-e737271fdf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-c3e77b90-9af3-4542-b071-cd7fa21de766,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-2b136b05-a0d8-4b0d-bf30-ea2cda1bc6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-9fb3fa04-9f2b-4632-8f1e-aad4671ac712,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-37e3dc73-4f5c-4b5a-88d6-cf69d5b3ddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-189e02a2-249f-426d-a104-4f5a20f621a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-494e9591-61a4-4c75-a813-52e28cb28f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348352507-172.17.0.4-1598686976580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33782,DS-3e907d2d-76c6-4131-81f6-748fa6f5d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-39abc1d2-db2b-4858-ba95-e737271fdf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-c3e77b90-9af3-4542-b071-cd7fa21de766,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-2b136b05-a0d8-4b0d-bf30-ea2cda1bc6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-9fb3fa04-9f2b-4632-8f1e-aad4671ac712,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-37e3dc73-4f5c-4b5a-88d6-cf69d5b3ddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-189e02a2-249f-426d-a104-4f5a20f621a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-494e9591-61a4-4c75-a813-52e28cb28f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594281167-172.17.0.4-1598687007236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-484c0885-1125-4965-8985-0e087b71f5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-00f58fed-733e-461f-8c82-0819228ad268,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8deb7118-270c-4416-85e0-569cafab1911,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-c719a233-1cc0-4770-9d80-c2adb70db5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-f7b02940-25dc-4cf5-bd39-1c4c2017121b,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-a65c2262-01a1-4000-b5f2-adb40f0f6628,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-d9d85ba7-0127-42d0-b4ac-77c81ecf55b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2d2df2e2-e145-40f6-b194-582aaff77788,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594281167-172.17.0.4-1598687007236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-484c0885-1125-4965-8985-0e087b71f5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-00f58fed-733e-461f-8c82-0819228ad268,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-8deb7118-270c-4416-85e0-569cafab1911,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-c719a233-1cc0-4770-9d80-c2adb70db5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-f7b02940-25dc-4cf5-bd39-1c4c2017121b,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-a65c2262-01a1-4000-b5f2-adb40f0f6628,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-d9d85ba7-0127-42d0-b4ac-77c81ecf55b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2d2df2e2-e145-40f6-b194-582aaff77788,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092693040-172.17.0.4-1598687204065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-3cce932c-8664-41d7-855a-ea910de81355,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-4d4bdcc1-852b-44bc-a40a-f92dd91f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-57430191-9900-4f9a-9914-724f486c24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e39c64ab-83b9-409b-b74b-8621044682c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cd07fdb5-90e2-4e6d-8120-b6043dbaee75,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-d68194b6-3ed2-4ac9-b804-e9ff04a48d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-63535765-205a-47ba-b112-90075cb2fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-07e37165-6fd7-4f60-96de-dbcca69943d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092693040-172.17.0.4-1598687204065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-3cce932c-8664-41d7-855a-ea910de81355,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-4d4bdcc1-852b-44bc-a40a-f92dd91f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-57430191-9900-4f9a-9914-724f486c24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e39c64ab-83b9-409b-b74b-8621044682c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cd07fdb5-90e2-4e6d-8120-b6043dbaee75,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-d68194b6-3ed2-4ac9-b804-e9ff04a48d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-63535765-205a-47ba-b112-90075cb2fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-07e37165-6fd7-4f60-96de-dbcca69943d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033563203-172.17.0.4-1598687244380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-1fdf057b-470b-49c7-87c6-8a0f25ab222f,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1dc49a5b-6f83-41f6-89bb-0f25ac7bf4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-75734b2b-8125-4f10-95f2-9d95acb25c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-883cca7d-0838-42c6-b876-6196b3029177,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-2b4b9fdf-527f-4719-9db6-1d9358b93d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-867ab2ab-3c26-4807-b60e-4b311288596e,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-2624b376-bac1-4012-92bb-14e5aa9f5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-4590f354-4780-431d-9b77-ba7cee0fe156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033563203-172.17.0.4-1598687244380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-1fdf057b-470b-49c7-87c6-8a0f25ab222f,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-1dc49a5b-6f83-41f6-89bb-0f25ac7bf4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-75734b2b-8125-4f10-95f2-9d95acb25c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-883cca7d-0838-42c6-b876-6196b3029177,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-2b4b9fdf-527f-4719-9db6-1d9358b93d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-867ab2ab-3c26-4807-b60e-4b311288596e,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-2624b376-bac1-4012-92bb-14e5aa9f5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-4590f354-4780-431d-9b77-ba7cee0fe156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984644876-172.17.0.4-1598687396449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-399eed4c-1c8d-497b-b2dc-655e71ad56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-50daa244-f71d-4f23-90dc-95ee452ee1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-70e44160-312b-4539-9b1c-5e47651d7038,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9eed269c-ee04-452a-b940-e91ec381ba2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-ee19ab39-8220-47a2-8522-f8eb6f2f3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-68b454d9-781f-433b-8220-a2f829b4fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-768c0b16-b6bf-4a81-8c7e-dddad44808bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-16a25be4-3e26-4a45-a359-6e53c8f0e5f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984644876-172.17.0.4-1598687396449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-399eed4c-1c8d-497b-b2dc-655e71ad56b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-50daa244-f71d-4f23-90dc-95ee452ee1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-70e44160-312b-4539-9b1c-5e47651d7038,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9eed269c-ee04-452a-b940-e91ec381ba2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-ee19ab39-8220-47a2-8522-f8eb6f2f3df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-68b454d9-781f-433b-8220-a2f829b4fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-768c0b16-b6bf-4a81-8c7e-dddad44808bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-16a25be4-3e26-4a45-a359-6e53c8f0e5f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255857161-172.17.0.4-1598687435626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-6f7c9e1b-4a38-4562-a47a-abcd6ce8f549,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a865b8fa-5c6a-4c9b-a9c1-f1b81a17d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-99889816-578c-4c34-92ef-c4d1daea45b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-058e8505-9c2f-4471-a218-1ca5b25a4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-d8fab16d-09ba-4a25-8c92-23128b9738d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-c29607cd-e5ad-4f00-8579-925127771880,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-6bffddec-42c8-45ea-bfb0-6d1c97fbcefb,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-cd6eb2f0-ef49-4b8e-923a-27c747c25746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255857161-172.17.0.4-1598687435626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-6f7c9e1b-4a38-4562-a47a-abcd6ce8f549,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a865b8fa-5c6a-4c9b-a9c1-f1b81a17d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-99889816-578c-4c34-92ef-c4d1daea45b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-058e8505-9c2f-4471-a218-1ca5b25a4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-d8fab16d-09ba-4a25-8c92-23128b9738d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-c29607cd-e5ad-4f00-8579-925127771880,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-6bffddec-42c8-45ea-bfb0-6d1c97fbcefb,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-cd6eb2f0-ef49-4b8e-923a-27c747c25746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723661861-172.17.0.4-1598687471160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37078,DS-5b0dfc56-b6ea-428a-8a98-b62c05bf8835,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-c6ba6875-e2b9-4131-8cab-38dd53c03d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-67d3dfa5-79f0-4ea7-8fbd-3f77cd71108d,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-2d42bb5c-c133-4b03-b9ce-5b7e6479ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-793623ec-0571-4f4e-b398-7e4633aae15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-1b125804-0360-48a1-8ebd-ad184c914075,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-539ad815-2343-43e8-aa80-07fea8d14d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-ff8de87a-c32b-4a4c-acb5-f6347cc6470b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723661861-172.17.0.4-1598687471160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37078,DS-5b0dfc56-b6ea-428a-8a98-b62c05bf8835,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-c6ba6875-e2b9-4131-8cab-38dd53c03d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-67d3dfa5-79f0-4ea7-8fbd-3f77cd71108d,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-2d42bb5c-c133-4b03-b9ce-5b7e6479ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-793623ec-0571-4f4e-b398-7e4633aae15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-1b125804-0360-48a1-8ebd-ad184c914075,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-539ad815-2343-43e8-aa80-07fea8d14d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-ff8de87a-c32b-4a4c-acb5-f6347cc6470b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172276473-172.17.0.4-1598687518704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-6b8a9d15-cb62-4bc5-83a4-8ca335c16b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-f357f62a-0074-4d5c-b581-67b05edae35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-d44c3fab-3897-4b37-be46-aba231977562,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-44ac195d-ca01-47bf-939d-642595dbd994,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-cab343ad-71ba-4330-9ce1-7d7817d1c850,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4759de0a-d685-419f-bdcc-3fb758439cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-0e8f8e4f-fc49-4ec8-851b-74009d5d4830,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-9c3556b2-0735-4fe9-a423-169b46000eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172276473-172.17.0.4-1598687518704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-6b8a9d15-cb62-4bc5-83a4-8ca335c16b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-f357f62a-0074-4d5c-b581-67b05edae35a,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-d44c3fab-3897-4b37-be46-aba231977562,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-44ac195d-ca01-47bf-939d-642595dbd994,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-cab343ad-71ba-4330-9ce1-7d7817d1c850,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-4759de0a-d685-419f-bdcc-3fb758439cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-0e8f8e4f-fc49-4ec8-851b-74009d5d4830,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-9c3556b2-0735-4fe9-a423-169b46000eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294830998-172.17.0.4-1598687637143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-3674e2c0-d5ff-4fbc-bddd-01e5f0e20ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-d5fb112f-658d-4cd8-aaaa-e8f17832e290,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-e0fd23f4-ffa4-4c3d-9890-6e3023ea0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-517b111a-9e63-474d-977a-46dca427642a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-e087fdf2-5c3b-47cd-9a76-1ca7eff34edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-8e14446b-9ab4-453f-abe6-fd527ba026eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-f835172d-2e77-455f-98af-273c07a8d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-4cf48f02-d6b4-4fed-8502-b5b2da9249f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294830998-172.17.0.4-1598687637143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-3674e2c0-d5ff-4fbc-bddd-01e5f0e20ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-d5fb112f-658d-4cd8-aaaa-e8f17832e290,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-e0fd23f4-ffa4-4c3d-9890-6e3023ea0db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-517b111a-9e63-474d-977a-46dca427642a,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-e087fdf2-5c3b-47cd-9a76-1ca7eff34edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-8e14446b-9ab4-453f-abe6-fd527ba026eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-f835172d-2e77-455f-98af-273c07a8d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-4cf48f02-d6b4-4fed-8502-b5b2da9249f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139835728-172.17.0.4-1598687673371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-55d24fb0-da36-47ed-9cb2-1010f5104337,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-74be8404-373f-4b3e-91ea-a45cd0c25c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-e2935946-953e-4e98-b45a-f46bdf524ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-27528178-e0cd-4c35-bcf7-fe499bca7755,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-d064975e-ec4e-485b-a60f-e133cf583b29,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-3dcc040d-61d8-4557-a262-86d448bf21b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8f72260e-4738-4787-b9f4-652c06dd26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-5f62ce0f-e639-44f8-8713-995de955a6d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139835728-172.17.0.4-1598687673371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-55d24fb0-da36-47ed-9cb2-1010f5104337,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-74be8404-373f-4b3e-91ea-a45cd0c25c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-e2935946-953e-4e98-b45a-f46bdf524ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-27528178-e0cd-4c35-bcf7-fe499bca7755,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-d064975e-ec4e-485b-a60f-e133cf583b29,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-3dcc040d-61d8-4557-a262-86d448bf21b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-8f72260e-4738-4787-b9f4-652c06dd26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-5f62ce0f-e639-44f8-8713-995de955a6d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314739428-172.17.0.4-1598687753443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-dd85a2ab-255c-44d3-b42c-d72841987a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ab815ee3-3b17-48f0-a925-ca7e366b34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-9d30bd2b-553c-4381-b735-02a32ed517f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7e1ce8e9-270c-4e47-aab3-f96055c64568,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-f88a6a9c-6ad9-4e69-ac18-1aa9852ef4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-c6b784c6-cd50-4670-bc81-68617d1aa0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-172255b3-5389-44c8-9c23-cfdd58e706ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-02e9ace0-9745-4739-9742-4f69742e19e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314739428-172.17.0.4-1598687753443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-dd85a2ab-255c-44d3-b42c-d72841987a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ab815ee3-3b17-48f0-a925-ca7e366b34e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-9d30bd2b-553c-4381-b735-02a32ed517f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7e1ce8e9-270c-4e47-aab3-f96055c64568,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-f88a6a9c-6ad9-4e69-ac18-1aa9852ef4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-c6b784c6-cd50-4670-bc81-68617d1aa0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-172255b3-5389-44c8-9c23-cfdd58e706ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-02e9ace0-9745-4739-9742-4f69742e19e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2984624-172.17.0.4-1598687788113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37289,DS-867373f8-50b5-4d5e-8c25-26832a107cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-810f64cc-18a4-4958-a50e-fac00aa38fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-492a6191-85d8-49f1-92ed-fc54aa3ef4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-1c361c02-b07d-4220-b273-5fd4a64a351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-8e916373-f8ba-45dd-baf8-b35ca6fcd895,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-61258101-9f48-444c-addb-9576c6ce6fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0e274bcb-699c-4c83-8f1a-3515e06b56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-322fa69c-89a9-482b-8a5d-bcdd312ef568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2984624-172.17.0.4-1598687788113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37289,DS-867373f8-50b5-4d5e-8c25-26832a107cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-810f64cc-18a4-4958-a50e-fac00aa38fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-492a6191-85d8-49f1-92ed-fc54aa3ef4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-1c361c02-b07d-4220-b273-5fd4a64a351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-8e916373-f8ba-45dd-baf8-b35ca6fcd895,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-61258101-9f48-444c-addb-9576c6ce6fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-0e274bcb-699c-4c83-8f1a-3515e06b56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-322fa69c-89a9-482b-8a5d-bcdd312ef568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789233810-172.17.0.4-1598688117203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-6f2297fd-56c0-4156-a19e-557a651129af,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-5af95643-b4ef-4cbb-9cbb-d2ef3ecbb162,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-d248ae1b-dba2-4c24-accf-b9895c0fbc38,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-fb2ccc27-675e-4701-b7d1-9bcbae4c51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-1f985211-0a92-428c-9671-b8e48953ef90,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-0a9e0488-a61d-4272-9683-9a379eff21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-8f11eb80-cf32-430a-8a70-832f67045ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-ea6676f8-05de-40e4-b7e9-153155b10f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789233810-172.17.0.4-1598688117203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-6f2297fd-56c0-4156-a19e-557a651129af,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-5af95643-b4ef-4cbb-9cbb-d2ef3ecbb162,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-d248ae1b-dba2-4c24-accf-b9895c0fbc38,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-fb2ccc27-675e-4701-b7d1-9bcbae4c51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-1f985211-0a92-428c-9671-b8e48953ef90,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-0a9e0488-a61d-4272-9683-9a379eff21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-8f11eb80-cf32-430a-8a70-832f67045ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-ea6676f8-05de-40e4-b7e9-153155b10f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910587702-172.17.0.4-1598688258098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-ef1de285-0bde-4188-9f3e-33127fe1aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-141fb008-31a6-44b9-8242-b677a7e4f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-f6297fee-c396-4d92-9e48-54f000f76233,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-c6dce839-117a-40b9-9310-f5f17647ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-cf6dcc26-5793-4585-ac39-0ebd88e407a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-fbfd2896-8d59-4dcc-a790-06957e039373,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b130a79a-d544-407c-ad2c-f98fc0780a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-3b51bc86-ee68-4906-8fb3-7ef72bb53c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910587702-172.17.0.4-1598688258098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43595,DS-ef1de285-0bde-4188-9f3e-33127fe1aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-141fb008-31a6-44b9-8242-b677a7e4f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-f6297fee-c396-4d92-9e48-54f000f76233,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-c6dce839-117a-40b9-9310-f5f17647ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-cf6dcc26-5793-4585-ac39-0ebd88e407a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-fbfd2896-8d59-4dcc-a790-06957e039373,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b130a79a-d544-407c-ad2c-f98fc0780a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-3b51bc86-ee68-4906-8fb3-7ef72bb53c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268450205-172.17.0.4-1598688422851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-4bd33a37-fac9-494d-b1b4-07291263ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-95758b26-eb91-44e8-b45e-b893da4a2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-35e0a6f3-7d41-446d-b4cf-cef2545d2a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-b9bf414e-4aad-44d8-9928-1ef8620708df,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-8c77b298-d237-446a-8cdd-343ac70c31cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-77233792-189e-4d8d-9506-64e6c69b19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-f8218eb2-016f-479f-902d-7eb3fc9c7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-150d3577-bacb-4405-9e28-69ffb31b37d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268450205-172.17.0.4-1598688422851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-4bd33a37-fac9-494d-b1b4-07291263ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-95758b26-eb91-44e8-b45e-b893da4a2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-35e0a6f3-7d41-446d-b4cf-cef2545d2a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-b9bf414e-4aad-44d8-9928-1ef8620708df,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-8c77b298-d237-446a-8cdd-343ac70c31cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-77233792-189e-4d8d-9506-64e6c69b19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-f8218eb2-016f-479f-902d-7eb3fc9c7f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-150d3577-bacb-4405-9e28-69ffb31b37d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631870606-172.17.0.4-1598688453888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-f6ae7bcd-5cc3-45fb-8918-b4685f68c896,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-89cd5b84-68d0-4396-97bb-7a778639c022,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-3764c7c3-949c-45d8-a52c-97b1054555f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-7acd7b5e-b0db-48e1-a3d4-a176102e05df,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-1d5e7d8f-2f13-475d-9e2e-2f8348d84b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-ef54f1e5-422f-4da7-8fdb-2ef966eb9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-a1d32619-d49f-4f83-94a2-a2b96fbb927f,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-0401f445-190a-4428-b8bf-fc171ab818fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631870606-172.17.0.4-1598688453888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-f6ae7bcd-5cc3-45fb-8918-b4685f68c896,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-89cd5b84-68d0-4396-97bb-7a778639c022,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-3764c7c3-949c-45d8-a52c-97b1054555f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-7acd7b5e-b0db-48e1-a3d4-a176102e05df,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-1d5e7d8f-2f13-475d-9e2e-2f8348d84b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-ef54f1e5-422f-4da7-8fdb-2ef966eb9adb,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-a1d32619-d49f-4f83-94a2-a2b96fbb927f,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-0401f445-190a-4428-b8bf-fc171ab818fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691738841-172.17.0.4-1598688655237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-117c348c-9794-4e5a-9c22-14f34affb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-af4d21bd-8f0e-4486-a7de-ccde88386e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-36564891-2e51-4fad-b204-a8e6ecb3481c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-ded7be2b-df2e-405b-aebe-2146975860fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-78255692-936a-401a-88f8-57e05091a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-c12b0ae1-7c45-45a4-910b-a3b1c5b464e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-3f090d3f-af4a-4d93-9fc0-d8955a3ae745,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-275b3c6e-80e8-4f7e-8395-c407e47d12c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691738841-172.17.0.4-1598688655237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-117c348c-9794-4e5a-9c22-14f34affb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-af4d21bd-8f0e-4486-a7de-ccde88386e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-36564891-2e51-4fad-b204-a8e6ecb3481c,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-ded7be2b-df2e-405b-aebe-2146975860fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-78255692-936a-401a-88f8-57e05091a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-c12b0ae1-7c45-45a4-910b-a3b1c5b464e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-3f090d3f-af4a-4d93-9fc0-d8955a3ae745,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-275b3c6e-80e8-4f7e-8395-c407e47d12c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121967254-172.17.0.4-1598688876969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-db20f201-676f-465b-8f6e-3a1a857c36a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-3d708e4a-ccc7-4b25-aa56-fe9cdfe1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-f1a02b32-3afa-4cbc-a204-7ec0c3fa7a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d22994e3-0a11-4808-b74d-27e40fd48981,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9ce7ebe8-1940-4d14-8a04-13a2a3e315f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-46266e48-121e-48a4-962b-8d7b5c3233b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-72a7234d-7a5a-4cd8-89ad-254317ea32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-90f762cd-c1f0-4683-9ba4-682df115cf65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121967254-172.17.0.4-1598688876969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-db20f201-676f-465b-8f6e-3a1a857c36a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-3d708e4a-ccc7-4b25-aa56-fe9cdfe1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-f1a02b32-3afa-4cbc-a204-7ec0c3fa7a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-d22994e3-0a11-4808-b74d-27e40fd48981,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9ce7ebe8-1940-4d14-8a04-13a2a3e315f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-46266e48-121e-48a4-962b-8d7b5c3233b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-72a7234d-7a5a-4cd8-89ad-254317ea32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-90f762cd-c1f0-4683-9ba4-682df115cf65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601427948-172.17.0.4-1598688943780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-f0831835-5bde-4e6b-9591-4223856471c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-990929c4-301a-4513-9c72-c430280f37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-e74d0715-42d8-487e-8fad-1a3f3b132e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-24a5ea6e-7cdc-4cdd-8f45-c48e78ac23b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-b2bdb422-f76e-4b10-a20d-b5a01ee8178a,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-68f6104e-c661-46d7-be0d-6e5552c5bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-deece36e-2bd0-45ad-b048-40a01ff205e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-5bed2554-5e16-4642-b7cc-e296b9cb5e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601427948-172.17.0.4-1598688943780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-f0831835-5bde-4e6b-9591-4223856471c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-990929c4-301a-4513-9c72-c430280f37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-e74d0715-42d8-487e-8fad-1a3f3b132e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-24a5ea6e-7cdc-4cdd-8f45-c48e78ac23b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-b2bdb422-f76e-4b10-a20d-b5a01ee8178a,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-68f6104e-c661-46d7-be0d-6e5552c5bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-deece36e-2bd0-45ad-b048-40a01ff205e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-5bed2554-5e16-4642-b7cc-e296b9cb5e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947432817-172.17.0.4-1598690008154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-5fc434a6-98e9-4b28-867e-92cec3eb91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-cd312306-9c05-4808-9bf1-0ab3bc3a5923,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-915149f4-7d76-43da-872a-91049796488a,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-b85b4993-aeb4-4515-9228-dd141b7709c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-dca22f34-d54b-46b2-87a7-3cbc491498e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-b6964478-f1e9-482b-abde-7e4b8ca2030b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-b2b7c43c-4b73-4092-a345-04a10ce73668,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-d1dfb85d-90df-479e-9123-13e7b725cd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947432817-172.17.0.4-1598690008154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-5fc434a6-98e9-4b28-867e-92cec3eb91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-cd312306-9c05-4808-9bf1-0ab3bc3a5923,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-915149f4-7d76-43da-872a-91049796488a,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-b85b4993-aeb4-4515-9228-dd141b7709c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-dca22f34-d54b-46b2-87a7-3cbc491498e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-b6964478-f1e9-482b-abde-7e4b8ca2030b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-b2b7c43c-4b73-4092-a345-04a10ce73668,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-d1dfb85d-90df-479e-9123-13e7b725cd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134058542-172.17.0.4-1598690042320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-71321295-9320-4e8b-91d8-e70710991591,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-098a5f04-05bb-4436-8d4c-b65e1b7e6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-34822bdc-548a-43a8-88de-04967b80c677,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-6ba2d0ae-5504-4779-a674-9727656fdc96,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ff9d0901-99b0-4d47-9881-14499c55cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-f75d9ffe-0ced-4106-ab9e-d7e4b3aa37f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-edd0d90b-4f98-4f92-bb35-f47678b4a129,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-c7b358cb-1264-4335-99d9-a849392e65dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134058542-172.17.0.4-1598690042320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-71321295-9320-4e8b-91d8-e70710991591,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-098a5f04-05bb-4436-8d4c-b65e1b7e6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-34822bdc-548a-43a8-88de-04967b80c677,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-6ba2d0ae-5504-4779-a674-9727656fdc96,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-ff9d0901-99b0-4d47-9881-14499c55cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-f75d9ffe-0ced-4106-ab9e-d7e4b3aa37f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-edd0d90b-4f98-4f92-bb35-f47678b4a129,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-c7b358cb-1264-4335-99d9-a849392e65dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367383895-172.17.0.4-1598690281717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-82b7935d-4d7e-4f90-8ddf-7887b5c41fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1035cf2b-e304-42d1-8d4a-2ec4dcf43531,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-0a0edbf1-9ebe-4d9c-8d41-4849059662c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-8d75bd9b-7791-470f-902a-09da65db28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-fc07c2f5-7207-4902-9c3b-f57a9f5ea86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-3199b01e-09f5-42ac-a03e-5e212a2caa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-29cbcced-357b-4b5d-8477-947f6d01493f,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-b7130df3-0ac8-4699-8983-3f43cf65e115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367383895-172.17.0.4-1598690281717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39207,DS-82b7935d-4d7e-4f90-8ddf-7887b5c41fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1035cf2b-e304-42d1-8d4a-2ec4dcf43531,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-0a0edbf1-9ebe-4d9c-8d41-4849059662c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-8d75bd9b-7791-470f-902a-09da65db28dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-fc07c2f5-7207-4902-9c3b-f57a9f5ea86d,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-3199b01e-09f5-42ac-a03e-5e212a2caa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-29cbcced-357b-4b5d-8477-947f6d01493f,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-b7130df3-0ac8-4699-8983-3f43cf65e115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689428595-172.17.0.4-1598690317356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e41c75c8-ac53-48aa-a1d2-d261f91600ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-f12dc1bf-6582-4607-91cb-74b5550564aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2a330afa-3428-4d23-9c9a-6888453d3d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-d2896159-da7a-4e7b-93b6-7a28938dc787,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-cdaf4b44-d817-4e8b-8afa-db382ac54b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0f99fbb7-3094-441f-9448-5735a1476432,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-cd2ffc84-8b22-4e52-8da0-f37a58e0d596,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-23b96935-b409-4176-b47b-9b41792f4f60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689428595-172.17.0.4-1598690317356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e41c75c8-ac53-48aa-a1d2-d261f91600ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-f12dc1bf-6582-4607-91cb-74b5550564aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2a330afa-3428-4d23-9c9a-6888453d3d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-d2896159-da7a-4e7b-93b6-7a28938dc787,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-cdaf4b44-d817-4e8b-8afa-db382ac54b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0f99fbb7-3094-441f-9448-5735a1476432,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-cd2ffc84-8b22-4e52-8da0-f37a58e0d596,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-23b96935-b409-4176-b47b-9b41792f4f60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111958777-172.17.0.4-1598690424122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-119a89d9-2d5a-4b2a-b8b7-27cb5ea8e502,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-df0c54e5-9784-4bf3-9795-ae9a45f93b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-c74de4b2-9d90-4f7a-8e58-6c963f01e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b8af58f1-bde9-488d-9870-999e9d48ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-e316d262-6c28-4f36-9054-c87cd1a5f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-659d171a-494a-4fc7-b640-527c515b2683,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2d781985-60a8-4491-bcc0-fdb14fb67cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-c64b232d-2b93-4fbc-9409-129a427f54aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111958777-172.17.0.4-1598690424122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-119a89d9-2d5a-4b2a-b8b7-27cb5ea8e502,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-df0c54e5-9784-4bf3-9795-ae9a45f93b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-c74de4b2-9d90-4f7a-8e58-6c963f01e7de,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-b8af58f1-bde9-488d-9870-999e9d48ebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-e316d262-6c28-4f36-9054-c87cd1a5f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-659d171a-494a-4fc7-b640-527c515b2683,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2d781985-60a8-4491-bcc0-fdb14fb67cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-c64b232d-2b93-4fbc-9409-129a427f54aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907791021-172.17.0.4-1598690807299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-fedfe947-3188-4cc9-a3b1-9081b7ea82d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6c47b14c-0443-43cd-8991-58344993f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-55275129-1f5f-4989-b6df-c318a4280107,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-7a79a635-cb9f-45f4-a986-50165fb6a653,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-beed74ca-4699-4a43-89fa-751a03c847a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-76625f19-0e11-4dc7-bde9-c28a0a0ab7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-738d8dd4-571a-4a22-959b-e605570a5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1f6dd2d4-b95d-489e-bee1-579b255d44aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907791021-172.17.0.4-1598690807299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-fedfe947-3188-4cc9-a3b1-9081b7ea82d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6c47b14c-0443-43cd-8991-58344993f41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-55275129-1f5f-4989-b6df-c318a4280107,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-7a79a635-cb9f-45f4-a986-50165fb6a653,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-beed74ca-4699-4a43-89fa-751a03c847a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-76625f19-0e11-4dc7-bde9-c28a0a0ab7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-738d8dd4-571a-4a22-959b-e605570a5feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1f6dd2d4-b95d-489e-bee1-579b255d44aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512202317-172.17.0.4-1598691023297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-7ecaf70a-15e3-4691-96ac-c49359fd0f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-cc140ec9-f459-4d23-8a57-b19a98040285,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-a27bcb3d-67af-4770-8846-b394ba463b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-144c3a9d-7e2e-4ded-ac0c-7369a0a564f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-57e64bb6-2d3b-4ec5-ba00-643829042ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-ee80a42a-96c1-40f8-a088-f411404df114,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-5b125520-62fa-4a0a-9827-7713cf222950,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-41755293-d0e4-4562-b631-761681be83fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512202317-172.17.0.4-1598691023297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-7ecaf70a-15e3-4691-96ac-c49359fd0f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-cc140ec9-f459-4d23-8a57-b19a98040285,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-a27bcb3d-67af-4770-8846-b394ba463b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-144c3a9d-7e2e-4ded-ac0c-7369a0a564f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-57e64bb6-2d3b-4ec5-ba00-643829042ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-ee80a42a-96c1-40f8-a088-f411404df114,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-5b125520-62fa-4a0a-9827-7713cf222950,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-41755293-d0e4-4562-b631-761681be83fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991878252-172.17.0.4-1598691166089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-fd622212-c9d0-47a9-81b7-c93af4703a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-c5daa017-5e22-4252-a760-f08daec37302,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d3c73b32-494d-4910-8dd6-35d334b88e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-31701819-2783-4ebf-9f94-a914ff4cde1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e6997113-d690-49a5-bbef-a7956eb78e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-56a2f13c-d8ff-46e6-9c66-f1b53f9a5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-35a2d2d0-dca6-43f4-81cb-72ca8ea69e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-996b287c-5edb-49cf-b7d3-46f082262524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991878252-172.17.0.4-1598691166089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-fd622212-c9d0-47a9-81b7-c93af4703a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-c5daa017-5e22-4252-a760-f08daec37302,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-d3c73b32-494d-4910-8dd6-35d334b88e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-31701819-2783-4ebf-9f94-a914ff4cde1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e6997113-d690-49a5-bbef-a7956eb78e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-56a2f13c-d8ff-46e6-9c66-f1b53f9a5ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-35a2d2d0-dca6-43f4-81cb-72ca8ea69e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-996b287c-5edb-49cf-b7d3-46f082262524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064080717-172.17.0.4-1598691384968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-308fa38d-b333-4097-b039-af071e916398,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-33974a74-df11-4f0d-a17c-f3fe9f4dbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-b9ece095-8f25-4c41-824e-00730a795e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-8172cf77-52fd-46a5-80ba-99196f9fc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-0d1ca5cd-9499-4b28-b073-73b953350550,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d40fc01c-f486-49fe-8825-9f9c6e7fdaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-308c7a04-10c3-4c88-8c7e-10365300ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-a12c9549-f1a6-4601-9713-e9f8b65f9679,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064080717-172.17.0.4-1598691384968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44881,DS-308fa38d-b333-4097-b039-af071e916398,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-33974a74-df11-4f0d-a17c-f3fe9f4dbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-b9ece095-8f25-4c41-824e-00730a795e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-8172cf77-52fd-46a5-80ba-99196f9fc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-0d1ca5cd-9499-4b28-b073-73b953350550,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d40fc01c-f486-49fe-8825-9f9c6e7fdaef,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-308c7a04-10c3-4c88-8c7e-10365300ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-a12c9549-f1a6-4601-9713-e9f8b65f9679,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5611463-172.17.0.4-1598691421181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-a5c7be4b-ddad-411f-9cf7-ccc1b099bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-7584bf78-69a6-4baf-b847-1822627b7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-968aa33f-5257-4df8-ba19-001e71333300,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-05cd0625-1918-417e-b2d1-f821403edee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-1111ede7-8afb-4657-850a-2ebd40c93d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-566cd131-031e-4d25-823e-f88e5fb65943,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-0693f8d0-589e-4eb9-9197-7c06f7964370,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-f3dcf0f6-73e9-4361-9ae7-e37a54c5f26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5611463-172.17.0.4-1598691421181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-a5c7be4b-ddad-411f-9cf7-ccc1b099bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-7584bf78-69a6-4baf-b847-1822627b7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-968aa33f-5257-4df8-ba19-001e71333300,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-05cd0625-1918-417e-b2d1-f821403edee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-1111ede7-8afb-4657-850a-2ebd40c93d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-566cd131-031e-4d25-823e-f88e5fb65943,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-0693f8d0-589e-4eb9-9197-7c06f7964370,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-f3dcf0f6-73e9-4361-9ae7-e37a54c5f26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5535
